Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.0
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.235910654067993
	train_negative_loss: 2.2804512977600098
	train_positive_acc: 0.6210397876146286
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.06601762026548386
	train_incorrect_loss: nan
	train_positive_loss: 0.06365986913442612
	train_negative_loss: 0.06836418807506561
	train_correct_acc: 0.9777556109725687
	train_incorrect_acc: nan
	train_positive_acc: 0.9865426998588505
	train_negative_acc: 0.9691690757709921
	train_correct_nonzero: 40100
	train_incorrect_nonzero: 0
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.02493702992796898
	val_negative_loss: 0.0017057403456419706
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.013352912850677967
	test_negative_loss: 0.013954664580523968
	test_positive_acc: 0.9948898800153425
	test_negative_acc: 0.9962601359878842
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.005537507124245167
	train_incorrect_loss: nan
	train_positive_loss: 0.005548112094402313
	train_negative_loss: 0.005476000253111124
	train_correct_acc: 0.9980798004987533
	train_incorrect_acc: nan
	train_positive_acc: 0.9979621454571395
	train_negative_acc: 0.9981943585231267
	train_correct_nonzero: 40100
	train_incorrect_nonzero: 0
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.006543243769556284
	val_negative_loss: 0.00023218771093524992
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02275211550295353
	test_negative_loss: 0.014564856886863708
	test_positive_acc: 0.9934017847772472
	test_negative_acc: 0.9948066476157911
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.006850356701761484
	train_incorrect_loss: nan
	train_positive_loss: 0.007020789198577404
	train_negative_loss: 0.006330861710011959
	train_correct_acc: 0.9977556109725686
	train_incorrect_acc: nan
	train_positive_acc: 0.9977915770933604
	train_negative_acc: 0.9978295233844792
	train_correct_nonzero: 40100
	train_incorrect_nonzero: 0
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00034122561919502914
	val_negative_loss: 0.0003577515308279544
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.014482960104942322
	test_negative_loss: 0.029409095644950867
	test_positive_acc: 0.9949094602158437
	test_negative_acc: 0.9921739139606792
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.0010639216052368283
	train_incorrect_loss: nan
	train_positive_loss: 0.000974617840256542
	train_negative_loss: 0.001130724442191422
	train_correct_acc: 0.9996758104738155
	train_incorrect_acc: nan
	train_positive_acc: 0.999696293700259
	train_negative_acc: 0.999665142602836
	train_correct_nonzero: 40100
	train_incorrect_nonzero: 0
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.0647872841218486e-05
	val_negative_loss: 9.100744500756264e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.012823528610169888
	test_negative_loss: 0.06124710291624069
	test_positive_acc: 0.9978441867380315
	test_negative_acc: 0.9895411803055674
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 6.989801477175206e-05
	train_incorrect_loss: nan
	train_positive_loss: 5.436866922536865e-05
	train_negative_loss: 8.403879473917186e-05
	train_correct_acc: 1.0
	train_incorrect_acc: nan
	train_positive_acc: 1.0
	train_negative_acc: 1.0
	train_correct_nonzero: 40100
	train_incorrect_nonzero: 0
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.001391964266076684
	val_negative_loss: 1.2344408787612338e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.022248879075050354
	test_negative_loss: 0.03416023775935173
	test_positive_acc: 0.9937933887872723
	test_negative_acc: 0.9948066476157911
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 2.149020838260185e-05
	train_incorrect_loss: nan
	train_positive_loss: 1.9915765733458102e-05
	train_negative_loss: 2.143165511370171e-05
	train_correct_acc: 1.0
	train_incorrect_acc: nan
	train_positive_acc: 1.0
	train_negative_acc: 1.0
	train_correct_nonzero: 40100
	train_incorrect_nonzero: 0
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0010082302615046501
	val_negative_loss: 9.198145562550053e-06
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02146366983652115
	test_negative_loss: 0.03647701069712639
	test_positive_acc: 0.9948898800153425
	test_negative_acc: 0.9948066476157911
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 1.2616975254786666e-05
	train_incorrect_loss: nan
	train_positive_loss: 1.0729246241680812e-05
	train_negative_loss: 1.3782022506347857e-05
	train_correct_acc: 1.0
	train_incorrect_acc: nan
	train_positive_acc: 1.0
	train_negative_acc: 1.0
	train_correct_nonzero: 40100
	train_incorrect_nonzero: 0
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.001458401558920741
	val_negative_loss: 5.789105671283323e-06
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.023703623563051224
	test_negative_loss: 0.035813093185424805
	test_positive_acc: 0.9948898800153425
	test_negative_acc: 0.9948066476157911
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 8.93001924850978e-06
	train_incorrect_loss: nan
	train_positive_loss: 8.438604709226638e-06
	train_negative_loss: 8.698017154529225e-06
	train_correct_acc: 1.0
	train_incorrect_acc: nan
	train_positive_acc: 1.0
	train_negative_acc: 1.0
	train_correct_nonzero: 40100
	train_incorrect_nonzero: 0
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0009483535541221499
	val_negative_loss: 5.249146397545701e-06
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.022098584100604057
	test_negative_loss: 0.03894449770450592
	test_positive_acc: 0.9948898800153425
	test_negative_acc: 0.9948066476157911
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 6.630258212680928e-06
	train_incorrect_loss: nan
	train_positive_loss: 5.8453115343581885e-06
	train_negative_loss: 6.848783414170612e-06
	train_correct_acc: 1.0
	train_incorrect_acc: nan
	train_positive_acc: 1.0
	train_negative_acc: 1.0
	train_correct_nonzero: 40100
	train_incorrect_nonzero: 0
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0018763007828965783
	val_negative_loss: 2.9664120120287407e-06
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02571454830467701
	test_negative_loss: 0.0366857647895813
	test_positive_acc: 0.9948898800153425
	test_negative_acc: 0.9948066476157911
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 5.081256404082524e-06
	train_incorrect_loss: nan
	train_positive_loss: 4.6216910050134175e-06
	train_negative_loss: 5.0879662012448534e-06
	train_correct_acc: 1.0
	train_incorrect_acc: nan
	train_positive_acc: 1.0
	train_negative_acc: 1.0
	train_correct_nonzero: 40100
	train_incorrect_nonzero: 0
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0008845199481584132
	val_negative_loss: 2.594026454971754e-06
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02438117377460003
	test_negative_loss: 0.03988059610128403
	test_positive_acc: 0.9948898800153425
	test_negative_acc: 0.9948066476157911
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 40.883500814437866 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.025
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2357494831085205
	train_negative_loss: 2.280472755432129
	train_positive_acc: 0.6270972681850142
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.07835467904806137
	train_incorrect_loss: 3.6428040006418816
	train_positive_loss: 0.14787933230400085
	train_negative_loss: 0.09642200917005539
	train_correct_acc: 0.9769785867663965
	train_incorrect_acc: 0.042382588774341354
	train_positive_acc: 0.986796176515794
	train_negative_acc: 0.9437997441773032
	train_correct_nonzero: 39600
	train_incorrect_nonzero: 500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.02382819913327694
	val_negative_loss: 0.034763261675834656
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.014985236339271069
	test_negative_loss: 0.04062400013208389
	test_positive_acc: 0.9917230115730502
	test_negative_acc: 0.9953131662909145
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.01884244754910469
	train_incorrect_loss: 3.3984605087922923
	train_positive_loss: 0.08939959853887558
	train_negative_loss: 0.0313870832324028
	train_correct_acc: 0.997606066653037
	train_incorrect_acc: 0.028067129629629626
	train_positive_acc: 0.9978412531870781
	train_negative_acc: 0.9732789521675151
	train_correct_nonzero: 39600
	train_incorrect_nonzero: 500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0006742979749105871
	val_negative_loss: 0.056499361991882324
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.005330345593392849
	test_negative_loss: 0.10070739686489105
	test_positive_acc: 0.9974154135338346
	test_negative_acc: 0.9774622738609102
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.014780574478209019
	train_incorrect_loss: 2.9564807752996947
	train_positive_loss: 0.07527211308479309
	train_negative_loss: 0.026746448129415512
	train_correct_acc: 0.998534189942204
	train_incorrect_acc: 0.08280701754385965
	train_positive_acc: 0.9988969504674555
	train_negative_acc: 0.9758074349989341
	train_correct_nonzero: 39600
	train_incorrect_nonzero: 500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0008467290317639709
	val_negative_loss: 0.013637268915772438
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.006324154790490866
	test_negative_loss: 0.06306412816047668
	test_positive_acc: 0.9989035087719298
	test_negative_acc: 0.9841899851645015
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.012551205232739449
	train_incorrect_loss: 2.2016273187729363
	train_positive_loss: 0.05617636442184448
	train_negative_loss: 0.0228070467710495
	train_correct_acc: 0.9985861278379431
	train_incorrect_acc: 0.21542553191489358
	train_positive_acc: 0.9991346633277047
	train_negative_acc: 0.9786975002825404
	train_correct_nonzero: 39600
	train_incorrect_nonzero: 500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00010421079787192866
	val_negative_loss: 0.050840213894844055
	val_positive_acc: 1.0
	val_negative_acc: 0.9789827658680117
test:
	test_positive_loss: 0.015149026177823544
	test_negative_loss: 0.04991832375526428
	test_positive_acc: 0.9974154135338346
	test_negative_acc: 0.9951825497809876
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.012266146019101143
	train_incorrect_loss: 1.9702464636472217
	train_positive_loss: 0.04947279021143913
	train_negative_loss: 0.021625928580760956
	train_correct_acc: 0.9980349539148514
	train_incorrect_acc: 0.27580782312925173
	train_positive_acc: 0.9987283099564301
	train_negative_acc: 0.9796155806962906
	train_correct_nonzero: 39600
	train_incorrect_nonzero: 500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0001827980886446312
	val_negative_loss: 0.018636906519532204
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.007867550477385521
	test_negative_loss: 0.0797915980219841
	test_positive_acc: 0.9959273182957393
	test_negative_acc: 0.9816322528390531
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.010803058743476868
	train_incorrect_loss: 1.1902490101798082
	train_positive_loss: 0.032418206334114075
	train_negative_loss: 0.0178813599050045
	train_correct_acc: 0.9979085611945013
	train_incorrect_acc: 0.5529513888888888
	train_positive_acc: 0.9987647745140555
	train_negative_acc: 0.9857522906073316
	train_correct_nonzero: 39600
	train_incorrect_nonzero: 500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.020060980692505836
	val_negative_loss: 0.035679858177900314
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.015849757939577103
	test_negative_loss: 0.10015735775232315
	test_positive_acc: 0.9959273182957393
	test_negative_acc: 0.9718097990712071
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.004558953456580639
	train_incorrect_loss: 0.5950830042002564
	train_positive_loss: 0.013775716535747051
	train_negative_loss: 0.008497530594468117
	train_correct_acc: 0.9989398998238095
	train_incorrect_acc: 0.7395539906103287
	train_positive_acc: 0.999742462238185
	train_negative_acc: 0.9922729782052473
	train_correct_nonzero: 39600
	train_incorrect_nonzero: 500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.054633211344480515
	val_negative_loss: 0.0028169674333184958
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.044879209250211716
	test_negative_loss: 0.02918434329330921
	test_positive_acc: 0.9903470891280488
	test_negative_acc: 0.9901205708428569
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.004410259425640106
	train_incorrect_loss: 0.44655042077089324
	train_positive_loss: 0.01210896484553814
	train_negative_loss: 0.007600575219839811
	train_correct_acc: 0.9989356670119106
	train_incorrect_acc: 0.8353951890034363
	train_positive_acc: 0.9996589207133165
	train_negative_acc: 0.9942425346146794
	train_correct_nonzero: 39600
	train_incorrect_nonzero: 500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.013327798806130886
	val_negative_loss: 0.0030155484564602375
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.035557083785533905
	test_negative_loss: 0.08282911777496338
	test_positive_acc: 0.9929925917735516
	test_negative_acc: 0.9819389728865495
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.0037074005231261253
	train_incorrect_loss: 0.2575612456879337
	train_positive_loss: 0.00805309135466814
	train_negative_loss: 0.005606034304946661
	train_correct_acc: 0.9991141059618709
	train_incorrect_acc: 0.9013111888111889
	train_positive_acc: 0.9996073660981063
	train_negative_acc: 0.9962750125288942
	train_correct_nonzero: 39600
	train_incorrect_nonzero: 500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.033643629401922226
	val_negative_loss: 0.0032633242662996054
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02036231756210327
	test_negative_loss: 0.09615948051214218
	test_positive_acc: 0.9962134904569115
	test_negative_acc: 0.9840008592353992
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.0012995401630178094
	train_incorrect_loss: 0.11594295098161869
	train_positive_loss: 0.0030072247609496117
	train_negative_loss: 0.002495026448741555
	train_correct_acc: 0.9996969174881399
	train_incorrect_acc: 0.9521468926553672
	train_positive_acc: 1.0
	train_negative_acc: 0.9980630766892681
	train_correct_nonzero: 39600
	train_incorrect_nonzero: 500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.023602522909641266
	val_negative_loss: 0.009197227656841278
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02608918398618698
	test_negative_loss: 0.10724753141403198
	test_positive_acc: 0.9959273182957393
	test_negative_acc: 0.9790525022983715
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.377811670303345 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.05
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.235595464706421
	train_negative_loss: 2.2804431915283203
	train_positive_acc: 0.6345275283621715
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.09254391491413116
	train_incorrect_loss: 2.892272385183692
	train_positive_loss: 0.1964675635099411
	train_negative_loss: 0.12630659341812134
	train_correct_acc: 0.9757766911960066
	train_incorrect_acc: 0.05130278526504942
	train_positive_acc: 0.9871458615258649
	train_negative_acc: 0.9184856784948393
	train_correct_nonzero: 39100
	train_incorrect_nonzero: 1000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.024745099246501923
	val_negative_loss: 0.06855839490890503
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.020029954612255096
	test_negative_loss: 0.07333864271640778
	test_positive_acc: 0.9918813195771029
	test_negative_acc: 0.9990530303030303
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03168686479330063
	train_incorrect_loss: 2.7891860622687323
	train_positive_loss: 0.1390925794839859
	train_negative_loss: 0.05753796920180321
	train_correct_acc: 0.9968590464283648
	train_incorrect_acc: 0.04390681003584229
	train_positive_acc: 0.9975744973934199
	train_negative_acc: 0.9484525870338202
	train_correct_nonzero: 39100
	train_incorrect_nonzero: 1000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0016558628994971514
	val_negative_loss: 0.0644991397857666
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01780705153942108
	test_negative_loss: 0.08719231188297272
	test_positive_acc: 0.9936093237902448
	test_negative_acc: 0.993604724538868
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02857346646487713
	train_incorrect_loss: 2.569821293714571
	train_positive_loss: 0.12724505364894867
	train_negative_loss: 0.05326734855771065
	train_correct_acc: 0.9974470510271601
	train_incorrect_acc: 0.08031419873885627
	train_positive_acc: 0.9978320880808771
	train_negative_acc: 0.952011556184743
	train_correct_nonzero: 39100
	train_incorrect_nonzero: 1000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0003632806765381247
	val_negative_loss: 0.03295509144663811
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01590544916689396
	test_negative_loss: 0.05131793022155762
	test_positive_acc: 0.9936538394597605
	test_negative_acc: 0.9936274023327722
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.02495862916111946
	train_incorrect_loss: 2.140293609147745
	train_positive_loss: 0.10534144937992096
	train_negative_loss: 0.04735170304775238
	train_correct_acc: 0.9975973308914775
	train_incorrect_acc: 0.15588463027487418
	train_positive_acc: 0.9985887113878098
	train_negative_acc: 0.9552094583085075
	train_correct_nonzero: 39100
	train_incorrect_nonzero: 1000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.148898238374386e-05
	val_negative_loss: 0.02444169670343399
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.009210462681949139
	test_negative_loss: 0.08777549862861633
	test_positive_acc: 0.9974154135338346
	test_negative_acc: 0.982569469776171
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.019601764157414436
	train_incorrect_loss: 1.647640594682489
	train_positive_loss: 0.07936374098062515
	train_negative_loss: 0.03852473199367523
	train_correct_acc: 0.9978583682221633
	train_incorrect_acc: 0.30933855125844073
	train_positive_acc: 0.9993063652680683
	train_negative_acc: 0.9625739416316528
	train_correct_nonzero: 39100
	train_incorrect_nonzero: 1000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00715710548684001
	val_negative_loss: 0.028702855110168457
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0334160178899765
	test_negative_loss: 0.0796370804309845
	test_positive_acc: 0.9925128325621746
	test_negative_acc: 0.9846064564111484
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.016981074586510658
	train_incorrect_loss: 1.176697633560719
	train_positive_loss: 0.05732520669698715
	train_negative_loss: 0.03271382674574852
	train_correct_acc: 0.9965236419785575
	train_incorrect_acc: 0.494993564993565
	train_positive_acc: 0.9991819952014716
	train_negative_acc: 0.9688688286898611
	train_correct_nonzero: 39100
	train_incorrect_nonzero: 1000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.02277546003460884
	val_negative_loss: 0.023163558915257454
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05380246415734291
	test_negative_loss: 0.07686673849821091
	test_positive_acc: 0.9875920129832682
	test_negative_acc: 0.9728100110489986
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.011565085500478745
	train_incorrect_loss: 0.7376156096244912
	train_positive_loss: 0.035020310431718826
	train_negative_loss: 0.022482318803668022
	train_correct_acc: 0.9970101097851537
	train_incorrect_acc: 0.6989976081756903
	train_positive_acc: 0.9996181490292322
	train_negative_acc: 0.9798378609564495
	train_correct_nonzero: 39100
	train_incorrect_nonzero: 1000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.04811733216047287
	val_negative_loss: 0.003523392602801323
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.039498358964920044
	test_negative_loss: 0.06826816499233246
	test_positive_acc: 0.9936093237902448
	test_negative_acc: 0.9849560056726041
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.008563458919525146
	train_incorrect_loss: 0.48995755802244395
	train_positive_loss: 0.024107055738568306
	train_negative_loss: 0.016627714037895203
	train_correct_acc: 0.9972824723136808
	train_incorrect_acc: 0.8057059651817716
	train_positive_acc: 0.9996044203710482
	train_negative_acc: 0.9857569253102701
	train_correct_nonzero: 39100
	train_incorrect_nonzero: 1000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0001455761812394485
	val_negative_loss: 0.11861307173967361
	val_positive_acc: 1.0
	val_negative_acc: 0.9533417402269861
test:
	test_positive_loss: 0.03672600910067558
	test_negative_loss: 0.25640976428985596
	test_positive_acc: 0.9936093237902448
	test_negative_acc: 0.9302061113619826
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.006780465133488178
	train_incorrect_loss: 0.33274320157802006
	train_positive_loss: 0.016437534242868423
	train_negative_loss: 0.012886658310890198
	train_correct_acc: 0.9979040327492796
	train_incorrect_acc: 0.8760706798442648
	train_positive_acc: 0.9998222553678177
	train_negative_acc: 0.9898162222523409
	train_correct_nonzero: 39100
	train_incorrect_nonzero: 1000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00609685480594635
	val_negative_loss: 0.06878085434436798
	val_positive_acc: 1.0
	val_negative_acc: 0.9789827658680117
test:
	test_positive_loss: 0.047667913138866425
	test_negative_loss: 0.1694084107875824
	test_positive_acc: 0.9922795365562023
	test_negative_acc: 0.9522057071947919
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.004754910711199045
	train_incorrect_loss: 0.17660635093619734
	train_positive_loss: 0.010337906889617443
	train_negative_loss: 0.008131192065775394
	train_correct_acc: 0.998719965791231
	train_incorrect_acc: 0.9345048125633233
	train_positive_acc: 0.9994796763491957
	train_negative_acc: 0.9946379253671904
	train_correct_nonzero: 39100
	train_incorrect_nonzero: 1000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.6305102690239437e-05
	val_negative_loss: 0.11238705366849899
	val_positive_acc: 1.0
	val_negative_acc: 0.9707860445565364
test:
	test_positive_loss: 0.030194733291864395
	test_negative_loss: 0.371104896068573
	test_positive_acc: 0.9934814596331254
	test_negative_acc: 0.9056355194644223
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.59732937812805 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.075
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2354838848114014
	train_negative_loss: 2.280458927154541
	train_positive_acc: 0.6395294747643672
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.1050979420542717
	train_incorrect_loss: 2.4975434170507103
	train_positive_loss: 0.2306012213230133
	train_negative_loss: 0.15454323589801788
	train_correct_acc: 0.9750172165508866
	train_incorrect_acc: 0.04744854463524541
	train_positive_acc: 0.988280084933414
	train_negative_acc: 0.8924111954956571
	train_correct_nonzero: 38600
	train_incorrect_nonzero: 1500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.021393990144133568
	val_negative_loss: 0.07422983646392822
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.021220313385128975
	test_negative_loss: 0.07640497386455536
	test_positive_acc: 0.9907239121696956
	test_negative_acc: 0.9990530303030303
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.04451242834329605
	train_incorrect_loss: 2.4548511115952008
	train_positive_loss: 0.1772102415561676
	train_negative_loss: 0.08452390134334564
	train_correct_acc: 0.9966252300868509
	train_incorrect_acc: 0.029312839059674505
	train_positive_acc: 0.9975824324870353
	train_negative_acc: 0.9232881446605713
	train_correct_nonzero: 38600
	train_incorrect_nonzero: 1500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.002770296297967434
	val_negative_loss: 0.07326354086399078
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.025533298030495644
	test_negative_loss: 0.08071987330913544
	test_positive_acc: 0.9881387201724272
	test_negative_acc: 0.9948066476157911
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.038932278752326965
	train_incorrect_loss: 2.2762781116251762
	train_positive_loss: 0.16297660768032074
	train_negative_loss: 0.077189140021801
	train_correct_acc: 0.998064780277143
	train_incorrect_acc: 0.06209096459096459
	train_positive_acc: 0.9987549316456857
	train_negative_acc: 0.9279090744666917
	train_correct_nonzero: 38600
	train_incorrect_nonzero: 1500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.823316779336892e-05
	val_negative_loss: 0.09097357839345932
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.003139383625239134
	test_negative_loss: 0.14513219892978668
	test_positive_acc: 0.9989035087719298
	test_negative_acc: 0.9654013113897622
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.0362175777554512
	train_incorrect_loss: 2.0023982170238335
	train_positive_loss: 0.14185449481010437
	train_negative_loss: 0.07188791036605835
	train_correct_acc: 0.9972242787776563
	train_incorrect_acc: 0.1314637331725939
	train_positive_acc: 0.9987333343157507
	train_negative_acc: 0.9306438802659216
	train_correct_nonzero: 38600
	train_incorrect_nonzero: 1500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 5.98912902205484e-06
	val_negative_loss: 0.11036646366119385
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.008103089407086372
	test_negative_loss: 0.18064521253108978
	test_positive_acc: 0.9959273182957393
	test_negative_acc: 0.9641354535197411
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.03061722218990326
	train_incorrect_loss: 1.6153271716812154
	train_positive_loss: 0.11362127959728241
	train_negative_loss: 0.06190456077456474
	train_correct_acc: 0.9966962119130317
	train_incorrect_acc: 0.2736978849510819
	train_positive_acc: 0.9993342708378018
	train_negative_acc: 0.9408465025024327
	train_correct_nonzero: 38600
	train_incorrect_nonzero: 1500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 7.33708748157369e-06
	val_negative_loss: 0.0979074090719223
	val_positive_acc: 1.0
	val_negative_acc: 0.9672131147540983
test:
	test_positive_loss: 0.022275902330875397
	test_negative_loss: 0.12917353212833405
	test_positive_acc: 0.9904980506567578
	test_negative_acc: 0.964905252956153
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.02725905552506447
	train_incorrect_loss: 1.2292923181426665
	train_positive_loss: 0.09058111160993576
	train_negative_loss: 0.05449333414435387
	train_correct_acc: 0.9949948735812183
	train_incorrect_acc: 0.4540424082090749
	train_positive_acc: 0.9992793580791843
	train_negative_acc: 0.9484812843142585
	train_correct_nonzero: 38600
	train_incorrect_nonzero: 1500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 4.4056083424948156e-05
	val_negative_loss: 0.07738710194826126
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.013667970895767212
	test_negative_loss: 0.16471567749977112
	test_positive_acc: 0.9945975310616968
	test_negative_acc: 0.9414753055706536
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.019590159878134727
	train_incorrect_loss: 0.850990239218773
	train_positive_loss: 0.05866648629307747
	train_negative_loss: 0.03873562812805176
	train_correct_acc: 0.9957653040951421
	train_incorrect_acc: 0.6372289759118404
	train_positive_acc: 0.999523911078786
	train_negative_acc: 0.9656731734698835
	train_correct_nonzero: 38600
	train_incorrect_nonzero: 1500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0029008646961301565
	val_negative_loss: 0.12441878020763397
	val_positive_acc: 1.0
	val_negative_acc: 0.9672131147540983
test:
	test_positive_loss: 0.01096243318170309
	test_negative_loss: 0.14564627408981323
	test_positive_acc: 0.9974154135338346
	test_negative_acc: 0.9596490240038265
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.01513962633907795
	train_incorrect_loss: 0.5788675562245261
	train_positive_loss: 0.040898896753787994
	train_negative_loss: 0.03004610165953636
	train_correct_acc: 0.9959055715747976
	train_incorrect_acc: 0.7439451142775951
	train_positive_acc: 0.9995821085742866
	train_negative_acc: 0.974170582326949
	train_correct_nonzero: 38600
	train_incorrect_nonzero: 1500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00016937218606472015
	val_negative_loss: 0.1653953492641449
	val_positive_acc: 1.0
	val_negative_acc: 0.9379991593106347
test:
	test_positive_loss: 0.0280349999666214
	test_negative_loss: 0.2740662693977356
	test_positive_acc: 0.9933956079847737
	test_negative_acc: 0.9137058066070138
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.01011572778224945
	train_incorrect_loss: 0.34152582966889294
	train_positive_loss: 0.024832218885421753
	train_negative_loss: 0.02065189555287361
	train_correct_acc: 0.9970000753167253
	train_incorrect_acc: 0.8613062107960067
	train_positive_acc: 0.999848917324964
	train_negative_acc: 0.9834995664866804
	train_correct_nonzero: 38600
	train_incorrect_nonzero: 1500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.1574925995082594e-05
	val_negative_loss: 0.1485772430896759
	val_positive_acc: 1.0
	val_negative_acc: 0.9415720891130728
test:
	test_positive_loss: 0.031322576105594635
	test_negative_loss: 0.2986822724342346
	test_positive_acc: 0.9916432243390076
	test_negative_acc: 0.9270722874494504
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.007263559382408857
	train_incorrect_loss: 0.22479747654853854
	train_positive_loss: 0.015631746500730515
	train_negative_loss: 0.014041037298738956
	train_correct_acc: 0.9977292658718176
	train_incorrect_acc: 0.9086552478134111
	train_positive_acc: 0.9997532465707137
	train_negative_acc: 0.9894998843703551
	train_correct_nonzero: 38600
	train_incorrect_nonzero: 1500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.5283241339147935e-09
	val_negative_loss: 0.17327092587947845
	val_positive_acc: 1.0
	val_negative_acc: 0.9508196721311475
test:
	test_positive_loss: 0.009512726217508316
	test_negative_loss: 0.2498047947883606
	test_positive_acc: 0.9974154135338346
	test_negative_acc: 0.9247568100891299
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.487457513809204 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.1
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.235337495803833
	train_negative_loss: 2.2804651260375977
	train_positive_acc: 0.6451661559634939
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.1188674122095108
	train_incorrect_loss: 2.216527453176677
	train_positive_loss: 0.2565581202507019
	train_negative_loss: 0.18495625257492065
	train_correct_acc: 0.9737127354437557
	train_incorrect_acc: 0.049709415584415585
	train_positive_acc: 0.9888024315049444
	train_negative_acc: 0.8658146850191295
	train_correct_nonzero: 38100
	train_incorrect_nonzero: 2000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.014776026830077171
	val_negative_loss: 0.09798037260770798
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01408479269593954
	test_negative_loss: 0.10417918115854263
	test_positive_acc: 0.994327178239717
	test_negative_acc: 0.9916106248885184
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.05646149441599846
	train_incorrect_loss: 2.1907046913801875
	train_positive_loss: 0.20587201416492462
	train_negative_loss: 0.11121781170368195
	train_correct_acc: 0.9966373382342747
	train_incorrect_acc: 0.028908580976250146
	train_positive_acc: 0.9977578099133849
	train_negative_acc: 0.8987416657627587
	train_correct_nonzero: 38100
	train_incorrect_nonzero: 2000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.001217117765918374
	val_negative_loss: 0.10543516278266907
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.007832147181034088
	test_negative_loss: 0.1274956464767456
	test_positive_acc: 0.9955771782397169
	test_negative_acc: 0.9892101668194557
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.05171990394592285
	train_incorrect_loss: 2.051333323158417
	train_positive_loss: 0.19136735796928406
	train_negative_loss: 0.10477615147829056
	train_correct_acc: 0.9975136768193194
	train_incorrect_acc: 0.049615651683320855
	train_positive_acc: 0.9984759582679761
	train_negative_acc: 0.9027736600851903
	train_correct_nonzero: 38100
	train_incorrect_nonzero: 2000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00017810982535593212
	val_negative_loss: 0.09971641004085541
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.003201867686584592
	test_negative_loss: 0.14991575479507446
	test_positive_acc: 0.9989035087719298
	test_negative_acc: 0.971391187292281
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.049531277269124985
	train_incorrect_loss: 1.867117544147186
	train_positive_loss: 0.17239725589752197
	train_negative_loss: 0.09970184415578842
	train_correct_acc: 0.9959584447859853
	train_incorrect_acc: 0.1150218253968254
	train_positive_acc: 0.9982812948659063
	train_negative_acc: 0.9056916240242187
	train_correct_nonzero: 38100
	train_incorrect_nonzero: 2000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0005349318380467594
	val_negative_loss: 0.11619031429290771
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.005638426169753075
	test_negative_loss: 0.1673557162284851
	test_positive_acc: 0.9973099816849818
	test_negative_acc: 0.9815034491308333
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.042853549122810364
	train_incorrect_loss: 1.574853614539967
	train_positive_loss: 0.1435302197933197
	train_negative_loss: 0.08799712359905243
	train_correct_acc: 0.9955190776272624
	train_incorrect_acc: 0.21815261022113813
	train_positive_acc: 0.9993042627183483
	train_negative_acc: 0.9148771133833535
	train_correct_nonzero: 38100
	train_incorrect_nonzero: 2000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00195365771651268
	val_negative_loss: 0.1100115031003952
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.008823731914162636
	test_negative_loss: 0.14476841688156128
	test_positive_acc: 0.9973099816849818
	test_negative_acc: 0.9657476762318711
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.03620847687125206
	train_incorrect_loss: 1.2429325496300498
	train_positive_loss: 0.11483005434274673
	train_negative_loss: 0.07490959763526917
	train_correct_acc: 0.9942243225417005
	train_incorrect_acc: 0.4154356060606061
	train_positive_acc: 0.999615172331577
	train_negative_acc: 0.9302089928585247
	train_correct_nonzero: 38100
	train_incorrect_nonzero: 2000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.823176029982278e-06
	val_negative_loss: 0.12351003289222717
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.004693076945841312
	test_negative_loss: 0.17003145813941956
	test_positive_acc: 0.9987980769230769
	test_negative_acc: 0.9563704553006934
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.029325000941753387
	train_incorrect_loss: 0.9248476448167714
	train_positive_loss: 0.08327759802341461
	train_negative_loss: 0.06055882200598717
	train_correct_acc: 0.9935821069626731
	train_incorrect_acc: 0.5530510981638801
	train_positive_acc: 0.999609326929087
	train_negative_acc: 0.9448122609503667
	train_correct_nonzero: 38100
	train_incorrect_nonzero: 2000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0023533557541668415
	val_negative_loss: 0.09437570720911026
	val_positive_acc: 1.0
	val_negative_acc: 0.9579655317360235
test:
	test_positive_loss: 0.05094025284051895
	test_negative_loss: 0.11947852373123169
	test_positive_acc: 0.982922263138886
	test_negative_acc: 0.958477916060424
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.02253839001059532
	train_incorrect_loss: 0.6691772449095686
	train_positive_loss: 0.06115535646677017
	train_negative_loss: 0.04635759815573692
	train_correct_acc: 0.994340655838851
	train_incorrect_acc: 0.7061169798575339
	train_positive_acc: 0.9997100857822689
	train_negative_acc: 0.960219057601424
	train_correct_nonzero: 38100
	train_incorrect_nonzero: 2000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.764440296232351e-06
	val_negative_loss: 0.24350887537002563
	val_positive_acc: 1.0
	val_negative_acc: 0.9497688104245481
test:
	test_positive_loss: 0.014962512068450451
	test_negative_loss: 0.25766846537590027
	test_positive_acc: 0.9962134904569115
	test_negative_acc: 0.9281118546147964
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.016857026144862175
	train_incorrect_loss: 0.4621233616544899
	train_positive_loss: 0.04094530642032623
	train_negative_loss: 0.03502596169710159
	train_correct_acc: 0.9952995941967179
	train_incorrect_acc: 0.7863255622071742
	train_positive_acc: 0.9998003671740238
	train_negative_acc: 0.9709909091154648
	train_correct_nonzero: 38100
	train_incorrect_nonzero: 2000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.01035303995013237
	val_negative_loss: 0.21743673086166382
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.8984867591424968
test:
	test_positive_loss: 0.043287429958581924
	test_negative_loss: 0.2858993709087372
	test_positive_acc: 0.9903999652832487
	test_negative_acc: 0.9068914539389582
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.013509389944374561
	train_incorrect_loss: 0.3216866961305485
	train_positive_loss: 0.029560768976807594
	train_negative_loss: 0.027038512751460075
	train_correct_acc: 0.9962928217751008
	train_incorrect_acc: 0.8645292784461549
	train_positive_acc: 0.9994885356034501
	train_negative_acc: 0.9804674523970716
	train_correct_nonzero: 38100
	train_incorrect_nonzero: 2000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.946405786019568e-08
	val_negative_loss: 0.20315086841583252
	val_positive_acc: 1.0
	val_negative_acc: 0.9113072719630096
test:
	test_positive_loss: 0.03711087629199028
	test_negative_loss: 0.22900405526161194
	test_positive_acc: 0.991557372690656
	test_negative_acc: 0.9254547241205572
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.23956537246704 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.125
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2352235317230225
	train_negative_loss: 2.2804722785949707
	train_positive_acc: 0.6501459646011946
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.13076554238796234
	train_incorrect_loss: 2.016419669389725
	train_positive_loss: 0.2751372754573822
	train_negative_loss: 0.2135201096534729
	train_correct_acc: 0.9728440731702483
	train_incorrect_acc: 0.05261931818181818
	train_positive_acc: 0.9907022386343092
	train_negative_acc: 0.840160527477848
	train_correct_nonzero: 37600
	train_incorrect_nonzero: 2500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.013764998875558376
	val_negative_loss: 0.13862204551696777
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.012014109641313553
	test_negative_loss: 0.14819948375225067
	test_positive_acc: 0.994327178239717
	test_negative_acc: 0.9901571365164253
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.07002901285886765
	train_incorrect_loss: 1.982553482055664
	train_positive_loss: 0.22740982472896576
	train_negative_loss: 0.1406225562095642
	train_correct_acc: 0.9958246037516291
	train_incorrect_acc: 0.028496309730723694
	train_positive_acc: 0.9972306160743133
	train_negative_acc: 0.8739522343537454
	train_correct_nonzero: 37600
	train_incorrect_nonzero: 2500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.005514644086360931
	val_negative_loss: 0.138712078332901
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.014246762730181217
	test_negative_loss: 0.15756943821907043
	test_positive_acc: 0.9929730115730502
	test_negative_acc: 0.987993420871605
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.06294023990631104
	train_incorrect_loss: 1.8544435710459948
	train_positive_loss: 0.2108890265226364
	train_negative_loss: 0.13040180504322052
	train_correct_acc: 0.9968469229385265
	train_incorrect_acc: 0.06260073953823954
	train_positive_acc: 0.9985212202100433
	train_negative_acc: 0.8794611874746968
	train_correct_nonzero: 37600
	train_incorrect_nonzero: 2500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.006614404264837503
	val_negative_loss: 0.12356968969106674
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.016240058466792107
	test_negative_loss: 0.16140924394130707
	test_positive_acc: 0.9940890830016217
	test_negative_acc: 0.9830307636389006
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.059259895235300064
	train_incorrect_loss: 1.648611068725586
	train_positive_loss: 0.18661724030971527
	train_negative_loss: 0.12168902158737183
	train_correct_acc: 0.995063870214217
	train_incorrect_acc: 0.15049187443202405
	train_positive_acc: 0.9982592841718206
	train_negative_acc: 0.8864000604065312
	train_correct_nonzero: 37600
	train_incorrect_nonzero: 2500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.005484958179295063
	val_negative_loss: 0.14315906167030334
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.008134080097079277
	test_negative_loss: 0.2278028130531311
	test_positive_acc: 0.9959078660704047
	test_negative_acc: 0.9587986218303024
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.05142691358923912
	train_incorrect_loss: 1.4027847857179498
	train_positive_loss: 0.1567470133304596
	train_negative_loss: 0.10830005258321762
	train_correct_acc: 0.9938048175379041
	train_incorrect_acc: 0.2725871629067118
	train_positive_acc: 0.9994655195066166
	train_negative_acc: 0.8982856478208912
	train_correct_nonzero: 37600
	train_incorrect_nonzero: 2500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.007466497831046581
	val_negative_loss: 0.14153659343719482
	val_positive_acc: 1.0
	val_negative_acc: 0.9707860445565364
test:
	test_positive_loss: 0.022140711545944214
	test_negative_loss: 0.21205049753189087
	test_positive_acc: 0.9944001906318083
	test_negative_acc: 0.9460400676524261
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.04446518048644066
	train_incorrect_loss: 1.1342138051986694
	train_positive_loss: 0.1267545074224472
	train_negative_loss: 0.09276239573955536
	train_correct_acc: 0.991101111862918
	train_incorrect_acc: 0.4388481011922408
	train_positive_acc: 0.9992216195208407
	train_negative_acc: 0.9138660521836358
	train_correct_nonzero: 37600
	train_incorrect_nonzero: 2500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 7.480409112758934e-05
	val_negative_loss: 0.11401683837175369
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.017092658206820488
	test_negative_loss: 0.24083080887794495
	test_positive_acc: 0.9944197708323095
	test_negative_acc: 0.9305560405607216
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.034045491367578506
	train_incorrect_loss: 0.8280441152211279
	train_positive_loss: 0.09122627973556519
	train_negative_loss: 0.07144487649202347
	train_correct_acc: 0.9920947465869712
	train_incorrect_acc: 0.6015846445221446
	train_positive_acc: 0.999799208018972
	train_negative_acc: 0.9359981616599176
	train_correct_nonzero: 37600
	train_incorrect_nonzero: 2500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00036936570541001856
	val_negative_loss: 0.10227943956851959
	val_positive_acc: 1.0
	val_negative_acc: 0.9625893232450609
test:
	test_positive_loss: 0.030333224684000015
	test_negative_loss: 0.25036880373954773
	test_positive_acc: 0.9919332697396532
	test_negative_acc: 0.9390497404170668
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.029550466686487198
	train_incorrect_loss: 0.6475160121917725
	train_positive_loss: 0.07183267176151276
	train_negative_loss: 0.06097850576043129
	train_correct_acc: 0.9917960924216146
	train_incorrect_acc: 0.6980757950832764
	train_positive_acc: 0.9993730898297704
	train_negative_acc: 0.9479538451984929
	train_correct_nonzero: 37600
	train_incorrect_nonzero: 2500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0001927418343257159
	val_negative_loss: 0.19819331169128418
	val_positive_acc: 1.0
	val_negative_acc: 0.8959646910466583
test:
	test_positive_loss: 0.028772924095392227
	test_negative_loss: 0.3510494530200958
	test_positive_acc: 0.9933159331288957
	test_negative_acc: 0.890198674136462
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.019254466518759727
	train_incorrect_loss: 0.41576024889945984
	train_positive_loss: 0.047187019139528275
	train_negative_loss: 0.04081342741847038
	train_correct_acc: 0.9941560913122043
	train_incorrect_acc: 0.8182941884936897
	train_positive_acc: 0.9999055931599574
	train_negative_acc: 0.9667987011859087
	train_correct_nonzero: 37600
	train_incorrect_nonzero: 2500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.029825542122125626
	val_negative_loss: 0.13697905838489532
	val_positive_acc: 0.9836065573770492
	val_negative_acc: 0.9415720891130728
test:
	test_positive_loss: 0.07811273634433746
	test_negative_loss: 0.4666394889354706
	test_positive_acc: 0.9845963702817432
	test_negative_acc: 0.8522656723176625
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.014974936842918396
	train_incorrect_loss: 0.2846643924713135
	train_positive_loss: 0.032925788313150406
	train_negative_loss: 0.030452746897935867
	train_correct_acc: 0.9955629164441837
	train_incorrect_acc: 0.8871171638004557
	train_positive_acc: 0.9996267584941599
	train_negative_acc: 0.9780444971828623
	train_correct_nonzero: 37600
	train_incorrect_nonzero: 2500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 7.365453598140448e-07
	val_negative_loss: 0.20983858406543732
	val_positive_acc: 1.0
	val_negative_acc: 0.9077343421605717
test:
	test_positive_loss: 0.028566887602210045
	test_negative_loss: 0.5019569396972656
	test_positive_acc: 0.9955162620603797
	test_negative_acc: 0.886098150830443
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.410091400146484 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.15
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.235092878341675
	train_negative_loss: 2.280439853668213
	train_positive_acc: 0.6557906113916965
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.14403435587882996
	train_incorrect_loss: 1.833734154701233
	train_positive_loss: 0.2890982925891876
	train_negative_loss: 0.24473358690738678
	train_correct_acc: 0.9705129815277914
	train_incorrect_acc: 0.05272142653688788
	train_positive_acc: 0.9895484619441619
	train_negative_acc: 0.8146821218946219
	train_correct_nonzero: 37100
	train_incorrect_nonzero: 3000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0066054752096533775
	val_negative_loss: 0.2131044864654541
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.008150261826813221
	test_negative_loss: 0.22011920809745789
	test_positive_acc: 0.9989035087719298
	test_negative_acc: 0.9859402979792935
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.08273851126432419
	train_incorrect_loss: 1.8213688135147095
	train_positive_loss: 0.24384857714176178
	train_negative_loss: 0.1703355610370636
	train_correct_acc: 0.9949817591411285
	train_incorrect_acc: 0.026944003627295397
	train_positive_acc: 0.9970736887761065
	train_negative_acc: 0.8483156996229275
	train_correct_nonzero: 37100
	train_incorrect_nonzero: 3000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.008810658007860184
	val_negative_loss: 0.1956188678741455
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.013085467740893364
	test_negative_loss: 0.20854917168617249
	test_positive_acc: 0.9942473910056744
	test_negative_acc: 0.9909527011746353
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.07501597702503204
	train_incorrect_loss: 1.7167607352137566
	train_positive_loss: 0.22860634326934814
	train_negative_loss: 0.1587168127298355
	train_correct_acc: 0.9969758909076064
	train_incorrect_acc: 0.05856140387390387
	train_positive_acc: 0.9983150812777386
	train_negative_acc: 0.8560711149693536
	train_correct_nonzero: 37100
	train_incorrect_nonzero: 3000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.000705782207660377
	val_negative_loss: 0.15210190415382385
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.010208703577518463
	test_negative_loss: 0.19033712148666382
	test_positive_acc: 0.9955771782397169
	test_negative_acc: 0.9757159445685204
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.07002577185630798
	train_incorrect_loss: 1.5865577459335327
	train_positive_loss: 0.20888471603393555
	train_negative_loss: 0.14872713387012482
	train_correct_acc: 0.9952478111523037
	train_incorrect_acc: 0.13083010151552033
	train_positive_acc: 0.9990228540760522
	train_negative_acc: 0.8624883279213357
	train_correct_nonzero: 37100
	train_incorrect_nonzero: 3000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.14494245685637e-05
	val_negative_loss: 0.21738122403621674
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.005577819421887398
	test_negative_loss: 0.273412823677063
	test_positive_acc: 0.9970652734778122
	test_negative_acc: 0.9461439521269286
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.06302275508642197
	train_incorrect_loss: 1.3811812998726964
	train_positive_loss: 0.18119487166404724
	train_negative_loss: 0.1348789781332016
	train_correct_acc: 0.9920936966772186
	train_incorrect_acc: 0.25241596944721945
	train_positive_acc: 0.999204231954418
	train_negative_acc: 0.8750196183207694
	train_correct_nonzero: 37100
	train_incorrect_nonzero: 3000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 9.527159272693098e-05
	val_negative_loss: 0.20232900977134705
	val_positive_acc: 1.0
	val_negative_acc: 0.959016393442623
test:
	test_positive_loss: 0.011247320100665092
	test_negative_loss: 0.23237460851669312
	test_positive_acc: 0.9970652734778122
	test_negative_acc: 0.9497223192047496
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.05509908124804497
	train_incorrect_loss: 1.1432249546051025
	train_positive_loss: 0.15010759234428406
	train_negative_loss: 0.11825266480445862
	train_correct_acc: 0.9908584180317523
	train_incorrect_acc: 0.4050323464288551
	train_positive_acc: 0.9994090663585017
	train_negative_acc: 0.8948680975462242
	train_correct_nonzero: 37100
	train_incorrect_nonzero: 3000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0021774068009108305
	val_negative_loss: 0.22806201875209808
	val_positive_acc: 1.0
	val_negative_acc: 0.905212274064733
test:
	test_positive_loss: 0.032898202538490295
	test_negative_loss: 0.32386040687561035
	test_positive_acc: 0.9891358934606662
	test_negative_acc: 0.8854128404588358
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.04621433466672897
	train_incorrect_loss: 0.9048947691917419
	train_positive_loss: 0.11921924352645874
	train_negative_loss: 0.09838747978210449
	train_correct_acc: 0.9895932238244121
	train_incorrect_acc: 0.558169981860755
	train_positive_acc: 0.999506435828497
	train_negative_acc: 0.9142903426349045
	train_correct_nonzero: 37100
	train_incorrect_nonzero: 3000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.001913299085572362
	val_negative_loss: 0.16516941785812378
	val_positive_acc: 1.0
	val_negative_acc: 0.9508196721311475
test:
	test_positive_loss: 0.03329876810312271
	test_negative_loss: 0.2798256278038025
	test_positive_acc: 0.9893496092661374
	test_negative_acc: 0.9230068078918185
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.036073438823223114
	train_incorrect_loss: 0.6703417897224426
	train_positive_loss: 0.08902411162853241
	train_negative_loss: 0.07770566642284393
	train_correct_acc: 0.9906560131704475
	train_incorrect_acc: 0.6870639710231907
	train_positive_acc: 0.999593578914174
	train_negative_acc: 0.9360727588102459
	train_correct_nonzero: 37100
	train_incorrect_nonzero: 3000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 6.569123911503993e-07
	val_negative_loss: 0.29899343848228455
	val_positive_acc: 1.0
	val_negative_acc: 0.9005884825556956
test:
	test_positive_loss: 0.02589000016450882
	test_negative_loss: 0.38760465383529663
	test_positive_acc: 0.9932037759328041
	test_negative_acc: 0.9021224214848946
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.026911813765764236
	train_incorrect_loss: 0.4673640727996826
	train_positive_loss: 0.06160462647676468
	train_negative_loss: 0.05817903205752373
	train_correct_acc: 0.9916872011647612
	train_incorrect_acc: 0.7799189657668459
	train_positive_acc: 0.999951102635568
	train_negative_acc: 0.9513321952520378
	train_correct_nonzero: 37100
	train_incorrect_nonzero: 3000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.0363207770278677e-07
	val_negative_loss: 0.4822680950164795
	val_positive_acc: 1.0
	val_negative_acc: 0.8411097099621689
test:
	test_positive_loss: 0.02913595549762249
	test_negative_loss: 0.5617157816886902
	test_positive_acc: 0.9920877045042326
	test_negative_acc: 0.8314317101002956
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.020496582612395287
	train_incorrect_loss: 0.33706945180892944
	train_positive_loss: 0.044612232595682144
	train_negative_loss: 0.043781328946352005
	train_correct_acc: 0.9940925692143265
	train_incorrect_acc: 0.85688333556164
	train_positive_acc: 0.9998150596710057
	train_negative_acc: 0.9677551162997783
	train_correct_nonzero: 37100
	train_incorrect_nonzero: 3000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 8.085343324637506e-06
	val_negative_loss: 0.48663458228111267
	val_positive_acc: 1.0
	val_negative_acc: 0.8385876418663304
test:
	test_positive_loss: 0.020097263157367706
	test_negative_loss: 0.7327612042427063
	test_positive_acc: 0.9950420112269216
	test_negative_acc: 0.8232603753970189
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.11676597595215 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.175
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.234931230545044
	train_negative_loss: 2.2804722785949707
	train_positive_acc: 0.6614058608035442
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.1563321053981781
	train_incorrect_loss: 1.6908305883407593
	train_positive_loss: 0.2997402548789978
	train_negative_loss: 0.2761518061161041
	train_correct_acc: 0.9698925538058996
	train_incorrect_acc: 0.06043724909061567
	train_positive_acc: 0.9922472753965436
	train_negative_acc: 0.7890471479302408
	train_correct_nonzero: 36600
	train_incorrect_nonzero: 3500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.005288606975227594
	val_negative_loss: 0.24339845776557922
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.009169016033411026
	test_negative_loss: 0.25605443120002747
	test_positive_acc: 0.9961458333333333
	test_negative_acc: 0.9843206016744284
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.093901626765728
	train_incorrect_loss: 1.6664528846740723
	train_positive_loss: 0.25411203503608704
	train_negative_loss: 0.19845257699489594
	train_correct_acc: 0.9949959644889451
	train_incorrect_acc: 0.03349366067570556
	train_positive_acc: 0.9973679261604338
	train_negative_acc: 0.8251849671515876
	train_correct_nonzero: 36600
	train_incorrect_nonzero: 3500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00521104596555233
	val_negative_loss: 0.25317031145095825
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.016595270484685898
	test_negative_loss: 0.2786935269832611
	test_positive_acc: 0.9905210884961272
	test_negative_acc: 0.983495314810999
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.0860590785741806
	train_incorrect_loss: 1.564350962638855
	train_positive_loss: 0.23739898204803467
	train_negative_loss: 0.1864875853061676
	train_correct_acc: 0.9954950140879794
	train_incorrect_acc: 0.07843517418477078
	train_positive_acc: 0.9985831818485218
	train_negative_acc: 0.8328481439049972
	train_correct_nonzero: 36600
	train_incorrect_nonzero: 3500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00036138901486992836
	val_negative_loss: 0.1709066927433014
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.008382140658795834
	test_negative_loss: 0.22149410843849182
	test_positive_acc: 0.9955771782397169
	test_negative_acc: 0.9706134556938787
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.07851507514715195
	train_incorrect_loss: 1.4276432991027832
	train_positive_loss: 0.21393992006778717
	train_negative_loss: 0.16995243728160858
	train_correct_acc: 0.9927372055545503
	train_incorrect_acc: 0.17754568321349895
	train_positive_acc: 0.9988885596995711
	train_negative_acc: 0.8451363915442872
	train_correct_nonzero: 36600
	train_incorrect_nonzero: 3500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 8.815589535515755e-05
	val_negative_loss: 0.33927369117736816
	val_positive_acc: 1.0
	val_negative_acc: 0.9216057166876839
test:
	test_positive_loss: 0.0043817064724862576
	test_negative_loss: 0.409659206867218
	test_positive_acc: 0.9966736694677871
	test_negative_acc: 0.8800974185935453
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.07088058441877365
	train_incorrect_loss: 1.2217477560043335
	train_positive_loss: 0.18307681381702423
	train_negative_loss: 0.15422458946704865
	train_correct_acc: 0.9884394673349859
	train_incorrect_acc: 0.31625555043297454
	train_positive_acc: 0.9990877879194997
	train_negative_acc: 0.8613555886395748
	train_correct_nonzero: 36600
	train_incorrect_nonzero: 3500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.0103013866901165e-06
	val_negative_loss: 0.3441053628921509
	val_positive_acc: 1.0
	val_negative_acc: 0.8411097099621689
test:
	test_positive_loss: 0.013658625073730946
	test_negative_loss: 0.46958357095718384
	test_positive_acc: 0.9955771782397169
	test_negative_acc: 0.8292166485923864
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.061278581619262695
	train_incorrect_loss: 1.0128746032714844
	train_positive_loss: 0.1522468775510788
	train_negative_loss: 0.13390232622623444
	train_correct_acc: 0.9866015183116148
	train_incorrect_acc: 0.4652711840422711
	train_positive_acc: 0.9994600670771346
	train_negative_acc: 0.8825207890719097
	train_correct_nonzero: 36600
	train_incorrect_nonzero: 3500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.8304914394539082e-06
	val_negative_loss: 0.28108614683151245
	val_positive_acc: 1.0
	val_negative_acc: 0.8831441782261454
test:
	test_positive_loss: 0.01662668213248253
	test_negative_loss: 0.38699042797088623
	test_positive_acc: 0.9966736694677871
	test_negative_acc: 0.8859287599663546
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.05135849490761757
	train_incorrect_loss: 0.8039979338645935
	train_positive_loss: 0.12077829241752625
	train_negative_loss: 0.11197721213102341
	train_correct_acc: 0.9864200252435656
	train_incorrect_acc: 0.5876865050585163
	train_positive_acc: 0.9994694492044215
	train_negative_acc: 0.904081345136791
	train_correct_nonzero: 36600
	train_incorrect_nonzero: 3500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0014974104706197977
	val_negative_loss: 0.261158287525177
	val_positive_acc: 1.0
	val_negative_acc: 0.8841950399327448
test:
	test_positive_loss: 0.04676153510808945
	test_negative_loss: 0.31370624899864197
	test_positive_acc: 0.9893819792281864
	test_negative_acc: 0.8863236877940817
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.04073657840490341
	train_incorrect_loss: 0.6153078079223633
	train_positive_loss: 0.091750867664814
	train_negative_loss: 0.08957826346158981
	train_correct_acc: 0.9883204545230326
	train_incorrect_acc: 0.7066479451472851
	train_positive_acc: 0.9996120088831055
	train_negative_acc: 0.9281298899403203
	train_correct_nonzero: 36600
	train_incorrect_nonzero: 3500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.015456661581993103
	val_negative_loss: 0.5238887667655945
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.7955023118957545
test:
	test_positive_loss: 0.05801347270607948
	test_negative_loss: 0.42091870307922363
	test_positive_acc: 0.9884701015519087
	test_negative_acc: 0.8488139584952066
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.030825715512037277
	train_incorrect_loss: 0.43883228302001953
	train_positive_loss: 0.06554269045591354
	train_negative_loss: 0.06687439233064651
	train_correct_acc: 0.9899988363867434
	train_incorrect_acc: 0.8044762948166204
	train_positive_acc: 0.9996561955829595
	train_negative_acc: 0.9484975445920688
	train_correct_nonzero: 36600
	train_incorrect_nonzero: 3500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.004246083088219166
	val_negative_loss: 0.489909291267395
	val_positive_acc: 1.0
	val_negative_acc: 0.8236654056326187
test:
	test_positive_loss: 0.07140420377254486
	test_negative_loss: 0.450878381729126
	test_positive_acc: 0.9881887286228594
	test_negative_acc: 0.8624676748309648
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.025469321757555008
	train_incorrect_loss: 0.3219740688800812
	train_positive_loss: 0.04754986986517906
	train_negative_loss: 0.05471920594573021
	train_correct_acc: 0.9918116968204732
	train_incorrect_acc: 0.8587554009972228
	train_positive_acc: 0.9996125615161388
	train_negative_acc: 0.9610638784032323
	train_correct_nonzero: 36600
	train_incorrect_nonzero: 3500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.5993819033610635e-05
	val_negative_loss: 0.3719974756240845
	val_positive_acc: 1.0
	val_negative_acc: 0.9041614123581336
test:
	test_positive_loss: 0.08391320705413818
	test_negative_loss: 0.31301671266555786
	test_positive_acc: 0.9884220246288318
	test_negative_acc: 0.9082494501821541
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.172191858291626 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.2
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.234855890274048
	train_negative_loss: 2.2804818153381348
	train_positive_acc: 0.665159741755368
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.16929340362548828
	train_incorrect_loss: 1.5508490800857544
	train_positive_loss: 0.30525678396224976
	train_negative_loss: 0.30930596590042114
	train_correct_acc: 0.9678331183023934
	train_incorrect_acc: 0.06250969393442157
	train_positive_acc: 0.9920684577610881
	train_negative_acc: 0.7632334870516732
	train_correct_nonzero: 36100
	train_incorrect_nonzero: 4000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.006904385052621365
	val_negative_loss: 0.2451266050338745
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.009797429665923119
	test_negative_loss: 0.25425252318382263
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9865774331643438
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.10490939766168594
	train_incorrect_loss: 1.5520728826522827
	train_positive_loss: 0.26413586735725403
	train_negative_loss: 0.22717376053333282
	train_correct_acc: 0.9952059893242059
	train_incorrect_acc: 0.033517589474736084
	train_positive_acc: 0.9973086015987254
	train_negative_acc: 0.8013447691960938
	train_correct_nonzero: 36100
	train_incorrect_nonzero: 4000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0008930440526455641
	val_negative_loss: 0.3220974802970886
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.0093846395611763
	test_negative_loss: 0.3616824150085449
	test_positive_acc: 0.9944611068111455
	test_negative_acc: 0.9671377601937267
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.09702351689338684
	train_incorrect_loss: 1.444818139076233
	train_positive_loss: 0.24461977183818817
	train_negative_loss: 0.21417024731636047
	train_correct_acc: 0.9947976348631126
	train_incorrect_acc: 0.0804727071977869
	train_positive_acc: 0.998602891263976
	train_negative_acc: 0.8087613260588538
	train_correct_nonzero: 36100
	train_incorrect_nonzero: 4000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0003854761889670044
	val_negative_loss: 0.2378026247024536
	val_positive_acc: 1.0
	val_negative_acc: 0.9625893232450609
test:
	test_positive_loss: 0.00535306241363287
	test_negative_loss: 0.352337121963501
	test_positive_acc: 0.9974154135338346
	test_negative_acc: 0.9388200955893427
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.08970321714878082
	train_incorrect_loss: 1.3180333375930786
	train_positive_loss: 0.22099000215530396
	train_negative_loss: 0.19705452024936676
	train_correct_acc: 0.9890050431807791
	train_incorrect_acc: 0.2023880323520156
	train_positive_acc: 0.9986593993469993
	train_negative_acc: 0.822793586047815
	train_correct_nonzero: 36100
	train_incorrect_nonzero: 4000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.5513716789428145e-05
	val_negative_loss: 0.23001644015312195
	val_positive_acc: 1.0
	val_negative_acc: 0.959016393442623
test:
	test_positive_loss: 0.002332274802029133
	test_negative_loss: 0.44527003169059753
	test_positive_acc: 0.9985119047619048
	test_negative_acc: 0.8974798843971319
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.07900065183639526
	train_incorrect_loss: 1.1274561882019043
	train_positive_loss: 0.1881484091281891
	train_negative_loss: 0.1750997006893158
	train_correct_acc: 0.9850543225463038
	train_incorrect_acc: 0.34938500586165483
	train_positive_acc: 0.9991252640319584
	train_negative_acc: 0.8446819467429609
	train_correct_nonzero: 36100
	train_incorrect_nonzero: 4000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 4.744422767544165e-05
	val_negative_loss: 0.22157049179077148
	val_positive_acc: 1.0
	val_negative_acc: 0.9543926019335855
test:
	test_positive_loss: 0.01369475107640028
	test_negative_loss: 0.4542323648929596
	test_positive_acc: 0.9942473910056744
	test_negative_acc: 0.8716900489272184
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.06645851582288742
	train_incorrect_loss: 0.8878294229507446
	train_positive_loss: 0.14902977645397186
	train_negative_loss: 0.147144615650177
	train_correct_acc: 0.9837932838073471
	train_incorrect_acc: 0.5175141202334249
	train_positive_acc: 0.9994953685056508
	train_negative_acc: 0.8745075035355315
	train_correct_nonzero: 36100
	train_incorrect_nonzero: 4000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.5072702303295955e-05
	val_negative_loss: 0.16159869730472565
	val_positive_acc: 1.0
	val_negative_acc: 0.9333753678015972
test:
	test_positive_loss: 0.0143740214407444
	test_negative_loss: 0.47874438762664795
	test_positive_acc: 0.9941262521957936
	test_negative_acc: 0.8679183753455084
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.055178940296173096
	train_incorrect_loss: 0.7050064206123352
	train_positive_loss: 0.11833992600440979
	train_negative_loss: 0.12047797441482544
	train_correct_acc: 0.9847816638136366
	train_incorrect_acc: 0.656795476620913
	train_positive_acc: 0.9991746244764239
	train_negative_acc: 0.9048884801911686
	train_correct_nonzero: 36100
	train_incorrect_nonzero: 4000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0011784795206040144
	val_negative_loss: 0.15335306525230408
	val_positive_acc: 1.0
	val_negative_acc: 0.9543926019335855
test:
	test_positive_loss: 0.035871703177690506
	test_negative_loss: 0.44978272914886475
	test_positive_acc: 0.9889663158868264
	test_negative_acc: 0.8681106106675045
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.0415329672396183
	train_incorrect_loss: 0.5102700591087341
	train_positive_loss: 0.08544076979160309
	train_negative_loss: 0.09240519255399704
	train_correct_acc: 0.9868978770508345
	train_incorrect_acc: 0.7686577114147893
	train_positive_acc: 0.9995130443278188
	train_negative_acc: 0.9309601078528484
	train_correct_nonzero: 36100
	train_incorrect_nonzero: 4000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 7.351463864324614e-05
	val_negative_loss: 0.4873988628387451
	val_positive_acc: 1.0
	val_negative_acc: 0.7662883564522909
test:
	test_positive_loss: 0.012164418585598469
	test_negative_loss: 0.9548548460006714
	test_positive_acc: 0.9971821175278622
	test_negative_acc: 0.7466959082978326
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.03136887773871422
	train_incorrect_loss: 0.3589054346084595
	train_positive_loss: 0.06150438264012337
	train_negative_loss: 0.0701364278793335
	train_correct_acc: 0.9894392639280751
	train_incorrect_acc: 0.8378347872567046
	train_positive_acc: 0.9996614101443078
	train_negative_acc: 0.9485852055973681
	train_correct_nonzero: 36100
	train_incorrect_nonzero: 4000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.8358856070553884e-05
	val_negative_loss: 0.2936175465583801
	val_positive_acc: 1.0
	val_negative_acc: 0.8703236654056326
test:
	test_positive_loss: 0.04605570808053017
	test_negative_loss: 0.5988814830780029
	test_positive_acc: 0.991557372690656
	test_negative_acc: 0.8398931050436766
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.021953267976641655
	train_incorrect_loss: 0.236623153090477
	train_positive_loss: 0.04008882865309715
	train_negative_loss: 0.04830439016222954
	train_correct_acc: 0.9928165436705654
	train_incorrect_acc: 0.9020744806164191
	train_positive_acc: 0.9998513120959106
	train_negative_acc: 0.9674717286065542
	train_correct_nonzero: 36100
	train_incorrect_nonzero: 4000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00018953988910652697
	val_negative_loss: 0.4337562918663025
	val_positive_acc: 1.0
	val_negative_acc: 0.837536780159731
test:
	test_positive_loss: 0.040937408804893494
	test_negative_loss: 0.9207131266593933
	test_positive_acc: 0.991662804539509
	test_negative_acc: 0.7904684282895156
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.238759994506836 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.225
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.234710454940796
	train_negative_loss: 2.2804484367370605
	train_positive_acc: 0.6701711000477298
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.1814650595188141
	train_incorrect_loss: 1.4385722875595093
	train_positive_loss: 0.3093206286430359
	train_negative_loss: 0.34282511472702026
	train_correct_acc: 0.9649607543580921
	train_incorrect_acc: 0.07133748095498132
	train_positive_acc: 0.9925089759017923
	train_negative_acc: 0.7372899783010477
	train_correct_nonzero: 35600
	train_incorrect_nonzero: 4500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.002799408510327339
	val_negative_loss: 0.29672616720199585
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.0057769292034208775
	test_negative_loss: 0.316631019115448
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9781251660941213
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.11652433127164841
	train_incorrect_loss: 1.4325017929077148
	train_positive_loss: 0.2679715156555176
	train_negative_loss: 0.25816041231155396
	train_correct_acc: 0.9945753560165315
	train_incorrect_acc: 0.03847643516997608
	train_positive_acc: 0.9977679952687901
	train_negative_acc: 0.7768581086674795
	train_correct_nonzero: 35600
	train_incorrect_nonzero: 4500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0043512145057320595
	val_negative_loss: 0.3659062385559082
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.015322890132665634
	test_negative_loss: 0.3874039649963379
	test_positive_acc: 0.9918813195771029
	test_negative_acc: 0.9766674432509974
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.10847601294517517
	train_incorrect_loss: 1.334323525428772
	train_positive_loss: 0.24955366551876068
	train_negative_loss: 0.24336010217666626
	train_correct_acc: 0.9930080613988114
	train_incorrect_acc: 0.09926631312707532
	train_positive_acc: 0.9982601793543245
	train_negative_acc: 0.7872656139272693
	train_correct_nonzero: 35600
	train_incorrect_nonzero: 4500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00020597504044417292
	val_negative_loss: 0.25299978256225586
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.005237692967057228
	test_negative_loss: 0.37550055980682373
	test_positive_acc: 0.9989035087719298
	test_negative_acc: 0.930744487797634
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.09934510290622711
	train_incorrect_loss: 1.2008529901504517
	train_positive_loss: 0.2229243814945221
	train_negative_loss: 0.22174085676670074
	train_correct_acc: 0.9851027942236821
	train_incorrect_acc: 0.24692705460416603
	train_positive_acc: 0.998462578004094
	train_negative_acc: 0.8065122255003893
	train_correct_nonzero: 35600
	train_incorrect_nonzero: 4500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 5.887257543690794e-07
	val_negative_loss: 0.32369521260261536
	val_positive_acc: 1.0
	val_negative_acc: 0.8970155527532577
test:
	test_positive_loss: 0.006124481558799744
	test_negative_loss: 0.48514223098754883
	test_positive_acc: 0.996299342105263
	test_negative_acc: 0.8630137759798683
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.08632320165634155
	train_incorrect_loss: 1.0097383260726929
	train_positive_loss: 0.187557652592659
	train_negative_loss: 0.1946374922990799
	train_correct_acc: 0.9804622272991141
	train_incorrect_acc: 0.4162018189401357
	train_positive_acc: 0.9989784943207543
	train_negative_acc: 0.8356511855904434
	train_correct_nonzero: 35600
	train_incorrect_nonzero: 4500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.7189540762483375e-06
	val_negative_loss: 0.3774425983428955
	val_positive_acc: 1.0
	val_negative_acc: 0.8503572929802439
test:
	test_positive_loss: 0.014830472879111767
	test_negative_loss: 0.622628390789032
	test_positive_acc: 0.996299342105263
	test_negative_acc: 0.7708029226455944
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.07220181077718735
	train_incorrect_loss: 0.8222908973693848
	train_positive_loss: 0.1529701054096222
	train_negative_loss: 0.16214445233345032
	train_correct_acc: 0.9799728042872582
	train_incorrect_acc: 0.5729526725488833
	train_positive_acc: 0.9991821386407501
	train_negative_acc: 0.8682428215812864
	train_correct_nonzero: 35600
	train_incorrect_nonzero: 4500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.312201712901697e-08
	val_negative_loss: 0.3699876368045807
	val_positive_acc: 1.0
	val_negative_acc: 0.8959646910466583
test:
	test_positive_loss: 0.012018553912639618
	test_negative_loss: 0.5463597774505615
	test_positive_acc: 0.996299342105263
	test_negative_acc: 0.8623853123342946
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.05830807611346245
	train_incorrect_loss: 0.6433287858963013
	train_positive_loss: 0.11801210045814514
	train_negative_loss: 0.130695179104805
	train_correct_acc: 0.9822603795634586
	train_incorrect_acc: 0.6891654580772537
	train_positive_acc: 0.9993988237366745
	train_negative_acc: 0.899985753452755
	train_correct_nonzero: 35600
	train_incorrect_nonzero: 4500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0005043402779847383
	val_negative_loss: 0.36680805683135986
	val_positive_acc: 1.0
	val_negative_acc: 0.8959646910466583
test:
	test_positive_loss: 0.023617073893547058
	test_negative_loss: 0.626758337020874
	test_positive_acc: 0.9950493421052631
	test_negative_acc: 0.8413410346205564
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.04757403954863548
	train_incorrect_loss: 0.4926961660385132
	train_positive_loss: 0.09217751026153564
	train_negative_loss: 0.10770026594400406
	train_correct_acc: 0.9848119609727455
	train_incorrect_acc: 0.7752030741826201
	train_positive_acc: 0.9994050389985155
	train_negative_acc: 0.922902079459019
	train_correct_nonzero: 35600
	train_incorrect_nonzero: 4500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.0958805063410182e-07
	val_negative_loss: 0.30787476897239685
	val_positive_acc: 1.0
	val_negative_acc: 0.87494745691467
test:
	test_positive_loss: 0.02938156947493553
	test_negative_loss: 0.47911322116851807
	test_positive_acc: 0.9952400200713649
	test_negative_acc: 0.8882881666213134
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.031743135303258896
	train_incorrect_loss: 0.3168245553970337
	train_positive_loss: 0.05881441757082939
	train_negative_loss: 0.07126109302043915
	train_correct_acc: 0.9897975238209926
	train_incorrect_acc: 0.8597992846232541
	train_positive_acc: 0.9996688548061057
	train_negative_acc: 0.9508881811485489
	train_correct_nonzero: 35600
	train_incorrect_nonzero: 4500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0003743378911167383
	val_negative_loss: 0.7369698286056519
	val_positive_acc: 1.0
	val_negative_acc: 0.8129466162253047
test:
	test_positive_loss: 0.0359189547598362
	test_negative_loss: 0.7990206480026245
	test_positive_acc: 0.9913256463711568
	test_negative_acc: 0.8242436252496763
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.02498961240053177
	train_incorrect_loss: 0.22973066568374634
	train_positive_loss: 0.04220668599009514
	train_negative_loss: 0.05720493942499161
	train_correct_acc: 0.9917274386965163
	train_incorrect_acc: 0.9038949016334308
	train_positive_acc: 0.9998039929865179
	train_negative_acc: 0.9639021088851252
	train_correct_nonzero: 35600
	train_incorrect_nonzero: 4500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 7.22629692972987e-07
	val_negative_loss: 0.4851451516151428
	val_positive_acc: 1.0
	val_negative_acc: 0.8293400588482556
test:
	test_positive_loss: 0.0890122652053833
	test_negative_loss: 0.5961892604827881
	test_positive_acc: 0.9889218002173107
	test_negative_acc: 0.875995797220281
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 40.87748908996582 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.25
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2346014976501465
	train_negative_loss: 2.2804691791534424
	train_positive_acc: 0.6736668358308302
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.19389109313488007
	train_incorrect_loss: 1.3332695960998535
	train_positive_loss: 0.31003493070602417
	train_negative_loss: 0.37800776958465576
	train_correct_acc: 0.9620235732702195
	train_incorrect_acc: 0.08287521911762394
	train_positive_acc: 0.992721604685217
	train_negative_acc: 0.7122073654699267
	train_correct_nonzero: 35100
	train_incorrect_nonzero: 5000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0031934818252921104
	val_negative_loss: 0.36996549367904663
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.004321658052504063
	test_negative_loss: 0.39667388796806335
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9600013213108953
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.128436878323555
	train_incorrect_loss: 1.3349262475967407
	train_positive_loss: 0.2713932394981384
	train_negative_loss: 0.2903239130973816
	train_correct_acc: 0.9936218113103558
	train_incorrect_acc: 0.03948961839614297
	train_positive_acc: 0.9977510725307445
	train_negative_acc: 0.7518409892559889
	train_correct_nonzero: 35100
	train_incorrect_nonzero: 5000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.015985608100891113
	val_negative_loss: 0.4269271492958069
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9789827658680117
test:
	test_positive_loss: 0.019083570688962936
	test_negative_loss: 0.4568890333175659
	test_positive_acc: 0.9914211405662273
	test_negative_acc: 0.9376689610817845
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.12008649110794067
	train_incorrect_loss: 1.2506691217422485
	train_positive_loss: 0.25451043248176575
	train_negative_loss: 0.27477559447288513
	train_correct_acc: 0.9907000781550069
	train_incorrect_acc: 0.11695236540325746
	train_positive_acc: 0.998524484597049
	train_negative_acc: 0.7648445267434717
	train_correct_nonzero: 35100
	train_incorrect_nonzero: 5000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0001429188996553421
	val_negative_loss: 0.38629573583602905
	val_positive_acc: 1.0
	val_negative_acc: 0.8795712484237075
test:
	test_positive_loss: 0.002541141351684928
	test_negative_loss: 0.4746302366256714
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.883796605947029
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.11026842147111893
	train_incorrect_loss: 1.1393733024597168
	train_positive_loss: 0.23034024238586426
	train_negative_loss: 0.25229257345199585
	train_correct_acc: 0.9799795272324026
	train_incorrect_acc: 0.2694786080252368
	train_positive_acc: 0.9985637979608581
	train_negative_acc: 0.7840372428617016
	train_correct_nonzero: 35100
	train_incorrect_nonzero: 5000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0003956842701882124
	val_negative_loss: 0.3784290552139282
	val_positive_acc: 1.0
	val_negative_acc: 0.9169819251786464
test:
	test_positive_loss: 0.0012918757274746895
	test_negative_loss: 0.5709449052810669
	test_positive_acc: 1.0
	test_negative_acc: 0.8371519506199345
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.09565868228673935
	train_incorrect_loss: 0.9810574054718018
	train_positive_loss: 0.1974417120218277
	train_negative_loss: 0.22103162109851837
	train_correct_acc: 0.9778277021080884
	train_incorrect_acc: 0.42192627491841594
	train_positive_acc: 0.9992268816256845
	train_negative_acc: 0.8181157235178578
	train_correct_nonzero: 35100
	train_incorrect_nonzero: 5000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 5.173963018023642e-07
	val_negative_loss: 0.5563267469406128
	val_positive_acc: 1.0
	val_negative_acc: 0.8129466162253047
test:
	test_positive_loss: 0.00019893312128260732
	test_negative_loss: 0.7894802093505859
	test_positive_acc: 1.0
	test_negative_acc: 0.757771739795393
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.08281976729631424
	train_incorrect_loss: 0.8182603120803833
	train_positive_loss: 0.16515736281871796
	train_negative_loss: 0.18963265419006348
	train_correct_acc: 0.9777366025762746
	train_incorrect_acc: 0.556200248265104
	train_positive_acc: 0.9994253047222802
	train_negative_acc: 0.8506666478773766
	train_correct_nonzero: 35100
	train_incorrect_nonzero: 5000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.002801046473905444
	val_negative_loss: 0.33778733015060425
	val_positive_acc: 1.0
	val_negative_acc: 0.8877679697351828
test:
	test_positive_loss: 0.003012279747053981
	test_negative_loss: 0.4843379557132721
	test_positive_acc: 1.0
	test_negative_acc: 0.8813293013708355
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.06603478640317917
	train_incorrect_loss: 0.647531270980835
	train_positive_loss: 0.12984347343444824
	train_negative_loss: 0.15263324975967407
	train_correct_acc: 0.9804332403173871
	train_incorrect_acc: 0.6702071845828168
	train_positive_acc: 0.9996955370116121
	train_negative_acc: 0.8841666370335654
	train_correct_nonzero: 35100
	train_incorrect_nonzero: 5000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00013360055163502693
	val_negative_loss: 0.42358699440956116
	val_positive_acc: 1.0
	val_negative_acc: 0.8631778058007566
test:
	test_positive_loss: 0.006033183075487614
	test_negative_loss: 0.6772603988647461
	test_positive_acc: 0.996299342105263
	test_negative_acc: 0.8161064558883412
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.05264594405889511
	train_incorrect_loss: 0.49018239974975586
	train_positive_loss: 0.098661407828331
	train_negative_loss: 0.12155388295650482
	train_correct_acc: 0.9825243442743018
	train_incorrect_acc: 0.7719466815415027
	train_positive_acc: 0.999575846591767
	train_negative_acc: 0.9131791462713335
	train_correct_nonzero: 35100
	train_incorrect_nonzero: 5000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.4125273082754575e-05
	val_negative_loss: 0.7473025321960449
	val_positive_acc: 1.0
	val_negative_acc: 0.7698612862547289
test:
	test_positive_loss: 0.0022975760512053967
	test_negative_loss: 1.263845443725586
	test_positive_acc: 0.9989406779661016
	test_negative_acc: 0.7207036942729371
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.03843056410551071
	train_incorrect_loss: 0.3345230221748352
	train_positive_loss: 0.06744765490293503
	train_negative_loss: 0.08824462443590164
	train_correct_acc: 0.9874163299118842
	train_incorrect_acc: 0.8503932468825391
	train_positive_acc: 0.9995970234687102
	train_negative_acc: 0.9414057054638961
	train_correct_nonzero: 35100
	train_incorrect_nonzero: 5000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00014081478002481163
	val_negative_loss: 0.7474925518035889
	val_positive_acc: 1.0
	val_negative_acc: 0.7452711223203027
test:
	test_positive_loss: 0.014791373163461685
	test_negative_loss: 1.29245924949646
	test_positive_acc: 0.9964948193034877
	test_negative_acc: 0.7303824285274225
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.028983579948544502
	train_incorrect_loss: 0.24942496418952942
	train_positive_loss: 0.05054648593068123
	train_negative_loss: 0.06667468696832657
	train_correct_acc: 0.9909698201110837
	train_incorrect_acc: 0.8979778878742769
	train_positive_acc: 0.9998107348024186
	train_negative_acc: 0.9586815028483077
	train_correct_nonzero: 35100
	train_incorrect_nonzero: 5000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00018837569223251194
	val_negative_loss: 0.6901229619979858
	val_positive_acc: 1.0
	val_negative_acc: 0.8795712484237075
test:
	test_positive_loss: 0.0063486248254776
	test_negative_loss: 1.1977046728134155
	test_positive_acc: 0.996859681372549
	test_negative_acc: 0.8162563900018635
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.1004376411438 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.275
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2345149517059326
	train_negative_loss: 2.280454635620117
	train_positive_acc: 0.6773676136085398
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.2056410014629364
	train_incorrect_loss: 1.2416456937789917
	train_positive_loss: 0.309280127286911
	train_negative_loss: 0.4141600728034973
	train_correct_acc: 0.9580666969965075
	train_incorrect_acc: 0.0980284157150428
	train_positive_acc: 0.993261000506428
	train_negative_acc: 0.6868329983990028
	train_correct_nonzero: 34600
	train_incorrect_nonzero: 5500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0017674495466053486
	val_negative_loss: 0.3814780116081238
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.004301563836634159
	test_negative_loss: 0.4147253930568695
	test_positive_acc: 1.0
	test_negative_acc: 0.9580964000693255
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.13998396694660187
	train_incorrect_loss: 1.2402609586715698
	train_positive_loss: 0.27227428555488586
	train_negative_loss: 0.32384470105171204
	train_correct_acc: 0.9916954850450308
	train_incorrect_acc: 0.04899313273435932
	train_positive_acc: 0.9973096640511299
	train_negative_acc: 0.7275652681205904
	train_correct_nonzero: 34600
	train_incorrect_nonzero: 5500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.008151044137775898
	val_negative_loss: 0.48417341709136963
	val_positive_acc: 1.0
	val_negative_acc: 0.8995376208490963
test:
	test_positive_loss: 0.015276525169610977
	test_negative_loss: 0.515923023223877
	test_positive_acc: 0.9912323602297706
	test_negative_acc: 0.8807802187872134
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.13362886011600494
	train_incorrect_loss: 1.1787594556808472
	train_positive_loss: 0.2589426636695862
	train_negative_loss: 0.31122928857803345
	train_correct_acc: 0.9846320311390651
	train_incorrect_acc: 0.13667843330416687
	train_positive_acc: 0.9978077911802647
	train_negative_acc: 0.7389734197499416
	train_correct_nonzero: 34600
	train_incorrect_nonzero: 5500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 6.618570478167385e-05
	val_negative_loss: 0.38006946444511414
	val_positive_acc: 1.0
	val_negative_acc: 0.9298024379991593
test:
	test_positive_loss: 0.0010868182871490717
	test_negative_loss: 0.5007059574127197
	test_positive_acc: 1.0
	test_negative_acc: 0.8966037666551936
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.12173920124769211
	train_incorrect_loss: 1.081446647644043
	train_positive_loss: 0.23608949780464172
	train_negative_loss: 0.28419771790504456
	train_correct_acc: 0.9771241131048972
	train_incorrect_acc: 0.27690317026231515
	train_positive_acc: 0.9985481856231582
	train_negative_acc: 0.7629101816560446
	train_correct_nonzero: 34600
	train_incorrect_nonzero: 5500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0006842967704869807
	val_negative_loss: 0.32399076223373413
	val_positive_acc: 1.0
	val_negative_acc: 0.9087852038671711
test:
	test_positive_loss: 0.0011072172783315182
	test_negative_loss: 0.5057237148284912
	test_positive_acc: 1.0
	test_negative_acc: 0.8792381627068807
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.10818392038345337
	train_incorrect_loss: 0.9542299509048462
	train_positive_loss: 0.20691990852355957
	train_negative_loss: 0.2547704577445984
	train_correct_acc: 0.9729910442686915
	train_incorrect_acc: 0.42045218230530795
	train_positive_acc: 0.9990460559192347
	train_negative_acc: 0.7956299210320287
	train_correct_nonzero: 34600
	train_incorrect_nonzero: 5500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00043044958147220314
	val_negative_loss: 0.49042853713035583
	val_positive_acc: 1.0
	val_negative_acc: 0.746321984026902
test:
	test_positive_loss: 0.00806619692593813
	test_negative_loss: 0.7200616598129272
	test_positive_acc: 0.996336511299435
	test_negative_acc: 0.7172506388425091
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.09319048374891281
	train_incorrect_loss: 0.7938785552978516
	train_positive_loss: 0.17349351942539215
	train_negative_loss: 0.21813732385635376
	train_correct_acc: 0.9734751988932615
	train_incorrect_acc: 0.5520431403202787
	train_positive_acc: 0.9989699421288867
	train_negative_acc: 0.8317248247546015
	train_correct_nonzero: 34600
	train_incorrect_nonzero: 5500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.7423460526042618e-06
	val_negative_loss: 0.42502033710479736
	val_positive_acc: 1.0
	val_negative_acc: 0.8175704077343422
test:
	test_positive_loss: 0.0007470825221389532
	test_negative_loss: 0.7656271457672119
	test_positive_acc: 1.0
	test_negative_acc: 0.8107157156197924
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.07551348209381104
	train_incorrect_loss: 0.6372631788253784
	train_positive_loss: 0.1374853551387787
	train_negative_loss: 0.17790542542934418
	train_correct_acc: 0.976484326609011
	train_incorrect_acc: 0.6652693293310045
	train_positive_acc: 0.9995646485950741
	train_negative_acc: 0.8683295045533037
	train_correct_nonzero: 34600
	train_incorrect_nonzero: 5500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.06346869468688965
	val_negative_loss: 0.4083230495452881
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.8257671290458175
test:
	test_positive_loss: 0.020603226497769356
	test_negative_loss: 0.6751449108123779
	test_positive_acc: 0.9918342068093964
	test_negative_acc: 0.7981033467310906
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.06283339112997055
	train_incorrect_loss: 0.5255907773971558
	train_positive_loss: 0.11341898888349533
	train_negative_loss: 0.14835482835769653
	train_correct_acc: 0.9797406875294703
	train_incorrect_acc: 0.7386064171336051
	train_positive_acc: 0.9997100857822689
	train_negative_acc: 0.893789853508344
	train_correct_nonzero: 34600
	train_incorrect_nonzero: 5500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.05862288549542427
	val_negative_loss: 0.14625665545463562
	val_positive_acc: 0.9743589743589743
	val_negative_acc: 0.9415720891130728
test:
	test_positive_loss: 0.028927354142069817
	test_negative_loss: 0.49175140261650085
	test_positive_acc: 0.9885668168466923
	test_negative_acc: 0.9008692410436857
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.048647139221429825
	train_incorrect_loss: 0.3825344145298004
	train_positive_loss: 0.08455583453178406
	train_negative_loss: 0.11464489251375198
	train_correct_acc: 0.9837107761352516
	train_incorrect_acc: 0.8226300463371048
	train_positive_acc: 0.9993704113274771
	train_negative_acc: 0.9229664071291177
	train_correct_nonzero: 34600
	train_incorrect_nonzero: 5500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0663493201136589
	val_negative_loss: 0.426738977432251
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.837536780159731
test:
	test_positive_loss: 0.042071059346199036
	test_negative_loss: 0.7639091610908508
	test_positive_acc: 0.9888568622473379
	test_negative_acc: 0.8355385862527801
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.03782188519835472
	train_incorrect_loss: 0.2939531207084656
	train_positive_loss: 0.06319267302751541
	train_negative_loss: 0.08741472661495209
	train_correct_acc: 0.987921764343043
	train_incorrect_acc: 0.8706600547814213
	train_positive_acc: 0.9994873724931301
	train_negative_acc: 0.9445249524742055
	train_correct_nonzero: 34600
	train_incorrect_nonzero: 5500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.023477287963032722
	val_negative_loss: 0.7484241724014282
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.8118957545187053
test:
	test_positive_loss: 0.010239595547318459
	test_negative_loss: 1.3457775115966797
	test_positive_acc: 0.9959863712434127
	test_negative_acc: 0.7350402206184593
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.28285098075867 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.3
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2344160079956055
	train_negative_loss: 2.2803797721862793
	train_positive_acc: 0.6797156146726531
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.21806000173091888
	train_incorrect_loss: 1.1608235836029053
	train_positive_loss: 0.30759313702583313
	train_negative_loss: 0.45153671503067017
	train_correct_acc: 0.953489661697535
	train_incorrect_acc: 0.1102290899856818
	train_positive_acc: 0.993485551863972
	train_negative_acc: 0.6626228294278566
	train_correct_nonzero: 34100
	train_incorrect_nonzero: 6000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0016922436188906431
	val_negative_loss: 0.46836280822753906
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.004237544722855091
	test_negative_loss: 0.49858224391937256
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9500244330285517
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.15118369460105896
	train_incorrect_loss: 1.1718329191207886
	train_positive_loss: 0.2743547856807709
	train_negative_loss: 0.358032763004303
	train_correct_acc: 0.9918649565273643
	train_incorrect_acc: 0.04324781253818535
	train_positive_acc: 0.9977857107066275
	train_negative_acc: 0.7028219487785822
	train_correct_nonzero: 34100
	train_incorrect_nonzero: 6000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.01139626931399107
	val_negative_loss: 0.4264819622039795
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.011913217604160309
	test_negative_loss: 0.45904821157455444
	test_positive_acc: 0.9922314596331253
	test_negative_acc: 0.9736890512939582
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.14327359199523926
	train_incorrect_loss: 1.118783712387085
	train_positive_loss: 0.26176717877388
	train_negative_loss: 0.34264659881591797
	train_correct_acc: 0.9865908173055927
	train_incorrect_acc: 0.12711937100918963
	train_positive_acc: 0.9985776761363373
	train_negative_acc: 0.7175119774795566
	train_correct_nonzero: 34100
	train_incorrect_nonzero: 6000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0002455008216202259
	val_negative_loss: 0.3617498278617859
	val_positive_acc: 1.0
	val_negative_acc: 0.9543926019335855
test:
	test_positive_loss: 0.0016302635194733739
	test_negative_loss: 0.4837852418422699
	test_positive_acc: 1.0
	test_negative_acc: 0.8979717175544154
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.13206079602241516
	train_incorrect_loss: 1.04188871383667
	train_positive_loss: 0.24274499714374542
	train_negative_loss: 0.3166041374206543
	train_correct_acc: 0.9772308906866007
	train_incorrect_acc: 0.2630736982569115
	train_positive_acc: 0.9990471064808176
	train_negative_acc: 0.7400173192923736
	train_correct_nonzero: 34100
	train_incorrect_nonzero: 6000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00020144613517913967
	val_negative_loss: 0.31675952672958374
	val_positive_acc: 1.0
	val_negative_acc: 0.9625893232450609
test:
	test_positive_loss: 0.0037879119627177715
	test_negative_loss: 0.5140318870544434
	test_positive_acc: 0.9989406779661016
	test_negative_acc: 0.8562831938858727
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.11952178925275803
	train_incorrect_loss: 0.9305820465087891
	train_positive_loss: 0.2156674712896347
	train_negative_loss: 0.287336140871048
	train_correct_acc: 0.9703111480448261
	train_incorrect_acc: 0.4064873031850107
	train_positive_acc: 0.9995691814932046
	train_negative_acc: 0.7720726432497005
	train_correct_nonzero: 34100
	train_incorrect_nonzero: 6000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00016521521320100874
	val_negative_loss: 0.3690279722213745
	val_positive_acc: 1.0
	val_negative_acc: 0.8841950399327448
test:
	test_positive_loss: 0.004350749775767326
	test_negative_loss: 0.6831091642379761
	test_positive_acc: 0.9978246065375302
	test_negative_acc: 0.7956697251014322
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.10193707048892975
	train_incorrect_loss: 0.7837901711463928
	train_positive_loss: 0.18204979598522186
	train_negative_loss: 0.2453506588935852
	train_correct_acc: 0.9720987174677378
	train_incorrect_acc: 0.5397155063486273
	train_positive_acc: 0.9995931197440312
	train_negative_acc: 0.8148359469886287
	train_correct_nonzero: 34100
	train_incorrect_nonzero: 6000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.007882080040872097
	val_negative_loss: 0.21932527422904968
	val_positive_acc: 1.0
	val_negative_acc: 0.9159310634720471
test:
	test_positive_loss: 0.017309455201029778
	test_negative_loss: 0.4016028940677643
	test_positive_acc: 0.9899209835133591
	test_negative_acc: 0.9005851027874306
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.08490361273288727
	train_incorrect_loss: 0.6474213600158691
	train_positive_loss: 0.14859838783740997
	train_negative_loss: 0.2044019252061844
	train_correct_acc: 0.9744726089598053
	train_incorrect_acc: 0.6559804149154831
	train_positive_acc: 0.9997063626729825
	train_negative_acc: 0.8548558023229876
	train_correct_nonzero: 34100
	train_incorrect_nonzero: 6000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.000296039623208344
	val_negative_loss: 0.6011394262313843
	val_positive_acc: 1.0
	val_negative_acc: 0.7662883564522909
test:
	test_positive_loss: 0.017706094309687614
	test_negative_loss: 0.8566100597381592
	test_positive_acc: 0.992850910803424
	test_negative_acc: 0.7184709482443016
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.06842287629842758
	train_incorrect_loss: 0.5012386441230774
	train_positive_loss: 0.11694849282503128
	train_negative_loss: 0.16472609341144562
	train_correct_acc: 0.9786223120686817
	train_incorrect_acc: 0.7560705366757439
	train_positive_acc: 0.9996937193981348
	train_negative_acc: 0.8907311311076148
	train_correct_nonzero: 34100
	train_incorrect_nonzero: 6000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0020228270441293716
	val_negative_loss: 0.4719686508178711
	val_positive_acc: 1.0
	val_negative_acc: 0.8795712484237075
test:
	test_positive_loss: 0.005852311849594116
	test_negative_loss: 0.8818644285202026
	test_positive_acc: 0.996336511299435
	test_negative_acc: 0.7966117973120652
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.05300454422831535
	train_incorrect_loss: 0.3800213932991028
	train_positive_loss: 0.08776501566171646
	train_negative_loss: 0.12815451622009277
	train_correct_acc: 0.9816434976536593
	train_incorrect_acc: 0.8231439897655249
	train_positive_acc: 0.9998036862941471
	train_negative_acc: 0.916355811049978
	train_correct_nonzero: 34100
	train_incorrect_nonzero: 6000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.05241469293832779
	val_negative_loss: 0.37313663959503174
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.844682639764607
test:
	test_positive_loss: 0.02910834550857544
	test_negative_loss: 1.085395336151123
	test_positive_acc: 0.9931684887712748
	test_negative_acc: 0.760749531830627
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.03828035667538643
	train_incorrect_loss: 0.2579633295536041
	train_positive_loss: 0.06027013435959816
	train_negative_loss: 0.09223329275846481
	train_correct_acc: 0.9870310927561446
	train_incorrect_acc: 0.8859517663899846
	train_positive_acc: 0.9997502231254976
	train_negative_acc: 0.9439056723224802
	train_correct_nonzero: 34100
	train_incorrect_nonzero: 6000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.032064519822597504
	val_negative_loss: 0.6426793932914734
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 0.7990752416981926
test:
	test_positive_loss: 0.02332637831568718
	test_negative_loss: 1.0435248613357544
	test_positive_acc: 0.9918664054379415
	test_negative_acc: 0.7699439307594002
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.432634353637695 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.325
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2343177795410156
	train_negative_loss: 2.2804057598114014
	train_positive_acc: 0.6832916175188505
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.22900983691215515
	train_incorrect_loss: 1.080924391746521
	train_positive_loss: 0.30357852578163147
	train_negative_loss: 0.4890410602092743
	train_correct_acc: 0.9510002684123519
	train_incorrect_acc: 0.11684399811920977
	train_positive_acc: 0.993195466059204
	train_negative_acc: 0.6404576446304016
	train_correct_nonzero: 33600
	train_incorrect_nonzero: 6500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0013398216105997562
	val_negative_loss: 0.517162024974823
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.0038723950274288654
	test_negative_loss: 0.5403345823287964
	test_positive_acc: 1.0
	test_negative_acc: 0.9523105740355777
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.1610940396785736
	train_incorrect_loss: 1.0952376127243042
	train_positive_loss: 0.2723141014575958
	train_negative_loss: 0.3915538787841797
	train_correct_acc: 0.9921339591432665
	train_incorrect_acc: 0.05035306518461348
	train_positive_acc: 0.9981534312641943
	train_negative_acc: 0.6812106080294853
	train_correct_nonzero: 33600
	train_incorrect_nonzero: 6500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00261248042806983
	val_negative_loss: 0.4669983983039856
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.008864586241543293
	test_negative_loss: 0.496385395526886
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9740332373947418
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.15525975823402405
	train_incorrect_loss: 1.0523632764816284
	train_positive_loss: 0.261273056268692
	train_negative_loss: 0.37975841760635376
	train_correct_acc: 0.9853751913991587
	train_incorrect_acc: 0.1216628893922032
	train_positive_acc: 0.9983132155492545
	train_negative_acc: 0.6930544793587216
	train_correct_nonzero: 33600
	train_incorrect_nonzero: 6500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 9.190604032482952e-05
	val_negative_loss: 0.36230331659317017
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.0025861114263534546
	test_negative_loss: 0.43491896986961365
	test_positive_acc: 1.0
	test_negative_acc: 0.9327775913083465
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.1417696624994278
	train_incorrect_loss: 0.982637882232666
	train_positive_loss: 0.24251748621463776
	train_negative_loss: 0.3486664593219757
	train_correct_acc: 0.9718859624144314
	train_incorrect_acc: 0.2884973860246189
	train_positive_acc: 0.9989484067552675
	train_negative_acc: 0.723294344573858
	train_correct_nonzero: 33600
	train_incorrect_nonzero: 6500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.339107252031681e-06
	val_negative_loss: 0.3910759687423706
	val_positive_acc: 1.0
	val_negative_acc: 0.9087852038671711
test:
	test_positive_loss: 0.0008549175690859556
	test_negative_loss: 0.560020923614502
	test_positive_acc: 1.0
	test_negative_acc: 0.860343819693238
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.12940974533557892
	train_incorrect_loss: 0.8684583306312561
	train_positive_loss: 0.21351203322410583
	train_negative_loss: 0.31870487332344055
	train_correct_acc: 0.9630524934992684
	train_incorrect_acc: 0.442102022353439
	train_positive_acc: 0.9993490616579912
	train_negative_acc: 0.7586993709514251
	train_correct_nonzero: 33600
	train_incorrect_nonzero: 6500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.773834694380639e-06
	val_negative_loss: 0.7153139114379883
	val_positive_acc: 1.0
	val_negative_acc: 0.5853299705758722
test:
	test_positive_loss: 0.00394090823829174
	test_negative_loss: 0.8736196756362915
	test_positive_acc: 0.9970652734778122
	test_negative_acc: 0.5251351556467245
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.11216846853494644
	train_incorrect_loss: 0.7387998700141907
	train_positive_loss: 0.1817118525505066
	train_negative_loss: 0.27599167823791504
	train_correct_acc: 0.9614689285917463
	train_incorrect_acc: 0.5937246413089472
	train_positive_acc: 0.9995591714506552
	train_negative_acc: 0.8041415538534924
	train_correct_nonzero: 33600
	train_incorrect_nonzero: 6500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0003102219197899103
	val_negative_loss: 0.22751875221729279
	val_positive_acc: 1.0
	val_negative_acc: 0.9159310634720471
test:
	test_positive_loss: 0.010359090752899647
	test_negative_loss: 0.3720969557762146
	test_positive_acc: 0.9944611068111455
	test_negative_acc: 0.9004987297322506
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.09252885729074478
	train_incorrect_loss: 0.5983229279518127
	train_positive_loss: 0.14649194478988647
	train_negative_loss: 0.2282109260559082
	train_correct_acc: 0.9654221294343215
	train_incorrect_acc: 0.6897933686312837
	train_positive_acc: 0.9997682762517223
	train_negative_acc: 0.842101381625278
	train_correct_nonzero: 33600
	train_incorrect_nonzero: 6500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00010994942567776889
	val_negative_loss: 0.4821598529815674
	val_positive_acc: 1.0
	val_negative_acc: 0.8200924758301807
test:
	test_positive_loss: 0.021015657112002373
	test_negative_loss: 0.7441084384918213
	test_positive_acc: 0.9929730115730502
	test_negative_acc: 0.6987499071239605
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.07120788842439651
	train_incorrect_loss: 0.44628700613975525
	train_positive_loss: 0.11063162237405777
	train_negative_loss: 0.17562413215637207
	train_correct_acc: 0.9732860417180467
	train_incorrect_acc: 0.7889985890311484
	train_positive_acc: 0.999623372708517
	train_negative_acc: 0.8870749257938128
	train_correct_nonzero: 33600
	train_incorrect_nonzero: 6500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.004343043547123671
	val_negative_loss: 1.006848931312561
	val_positive_acc: 1.0
	val_negative_acc: 0.6519546027742749
test:
	test_positive_loss: 0.03760237991809845
	test_negative_loss: 1.2546608448028564
	test_positive_acc: 0.9894617664622289
	test_negative_acc: 0.5915732233216968
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.053821053355932236
	train_incorrect_loss: 0.3177845776081085
	train_positive_loss: 0.07713406533002853
	train_negative_loss: 0.13152126967906952
	train_correct_acc: 0.9808233122294783
	train_incorrect_acc: 0.8608627758321495
	train_positive_acc: 0.999806133625449
	train_negative_acc: 0.9238211054557897
	train_correct_nonzero: 33600
	train_incorrect_nonzero: 6500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.3961937838757876e-05
	val_negative_loss: 0.372009813785553
	val_positive_acc: 1.0
	val_negative_acc: 0.8493064312736444
test:
	test_positive_loss: 0.02520826831459999
	test_negative_loss: 0.7171181440353394
	test_positive_acc: 0.9938534834426491
	test_negative_acc: 0.8398801310711606
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.035507239401340485
	train_incorrect_loss: 0.20882685482501984
	train_positive_loss: 0.05183589830994606
	train_negative_loss: 0.08743993192911148
	train_correct_acc: 0.987753861529254
	train_incorrect_acc: 0.9105210263361384
	train_positive_acc: 0.9999529478191314
	train_negative_acc: 0.9508139818613125
	train_correct_nonzero: 33600
	train_incorrect_nonzero: 6500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 4.643565716833109e-06
	val_negative_loss: 1.2204266786575317
	val_positive_acc: 1.0
	val_negative_acc: 0.6939890710382514
test:
	test_positive_loss: 0.04099075496196747
	test_negative_loss: 1.9683918952941895
	test_positive_acc: 0.9903932243390077
	test_negative_acc: 0.5632815888913971
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.348328590393066 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.35
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.234222412109375
	train_negative_loss: 2.280397415161133
	train_positive_acc: 0.6870120012317508
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.2415565401315689
	train_incorrect_loss: 1.0138304233551025
	train_positive_loss: 0.3002176880836487
	train_negative_loss: 0.5314909219741821
	train_correct_acc: 0.9410203377702803
	train_incorrect_acc: 0.15343326521252784
	train_positive_acc: 0.9946273843473187
	train_negative_acc: 0.6143423409374813
	train_correct_nonzero: 33100
	train_incorrect_nonzero: 7000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0024295421317219734
	val_negative_loss: 0.5577372312545776
	val_positive_acc: 1.0
	val_negative_acc: 0.959016393442623
test:
	test_positive_loss: 0.005012327339500189
	test_negative_loss: 0.5886644124984741
	test_positive_acc: 1.0
	test_negative_acc: 0.9416956223341166
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.17326457798480988
	train_incorrect_loss: 1.0259644985198975
	train_positive_loss: 0.2691819369792938
	train_negative_loss: 0.43045684695243835
	train_correct_acc: 0.9870772846366068
	train_incorrect_acc: 0.06759618669569954
	train_positive_acc: 0.9982459024082343
	train_negative_acc: 0.6555489066718382
	train_correct_nonzero: 33100
	train_incorrect_nonzero: 7000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.003614392364397645
	val_negative_loss: 0.5721652507781982
	val_positive_acc: 1.0
	val_negative_acc: 0.8770491803278688
test:
	test_positive_loss: 0.004792834632098675
	test_negative_loss: 0.6262496113777161
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.82123078458056
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.165615051984787
	train_incorrect_loss: 0.9799548983573914
	train_positive_loss: 0.257506787776947
	train_negative_loss: 0.41457387804985046
	train_correct_acc: 0.9755876608480217
	train_incorrect_acc: 0.1815625642403244
	train_positive_acc: 0.9983786774055343
	train_negative_acc: 0.6759990504036524
	train_correct_nonzero: 33100
	train_incorrect_nonzero: 7000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00013647758169099689
	val_negative_loss: 0.45469897985458374
	val_positive_acc: 1.0
	val_negative_acc: 0.9461958806221101
test:
	test_positive_loss: 0.002061206614598632
	test_negative_loss: 0.5168187618255615
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.8932998260392514
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.15345171093940735
	train_incorrect_loss: 0.9222280383110046
	train_positive_loss: 0.2406167984008789
	train_negative_loss: 0.3866642117500305
	train_correct_acc: 0.9619752076173836
	train_incorrect_acc: 0.3283600282510867
	train_positive_acc: 0.9991400463179022
	train_negative_acc: 0.7034004400153557
	train_correct_nonzero: 33100
	train_incorrect_nonzero: 7000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.1016068785684183e-05
	val_negative_loss: 0.5724841356277466
	val_positive_acc: 1.0
	val_negative_acc: 0.7299285414039512
test:
	test_positive_loss: 0.0012642480432987213
	test_negative_loss: 0.8078266382217407
	test_positive_acc: 1.0
	test_negative_acc: 0.672044094550721
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.14007675647735596
	train_incorrect_loss: 0.8369464874267578
	train_positive_loss: 0.21737191081047058
	train_negative_loss: 0.35369980335235596
	train_correct_acc: 0.9557628283525004
	train_incorrect_acc: 0.46021845332476147
	train_positive_acc: 0.9993678536334809
	train_negative_acc: 0.7405627775812297
	train_correct_nonzero: 33100
	train_incorrect_nonzero: 7000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0008147659245878458
	val_negative_loss: 0.6516727209091187
	val_positive_acc: 1.0
	val_negative_acc: 0.7217318200924758
test:
	test_positive_loss: 0.002591510768979788
	test_negative_loss: 0.8396811485290527
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.6109284568533293
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.12283521890640259
	train_incorrect_loss: 0.7127371430397034
	train_positive_loss: 0.18611523509025574
	train_negative_loss: 0.3092956840991974
	train_correct_acc: 0.9569779250940933
	train_incorrect_acc: 0.5853167659836799
	train_positive_acc: 0.9994609356498353
	train_negative_acc: 0.7844699945195328
	train_correct_nonzero: 33100
	train_incorrect_nonzero: 7000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.034478217363357544
	val_negative_loss: 0.29910808801651
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9262295081967213
test:
	test_positive_loss: 0.017356570810079575
	test_negative_loss: 0.46822187304496765
	test_positive_acc: 0.9931684887712748
	test_negative_acc: 0.8589361472256605
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.10428061336278915
	train_incorrect_loss: 0.6066551804542542
	train_positive_loss: 0.1572968065738678
	train_negative_loss: 0.2624534070491791
	train_correct_acc: 0.9627294858786076
	train_incorrect_acc: 0.680462520962498
	train_positive_acc: 0.9994003209535003
	train_negative_acc: 0.8274252087605638
	train_correct_nonzero: 33100
	train_incorrect_nonzero: 7000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0030791889876127243
	val_negative_loss: 0.699958086013794
	val_positive_acc: 1.0
	val_negative_acc: 0.6996637242538881
test:
	test_positive_loss: 0.005317314062267542
	test_negative_loss: 0.9818462133407593
	test_positive_acc: 0.9973958333333333
	test_negative_acc: 0.6644968556665634
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.08183855563402176
	train_incorrect_loss: 0.4614403247833252
	train_positive_loss: 0.1204322949051857
	train_negative_loss: 0.20643895864486694
	train_correct_acc: 0.9709962800079204
	train_incorrect_acc: 0.778992516653194
	train_positive_acc: 0.9996543583038526
	train_negative_acc: 0.8746156067609762
	train_correct_nonzero: 33100
	train_incorrect_nonzero: 7000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.017572781071066856
	val_negative_loss: 0.7410557270050049
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.6996637242538881
test:
	test_positive_loss: 0.022953234612941742
	test_negative_loss: 1.2399808168411255
	test_positive_acc: 0.9942845601998462
	test_negative_acc: 0.6624707235523044
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.06415454298257828
	train_incorrect_loss: 0.34278813004493713
	train_positive_loss: 0.08915631473064423
	train_negative_loss: 0.16274362802505493
	train_correct_acc: 0.9762478481291101
	train_incorrect_acc: 0.8485279047431199
	train_positive_acc: 0.999763401541153
	train_negative_acc: 0.9085548313163921
	train_correct_nonzero: 33100
	train_incorrect_nonzero: 7000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.05300962179899216
	val_negative_loss: 0.45423442125320435
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.8385876418663304
test:
	test_positive_loss: 0.027704454958438873
	test_negative_loss: 0.8387945890426636
	test_positive_acc: 0.9925804456032797
	test_negative_acc: 0.8008453975991591
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.04142531007528305
	train_incorrect_loss: 0.21879954636096954
	train_positive_loss: 0.05720255523920059
	train_negative_loss: 0.10424711555242538
	train_correct_acc: 0.9852955140525708
	train_incorrect_acc: 0.9081378558502395
	train_positive_acc: 0.9998949877080349
	train_negative_acc: 0.9435071020479886
	train_correct_nonzero: 33100
	train_incorrect_nonzero: 7000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.023749466985464096
	val_negative_loss: 1.2153706550598145
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.7288776796973518
test:
	test_positive_loss: 0.010288666002452374
	test_negative_loss: 1.647348165512085
	test_positive_acc: 0.9953438822337446
	test_negative_acc: 0.6788800568873359
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.10275220870972 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.375
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2341129779815674
	train_negative_loss: 2.2804253101348877
	train_positive_acc: 0.6900495560435597
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.2518772482872009
	train_incorrect_loss: 0.9475319385528564
	train_positive_loss: 0.29400715231895447
	train_negative_loss: 0.572075366973877
	train_correct_acc: 0.9295549739872037
	train_incorrect_acc: 0.19348513522827726
	train_positive_acc: 0.995760583220299
	train_negative_acc: 0.5908900749386858
	train_correct_nonzero: 32600
	train_incorrect_nonzero: 7500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.004995944909751415
	val_negative_loss: 0.557754635810852
	val_positive_acc: 1.0
	val_negative_acc: 0.9672131147540983
test:
	test_positive_loss: 0.0053482200019061565
	test_negative_loss: 0.5848394632339478
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9472380880852391
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.18421940505504608
	train_incorrect_loss: 0.9545461535453796
	train_positive_loss: 0.26434823870658875
	train_negative_loss: 0.46864762902259827
	train_correct_acc: 0.9794862049565443
	train_incorrect_acc: 0.09444139191529163
	train_positive_acc: 0.9979893077942572
	train_negative_acc: 0.6303159135675229
	train_correct_nonzero: 32600
	train_incorrect_nonzero: 7500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.012095187790691853
	val_negative_loss: 0.5625642538070679
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.87494745691467
test:
	test_positive_loss: 0.005612649954855442
	test_negative_loss: 0.612023651599884
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.8128789051225149
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.17543289065361023
	train_incorrect_loss: 0.9134209752082825
	train_positive_loss: 0.2527889907360077
	train_negative_loss: 0.44945231080055237
	train_correct_acc: 0.9630630974677413
	train_incorrect_acc: 0.24665341269688001
	train_positive_acc: 0.9981566633093397
	train_negative_acc: 0.6594492769625803
	train_correct_nonzero: 32600
	train_incorrect_nonzero: 7500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.910878356487956e-05
	val_negative_loss: 0.48462730646133423
	val_positive_acc: 1.0
	val_negative_acc: 0.8549810844892812
test:
	test_positive_loss: 0.0021988172084093094
	test_negative_loss: 0.659678041934967
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.7935989803760735
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.16285938024520874
	train_incorrect_loss: 0.8559370636940002
	train_positive_loss: 0.23509056866168976
	train_negative_loss: 0.41820913553237915
	train_correct_acc: 0.9515630696342546
	train_incorrect_acc: 0.38124618904154994
	train_positive_acc: 0.9987849688117322
	train_negative_acc: 0.6908697344934182
	train_correct_nonzero: 32600
	train_incorrect_nonzero: 7500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0003029911022167653
	val_negative_loss: 0.4770375192165375
	val_positive_acc: 1.0
	val_negative_acc: 0.7965531736023539
test:
	test_positive_loss: 0.0027625160291790962
	test_negative_loss: 0.6757441163063049
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.7460265909051198
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.1450803428888321
	train_incorrect_loss: 0.7561598420143127
	train_positive_loss: 0.2069065123796463
	train_negative_loss: 0.3734302222728729
	train_correct_acc: 0.948801645337096
	train_incorrect_acc: 0.5326511194215163
	train_positive_acc: 0.999396576277821
	train_negative_acc: 0.7427467394162565
	train_correct_nonzero: 32600
	train_incorrect_nonzero: 7500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 4.98170884384308e-05
	val_negative_loss: 0.6276711225509644
	val_positive_acc: 1.0
	val_negative_acc: 0.6483816729718369
test:
	test_positive_loss: 0.0067770639434456825
	test_negative_loss: 0.9751884341239929
	test_positive_acc: 0.996671365914787
	test_negative_acc: 0.5529916456102184
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.12517675757408142
	train_incorrect_loss: 0.6499889492988586
	train_positive_loss: 0.17778243124485016
	train_negative_loss: 0.32160285115242004
	train_correct_acc: 0.9534608151246873
	train_incorrect_acc: 0.6417715162278161
	train_positive_acc: 0.9994980912470038
	train_negative_acc: 0.7914428955328062
	train_correct_nonzero: 32600
	train_incorrect_nonzero: 7500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.03913407027721405
	val_negative_loss: 0.22992369532585144
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9497688104245481
test:
	test_positive_loss: 0.03407655283808708
	test_negative_loss: 0.39307042956352234
	test_positive_acc: 0.9882963516465482
	test_negative_acc: 0.8860214160480708
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.10215538740158081
	train_incorrect_loss: 0.5270931124687195
	train_positive_loss: 0.14386378228664398
	train_negative_loss: 0.2632271647453308
	train_correct_acc: 0.9616164647605394
	train_incorrect_acc: 0.7228505644886224
	train_positive_acc: 0.9997061530318723
	train_negative_acc: 0.8343919751563424
	train_correct_nonzero: 32600
	train_incorrect_nonzero: 7500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 9.224146197084337e-06
	val_negative_loss: 0.5824463963508606
	val_positive_acc: 1.0
	val_negative_acc: 0.7673392181588903
test:
	test_positive_loss: 0.027832351624965668
	test_negative_loss: 0.9918838739395142
	test_positive_acc: 0.9922857133486758
	test_negative_acc: 0.6694894321101276
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.07716107368469238
	train_incorrect_loss: 0.39677074551582336
	train_positive_loss: 0.1091497391462326
	train_negative_loss: 0.19942909479141235
	train_correct_acc: 0.9720366608617952
	train_incorrect_acc: 0.814091580964574
	train_positive_acc: 0.9995518778380548
	train_negative_acc: 0.885772149606883
	train_correct_nonzero: 32600
	train_incorrect_nonzero: 7500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.02168416418135166
	val_negative_loss: 0.7429031133651733
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.6914670029424128
test:
	test_positive_loss: 0.04243908077478409
	test_negative_loss: 1.3014177083969116
	test_positive_acc: 0.9897857133486758
	test_negative_acc: 0.6143812070750121
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.0600954033434391
	train_incorrect_loss: 0.3016762435436249
	train_positive_loss: 0.08233273774385452
	train_negative_loss: 0.15511983633041382
	train_correct_acc: 0.978269424743607
	train_incorrect_acc: 0.8603030913026581
	train_positive_acc: 0.9998520970049902
	train_negative_acc: 0.9128355136855727
	train_correct_nonzero: 32600
	train_incorrect_nonzero: 7500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.9234053727122955e-05
	val_negative_loss: 0.7000139355659485
	val_positive_acc: 1.0
	val_negative_acc: 0.7919293820933165
test:
	test_positive_loss: 0.02198467031121254
	test_negative_loss: 1.3633784055709839
	test_positive_acc: 0.9922857133486758
	test_negative_acc: 0.730075852916604
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.04377029463648796
	train_incorrect_loss: 0.22280453145503998
	train_positive_loss: 0.061018433421850204
	train_negative_loss: 0.11290724575519562
	train_correct_acc: 0.984759135411843
	train_incorrect_acc: 0.9029040923887641
	train_positive_acc: 0.9998133292242282
	train_negative_acc: 0.9390465606937451
	train_correct_nonzero: 32600
	train_incorrect_nonzero: 7500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00043835132964886725
	val_negative_loss: 1.014388084411621
	val_positive_acc: 1.0
	val_negative_acc: 0.6540563261874737
test:
	test_positive_loss: 0.027849724516272545
	test_negative_loss: 1.8477013111114502
	test_positive_acc: 0.992095035382574
	test_negative_acc: 0.657270524970658
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 40.965734004974365 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.4
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2340149879455566
	train_negative_loss: 2.280461311340332
	train_positive_acc: 0.6933570569302053
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.2634320855140686
	train_incorrect_loss: 0.8836389780044556
	train_positive_loss: 0.2874332070350647
	train_negative_loss: 0.6168143153190613
	train_correct_acc: 0.9161159913997933
	train_incorrect_acc: 0.24077593721925045
	train_positive_acc: 0.9961805290751775
	train_negative_acc: 0.5702051991604442
	train_correct_nonzero: 32100
	train_incorrect_nonzero: 8000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.002941808197647333
	val_negative_loss: 0.5922149419784546
	val_positive_acc: 1.0
	val_negative_acc: 0.9707860445565364
test:
	test_positive_loss: 0.004196579568088055
	test_negative_loss: 0.618793249130249
	test_positive_acc: 1.0
	test_negative_acc: 0.9202193978524318
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.19532467424869537
	train_incorrect_loss: 0.8916997313499451
	train_positive_loss: 0.2583341598510742
	train_negative_loss: 0.5102837681770325
	train_correct_acc: 0.9692854768363988
	train_incorrect_acc: 0.13722900233697527
	train_positive_acc: 0.9985930470579977
	train_negative_acc: 0.6082505982419373
	train_correct_nonzero: 32100
	train_incorrect_nonzero: 8000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0012421689461916685
	val_negative_loss: 0.5918071269989014
	val_positive_acc: 1.0
	val_negative_acc: 0.8118957545187053
test:
	test_positive_loss: 0.003113972255960107
	test_negative_loss: 0.6395235061645508
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.8140697474212183
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.18440185487270355
	train_incorrect_loss: 0.8509016036987305
	train_positive_loss: 0.2457215040922165
	train_negative_loss: 0.4856119751930237
	train_correct_acc: 0.9523473804497323
	train_incorrect_acc: 0.2894247596794076
	train_positive_acc: 0.9985817516569503
	train_negative_acc: 0.6417954558362519
	train_correct_nonzero: 32100
	train_incorrect_nonzero: 8000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 5.306191451381892e-05
	val_negative_loss: 0.5782316327095032
	val_positive_acc: 1.0
	val_negative_acc: 0.7253047498949138
test:
	test_positive_loss: 0.0026827710680663586
	test_negative_loss: 0.6947957277297974
	test_positive_acc: 0.9989035087719298
	test_negative_acc: 0.7166105968776023
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.1687077134847641
	train_incorrect_loss: 0.7857728600502014
	train_positive_loss: 0.22616246342658997
	train_negative_loss: 0.4456118643283844
	train_correct_acc: 0.9390262130982238
	train_incorrect_acc: 0.45591645753515997
	train_positive_acc: 0.9991414043933294
	train_negative_acc: 0.6854882181944951
	train_correct_nonzero: 32100
	train_incorrect_nonzero: 8000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.2160932783444878e-05
	val_negative_loss: 0.7432534694671631
	val_positive_acc: 1.0
	val_negative_acc: 0.6786464901219
test:
	test_positive_loss: 0.0015010097995400429
	test_negative_loss: 0.9494894742965698
	test_positive_acc: 1.0
	test_negative_acc: 0.5582120590488826
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.14922918379306793
	train_incorrect_loss: 0.6857975721359253
	train_positive_loss: 0.19606223702430725
	train_negative_loss: 0.39587727189064026
	train_correct_acc: 0.9383462655462024
	train_incorrect_acc: 0.599319143080637
	train_positive_acc: 0.999260209055683
	train_negative_acc: 0.7428816725314045
	train_correct_nonzero: 32100
	train_incorrect_nonzero: 8000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 4.465046004042961e-05
	val_negative_loss: 0.5868370532989502
	val_positive_acc: 1.0
	val_negative_acc: 0.7242538881883145
test:
	test_positive_loss: 0.008481287397444248
	test_negative_loss: 0.8770264387130737
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.6222941213933143
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.1300797313451767
	train_incorrect_loss: 0.5998615622520447
	train_positive_loss: 0.1721433848142624
	train_negative_loss: 0.3435958921909332
	train_correct_acc: 0.9495526491453457
	train_incorrect_acc: 0.6765303240407
	train_positive_acc: 0.9994842293788251
	train_negative_acc: 0.7913439980657894
	train_correct_nonzero: 32100
	train_incorrect_nonzero: 8000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0019233953207731247
	val_negative_loss: 0.4396507143974304
	val_positive_acc: 1.0
	val_negative_acc: 0.7990752416981926
test:
	test_positive_loss: 0.012828858569264412
	test_negative_loss: 0.714523196220398
	test_positive_acc: 0.9946194148151982
	test_negative_acc: 0.7333263354902855
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.10919804871082306
	train_incorrect_loss: 0.49377068877220154
	train_positive_loss: 0.14174668490886688
	train_negative_loss: 0.28873932361602783
	train_correct_acc: 0.9569757059521609
	train_incorrect_acc: 0.7507123804076767
	train_positive_acc: 0.9996145012252242
	train_negative_acc: 0.8320287803721008
	train_correct_nonzero: 32100
	train_incorrect_nonzero: 8000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00036729019484482706
	val_negative_loss: 0.8711477518081665
	val_positive_acc: 1.0
	val_negative_acc: 0.6437578814627996
test:
	test_positive_loss: 0.010206907987594604
	test_negative_loss: 1.2407245635986328
	test_positive_acc: 0.9946194148151982
	test_negative_acc: 0.6042552535352903
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.08371742069721222
	train_incorrect_loss: 0.3802737295627594
	train_positive_loss: 0.10910533368587494
	train_negative_loss: 0.2221747636795044
	train_correct_acc: 0.9680095885365154
	train_incorrect_acc: 0.8230621973595449
	train_positive_acc: 0.9998055111132489
	train_negative_acc: 0.8783317649387835
	train_correct_nonzero: 32100
	train_incorrect_nonzero: 8000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00023142187274061143
	val_negative_loss: 0.9224519729614258
	val_positive_acc: 1.0
	val_negative_acc: 0.5899537620849096
test:
	test_positive_loss: 0.02115520089864731
	test_negative_loss: 1.4272257089614868
	test_positive_acc: 0.9949695548712205
	test_negative_acc: 0.591728773797711
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.06783532351255417
	train_incorrect_loss: 0.2962326407432556
	train_positive_loss: 0.08509133756160736
	train_negative_loss: 0.17967109382152557
	train_correct_acc: 0.9738900677732841
	train_incorrect_acc: 0.8655645768048513
	train_positive_acc: 0.9997552251538143
	train_negative_acc: 0.904892663305657
	train_correct_nonzero: 32100
	train_incorrect_nonzero: 8000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0349675714969635
	val_negative_loss: 0.5294826030731201
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 0.8072719630096679
test:
	test_positive_loss: 0.06336644291877747
	test_negative_loss: 1.0696284770965576
	test_positive_acc: 0.9880521919941437
	test_negative_acc: 0.6808526045749308
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.04917150363326073
	train_incorrect_loss: 0.21145205199718475
	train_positive_loss: 0.060256436467170715
	train_negative_loss: 0.13038663566112518
	train_correct_acc: 0.9814421301274697
	train_incorrect_acc: 0.9083898402459736
	train_positive_acc: 0.9998059851580531
	train_negative_acc: 0.9345950180395141
	train_correct_nonzero: 32100
	train_incorrect_nonzero: 8000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0020397715270519257
	val_negative_loss: 0.8849947452545166
	val_positive_acc: 1.0
	val_negative_acc: 0.7114333753678016
test:
	test_positive_loss: 0.04083438217639923
	test_negative_loss: 1.5246968269348145
	test_positive_acc: 0.993131319577103
	test_negative_acc: 0.6758131759050877
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.19926309585571 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.425
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2339446544647217
	train_negative_loss: 2.2804436683654785
	train_positive_acc: 0.6968891955828773
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.2742406129837036
	train_incorrect_loss: 0.8242913484573364
	train_positive_loss: 0.27996769547462463
	train_negative_loss: 0.6626994013786316
	train_correct_acc: 0.8941871496485322
	train_incorrect_acc: 0.3009902268431502
	train_positive_acc: 0.9964788978101347
	train_negative_acc: 0.5442736950315314
	train_correct_nonzero: 31600
	train_incorrect_nonzero: 8500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0021313554607331753
	val_negative_loss: 0.7006086111068726
	val_positive_acc: 1.0
	val_negative_acc: 0.5069356872635561
test:
	test_positive_loss: 0.004623702727258205
	test_negative_loss: 0.7357659339904785
	test_positive_acc: 1.0
	test_negative_acc: 0.4603161289756339
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.20536495745182037
	train_incorrect_loss: 0.8315131068229675
	train_positive_loss: 0.25162723660469055
	train_negative_loss: 0.5517008304595947
	train_correct_acc: 0.9526598906709475
	train_incorrect_acc: 0.20200455952643276
	train_positive_acc: 0.9987884768874816
	train_negative_acc: 0.5871373292503562
	train_correct_nonzero: 31600
	train_incorrect_nonzero: 8500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0016227844171226025
	val_negative_loss: 0.6973650455474854
	val_positive_acc: 1.0
	val_negative_acc: 0.5361496427070198
test:
	test_positive_loss: 0.0025300337001681328
	test_negative_loss: 0.7728743553161621
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.5363050726333807
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.1923205554485321
	train_incorrect_loss: 0.794305145740509
	train_positive_loss: 0.23909147083759308
	train_negative_loss: 0.5203335285186768
	train_correct_acc: 0.9377972736363828
	train_incorrect_acc: 0.36690358961916214
	train_positive_acc: 0.9987920770704088
	train_negative_acc: 0.6350402651247746
	train_correct_nonzero: 31600
	train_incorrect_nonzero: 8500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.000549103831872344
	val_negative_loss: 0.6313754320144653
	val_positive_acc: 1.0
	val_negative_acc: 0.6412358133669609
test:
	test_positive_loss: 0.0022392100654542446
	test_negative_loss: 0.7281123399734497
	test_positive_acc: 1.0
	test_negative_acc: 0.6114916617231243
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.17700792849063873
	train_incorrect_loss: 0.7396580576896667
	train_positive_loss: 0.22126910090446472
	train_negative_loss: 0.47872352600097656
	train_correct_acc: 0.9292725201804246
	train_incorrect_acc: 0.5022606240264146
	train_positive_acc: 0.9990063308201118
	train_negative_acc: 0.6790705355740826
	train_correct_nonzero: 31600
	train_incorrect_nonzero: 8500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0009934055851772428
	val_negative_loss: 0.9031116366386414
	val_positive_acc: 1.0
	val_negative_acc: 0.45775535939470363
test:
	test_positive_loss: 0.0009967554360628128
	test_negative_loss: 1.1195259094238281
	test_positive_acc: 1.0
	test_negative_acc: 0.4463664936840557
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.15520307421684265
	train_incorrect_loss: 0.6465393900871277
	train_positive_loss: 0.1930912584066391
	train_negative_loss: 0.42184558510780334
	train_correct_acc: 0.9374372691640672
	train_incorrect_acc: 0.622197130004073
	train_positive_acc: 0.9992419269488308
	train_negative_acc: 0.7425457826807723
	train_correct_nonzero: 31600
	train_incorrect_nonzero: 8500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 8.068020179052837e-06
	val_negative_loss: 1.0676558017730713
	val_positive_acc: 1.0
	val_negative_acc: 0.4228667507356032
test:
	test_positive_loss: 0.0012487908825278282
	test_negative_loss: 1.3885738849639893
	test_positive_acc: 1.0
	test_negative_acc: 0.37275898168449284
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.13457758724689484
	train_incorrect_loss: 0.5567876696586609
	train_positive_loss: 0.1661539375782013
	train_negative_loss: 0.364422470331192
	train_correct_acc: 0.9454004433481541
	train_incorrect_acc: 0.7001872354017272
	train_positive_acc: 0.9996548504860777
	train_negative_acc: 0.7876383659108853
	train_correct_nonzero: 31600
	train_incorrect_nonzero: 8500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00021922355517745018
	val_negative_loss: 0.5662549734115601
	val_positive_acc: 1.0
	val_negative_acc: 0.7171080285834384
test:
	test_positive_loss: 0.0012442916631698608
	test_negative_loss: 0.8285139799118042
	test_positive_acc: 1.0
	test_negative_acc: 0.6913906770357822
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.11267778277397156
	train_incorrect_loss: 0.4595884382724762
	train_positive_loss: 0.1374230831861496
	train_negative_loss: 0.30424392223358154
	train_correct_acc: 0.9522001617074084
	train_incorrect_acc: 0.7732785842009379
	train_positive_acc: 0.9996540773529684
	train_negative_acc: 0.8302124208464117
	train_correct_nonzero: 31600
	train_incorrect_nonzero: 8500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0002261446206830442
	val_negative_loss: 0.9168412089347839
	val_positive_acc: 1.0
	val_negative_acc: 0.6202185792349726
test:
	test_positive_loss: 0.005494336131960154
	test_negative_loss: 1.2341649532318115
	test_positive_acc: 0.9974154135338346
	test_negative_acc: 0.5584748988429742
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.08489855378866196
	train_incorrect_loss: 0.3568252623081207
	train_positive_loss: 0.10584702342748642
	train_negative_loss: 0.2287355214357376
	train_correct_acc: 0.9666363327015087
	train_incorrect_acc: 0.8349122079557426
	train_positive_acc: 0.9997559449644869
	train_negative_acc: 0.8787055247500437
	train_correct_nonzero: 31600
	train_incorrect_nonzero: 8500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.865925918944413e-06
	val_negative_loss: 1.9370315074920654
	val_positive_acc: 1.0
	val_negative_acc: 0.4100462379150904
test:
	test_positive_loss: 0.00222946610301733
	test_negative_loss: 2.18519926071167
	test_positive_acc: 0.9989035087719298
	test_negative_acc: 0.4566932245055945
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.06462133675813675
	train_incorrect_loss: 0.26637470722198486
	train_positive_loss: 0.07888256758451462
	train_negative_loss: 0.17551854252815247
	train_correct_acc: 0.9752335758411251
	train_incorrect_acc: 0.8804409566433813
	train_positive_acc: 0.9999084162908094
	train_negative_acc: 0.9107140609490068
	train_correct_nonzero: 31600
	train_incorrect_nonzero: 8500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00015318057558033615
	val_negative_loss: 0.9213311672210693
	val_positive_acc: 1.0
	val_negative_acc: 0.7288776796973518
test:
	test_positive_loss: 0.010081298649311066
	test_negative_loss: 1.2676231861114502
	test_positive_acc: 0.9974154135338346
	test_negative_acc: 0.6922396865453699
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.04709232226014137
	train_incorrect_loss: 0.1922169327735901
	train_positive_loss: 0.05692301690578461
	train_negative_loss: 0.12790067493915558
	train_correct_acc: 0.9828283894975773
	train_incorrect_acc: 0.9190840343886718
	train_positive_acc: 0.999951102635568
	train_negative_acc: 0.9394730049375497
	train_correct_nonzero: 31600
	train_incorrect_nonzero: 8500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00027704762760549784
	val_negative_loss: 1.3388500213623047
	val_positive_acc: 1.0
	val_negative_acc: 0.6868432114333753
test:
	test_positive_loss: 0.01672932878136635
	test_negative_loss: 1.6753348112106323
	test_positive_acc: 0.99509741902834
	test_negative_acc: 0.6534399414477455
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 40.8039231300354 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.45
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2338531017303467
	train_negative_loss: 2.280409812927246
	train_positive_acc: 0.7003691726893747
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.283290833234787
	train_incorrect_loss: 0.7688782811164856
	train_positive_loss: 0.27133235335350037
	train_negative_loss: 0.7077721953392029
	train_correct_acc: 0.872188322352797
	train_incorrect_acc: 0.373702757807041
	train_positive_acc: 0.9972042224080339
	train_negative_acc: 0.5263837665621223
	train_correct_nonzero: 31100
	train_incorrect_nonzero: 9000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0019016144797205925
	val_negative_loss: 0.7271867990493774
	val_positive_acc: 1.0
	val_negative_acc: 0.27574611181168557
test:
	test_positive_loss: 0.005392877385020256
	test_negative_loss: 0.7634361386299133
	test_positive_acc: 1.0
	test_negative_acc: 0.2965932593858655
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.21485833823680878
	train_incorrect_loss: 0.7730041742324829
	train_positive_loss: 0.24309761822223663
	train_negative_loss: 0.5935012102127075
	train_correct_acc: 0.9244430881431355
	train_incorrect_acc: 0.32396398405966015
	train_positive_acc: 0.9988154765504613
	train_negative_acc: 0.5805061453401114
	train_correct_nonzero: 31100
	train_incorrect_nonzero: 9000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.002625967375934124
	val_negative_loss: 0.6248104572296143
	val_positive_acc: 1.0
	val_negative_acc: 0.7406473308112653
test:
	test_positive_loss: 0.003096591215580702
	test_negative_loss: 0.6922463178634644
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.7016622654764674
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.20023313164710999
	train_incorrect_loss: 0.7361477017402649
	train_positive_loss: 0.23030352592468262
	train_negative_loss: 0.5571863651275635
	train_correct_acc: 0.9161330279553634
	train_incorrect_acc: 0.46210135324682106
	train_positive_acc: 0.999112336754834
	train_negative_acc: 0.6297401576315648
	train_correct_nonzero: 31100
	train_incorrect_nonzero: 9000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00016579151269979775
	val_negative_loss: 0.6352553367614746
	val_positive_acc: 1.0
	val_negative_acc: 0.6822194199243379
test:
	test_positive_loss: 0.0017436263151466846
	test_negative_loss: 0.7740333080291748
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.583025725601133
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.1838526874780655
	train_incorrect_loss: 0.6805127859115601
	train_positive_loss: 0.21285496652126312
	train_negative_loss: 0.5109679102897644
	train_correct_acc: 0.9194657483241496
	train_incorrect_acc: 0.5674844037362711
	train_positive_acc: 0.9988358704245036
	train_negative_acc: 0.682624551822982
	train_correct_nonzero: 31100
	train_incorrect_nonzero: 9000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 4.407187952892855e-05
	val_negative_loss: 0.864680290222168
	val_positive_acc: 1.0
	val_negative_acc: 0.5479192938209332
test:
	test_positive_loss: 0.0007898170733824372
	test_negative_loss: 1.0598034858703613
	test_positive_acc: 1.0
	test_negative_acc: 0.5448550822267179
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.158931165933609
	train_incorrect_loss: 0.5997868776321411
	train_positive_loss: 0.18755175173282623
	train_negative_loss: 0.443999320268631
	train_correct_acc: 0.9341442706535855
	train_incorrect_acc: 0.6535828596418952
	train_positive_acc: 0.9992052135987425
	train_negative_acc: 0.7414294016422094
	train_correct_nonzero: 31100
	train_incorrect_nonzero: 9000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.1066234694444574e-06
	val_negative_loss: 1.1587462425231934
	val_positive_acc: 1.0
	val_negative_acc: 0.36338797814207646
test:
	test_positive_loss: 0.0023758052848279476
	test_negative_loss: 1.4796665906906128
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.3649388424992905
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.1377340853214264
	train_incorrect_loss: 0.5182860493659973
	train_positive_loss: 0.16215425729751587
	train_negative_loss: 0.3819047808647156
	train_correct_acc: 0.9436808988887205
	train_incorrect_acc: 0.7192056559388674
	train_positive_acc: 0.9991926317936933
	train_negative_acc: 0.7878400344160145
	train_correct_nonzero: 31100
	train_incorrect_nonzero: 9000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00011396203626645729
	val_negative_loss: 0.410392165184021
	val_positive_acc: 1.0
	val_negative_acc: 0.7826817990752417
test:
	test_positive_loss: 0.009322427213191986
	test_negative_loss: 0.6823470592498779
	test_positive_acc: 0.9944133004946453
	test_negative_acc: 0.7270611646166361
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.11225230991840363
	train_incorrect_loss: 0.4214850068092346
	train_positive_loss: 0.1316707283258438
	train_negative_loss: 0.3130665421485901
	train_correct_acc: 0.9548124178126303
	train_incorrect_acc: 0.7875856780108028
	train_positive_acc: 0.999446204166706
	train_negative_acc: 0.8353349503265795
	train_correct_nonzero: 31100
	train_incorrect_nonzero: 9000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0005986017058603466
	val_negative_loss: 0.7022573947906494
	val_positive_acc: 1.0
	val_negative_acc: 0.6786464901219
test:
	test_positive_loss: 0.019081860780715942
	test_negative_loss: 1.141513466835022
	test_positive_acc: 0.9919261058531953
	test_negative_acc: 0.6154960108885758
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.08359061181545258
	train_incorrect_loss: 0.31975382566452026
	train_positive_loss: 0.09934227168560028
	train_negative_loss: 0.23360012471675873
	train_correct_acc: 0.9684812491856671
	train_incorrect_acc: 0.8533040286491823
	train_positive_acc: 0.9996060759746265
	train_negative_acc: 0.8855839795142305
	train_correct_nonzero: 31100
	train_incorrect_nonzero: 9000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.007145126350224018
	val_negative_loss: 1.0286753177642822
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 0.6284153005464481
test:
	test_positive_loss: 0.02503264509141445
	test_negative_loss: 1.4079939126968384
	test_positive_acc: 0.9886542211626554
	test_negative_acc: 0.5920320139395814
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.06846064329147339
	train_incorrect_loss: 0.2606266736984253
	train_positive_loss: 0.07994911074638367
	train_negative_loss: 0.18986880779266357
	train_correct_acc: 0.9738616558702653
	train_incorrect_acc: 0.8821372001447576
	train_positive_acc: 0.9999591185969502
	train_negative_acc: 0.9068000760349019
	train_correct_nonzero: 31100
	train_incorrect_nonzero: 9000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 7.193976489361376e-05
	val_negative_loss: 1.3153470754623413
	val_positive_acc: 1.0
	val_negative_acc: 0.557166876839008
test:
	test_positive_loss: 0.007452517282217741
	test_negative_loss: 1.9250930547714233
	test_positive_acc: 0.9963967339299786
	test_negative_acc: 0.5464971136510848
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.048560407012701035
	train_incorrect_loss: 0.17910829186439514
	train_positive_loss: 0.05614308640360832
	train_negative_loss: 0.13527828454971313
	train_correct_acc: 0.9823109146515395
	train_incorrect_acc: 0.9252837033945863
	train_positive_acc: 0.9997209499146292
	train_negative_acc: 0.9392703252770574
	train_correct_nonzero: 31100
	train_incorrect_nonzero: 9000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 4.592476088305375e-08
	val_negative_loss: 2.3344874382019043
	val_positive_acc: 1.0
	val_negative_acc: 0.4567044976881042
test:
	test_positive_loss: 0.01360875740647316
	test_negative_loss: 3.1775403022766113
	test_positive_acc: 0.9953002427019084
	test_negative_acc: 0.48061997788702804
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.19214677810669 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.475
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2338171005249023
	train_negative_loss: 2.280332565307617
	train_positive_acc: 0.702860990901652
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.2932705283164978
	train_incorrect_loss: 0.71830815076828
	train_positive_loss: 0.2629961669445038
	train_negative_loss: 0.7583466172218323
	train_correct_acc: 0.8452731078199406
	train_incorrect_acc: 0.47432957893764416
	train_positive_acc: 0.9977183192724484
	train_negative_acc: 0.5183212338433072
	train_correct_nonzero: 30600
	train_incorrect_nonzero: 9500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.005571151617914438
	val_negative_loss: 0.7330435514450073
	val_positive_acc: 1.0
	val_negative_acc: 0.27574611181168557
test:
	test_positive_loss: 0.010240934789180756
	test_negative_loss: 0.7615554332733154
	test_positive_acc: 1.0
	test_negative_acc: 0.24139878791052516
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.2246669977903366
	train_incorrect_loss: 0.722189724445343
	train_positive_loss: 0.23561255633831024
	train_negative_loss: 0.6405953168869019
	train_correct_acc: 0.8935748985097273
	train_incorrect_acc: 0.4270296664928621
	train_positive_acc: 0.9991403633968143
	train_negative_acc: 0.5681346920170602
	train_correct_nonzero: 30600
	train_incorrect_nonzero: 9500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0016317410627380013
	val_negative_loss: 0.6937391757965088
	val_positive_acc: 1.0
	val_negative_acc: 0.601723413198823
test:
	test_positive_loss: 0.0023040003143250942
	test_negative_loss: 0.7491256594657898
	test_positive_acc: 1.0
	test_negative_acc: 0.5683827469205995
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.20992594957351685
	train_incorrect_loss: 0.6908818483352661
	train_positive_loss: 0.22437864542007446
	train_negative_loss: 0.6027828454971313
	train_correct_acc: 0.9006687871205826
	train_incorrect_acc: 0.5209950614598873
	train_positive_acc: 0.9991656704091753
	train_negative_acc: 0.6225517596986843
	train_correct_nonzero: 30600
	train_incorrect_nonzero: 9500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.001108794822357595
	val_negative_loss: 0.5290483236312866
	val_positive_acc: 1.0
	val_negative_acc: 0.8072719630096679
test:
	test_positive_loss: 0.003658509813249111
	test_negative_loss: 0.6515984535217285
	test_positive_acc: 0.9989035087719298
	test_negative_acc: 0.6971100394039516
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.19243402779102325
	train_incorrect_loss: 0.644935667514801
	train_positive_loss: 0.20910727977752686
	train_negative_loss: 0.553026556968689
	train_correct_acc: 0.9084191464544867
	train_incorrect_acc: 0.5940349004900559
	train_positive_acc: 0.9988319944830183
	train_negative_acc: 0.6690717173208823
	train_correct_nonzero: 30600
	train_incorrect_nonzero: 9500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 6.195454625412822e-05
	val_negative_loss: 0.5871177911758423
	val_positive_acc: 1.0
	val_negative_acc: 0.716057166876839
test:
	test_positive_loss: 0.0036253107246011496
	test_negative_loss: 0.7546316385269165
	test_positive_acc: 0.9975737215378873
	test_negative_acc: 0.6875730409758524
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.16837933659553528
	train_incorrect_loss: 0.5676605105400085
	train_positive_loss: 0.18404614925384521
	train_negative_loss: 0.48658767342567444
	train_correct_acc: 0.9221441283788574
	train_incorrect_acc: 0.6826993647314235
	train_positive_acc: 0.9994266295773916
	train_negative_acc: 0.7305031726059468
	train_correct_nonzero: 30600
	train_incorrect_nonzero: 9500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.0296536717978597e-07
	val_negative_loss: 1.2269001007080078
	val_positive_acc: 1.0
	val_negative_acc: 0.36338797814207646
test:
	test_positive_loss: 0.0011982081923633814
	test_negative_loss: 1.4691743850708008
	test_positive_acc: 1.0
	test_negative_acc: 0.3663285770152526
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.1491045355796814
	train_incorrect_loss: 0.509673535823822
	train_positive_loss: 0.16357290744781494
	train_negative_loss: 0.4300132095813751
	train_correct_acc: 0.9328347270109036
	train_incorrect_acc: 0.7274390523301766
	train_positive_acc: 0.9997095237914182
	train_negative_acc: 0.7702030266156162
	train_correct_nonzero: 30600
	train_incorrect_nonzero: 9500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.5894975149421953e-05
	val_negative_loss: 0.3582214415073395
	val_positive_acc: 1.0
	val_negative_acc: 0.8621269440941572
test:
	test_positive_loss: 0.016370980069041252
	test_negative_loss: 0.5405540466308594
	test_positive_acc: 0.9949695548712205
	test_negative_acc: 0.7836883136070973
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.1218024268746376
	train_incorrect_loss: 0.4163261353969574
	train_positive_loss: 0.13465836644172668
	train_negative_loss: 0.3512875735759735
	train_correct_acc: 0.9483239938611145
	train_incorrect_acc: 0.7947503178312054
	train_positive_acc: 0.9997550532111065
	train_negative_acc: 0.8240068288848628
	train_correct_nonzero: 30600
	train_incorrect_nonzero: 9500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0005165227921679616
	val_negative_loss: 0.9378124475479126
	val_positive_acc: 1.0
	val_negative_acc: 0.6309373686422867
test:
	test_positive_loss: 0.015543639659881592
	test_negative_loss: 1.211726427078247
	test_positive_acc: 0.9937195548712205
	test_negative_acc: 0.5557585633812305
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.09433980286121368
	train_incorrect_loss: 0.3280615210533142
	train_positive_loss: 0.10557618737220764
	train_negative_loss: 0.27028754353523254
	train_correct_acc: 0.9619242833015893
	train_incorrect_acc: 0.8506544015570365
	train_positive_acc: 0.9996824629059271
	train_negative_acc: 0.8713386229352121
	train_correct_nonzero: 30600
	train_incorrect_nonzero: 9500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 5.960450621955715e-08
	val_negative_loss: 2.282219648361206
	val_positive_acc: 1.0
	val_negative_acc: 0.317780580075662
test:
	test_positive_loss: 0.0018426913302391768
	test_negative_loss: 2.8502306938171387
	test_positive_acc: 0.9986702127659575
	test_negative_acc: 0.3327286826956741
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.07400188595056534
	train_incorrect_loss: 0.24410060048103333
	train_positive_loss: 0.07860569655895233
	train_negative_loss: 0.2141416221857071
	train_correct_acc: 0.9707615190146665
	train_incorrect_acc: 0.8918566706396311
	train_positive_acc: 0.9997760517401848
	train_negative_acc: 0.9047684312121304
	train_correct_nonzero: 30600
	train_incorrect_nonzero: 9500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.7062493245466612e-05
	val_negative_loss: 1.674639105796814
	val_positive_acc: 1.0
	val_negative_acc: 0.567885666246322
test:
	test_positive_loss: 0.012411486357450485
	test_negative_loss: 2.116412878036499
	test_positive_acc: 0.9986702127659575
	test_negative_acc: 0.5400851178828643
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.05255947262048721
	train_incorrect_loss: 0.1829620897769928
	train_positive_loss: 0.05884888395667076
	train_negative_loss: 0.15349391102790833
	train_correct_acc: 0.9800011172488552
	train_incorrect_acc: 0.9253723712550851
	train_positive_acc: 0.9999546588075267
	train_negative_acc: 0.9342641217205689
	train_correct_nonzero: 30600
	train_incorrect_nonzero: 9500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00027157581644132733
	val_negative_loss: 2.110464572906494
	val_positive_acc: 1.0
	val_negative_acc: 0.5653635981504834
test:
	test_positive_loss: 0.014822948724031448
	test_negative_loss: 2.2603960037231445
	test_positive_acc: 0.9986702127659575
	test_negative_acc: 0.5816116638192328
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.12877058982849 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.5
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233757734298706
	train_negative_loss: 2.2803099155426025
	train_positive_acc: 0.7051644685685265
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.30244237184524536
	train_incorrect_loss: 0.667185366153717
	train_positive_loss: 0.25356757640838623
	train_negative_loss: 0.810063362121582
	train_correct_acc: 0.824684346974447
	train_incorrect_acc: 0.5509866849420123
	train_positive_acc: 0.9980683777312557
	train_negative_acc: 0.5160831689380887
	train_correct_nonzero: 30100
	train_incorrect_nonzero: 10000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0037624791730195284
	val_negative_loss: 0.9016004800796509
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.007198263891041279
	test_negative_loss: 0.9285341501235962
	test_positive_acc: 1.0
	test_negative_acc: 0.001524390243902439
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.2343202829360962
	train_incorrect_loss: 0.6768977046012878
	train_positive_loss: 0.2284269779920578
	train_negative_loss: 0.6915008425712585
	train_correct_acc: 0.8585561091432131
	train_incorrect_acc: 0.5204415090058045
	train_positive_acc: 0.999515321319917
	train_negative_acc: 0.5500780517370408
	train_correct_nonzero: 30100
	train_incorrect_nonzero: 10000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.002706443192437291
	val_negative_loss: 0.7391493320465088
	val_positive_acc: 1.0
	val_negative_acc: 0.5468684321143338
test:
	test_positive_loss: 0.0036269654519855976
	test_negative_loss: 0.7994036674499512
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.500136569312098
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.22194252908229828
	train_incorrect_loss: 0.6542922854423523
	train_positive_loss: 0.21972393989562988
	train_negative_loss: 0.6587867140769958
	train_correct_acc: 0.8759984908043373
	train_incorrect_acc: 0.5668826094336809
	train_positive_acc: 0.9992417569528618
	train_negative_acc: 0.5998905638138822
	train_correct_nonzero: 30100
	train_incorrect_nonzero: 10000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0012569496175274253
	val_negative_loss: 0.7199093103408813
	val_positive_acc: 1.0
	val_negative_acc: 0.6027742749054225
test:
	test_positive_loss: 0.0029143993742763996
	test_negative_loss: 0.8605998754501343
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.5646428926300018
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.2022765725851059
	train_incorrect_loss: 0.6121900081634521
	train_positive_loss: 0.20507793128490448
	train_negative_loss: 0.6006919741630554
	train_correct_acc: 0.8986612077319126
	train_incorrect_acc: 0.6246805807012702
	train_positive_acc: 0.9992166257379611
	train_negative_acc: 0.6625210421301605
	train_correct_nonzero: 30100
	train_incorrect_nonzero: 10000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00010350083175580949
	val_negative_loss: 0.9131484627723694
	val_positive_acc: 1.0
	val_negative_acc: 0.4930643127364439
test:
	test_positive_loss: 0.001282974611967802
	test_negative_loss: 1.2032620906829834
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.4717206821810047
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.1780361831188202
	train_incorrect_loss: 0.5486060380935669
	train_positive_loss: 0.18383829295635223
	train_negative_loss: 0.5316326022148132
	train_correct_acc: 0.9185348383555679
	train_incorrect_acc: 0.6834577429339157
	train_positive_acc: 0.9995682689495698
	train_negative_acc: 0.7200362140044663
	train_correct_nonzero: 30100
	train_incorrect_nonzero: 10000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00026445105322636664
	val_negative_loss: 0.9906798601150513
	val_positive_acc: 1.0
	val_negative_acc: 0.47309794031105507
test:
	test_positive_loss: 0.00248440052382648
	test_negative_loss: 1.3156604766845703
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.456242233943534
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.15378350019454956
	train_incorrect_loss: 0.4766155481338501
	train_positive_loss: 0.15926894545555115
	train_negative_loss: 0.45595064759254456
	train_correct_acc: 0.9321798253834469
	train_incorrect_acc: 0.7361114604142633
	train_positive_acc: 0.9995920395154388
	train_negative_acc: 0.7672666272417067
	train_correct_nonzero: 30100
	train_incorrect_nonzero: 10000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.01233640406280756
	val_negative_loss: 0.8988437056541443
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.5828079024800337
test:
	test_positive_loss: 0.01471489667892456
	test_negative_loss: 1.2208503484725952
	test_positive_acc: 0.9927569922145789
	test_negative_acc: 0.48356907664398907
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.1276317536830902
	train_incorrect_loss: 0.39672330021858215
	train_positive_loss: 0.13249275088310242
	train_negative_loss: 0.3807857036590576
	train_correct_acc: 0.946107538826532
	train_incorrect_acc: 0.7971308969979417
	train_positive_acc: 0.9998332541661719
	train_negative_acc: 0.8181521559074724
	train_correct_nonzero: 30100
	train_incorrect_nonzero: 10000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0007899461779743433
	val_negative_loss: 0.9407151937484741
	val_positive_acc: 1.0
	val_negative_acc: 0.6612021857923497
test:
	test_positive_loss: 0.028905434533953667
	test_negative_loss: 1.1316373348236084
	test_positive_acc: 0.9904421773997643
	test_negative_acc: 0.634473996202747
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.09655345231294632
	train_incorrect_loss: 0.3093729019165039
	train_positive_loss: 0.10298885405063629
	train_negative_loss: 0.28711065649986267
	train_correct_acc: 0.961266672257827
	train_incorrect_acc: 0.8498612257621919
	train_positive_acc: 0.999657795832978
	train_negative_acc: 0.8676556839084134
	train_correct_nonzero: 30100
	train_incorrect_nonzero: 10000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 8.281529517262243e-06
	val_negative_loss: 2.0177271366119385
	val_positive_acc: 1.0
	val_negative_acc: 0.43926019335855404
test:
	test_positive_loss: 0.015764620155096054
	test_negative_loss: 2.4549288749694824
	test_positive_acc: 0.9928367794486215
	test_negative_acc: 0.38061602401444294
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.07296056300401688
	train_incorrect_loss: 0.22569383680820465
	train_positive_loss: 0.07545742392539978
	train_negative_loss: 0.21694353222846985
	train_correct_acc: 0.9722324823217887
	train_incorrect_acc: 0.8961800862618373
	train_positive_acc: 0.999821203756891
	train_negative_acc: 0.9065075571126597
	train_correct_nonzero: 30100
	train_incorrect_nonzero: 10000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.2962567552676774e-06
	val_negative_loss: 1.8384335041046143
	val_positive_acc: 1.0
	val_negative_acc: 0.5397225725094578
test:
	test_positive_loss: 0.013983342796564102
	test_negative_loss: 2.36968994140625
	test_positive_acc: 0.9951832706766917
	test_negative_acc: 0.5449808429426706
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.055947452783584595
	train_incorrect_loss: 0.1649194061756134
	train_positive_loss: 0.055871348828077316
	train_negative_loss: 0.16951897740364075
	train_correct_acc: 0.9785448660132532
	train_incorrect_acc: 0.9276337824852215
	train_positive_acc: 0.9998561387034361
	train_negative_acc: 0.9312329718344006
	train_correct_nonzero: 30100
	train_incorrect_nonzero: 10000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0033911685459315777
	val_negative_loss: 1.1858501434326172
	val_positive_acc: 1.0
	val_negative_acc: 0.6693989071038251
test:
	test_positive_loss: 0.05157160013914108
	test_negative_loss: 1.6679017543792725
	test_positive_acc: 0.9915995848071716
	test_negative_acc: 0.6725982300011104
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 40.8421528339386 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.525
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233675956726074
	train_negative_loss: 2.2802953720092773
	train_positive_acc: 0.7078619092082715
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.3099067807197571
	train_incorrect_loss: 0.6196913719177246
	train_positive_loss: 0.2433898001909256
	train_negative_loss: 0.8629570603370667
	train_correct_acc: 0.7945696802825385
	train_incorrect_acc: 0.6595451157050756
	train_positive_acc: 0.9981169256723873
	train_negative_acc: 0.5192861709961064
	train_correct_nonzero: 29600
	train_incorrect_nonzero: 10500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0041834088042378426
	val_negative_loss: 0.8570672273635864
	val_positive_acc: 1.0
	val_negative_acc: 0.01639344262295082
test:
	test_positive_loss: 0.010053489357233047
	test_negative_loss: 0.8756675720214844
	test_positive_acc: 1.0
	test_negative_acc: 0.017508696732464465
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.24252265691757202
	train_incorrect_loss: 0.6322856545448303
	train_positive_loss: 0.21999020874500275
	train_negative_loss: 0.7419763803482056
	train_correct_acc: 0.8153721146960904
	train_incorrect_acc: 0.6423382580570777
	train_positive_acc: 0.9994933145751684
	train_negative_acc: 0.5408842160612891
	train_correct_nonzero: 29600
	train_incorrect_nonzero: 10500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00033963314490392804
	val_negative_loss: 0.8480650186538696
	val_positive_acc: 1.0
	val_negative_acc: 0.3213535098781001
test:
	test_positive_loss: 0.0016759522259235382
	test_negative_loss: 0.9432159662246704
	test_positive_acc: 1.0
	test_negative_acc: 0.3392369128510935
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.23144210875034332
	train_incorrect_loss: 0.6172196269035339
	train_positive_loss: 0.2138070911169052
	train_negative_loss: 0.7116544842720032
	train_correct_acc: 0.8515207682525358
	train_incorrect_acc: 0.6359435468250694
	train_positive_acc: 0.9995059930132183
	train_negative_acc: 0.5922300981864212
	train_correct_nonzero: 29600
	train_incorrect_nonzero: 10500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.001816530479118228
	val_negative_loss: 0.7766348123550415
	val_positive_acc: 1.0
	val_negative_acc: 0.32597730138713743
test:
	test_positive_loss: 0.0042142439633607864
	test_negative_loss: 0.8685328960418701
	test_positive_acc: 1.0
	test_negative_acc: 0.3285172216998523
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.2147742062807083
	train_incorrect_loss: 0.5834211707115173
	train_positive_loss: 0.20192119479179382
	train_negative_loss: 0.6602758169174194
	train_correct_acc: 0.8768020382222308
	train_incorrect_acc: 0.6610814920007713
	train_positive_acc: 0.9995102022064852
	train_negative_acc: 0.6408515412430208
	train_correct_nonzero: 29600
	train_incorrect_nonzero: 10500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00018100417219102383
	val_negative_loss: 0.9962326288223267
	val_positive_acc: 1.0
	val_negative_acc: 0.3167297183690626
test:
	test_positive_loss: 0.000697965850122273
	test_negative_loss: 1.1349058151245117
	test_positive_acc: 1.0
	test_negative_acc: 0.34927652502607137
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.19047635793685913
	train_incorrect_loss: 0.531549334526062
	train_positive_loss: 0.18404942750930786
	train_negative_loss: 0.5879937410354614
	train_correct_acc: 0.9040405998453039
	train_incorrect_acc: 0.7037745652308616
	train_positive_acc: 0.9995778648231568
	train_negative_acc: 0.7021832765198407
	train_correct_nonzero: 29600
	train_incorrect_nonzero: 10500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0002082700520986691
	val_negative_loss: 0.7326091527938843
	val_positive_acc: 1.0
	val_negative_acc: 0.6099201345102985
test:
	test_positive_loss: 0.003470337949693203
	test_negative_loss: 1.0370090007781982
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.5754087802865865
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.16650164127349854
	train_incorrect_loss: 0.4724528193473816
	train_positive_loss: 0.16297616064548492
	train_negative_loss: 0.511702835559845
	train_correct_acc: 0.9229323412895202
	train_incorrect_acc: 0.7403171203419879
	train_positive_acc: 0.9998129631779936
	train_negative_acc: 0.7505590434184048
	train_correct_nonzero: 29600
	train_incorrect_nonzero: 10500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.013857053592801094
	val_negative_loss: 1.1234962940216064
	val_positive_acc: 1.0
	val_negative_acc: 0.38335435056746536
test:
	test_positive_loss: 0.004757724702358246
	test_negative_loss: 1.2883837223052979
	test_positive_acc: 0.9975541413373861
	test_negative_acc: 0.4064160756765966
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.13556024432182312
	train_incorrect_loss: 0.39556583762168884
	train_positive_loss: 0.1362195611000061
	train_negative_loss: 0.4174194037914276
	train_correct_acc: 0.9425283120464666
	train_incorrect_acc: 0.7955691549328376
	train_positive_acc: 0.9999491068247748
	train_negative_acc: 0.808344258984171
	train_correct_nonzero: 29600
	train_incorrect_nonzero: 10500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0006418955163098872
	val_negative_loss: 0.869317889213562
	val_positive_acc: 1.0
	val_negative_acc: 0.5807061790668349
test:
	test_positive_loss: 0.003660063026472926
	test_negative_loss: 1.3713202476501465
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.5395326815766648
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.10686047375202179
	train_incorrect_loss: 0.32012444734573364
	train_positive_loss: 0.11005225032567978
	train_negative_loss: 0.3296562135219574
	train_correct_acc: 0.9556829858520414
	train_incorrect_acc: 0.8471993652824361
	train_positive_acc: 0.9996992100097198
	train_negative_acc: 0.8553790419522868
	train_correct_nonzero: 29600
	train_incorrect_nonzero: 10500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 4.192335723018914e-07
	val_negative_loss: 2.0067696571350098
	val_positive_acc: 1.0
	val_negative_acc: 0.3879781420765027
test:
	test_positive_loss: 0.00035099737579002976
	test_negative_loss: 2.699738025665283
	test_positive_acc: 1.0
	test_negative_acc: 0.38126864784015446
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.08376363664865494
	train_incorrect_loss: 0.238950714468956
	train_positive_loss: 0.0827641487121582
	train_negative_loss: 0.25826096534729004
	train_correct_acc: 0.9676890930739869
	train_incorrect_acc: 0.8866993368741597
	train_positive_acc: 0.999944582986977
	train_negative_acc: 0.892321760825627
	train_correct_nonzero: 29600
	train_incorrect_nonzero: 10500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 4.159863237873651e-05
	val_negative_loss: 1.50923752784729
	val_positive_acc: 1.0
	val_negative_acc: 0.5550651534258092
test:
	test_positive_loss: 0.005470608826726675
	test_negative_loss: 2.3474764823913574
	test_positive_acc: 0.9975541413373861
	test_negative_acc: 0.5088120426611732
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.0655863955616951
	train_incorrect_loss: 0.1808754801750183
	train_positive_loss: 0.062353525310754776
	train_negative_loss: 0.20178289711475372
	train_correct_acc: 0.9744898771357944
	train_incorrect_acc: 0.9180330177214182
	train_positive_acc: 0.9998572898355204
	train_negative_acc: 0.9195837488340206
	train_correct_nonzero: 29600
	train_incorrect_nonzero: 10500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.5114824236661661e-05
	val_negative_loss: 2.5506677627563477
	val_positive_acc: 1.0
	val_negative_acc: 0.44745691467002946
test:
	test_positive_loss: 0.00023348958347924054
	test_negative_loss: 3.6707956790924072
	test_positive_acc: 1.0
	test_negative_acc: 0.3808225047396379
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.396833658218384 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.55
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2335636615753174
	train_negative_loss: 2.2802512645721436
	train_positive_acc: 0.7108092040388617
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.31780675053596497
	train_incorrect_loss: 0.5776480436325073
	train_positive_loss: 0.23393160104751587
	train_negative_loss: 0.9207775592803955
	train_correct_acc: 0.7779714737372558
	train_incorrect_acc: 0.7423351375933538
	train_positive_acc: 0.9984444549004846
	train_negative_acc: 0.5362956175700571
	train_correct_nonzero: 29100
	train_incorrect_nonzero: 11000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0037317820824682713
	val_negative_loss: 0.8653215169906616
	val_positive_acc: 1.0
	val_negative_acc: 0.01639344262295082
test:
	test_positive_loss: 0.009434841573238373
	test_negative_loss: 0.8895981311798096
	test_positive_acc: 1.0
	test_negative_acc: 0.03483014633459927
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.24997641146183014
	train_incorrect_loss: 0.5863702297210693
	train_positive_loss: 0.210593581199646
	train_negative_loss: 0.7921165227890015
	train_correct_acc: 0.7878614777015553
	train_incorrect_acc: 0.753886699952261
	train_positive_acc: 0.999797920193941
	train_negative_acc: 0.5578418855752115
	train_correct_nonzero: 29100
	train_incorrect_nonzero: 11000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0003428975469432771
	val_negative_loss: 0.979876697063446
	val_positive_acc: 1.0
	val_negative_acc: 0.07482135350987809
test:
	test_positive_loss: 0.0011962298303842545
	test_negative_loss: 1.0548890829086304
	test_positive_acc: 1.0
	test_negative_acc: 0.10281579230407503
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.23715877532958984
	train_incorrect_loss: 0.5692600607872009
	train_positive_loss: 0.203045055270195
	train_negative_loss: 0.7550681233406067
	train_correct_acc: 0.8292645821710355
	train_incorrect_acc: 0.7175538752387126
	train_positive_acc: 0.9997591537963955
	train_negative_acc: 0.599137106738602
	train_correct_nonzero: 29100
	train_incorrect_nonzero: 11000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.000549814198166132
	val_negative_loss: 0.7222776412963867
	val_positive_acc: 1.0
	val_negative_acc: 0.4884405212274065
test:
	test_positive_loss: 0.004059141501784325
	test_negative_loss: 0.8105228543281555
	test_positive_acc: 1.0
	test_negative_acc: 0.4882582573835029
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.21834878623485565
	train_incorrect_loss: 0.5359563231468201
	train_positive_loss: 0.19124390184879303
	train_negative_loss: 0.6964982151985168
	train_correct_acc: 0.8688587647695496
	train_incorrect_acc: 0.711988790544923
	train_positive_acc: 0.9994332853901121
	train_negative_acc: 0.6524117519246821
	train_correct_nonzero: 29100
	train_incorrect_nonzero: 11000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.9643666493939236e-05
	val_negative_loss: 1.0228979587554932
	val_positive_acc: 1.0
	val_negative_acc: 0.37620849096258935
test:
	test_positive_loss: 0.0008468912565149367
	test_negative_loss: 1.2000534534454346
	test_positive_acc: 1.0
	test_negative_acc: 0.3922599306371235
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.1928391307592392
	train_incorrect_loss: 0.4806565046310425
	train_positive_loss: 0.17208603024482727
	train_negative_loss: 0.615775465965271
	train_correct_acc: 0.896519589358346
	train_incorrect_acc: 0.7514091550977449
	train_positive_acc: 0.9994677105351863
	train_negative_acc: 0.7121741535804953
	train_correct_nonzero: 29100
	train_incorrect_nonzero: 11000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 6.187247345224023e-05
	val_negative_loss: 1.0502276420593262
	val_positive_acc: 1.0
	val_negative_acc: 0.39260193358554013
test:
	test_positive_loss: 0.003644585143774748
	test_negative_loss: 1.3589078187942505
	test_positive_acc: 0.9985119047619048
	test_negative_acc: 0.39907346413765277
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.16750109195709229
	train_incorrect_loss: 0.4270341694355011
	train_positive_loss: 0.15249310433864594
	train_negative_loss: 0.531789243221283
	train_correct_acc: 0.9174331474440367
	train_incorrect_acc: 0.7784907142265066
	train_positive_acc: 0.9995590802286485
	train_negative_acc: 0.7591846152792416
	train_correct_nonzero: 29100
	train_incorrect_nonzero: 11000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.007047394756227732
	val_negative_loss: 0.8093212246894836
	val_positive_acc: 1.0
	val_negative_acc: 0.5386717108028584
test:
	test_positive_loss: 0.011645112186670303
	test_negative_loss: 0.9764560461044312
	test_positive_acc: 0.9961044973544974
	test_negative_acc: 0.5368334351897395
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.13895562291145325
	train_incorrect_loss: 0.35939234495162964
	train_positive_loss: 0.12761132419109344
	train_negative_loss: 0.445505827665329
	train_correct_acc: 0.9352413496239452
	train_incorrect_acc: 0.8211291003958545
	train_positive_acc: 0.9997547381631814
	train_negative_acc: 0.8083037813239474
	train_correct_nonzero: 29100
	train_incorrect_nonzero: 11000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0004654023505281657
	val_negative_loss: 1.2967426776885986
	val_positive_acc: 1.0
	val_negative_acc: 0.33060109289617484
test:
	test_positive_loss: 0.0020414788741618395
	test_negative_loss: 1.7884160280227661
	test_positive_acc: 0.99875
	test_negative_acc: 0.37596117766432424
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.10275702178478241
	train_incorrect_loss: 0.27516642212867737
	train_positive_loss: 0.09766074270009995
	train_negative_loss: 0.3299075663089752
	train_correct_acc: 0.9566146635148207
	train_incorrect_acc: 0.8721406795416217
	train_positive_acc: 0.9998138858560174
	train_negative_acc: 0.8668471782976503
	train_correct_nonzero: 29100
	train_incorrect_nonzero: 11000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00022948293189983815
	val_negative_loss: 1.8933429718017578
	val_positive_acc: 1.0
	val_negative_acc: 0.44640605296343006
test:
	test_positive_loss: 0.0019727395847439766
	test_negative_loss: 2.3861632347106934
	test_positive_acc: 0.9988425925925926
	test_negative_acc: 0.43172748007545375
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.0858842208981514
	train_incorrect_loss: 0.22084514796733856
	train_positive_loss: 0.07965334504842758
	train_negative_loss: 0.2735733091831207
	train_correct_acc: 0.9647969119481946
	train_incorrect_acc: 0.8974179480704916
	train_positive_acc: 0.9997187422536737
	train_negative_acc: 0.8926045688356805
	train_correct_nonzero: 29100
	train_incorrect_nonzero: 11000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0025052030105143785
	val_negative_loss: 1.6578142642974854
	val_positive_acc: 1.0
	val_negative_acc: 0.4627994955863809
test:
	test_positive_loss: 0.007694284897297621
	test_negative_loss: 2.480513572692871
	test_positive_acc: 0.9972619047619048
	test_negative_acc: 0.48516517042003937
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.056388575583696365
	train_incorrect_loss: 0.1486869603395462
	train_positive_loss: 0.05307508260011673
	train_negative_loss: 0.17965123057365417
	train_correct_acc: 0.9783557440178398
	train_incorrect_acc: 0.9384183320163981
	train_positive_acc: 0.9999520429694994
	train_negative_acc: 0.9346725710670548
	train_correct_nonzero: 29100
	train_incorrect_nonzero: 11000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0007343792240135372
	val_negative_loss: 3.6406521797180176
	val_positive_acc: 1.0
	val_negative_acc: 0.3459436738125263
test:
	test_positive_loss: 0.0024466426111757755
	test_negative_loss: 4.3871564865112305
	test_positive_acc: 0.99875
	test_negative_acc: 0.3587623158059793
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 40.98577809333801 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.575
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233494281768799
	train_negative_loss: 2.280289888381958
	train_positive_acc: 0.7135953333063701
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.3282169699668884
	train_incorrect_loss: 0.5316441059112549
	train_positive_loss: 0.22350157797336578
	train_negative_loss: 0.9888820052146912
	train_correct_acc: 0.7516176499621653
	train_incorrect_acc: 0.8451791327907918
	train_positive_acc: 0.9984444549004846
	train_negative_acc: 0.5577133767438905
	train_correct_nonzero: 28600
	train_incorrect_nonzero: 11500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0045625194907188416
	val_negative_loss: 0.8993358612060547
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.009895778261125088
	test_negative_loss: 0.9226155281066895
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.25885480642318726
	train_incorrect_loss: 0.5466042160987854
	train_positive_loss: 0.20209161937236786
	train_negative_loss: 0.855147659778595
	train_correct_acc: 0.7572592970984511
	train_incorrect_acc: 0.8567658179457038
	train_positive_acc: 0.9997949840492164
	train_negative_acc: 0.5721622266094504
	train_correct_nonzero: 28600
	train_incorrect_nonzero: 11500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00031974122975952923
	val_negative_loss: 0.8535702228546143
	val_positive_acc: 1.0
	val_negative_acc: 0.045607398066414465
test:
	test_positive_loss: 0.002541019581258297
	test_negative_loss: 0.9111794233322144
	test_positive_acc: 1.0
	test_negative_acc: 0.06748282254231139
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.24840255081653595
	train_incorrect_loss: 0.533312201499939
	train_positive_loss: 0.19577361643314362
	train_negative_loss: 0.8233601450920105
	train_correct_acc: 0.7923663540328417
	train_incorrect_acc: 0.8215965941458016
	train_positive_acc: 0.9998038328209689
	train_negative_acc: 0.603590757836315
	train_correct_nonzero: 28600
	train_incorrect_nonzero: 11500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.004829696379601955
	val_negative_loss: 0.6048938035964966
	val_positive_acc: 1.0
	val_negative_acc: 0.8179907524169819
test:
	test_positive_loss: 0.014484023675322533
	test_negative_loss: 0.6366112232208252
	test_positive_acc: 0.9951541684230132
	test_negative_acc: 0.7415373903195559
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.23069192469120026
	train_incorrect_loss: 0.5112020969390869
	train_positive_loss: 0.1875387579202652
	train_negative_loss: 0.7678321599960327
	train_correct_acc: 0.841661720885998
	train_incorrect_acc: 0.7686906449328502
	train_positive_acc: 0.9997638745410415
	train_negative_acc: 0.6404249485837733
	train_correct_nonzero: 28600
	train_incorrect_nonzero: 11500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00027950768708251417
	val_negative_loss: 0.9689257144927979
	val_positive_acc: 1.0
	val_negative_acc: 0.35414039512400164
test:
	test_positive_loss: 0.0017281444743275642
	test_negative_loss: 1.095604419708252
	test_positive_acc: 1.0
	test_negative_acc: 0.35773127986047587
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.2062786966562271
	train_incorrect_loss: 0.4681217670440674
	train_positive_loss: 0.17209744453430176
	train_negative_loss: 0.6874958872795105
	train_correct_acc: 0.8788105512624145
	train_incorrect_acc: 0.7712159761636646
	train_positive_acc: 0.9994934871247896
	train_negative_acc: 0.695112250781056
	train_correct_nonzero: 28600
	train_incorrect_nonzero: 11500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00029852319858036935
	val_negative_loss: 1.2653529644012451
	val_positive_acc: 1.0
	val_negative_acc: 0.287515762925599
test:
	test_positive_loss: 0.001469765673391521
	test_negative_loss: 1.4003138542175293
	test_positive_acc: 1.0
	test_negative_acc: 0.3543709116615125
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.17865334451198578
	train_incorrect_loss: 0.41589561104774475
	train_positive_loss: 0.1529872566461563
	train_negative_loss: 0.5902880430221558
	train_correct_acc: 0.9079118478052299
	train_incorrect_acc: 0.7942665026885594
	train_positive_acc: 0.9996061085464975
	train_negative_acc: 0.7508237961994974
	train_correct_nonzero: 28600
	train_incorrect_nonzero: 11500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.02143431454896927
	val_negative_loss: 0.7876177430152893
	val_positive_acc: 0.9743589743589743
	val_negative_acc: 0.5294241277847835
test:
	test_positive_loss: 0.01983710564672947
	test_negative_loss: 0.9329344034194946
	test_positive_acc: 0.9912676317942974
	test_negative_acc: 0.4923048414756073
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.15141400694847107
	train_incorrect_loss: 0.3570958971977234
	train_positive_loss: 0.13077962398529053
	train_negative_loss: 0.5035345554351807
	train_correct_acc: 0.9267123039521579
	train_incorrect_acc: 0.8291086283124948
	train_positive_acc: 0.999643819314081
	train_negative_acc: 0.7978246700631874
	train_correct_nonzero: 28600
	train_incorrect_nonzero: 11500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 6.6158468143839855e-06
	val_negative_loss: 1.7670942544937134
	val_positive_acc: 1.0
	val_negative_acc: 0.33879781420765026
test:
	test_positive_loss: 0.0005784842651337385
	test_negative_loss: 2.1941890716552734
	test_positive_acc: 1.0
	test_negative_acc: 0.2705617365476435
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.11811006814241409
	train_incorrect_loss: 0.28606101870536804
	train_positive_loss: 0.10460543632507324
	train_negative_loss: 0.39155739545822144
	train_correct_acc: 0.9456865379237905
	train_incorrect_acc: 0.8690739881762137
	train_positive_acc: 0.9996928934808796
	train_negative_acc: 0.8481736439097699
	train_correct_nonzero: 28600
	train_incorrect_nonzero: 11500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00031070702243596315
	val_negative_loss: 1.5965585708618164
	val_positive_acc: 1.0
	val_negative_acc: 0.3879781420765027
test:
	test_positive_loss: 0.00840721745043993
	test_negative_loss: 2.2375330924987793
	test_positive_acc: 0.9973099816849818
	test_negative_acc: 0.375349951558967
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.09394873678684235
	train_incorrect_loss: 0.2262938916683197
	train_positive_loss: 0.08270043134689331
	train_negative_loss: 0.3111996650695801
	train_correct_acc: 0.9588895598629859
	train_incorrect_acc: 0.9003713456526495
	train_positive_acc: 0.999798453601446
	train_negative_acc: 0.8853840146341307
	train_correct_nonzero: 28600
	train_incorrect_nonzero: 11500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.4624612251500366e-06
	val_negative_loss: 1.8011152744293213
	val_positive_acc: 1.0
	val_negative_acc: 0.5361496427070198
test:
	test_positive_loss: 0.002011268399655819
	test_negative_loss: 2.7457494735717773
	test_positive_acc: 0.9985119047619048
	test_negative_acc: 0.4249158476833552
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.07010241597890854
	train_incorrect_loss: 0.1664951592683792
	train_positive_loss: 0.061460528522729874
	train_negative_loss: 0.23271220922470093
	train_correct_acc: 0.9723236449529065
	train_incorrect_acc: 0.9273464052224917
	train_positive_acc: 0.9997161124372577
	train_negative_acc: 0.9186371022037702
	train_correct_nonzero: 28600
	train_incorrect_nonzero: 11500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.3114931536838412e-05
	val_negative_loss: 2.893646717071533
	val_positive_acc: 1.0
	val_negative_acc: 0.3900798654897015
test:
	test_positive_loss: 0.011530603282153606
	test_negative_loss: 4.0007171630859375
	test_positive_acc: 0.9985119047619048
	test_negative_acc: 0.3326824773897227
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 40.94342088699341 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.6
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233433723449707
	train_negative_loss: 2.2802317142486572
	train_positive_acc: 0.7163151086288699
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.33440276980400085
	train_incorrect_loss: 0.4910065233707428
	train_positive_loss: 0.21242408454418182
	train_negative_loss: 1.0563037395477295
	train_correct_acc: 0.7462191068755402
	train_incorrect_acc: 0.8972860685275182
	train_positive_acc: 0.9984444549004846
	train_negative_acc: 0.5836986373361409
	train_correct_nonzero: 28100
	train_incorrect_nonzero: 12000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0013666138984262943
	val_negative_loss: 1.0291801691055298
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0039851428009569645
	test_negative_loss: 1.0691382884979248
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.2649036645889282
	train_incorrect_loss: 0.5034475922584534
	train_positive_loss: 0.19118356704711914
	train_negative_loss: 0.912111759185791
	train_correct_acc: 0.7440797873973181
	train_incorrect_acc: 0.9236103772439344
	train_positive_acc: 0.999797920193941
	train_negative_acc: 0.5960152487996121
	train_correct_nonzero: 28100
	train_incorrect_nonzero: 12000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0004790356906596571
	val_negative_loss: 0.9878166913986206
	val_positive_acc: 1.0
	val_negative_acc: 0.01639344262295082
test:
	test_positive_loss: 0.00245369179174304
	test_negative_loss: 1.0686498880386353
	test_positive_acc: 1.0
	test_negative_acc: 0.027872805321810648
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.2516919672489166
	train_incorrect_loss: 0.4906005859375
	train_positive_loss: 0.18490836024284363
	train_negative_loss: 0.8713562488555908
	train_correct_acc: 0.7829748286451056
	train_incorrect_acc: 0.869134287814562
	train_positive_acc: 0.9999157274372502
	train_negative_acc: 0.6190990967658474
	train_correct_nonzero: 28100
	train_incorrect_nonzero: 12000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.005852940492331982
	val_negative_loss: 0.768622636795044
	val_positive_acc: 1.0
	val_negative_acc: 0.2967633459436738
test:
	test_positive_loss: 0.012677500024437904
	test_negative_loss: 0.8394126892089844
	test_positive_acc: 1.0
	test_negative_acc: 0.2746933629925024
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.2354862540960312
	train_incorrect_loss: 0.4703249931335449
	train_positive_loss: 0.17701537907123566
	train_negative_loss: 0.8194453716278076
	train_correct_acc: 0.828557443649043
	train_incorrect_acc: 0.8144901380416963
	train_positive_acc: 0.9996101973025326
	train_negative_acc: 0.6488788746712411
	train_correct_nonzero: 28100
	train_incorrect_nonzero: 12000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00035632128128781915
	val_negative_loss: 0.8404092788696289
	val_positive_acc: 1.0
	val_negative_acc: 0.5468684321143338
test:
	test_positive_loss: 0.0013195858336985111
	test_negative_loss: 1.0611993074417114
	test_positive_acc: 1.0
	test_negative_acc: 0.4811374869844678
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.21357844769954681
	train_incorrect_loss: 0.43434229493141174
	train_positive_loss: 0.16389694809913635
	train_negative_loss: 0.7400855422019958
	train_correct_acc: 0.8687267412671734
	train_incorrect_acc: 0.8020770227176471
	train_positive_acc: 0.9997516724361377
	train_negative_acc: 0.6969784313041839
	train_correct_nonzero: 28100
	train_incorrect_nonzero: 12000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0006849386845715344
	val_negative_loss: 0.9042145013809204
	val_positive_acc: 1.0
	val_negative_acc: 0.3705338377469525
test:
	test_positive_loss: 0.0060538253746926785
	test_negative_loss: 1.2282358407974243
	test_positive_acc: 0.9972619047619048
	test_negative_acc: 0.30489444451378556
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.18615658581256866
	train_incorrect_loss: 0.38796183466911316
	train_positive_loss: 0.14625589549541473
	train_negative_loss: 0.6426218152046204
	train_correct_acc: 0.8951960114864854
	train_incorrect_acc: 0.8181928059366314
	train_positive_acc: 0.9998107131026712
	train_negative_acc: 0.7438772886767823
	train_correct_nonzero: 28100
	train_incorrect_nonzero: 12000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.03825942054390907
	val_negative_loss: 0.9604625701904297
	val_positive_acc: 0.9743589743589743
	val_negative_acc: 0.3823034888608659
test:
	test_positive_loss: 0.024891318753361702
	test_negative_loss: 1.2614078521728516
	test_positive_acc: 0.9914096273062195
	test_negative_acc: 0.3477612655595451
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.1585254669189453
	train_incorrect_loss: 0.33549898862838745
	train_positive_loss: 0.12586693465709686
	train_negative_loss: 0.5489292144775391
	train_correct_acc: 0.9167654420639482
	train_incorrect_acc: 0.844167501453377
	train_positive_acc: 0.9996989402583908
	train_negative_acc: 0.7915668549841385
	train_correct_nonzero: 28100
	train_incorrect_nonzero: 12000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0009192807483486831
	val_negative_loss: 1.1607348918914795
	val_positive_acc: 1.0
	val_negative_acc: 0.42538881883144175
test:
	test_positive_loss: 0.009902826510369778
	test_negative_loss: 1.584815502166748
	test_positive_acc: 0.9927899946240868
	test_negative_acc: 0.409468188952685
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.11947278678417206
	train_incorrect_loss: 0.2682573199272156
	train_positive_loss: 0.10060780495405197
	train_negative_loss: 0.4145492613315582
	train_correct_acc: 0.9420331249928874
	train_incorrect_acc: 0.8780002270134651
	train_positive_acc: 0.999894987708035
	train_negative_acc: 0.8460825721526075
	train_correct_nonzero: 28100
	train_incorrect_nonzero: 12000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0005559129058383405
	val_negative_loss: 1.5943331718444824
	val_positive_acc: 1.0
	val_negative_acc: 0.5329970575872215
test:
	test_positive_loss: 0.011888771317899227
	test_negative_loss: 1.9564487934112549
	test_positive_acc: 0.996336511299435
	test_negative_acc: 0.4932030708845325
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.09270045161247253
	train_incorrect_loss: 0.20496636629104614
	train_positive_loss: 0.07689861953258514
	train_negative_loss: 0.320941686630249
	train_correct_acc: 0.9591518547542209
	train_incorrect_acc: 0.9109384085078871
	train_positive_acc: 0.9999520429694994
	train_negative_acc: 0.8896880006281355
	train_correct_nonzero: 28100
	train_incorrect_nonzero: 12000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0016003717901185155
	val_negative_loss: 2.3744916915893555
	val_positive_acc: 1.0
	val_negative_acc: 0.40899537620849097
test:
	test_positive_loss: 0.015912272036075592
	test_negative_loss: 3.084324836730957
	test_positive_acc: 0.9951791038920277
	test_negative_acc: 0.3593241581742693
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.07312548160552979
	train_incorrect_loss: 0.15765315294265747
	train_positive_loss: 0.059390489012002945
	train_negative_loss: 0.2545173168182373
	train_correct_acc: 0.9701999933396035
	train_incorrect_acc: 0.9315865997847644
	train_positive_acc: 0.999948046550291
	train_negative_acc: 0.9172490789041197
	train_correct_nonzero: 28100
	train_incorrect_nonzero: 12000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 6.698860488540959e-06
	val_negative_loss: 2.638577699661255
	val_positive_acc: 1.0
	val_negative_acc: 0.4243379571248424
test:
	test_positive_loss: 0.020513277500867844
	test_negative_loss: 3.7672901153564453
	test_positive_acc: 0.9949884259259258
	test_negative_acc: 0.3927780807044001
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.13797354698181 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.625
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233368396759033
	train_negative_loss: 2.280108690261841
	train_positive_acc: 0.7194141765259525
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.33853256702423096
	train_incorrect_loss: 0.45231130719184875
	train_positive_loss: 0.2013791799545288
	train_negative_loss: 1.119847297668457
	train_correct_acc: 0.7473775588027537
	train_incorrect_acc: 0.9319960398242888
	train_positive_acc: 0.9984943302122053
	train_negative_acc: 0.6108746475461884
	train_correct_nonzero: 27600
	train_incorrect_nonzero: 12500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0033926451578736305
	val_negative_loss: 1.0882123708724976
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.006297987885773182
	test_negative_loss: 1.1168965101242065
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.2694600522518158
	train_incorrect_loss: 0.46197980642318726
	train_positive_loss: 0.17990721762180328
	train_negative_loss: 0.9722680449485779
	train_correct_acc: 0.7480193874275465
	train_incorrect_acc: 0.9511080815034244
	train_positive_acc: 0.999797920193941
	train_negative_acc: 0.6225491426029823
	train_correct_nonzero: 27600
	train_incorrect_nonzero: 12500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00011939530668314546
	val_negative_loss: 1.1932425498962402
	val_positive_acc: 1.0
	val_negative_acc: 0.01282051282051282
test:
	test_positive_loss: 0.0005561235011555254
	test_negative_loss: 1.30185866355896
	test_positive_acc: 1.0
	test_negative_acc: 0.027001129333497013
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.25539931654930115
	train_incorrect_loss: 0.45075908303260803
	train_positive_loss: 0.17444533109664917
	train_negative_loss: 0.9270153641700745
	train_correct_acc: 0.7875423035773383
	train_incorrect_acc: 0.8915533860041898
	train_positive_acc: 0.9999627796181187
	train_negative_acc: 0.6418445800722751
	train_correct_nonzero: 27600
	train_incorrect_nonzero: 12500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.008130591362714767
	val_negative_loss: 0.876952052116394
	val_positive_acc: 1.0
	val_negative_acc: 0.21626733921815888
test:
	test_positive_loss: 0.010607090778648853
	test_negative_loss: 0.9369428753852844
	test_positive_acc: 1.0
	test_negative_acc: 0.1951593027360617
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.2324822098016739
	train_incorrect_loss: 0.42548897862434387
	train_positive_loss: 0.164093479514122
	train_negative_loss: 0.8478244543075562
	train_correct_acc: 0.841775645357389
	train_incorrect_acc: 0.8317180418699276
	train_positive_acc: 0.9996823761824165
	train_negative_acc: 0.6785145173009602
	train_correct_nonzero: 27600
	train_incorrect_nonzero: 12500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00021815956279169768
	val_negative_loss: 1.0636727809906006
	val_positive_acc: 1.0
	val_negative_acc: 0.3459436738125263
test:
	test_positive_loss: 0.0007408904493786395
	test_negative_loss: 1.2989517450332642
	test_positive_acc: 1.0
	test_negative_acc: 0.330824043630111
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.20293624699115753
	train_incorrect_loss: 0.3833194673061371
	train_positive_loss: 0.14812253415584564
	train_negative_loss: 0.7379611730575562
	train_correct_acc: 0.8814901820251086
	train_incorrect_acc: 0.8304275274239141
	train_positive_acc: 0.9995743773569464
	train_negative_acc: 0.7305374192516333
	train_correct_nonzero: 27600
	train_incorrect_nonzero: 12500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0006178331677801907
	val_negative_loss: 1.0328011512756348
	val_positive_acc: 1.0
	val_negative_acc: 0.24905422446406053
test:
	test_positive_loss: 0.00408911844715476
	test_negative_loss: 1.3119877576828003
	test_positive_acc: 1.0
	test_negative_acc: 0.2857507267085923
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.17396561801433563
	train_incorrect_loss: 0.33716681599617004
	train_positive_loss: 0.1299770623445511
	train_negative_loss: 0.6279588937759399
	train_correct_acc: 0.9101702111020086
	train_incorrect_acc: 0.8471951380147142
	train_positive_acc: 0.9996888319272884
	train_negative_acc: 0.7827645114567342
	train_correct_nonzero: 27600
	train_incorrect_nonzero: 12500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00804365985095501
	val_negative_loss: 0.8601250648498535
	val_positive_acc: 1.0
	val_negative_acc: 0.5970996216897856
test:
	test_positive_loss: 0.01278730109333992
	test_negative_loss: 1.1455625295639038
	test_positive_acc: 0.9954236694677872
	test_negative_acc: 0.5025139934300478
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.1444244682788849
	train_incorrect_loss: 0.28909873962402344
	train_positive_loss: 0.11107394099235535
	train_negative_loss: 0.5210464000701904
	train_correct_acc: 0.9288280768909898
	train_incorrect_acc: 0.8628789386637893
	train_positive_acc: 0.9994901569712792
	train_negative_acc: 0.8180172726033867
	train_correct_nonzero: 27600
	train_incorrect_nonzero: 12500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.1769860066124238e-05
	val_negative_loss: 1.4330135583877563
	val_positive_acc: 1.0
	val_negative_acc: 0.42643968053804115
test:
	test_positive_loss: 0.0014096538070589304
	test_negative_loss: 1.9591832160949707
	test_positive_acc: 1.0
	test_negative_acc: 0.3865038752704061
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.10891423374414444
	train_incorrect_loss: 0.22443841397762299
	train_positive_loss: 0.08608093857765198
	train_negative_loss: 0.3935066759586334
	train_correct_acc: 0.9506402118834576
	train_incorrect_acc: 0.9018201434385176
	train_positive_acc: 0.9998067113368807
	train_negative_acc: 0.871247463441782
	train_correct_nonzero: 27600
	train_incorrect_nonzero: 12500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 9.227866257788264e-07
	val_negative_loss: 1.449143648147583
	val_positive_acc: 1.0
	val_negative_acc: 0.5386717108028584
test:
	test_positive_loss: 0.0008015180937945843
	test_negative_loss: 1.9682576656341553
	test_positive_acc: 1.0
	test_negative_acc: 0.4686804368851641
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.08674026280641556
	train_incorrect_loss: 0.17753760516643524
	train_positive_loss: 0.06858383119106293
	train_negative_loss: 0.31242236495018005
	train_correct_acc: 0.9655013527300621
	train_incorrect_acc: 0.9211112194835069
	train_positive_acc: 0.9996538130752249
	train_negative_acc: 0.9038378276789157
	train_correct_nonzero: 27600
	train_incorrect_nonzero: 12500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.0698265384689876e-08
	val_negative_loss: 3.420879364013672
	val_positive_acc: 1.0
	val_negative_acc: 0.2885666246321984
test:
	test_positive_loss: 3.31813316734042e-05
	test_negative_loss: 4.1277995109558105
	test_positive_acc: 1.0
	test_negative_acc: 0.28850670495988695
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.06225550174713135
	train_incorrect_loss: 0.13360033929347992
	train_positive_loss: 0.0515214279294014
	train_negative_loss: 0.22596177458763123
	train_correct_acc: 0.9745339047486233
	train_incorrect_acc: 0.9439930715502545
	train_positive_acc: 1.0
	train_negative_acc: 0.9298720337766482
	train_correct_nonzero: 27600
	train_incorrect_nonzero: 12500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 4.9808274837914723e-08
	val_negative_loss: 3.634894847869873
	val_positive_acc: 1.0
	val_negative_acc: 0.3434216057166877
test:
	test_positive_loss: 0.0001471579889766872
	test_negative_loss: 4.712705612182617
	test_positive_acc: 1.0
	test_negative_acc: 0.3098313685377303
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 40.53717875480652 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.65
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233320713043213
	train_negative_loss: 2.280116558074951
	train_positive_acc: 0.7213377320008312
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.34189993143081665
	train_incorrect_loss: 0.4153009355068207
	train_positive_loss: 0.18968060612678528
	train_negative_loss: 1.1937769651412964
	train_correct_acc: 0.750938616598947
	train_incorrect_acc: 0.9620726013812256
	train_positive_acc: 0.9984943302122053
	train_negative_acc: 0.6411596054459567
	train_correct_nonzero: 27100
	train_incorrect_nonzero: 13000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.002714034402742982
	val_negative_loss: 1.0760900974273682
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.006347233429551125
	test_negative_loss: 1.1016747951507568
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.27307745814323425
	train_incorrect_loss: 0.42257553339004517
	train_positive_loss: 0.1684001237154007
	train_negative_loss: 1.0382734537124634
	train_correct_acc: 0.7490739918809961
	train_incorrect_acc: 0.9805363815956466
	train_positive_acc: 0.9997470270187158
	train_negative_acc: 0.6486365034939673
	train_correct_nonzero: 27100
	train_incorrect_nonzero: 13000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0005468891467899084
	val_negative_loss: 1.4100580215454102
	val_positive_acc: 1.0
	val_negative_acc: 0.05380411937788987
test:
	test_positive_loss: 0.0009521177271381021
	test_negative_loss: 1.4189860820770264
	test_positive_acc: 1.0
	test_negative_acc: 0.04721880535197267
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.25572848320007324
	train_incorrect_loss: 0.40887436270713806
	train_positive_loss: 0.1621827334165573
	train_negative_loss: 0.9730021357536316
	train_correct_acc: 0.7902277900066127
	train_incorrect_acc: 0.9188841345636173
	train_positive_acc: 0.9999030725074107
	train_negative_acc: 0.6649095906092458
	train_correct_nonzero: 27100
	train_incorrect_nonzero: 13000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0014930360484868288
	val_negative_loss: 1.2699837684631348
	val_positive_acc: 1.0
	val_negative_acc: 0.045607398066414465
test:
	test_positive_loss: 0.0030591217800974846
	test_negative_loss: 1.3898663520812988
	test_positive_acc: 1.0
	test_negative_acc: 0.05122179641596619
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.2322283685207367
	train_incorrect_loss: 0.3840811252593994
	train_positive_loss: 0.1518755406141281
	train_negative_loss: 0.8899648785591125
	train_correct_acc: 0.8473201906376386
	train_incorrect_acc: 0.8590272607488232
	train_positive_acc: 0.9998030318006346
	train_negative_acc: 0.7026591113815328
	train_correct_nonzero: 27100
	train_incorrect_nonzero: 13000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.002455090405419469
	val_negative_loss: 0.9342905282974243
	val_positive_acc: 1.0
	val_negative_acc: 0.46027742749054223
test:
	test_positive_loss: 0.004703825805336237
	test_negative_loss: 1.1235384941101074
	test_positive_acc: 0.9971024426719841
	test_negative_acc: 0.37275650244419267
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.20132289826869965
	train_incorrect_loss: 0.3469861149787903
	train_positive_loss: 0.13666397333145142
	train_negative_loss: 0.7694913148880005
	train_correct_acc: 0.8856201451454444
	train_incorrect_acc: 0.8525097699557073
	train_positive_acc: 0.9998509916124434
	train_negative_acc: 0.7509203223465978
	train_correct_nonzero: 27100
	train_incorrect_nonzero: 13000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 6.568241224158555e-05
	val_negative_loss: 1.873155951499939
	val_positive_acc: 1.0
	val_negative_acc: 0.162463219840269
test:
	test_positive_loss: 0.000564808608032763
	test_negative_loss: 2.293107509613037
	test_positive_acc: 1.0
	test_negative_acc: 0.11041255911143322
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.1731012612581253
	train_incorrect_loss: 0.30946090817451477
	train_positive_loss: 0.12206464260816574
	train_negative_loss: 0.656065821647644
	train_correct_acc: 0.9094134492418805
	train_incorrect_acc: 0.85961692768745
	train_positive_acc: 0.999944582986977
	train_negative_acc: 0.7867736716264929
	train_correct_nonzero: 27100
	train_incorrect_nonzero: 13000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0008216087007895112
	val_negative_loss: 0.9739116430282593
	val_positive_acc: 1.0
	val_negative_acc: 0.5023118957545187
test:
	test_positive_loss: 0.010059695690870285
	test_negative_loss: 1.243231177330017
	test_positive_acc: 0.9959863712434127
	test_negative_acc: 0.43682052864389187
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.1419803947210312
	train_incorrect_loss: 0.2602345645427704
	train_positive_loss: 0.10221605747938156
	train_negative_loss: 0.5431750416755676
	train_correct_acc: 0.9313243686808715
	train_incorrect_acc: 0.885528541267154
	train_positive_acc: 0.9999591185969502
	train_negative_acc: 0.8334245481225044
	train_correct_nonzero: 27100
	train_incorrect_nonzero: 13000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 6.352580385282636e-05
	val_negative_loss: 1.3791776895523071
	val_positive_acc: 1.0
	val_negative_acc: 0.49768810424548127
test:
	test_positive_loss: 0.006352519150823355
	test_negative_loss: 1.8407230377197266
	test_positive_acc: 0.9978246065375302
	test_negative_acc: 0.42629488336990057
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.11149992793798447
	train_incorrect_loss: 0.21126124262809753
	train_positive_loss: 0.08315733075141907
	train_negative_loss: 0.4244568943977356
	train_correct_acc: 0.9511975456468189
	train_incorrect_acc: 0.9110014229406254
	train_positive_acc: 0.999955468471678
	train_negative_acc: 0.8765678031418288
	train_correct_nonzero: 27100
	train_incorrect_nonzero: 13000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00019411729590501636
	val_negative_loss: 1.8958618640899658
	val_positive_acc: 1.0
	val_negative_acc: 0.44850777637662886
test:
	test_positive_loss: 0.007393118925392628
	test_negative_loss: 2.2211248874664307
	test_positive_acc: 0.996765284503632
	test_negative_acc: 0.36375914780420776
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.0809871256351471
	train_incorrect_loss: 0.15938057005405426
	train_positive_loss: 0.0628252923488617
	train_negative_loss: 0.3082987368106842
	train_correct_acc: 0.9667305912340244
	train_incorrect_acc: 0.9315778475503287
	train_positive_acc: 0.99980321312976
	train_negative_acc: 0.9111393623687171
	train_correct_nonzero: 27100
	train_incorrect_nonzero: 13000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.4656866831330717e-08
	val_negative_loss: 2.850459575653076
	val_positive_acc: 1.0
	val_negative_acc: 0.40184951660361495
test:
	test_positive_loss: 0.006623447872698307
	test_negative_loss: 3.4828314781188965
	test_positive_acc: 0.9978246065375302
	test_negative_acc: 0.33607289707853144
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.059693582355976105
	train_incorrect_loss: 0.11784644424915314
	train_positive_loss: 0.046701375395059586
	train_negative_loss: 0.22777213156223297
	train_correct_acc: 0.9757287760835051
	train_incorrect_acc: 0.9511600173886782
	train_positive_acc: 0.9998579984110425
	train_negative_acc: 0.9358526557173336
	train_correct_nonzero: 27100
	train_incorrect_nonzero: 13000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.098576987918932e-05
	val_negative_loss: 4.740612983703613
	val_positive_acc: 1.0
	val_negative_acc: 0.2547288776796973
test:
	test_positive_loss: 0.008623389527201653
	test_negative_loss: 5.53294563293457
	test_positive_acc: 0.9976906779661017
	test_negative_acc: 0.21557788224113864
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 40.852439165115356 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.675
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2332677841186523
	train_negative_loss: 2.2801103591918945
	train_positive_acc: 0.7237692101672392
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.3474801182746887
	train_incorrect_loss: 0.3786727786064148
	train_positive_loss: 0.17809027433395386
	train_negative_loss: 1.2800617218017578
	train_correct_acc: 0.7583358822622781
	train_incorrect_acc: 0.9826661379647013
	train_positive_acc: 0.9984943302122053
	train_negative_acc: 0.6693957779481748
	train_correct_nonzero: 26600
	train_incorrect_nonzero: 13500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0023479450028389692
	val_negative_loss: 1.250884771347046
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.005215432960540056
	test_negative_loss: 1.278634786605835
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.27716341614723206
	train_incorrect_loss: 0.3875887393951416
	train_positive_loss: 0.15799351036548615
	train_negative_loss: 1.1140787601470947
	train_correct_acc: 0.7579276153160002
	train_incorrect_acc: 0.9899740986049184
	train_positive_acc: 0.9998458772244416
	train_negative_acc: 0.6726904309097544
	train_correct_nonzero: 26600
	train_incorrect_nonzero: 13500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 8.521537529304624e-05
	val_negative_loss: 1.5349987745285034
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0003502040053717792
	test_negative_loss: 1.6269326210021973
	test_positive_acc: 1.0
	test_negative_acc: 0.0038119789381307586
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.2617983818054199
	train_incorrect_loss: 0.37582945823669434
	train_positive_loss: 0.15277662873268127
	train_negative_loss: 1.0548102855682373
	train_correct_acc: 0.7820289133910255
	train_incorrect_acc: 0.957451769754342
	train_positive_acc: 0.9999501246882794
	train_negative_acc: 0.6820818195879327
	train_correct_nonzero: 26600
	train_incorrect_nonzero: 13500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0011345904786139727
	val_negative_loss: 1.1382758617401123
	val_positive_acc: 1.0
	val_negative_acc: 0.037410676754939046
test:
	test_positive_loss: 0.005466395989060402
	test_negative_loss: 1.2116886377334595
	test_positive_acc: 1.0
	test_negative_acc: 0.0574409553982628
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.23647835850715637
	train_incorrect_loss: 0.3526010513305664
	train_positive_loss: 0.14276090264320374
	train_negative_loss: 0.9585755467414856
	train_correct_acc: 0.8362108322443034
	train_incorrect_acc: 0.8968270182390754
	train_positive_acc: 0.9998070282198429
	train_negative_acc: 0.7133319096725812
	train_correct_nonzero: 26600
	train_incorrect_nonzero: 13500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0003740491229109466
	val_negative_loss: 1.7298927307128906
	val_positive_acc: 1.0
	val_negative_acc: 0.09226565783942833
test:
	test_positive_loss: 0.0036589817609637976
	test_negative_loss: 1.8628993034362793
	test_positive_acc: 0.9981617647058824
	test_negative_acc: 0.08762284240081454
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.20196154713630676
	train_incorrect_loss: 0.31305766105651855
	train_positive_loss: 0.12634064257144928
	train_negative_loss: 0.8136770129203796
	train_correct_acc: 0.8835140834097894
	train_incorrect_acc: 0.879524273406889
	train_positive_acc: 0.9997088277100076
	train_negative_acc: 0.7655942181995965
	train_correct_nonzero: 26600
	train_incorrect_nonzero: 13500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0001451763673685491
	val_negative_loss: 1.8255126476287842
	val_positive_acc: 1.0
	val_negative_acc: 0.1414459857082808
test:
	test_positive_loss: 0.002702959580346942
	test_negative_loss: 2.2182016372680664
	test_positive_acc: 1.0
	test_negative_acc: 0.1578758211246285
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.17663662135601044
	train_incorrect_loss: 0.27655163407325745
	train_positive_loss: 0.11220961809158325
	train_negative_loss: 0.7073337435722351
	train_correct_acc: 0.9068854802676716
	train_incorrect_acc: 0.887035415215241
	train_positive_acc: 0.9996132850727798
	train_negative_acc: 0.8012820121398982
	train_correct_nonzero: 26600
	train_incorrect_nonzero: 13500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.000980442389845848
	val_negative_loss: 1.403794527053833
	val_positive_acc: 1.0
	val_negative_acc: 0.33417402269861285
test:
	test_positive_loss: 0.010406773537397385
	test_negative_loss: 1.7528581619262695
	test_positive_acc: 0.993225238165948
	test_negative_acc: 0.2767531200662427
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.13781024515628815
	train_incorrect_loss: 0.22586683928966522
	train_positive_loss: 0.09127083420753479
	train_negative_loss: 0.5574232935905457
	train_correct_acc: 0.9330641855876214
	train_incorrect_acc: 0.9084065632239073
	train_positive_acc: 0.9998498381593507
	train_negative_acc: 0.8501019555520728
	train_correct_nonzero: 26600
	train_incorrect_nonzero: 13500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00023702444741502404
	val_negative_loss: 1.8375225067138672
	val_positive_acc: 1.0
	val_negative_acc: 0.4029003783102144
test:
	test_positive_loss: 0.00048557372065261006
	test_negative_loss: 2.448151111602783
	test_positive_acc: 1.0
	test_negative_acc: 0.3081594892507181
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.11116471141576767
	train_incorrect_loss: 0.18546104431152344
	train_positive_loss: 0.07478560507297516
	train_negative_loss: 0.4452970027923584
	train_correct_acc: 0.9481567689955286
	train_incorrect_acc: 0.9259500275868984
	train_positive_acc: 0.9998440838229663
	train_negative_acc: 0.8815296243051707
	train_correct_nonzero: 26600
	train_incorrect_nonzero: 13500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00019903255451936275
	val_negative_loss: 1.6505669355392456
	val_positive_acc: 1.0
	val_negative_acc: 0.5304749894913829
test:
	test_positive_loss: 0.012303599156439304
	test_negative_loss: 2.295806646347046
	test_positive_acc: 0.99657927259887
	test_negative_acc: 0.4336917592462317
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.0875292643904686
	train_incorrect_loss: 0.1502937376499176
	train_positive_loss: 0.06029544398188591
	train_negative_loss: 0.35344523191452026
	train_correct_acc: 0.9596590504863199
	train_incorrect_acc: 0.9391240725373239
	train_positive_acc: 0.9998528367960068
	train_negative_acc: 0.9059099334399717
	train_correct_nonzero: 26600
	train_incorrect_nonzero: 13500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.480958218280648e-07
	val_negative_loss: 1.904667854309082
	val_positive_acc: 1.0
	val_negative_acc: 0.4510298444724674
test:
	test_positive_loss: 0.01383358146995306
	test_negative_loss: 2.714221954345703
	test_positive_acc: 0.9965515686981609
	test_negative_acc: 0.40580118896352363
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.06755319237709045
	train_incorrect_loss: 0.11486101150512695
	train_positive_loss: 0.046590134501457214
	train_negative_loss: 0.273899644613266
	train_correct_acc: 0.971077840722856
	train_incorrect_acc: 0.9556640047644054
	train_positive_acc: 0.999679454781428
	train_negative_acc: 0.9320027920511365
	train_correct_nonzero: 26600
	train_incorrect_nonzero: 13500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.14967297296198e-08
	val_negative_loss: 4.830408573150635
	val_positive_acc: 1.0
	val_negative_acc: 0.23224043715846993
test:
	test_positive_loss: 0.0003682303358800709
	test_negative_loss: 6.410486221313477
	test_positive_acc: 1.0
	test_negative_acc: 0.181908522503204
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.12917971611023 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.7
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233198642730713
	train_negative_loss: 2.2801876068115234
	train_positive_acc: 0.726779143718844
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.3489665985107422
	train_incorrect_loss: 0.34394511580467224
	train_positive_loss: 0.1665257066488266
	train_negative_loss: 1.366316556930542
	train_correct_acc: 0.7695436093078659
	train_incorrect_acc: 0.9908331017908375
	train_positive_acc: 0.9984943302122053
	train_negative_acc: 0.6951082179695279
	train_correct_nonzero: 26100
	train_incorrect_nonzero: 14000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0036159097217023373
	val_negative_loss: 1.1942598819732666
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.007186416070908308
	test_negative_loss: 1.2319860458374023
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.2774370014667511
	train_incorrect_loss: 0.35079172253608704
	train_positive_loss: 0.14626444876194
	train_negative_loss: 1.1840282678604126
	train_correct_acc: 0.7694658643725981
	train_incorrect_acc: 0.9974750337000473
	train_positive_acc: 1.0
	train_negative_acc: 0.6986762166733161
	train_correct_nonzero: 26100
	train_incorrect_nonzero: 14000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00014226695930119604
	val_negative_loss: 1.4782288074493408
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0007737590349279344
	test_negative_loss: 1.5881102085113525
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.2605127692222595
	train_incorrect_loss: 0.3388981521129608
	train_positive_loss: 0.14054128527641296
	train_negative_loss: 1.114635705947876
	train_correct_acc: 0.7906370022972132
	train_incorrect_acc: 0.9719058166822169
	train_positive_acc: 1.0
	train_negative_acc: 0.7079550964501802
	train_correct_nonzero: 26100
	train_incorrect_nonzero: 14000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0005599268479272723
	val_negative_loss: 1.4055628776550293
	val_positive_acc: 1.0
	val_negative_acc: 0.02101723413198823
test:
	test_positive_loss: 0.004123156890273094
	test_negative_loss: 1.4942054748535156
	test_positive_acc: 1.0
	test_negative_acc: 0.022115393942557793
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.23589414358139038
	train_incorrect_loss: 0.319846510887146
	train_positive_loss: 0.1320304572582245
	train_negative_loss: 1.016352891921997
	train_correct_acc: 0.8383230784424733
	train_incorrect_acc: 0.9147562298232964
	train_positive_acc: 0.9998307518584238
	train_negative_acc: 0.730762035273497
	train_correct_nonzero: 26100
	train_incorrect_nonzero: 14000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0002203790791099891
	val_negative_loss: 1.0955536365509033
	val_positive_acc: 1.0
	val_negative_acc: 0.29213955443463635
test:
	test_positive_loss: 0.004272817634046078
	test_negative_loss: 1.267292857170105
	test_positive_acc: 0.9966736694677871
	test_negative_acc: 0.3143021356211444
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.200758159160614
	train_incorrect_loss: 0.2835521399974823
	train_positive_loss: 0.11690747737884521
	train_negative_loss: 0.8626704216003418
	train_correct_acc: 0.8829600152503273
	train_incorrect_acc: 0.900044935402924
	train_positive_acc: 0.9998934481976876
	train_negative_acc: 0.7787019117398314
	train_correct_nonzero: 26100
	train_incorrect_nonzero: 14000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.0147335817455314e-06
	val_negative_loss: 1.881029725074768
	val_positive_acc: 1.0
	val_negative_acc: 0.062000840689365275
test:
	test_positive_loss: 0.00048451859038323164
	test_negative_loss: 2.2125182151794434
	test_positive_acc: 1.0
	test_negative_acc: 0.07293371250562272
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.17353671789169312
	train_incorrect_loss: 0.24916106462478638
	train_positive_loss: 0.10295207798480988
	train_negative_loss: 0.7401608824729919
	train_correct_acc: 0.9087936609741398
	train_incorrect_acc: 0.9023973937841708
	train_positive_acc: 0.9998524894816774
	train_negative_acc: 0.8132933853036347
	train_correct_nonzero: 26100
	train_incorrect_nonzero: 14000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.503821790218353e-05
	val_negative_loss: 1.9532999992370605
	val_positive_acc: 1.0
	val_negative_acc: 0.1614123581336696
test:
	test_positive_loss: 0.004944896791130304
	test_negative_loss: 2.2779479026794434
	test_positive_acc: 0.9989406779661016
	test_negative_acc: 0.15435644362855794
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.13737067580223083
	train_incorrect_loss: 0.20486262440681458
	train_positive_loss: 0.08447478711605072
	train_negative_loss: 0.5927765369415283
	train_correct_acc: 0.9340071918116267
	train_incorrect_acc: 0.918051150544303
	train_positive_acc: 0.9998565245136318
	train_negative_acc: 0.857008562575436
	train_correct_nonzero: 26100
	train_incorrect_nonzero: 14000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.164277421139559e-07
	val_negative_loss: 2.466416835784912
	val_positive_acc: 1.0
	val_negative_acc: 0.21269440941572088
test:
	test_positive_loss: 0.00287422607652843
	test_negative_loss: 3.17451810836792
	test_positive_acc: 0.9974525827280065
	test_negative_acc: 0.15858440798860787
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.1045476645231247
	train_incorrect_loss: 0.16580963134765625
	train_positive_loss: 0.06795089691877365
	train_negative_loss: 0.452056348323822
	train_correct_acc: 0.9522620496862729
	train_incorrect_acc: 0.9341573364813264
	train_positive_acc: 0.9999101272792046
	train_negative_acc: 0.89146194188055
	train_correct_nonzero: 26100
	train_incorrect_nonzero: 14000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 5.1486857444160705e-08
	val_negative_loss: 2.4219930171966553
	val_positive_acc: 1.0
	val_negative_acc: 0.34237074401008827
test:
	test_positive_loss: 0.007686790078878403
	test_negative_loss: 2.9351794719696045
	test_positive_acc: 0.9974525827280065
	test_negative_acc: 0.30975521811906737
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.08107499033212662
	train_incorrect_loss: 0.1287527084350586
	train_positive_loss: 0.05286410450935364
	train_negative_loss: 0.34455326199531555
	train_correct_acc: 0.9663074169718912
	train_incorrect_acc: 0.9502752008280739
	train_positive_acc: 0.999912256396047
	train_negative_acc: 0.92132509680516
	train_correct_nonzero: 26100
	train_incorrect_nonzero: 14000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0
	val_negative_loss: 2.7224769592285156
	val_positive_acc: 1.0
	val_negative_acc: 0.3715846994535519
test:
	test_positive_loss: 0.004664543084800243
	test_negative_loss: 3.6277270317077637
	test_positive_acc: 0.9989406779661016
	test_negative_acc: 0.31786327898983374
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.05906753987073898
	train_incorrect_loss: 0.09462947398424149
	train_positive_loss: 0.03911321982741356
	train_negative_loss: 0.25738126039505005
	train_correct_acc: 0.9752122848797298
	train_incorrect_acc: 0.9636140692560149
	train_positive_acc: 0.9999584372402328
	train_negative_acc: 0.9417553948423185
	train_correct_nonzero: 26100
	train_incorrect_nonzero: 14000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.056648045784982e-09
	val_negative_loss: 3.6103458404541016
	val_positive_acc: 1.0
	val_negative_acc: 0.3167297183690626
test:
	test_positive_loss: 0.01047874242067337
	test_negative_loss: 4.435910224914551
	test_positive_acc: 0.9974525827280065
	test_negative_acc: 0.3116801368932887
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 40.94007110595703 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.725
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233133554458618
	train_negative_loss: 2.280287981033325
	train_positive_acc: 0.7292751257673277
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.3516007363796234
	train_incorrect_loss: 0.30887648463249207
	train_positive_loss: 0.15412437915802002
	train_negative_loss: 1.4676300287246704
	train_correct_acc: 0.7826569986007029
	train_incorrect_acc: 0.997228705335353
	train_positive_acc: 0.9984943302122053
	train_negative_acc: 0.7221652570934465
	train_correct_nonzero: 25600
	train_incorrect_nonzero: 14500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.004337803926318884
	val_negative_loss: 1.3368185758590698
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.009626959450542927
	test_negative_loss: 1.3860119581222534
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.2780593931674957
	train_incorrect_loss: 0.316744327545166
	train_positive_loss: 0.13485969603061676
	train_negative_loss: 1.2696876525878906
	train_correct_acc: 0.7838715696703935
	train_incorrect_acc: 0.998241706505964
	train_positive_acc: 1.0
	train_negative_acc: 0.7236858405341062
	train_correct_nonzero: 25600
	train_incorrect_nonzero: 14500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 9.787998715182766e-05
	val_negative_loss: 1.6601723432540894
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0007083793170750141
	test_negative_loss: 1.7400511503219604
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.2630252242088318
	train_incorrect_loss: 0.30750060081481934
	train_positive_loss: 0.13035695254802704
	train_negative_loss: 1.2041878700256348
	train_correct_acc: 0.7945342253348522
	train_incorrect_acc: 0.9853528307051042
	train_positive_acc: 0.999894443784718
	train_negative_acc: 0.7274810050998853
	train_correct_nonzero: 25600
	train_incorrect_nonzero: 14500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0015428784536197782
	val_negative_loss: 1.3128923177719116
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.00571703165769577
	test_negative_loss: 1.4184720516204834
	test_positive_acc: 0.9985119047619048
	test_negative_acc: 0.020141962968994873
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.2401244193315506
	train_incorrect_loss: 0.2899223566055298
	train_positive_loss: 0.1227666437625885
	train_negative_loss: 1.0981858968734741
	train_correct_acc: 0.834178901846485
	train_incorrect_acc: 0.9466271237845229
	train_positive_acc: 0.9997955759392503
	train_negative_acc: 0.7503405929218887
	train_correct_nonzero: 25600
	train_incorrect_nonzero: 14500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0006120597245171666
	val_negative_loss: 1.4211236238479614
	val_positive_acc: 1.0
	val_negative_acc: 0.10970996216897858
test:
	test_positive_loss: 0.004667706787586212
	test_negative_loss: 1.52919602394104
	test_positive_acc: 0.9985119047619048
	test_negative_acc: 0.10704261095614967
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.2014363706111908
	train_incorrect_loss: 0.254658043384552
	train_positive_loss: 0.10738644003868103
	train_negative_loss: 0.9283763766288757
	train_correct_acc: 0.8813850036383414
	train_incorrect_acc: 0.9199230544626292
	train_positive_acc: 1.0
	train_negative_acc: 0.79077851943316
	train_correct_nonzero: 25600
	train_incorrect_nonzero: 14500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0004552563768811524
	val_negative_loss: 1.5710747241973877
	val_positive_acc: 1.0
	val_negative_acc: 0.13787305590584278
test:
	test_positive_loss: 0.006854247767478228
	test_negative_loss: 1.784445881843567
	test_positive_acc: 0.9985119047619048
	test_negative_acc: 0.1600683539191782
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.1750054508447647
	train_incorrect_loss: 0.22877873480319977
	train_positive_loss: 0.09661855548620224
	train_negative_loss: 0.7965267300605774
	train_correct_acc: 0.907047371354115
	train_incorrect_acc: 0.9203524956444824
	train_positive_acc: 0.9996015044114495
	train_negative_acc: 0.8241774826437023
	train_correct_nonzero: 25600
	train_incorrect_nonzero: 14500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 9.742209658725187e-05
	val_negative_loss: 1.723433494567871
	val_positive_acc: 1.0
	val_negative_acc: 0.2793190416141236
test:
	test_positive_loss: 0.009985143318772316
	test_negative_loss: 1.975085735321045
	test_positive_acc: 0.9958523302938197
	test_negative_acc: 0.2801901319273228
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.13503876328468323
	train_incorrect_loss: 0.1855839341878891
	train_positive_loss: 0.07850541919469833
	train_negative_loss: 0.6241232752799988
	train_correct_acc: 0.9317836650442478
	train_incorrect_acc: 0.9303847198800413
	train_positive_acc: 0.9997943145357219
	train_negative_acc: 0.8628459769307929
	train_correct_nonzero: 25600
	train_incorrect_nonzero: 14500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0024378816597163677
	val_negative_loss: 1.526078462600708
	val_positive_acc: 1.0
	val_negative_acc: 0.4766708701134931
test:
	test_positive_loss: 0.010386139154434204
	test_negative_loss: 1.954058289527893
	test_positive_acc: 0.9960247101204548
	test_negative_acc: 0.36436589147351156
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.11228984594345093
	train_incorrect_loss: 0.1559070199728012
	train_positive_loss: 0.0658106729388237
	train_negative_loss: 0.5186184048652649
	train_correct_acc: 0.9479985066753466
	train_incorrect_acc: 0.9420384398863814
	train_positive_acc: 0.9998482560106338
	train_negative_acc: 0.8917190833446068
	train_correct_nonzero: 25600
	train_incorrect_nonzero: 14500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.7036829780845437e-06
	val_negative_loss: 2.06233549118042
	val_positive_acc: 1.0
	val_negative_acc: 0.39827658680117695
test:
	test_positive_loss: 0.018160497769713402
	test_negative_loss: 2.4870963096618652
	test_positive_acc: 0.9947362588652482
	test_negative_acc: 0.3911891492909799
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.08274020254611969
	train_incorrect_loss: 0.1185554638504982
	train_positive_loss: 0.04987885057926178
	train_negative_loss: 0.3786258399486542
	train_correct_acc: 0.9635222236646765
	train_incorrect_acc: 0.9549145436996599
	train_positive_acc: 0.9997906382940587
	train_negative_acc: 0.9204869651929799
	train_correct_nonzero: 25600
	train_incorrect_nonzero: 14500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 9.302196303906385e-06
	val_negative_loss: 2.57558274269104
	val_positive_acc: 1.0
	val_negative_acc: 0.37620849096258935
test:
	test_positive_loss: 0.008999470621347427
	test_negative_loss: 3.301906108856201
	test_positive_acc: 0.9971821175278622
	test_negative_acc: 0.28773816240091415
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.06205468997359276
	train_incorrect_loss: 0.0876036211848259
	train_positive_loss: 0.03742218762636185
	train_negative_loss: 0.2827337980270386
	train_correct_acc: 0.974580012135688
	train_incorrect_acc: 0.9675880377780095
	train_positive_acc: 0.9998071584464094
	train_negative_acc: 0.9440439515595425
	train_correct_nonzero: 25600
	train_incorrect_nonzero: 14500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.5400007075404574e-07
	val_negative_loss: 3.8108630180358887
	val_positive_acc: 1.0
	val_negative_acc: 0.30601092896174864
test:
	test_positive_loss: 0.014472924172878265
	test_negative_loss: 4.54182767868042
	test_positive_acc: 0.9971821175278622
	test_negative_acc: 0.2819059452342286
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.14632225036621 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.75
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233088493347168
	train_negative_loss: 2.2801828384399414
	train_positive_acc: 0.7311465810586171
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.3492729663848877
	train_incorrect_loss: 0.27752941846847534
	train_positive_loss: 0.14223666489124298
	train_negative_loss: 1.5705045461654663
	train_correct_acc: 0.7978619108910225
	train_incorrect_acc: 0.9987982418747611
	train_positive_acc: 0.9984943302122053
	train_negative_acc: 0.74776870292652
	train_correct_nonzero: 25100
	train_incorrect_nonzero: 15000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.004069397691637278
	val_negative_loss: 1.4561190605163574
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.008851375430822372
	test_negative_loss: 1.4941577911376953
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.277608722448349
	train_incorrect_loss: 0.28312215209007263
	train_positive_loss: 0.12313485145568848
	train_negative_loss: 1.3626166582107544
	train_correct_acc: 0.7989177758278989
	train_incorrect_acc: 0.9994970212846574
	train_positive_acc: 1.0
	train_negative_acc: 0.7489863493736456
	train_correct_nonzero: 25100
	train_incorrect_nonzero: 15000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0004479675553739071
	val_negative_loss: 1.661231279373169
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0016152283642441034
	test_negative_loss: 1.7021973133087158
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.26319101452827454
	train_incorrect_loss: 0.2770613729953766
	train_positive_loss: 0.12004075944423676
	train_negative_loss: 1.2993967533111572
	train_correct_acc: 0.8050976953035481
	train_incorrect_acc: 0.9894084866548096
	train_positive_acc: 1.0
	train_negative_acc: 0.7483246983881676
	train_correct_nonzero: 25100
	train_incorrect_nonzero: 15000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 9.528380905976519e-05
	val_negative_loss: 1.6666685342788696
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0007941242074593902
	test_negative_loss: 1.7635688781738281
	test_positive_acc: 1.0
	test_negative_acc: 0.0070646139842440656
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.23779703676700592
	train_incorrect_loss: 0.26313894987106323
	train_positive_loss: 0.11309920996427536
	train_negative_loss: 1.180406093597412
	train_correct_acc: 0.8376163822770462
	train_incorrect_acc: 0.9611370950824963
	train_positive_acc: 0.9999591185969502
	train_negative_acc: 0.7674867554180199
	train_correct_nonzero: 25100
	train_incorrect_nonzero: 15000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 7.905858365120366e-05
	val_negative_loss: 1.949176549911499
	val_positive_acc: 1.0
	val_negative_acc: 0.05842791088692728
test:
	test_positive_loss: 0.0008505828445777297
	test_negative_loss: 2.1364526748657227
	test_positive_acc: 1.0
	test_negative_acc: 0.05190962501864242
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.2013484686613083
	train_incorrect_loss: 0.2335587441921234
	train_positive_loss: 0.10012871026992798
	train_negative_loss: 0.9948216080665588
	train_correct_acc: 0.8797804224771909
	train_incorrect_acc: 0.9345478752208047
	train_positive_acc: 0.9999562497265608
	train_negative_acc: 0.80083047181838
	train_correct_nonzero: 25100
	train_incorrect_nonzero: 15000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.118849781458266e-05
	val_negative_loss: 1.5381544828414917
	val_positive_acc: 1.0
	val_negative_acc: 0.24548129466162255
test:
	test_positive_loss: 0.0038488064892590046
	test_negative_loss: 1.8441344499588013
	test_positive_acc: 0.9986702127659575
	test_negative_acc: 0.20724635536685154
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.16781288385391235
	train_incorrect_loss: 0.20258085429668427
	train_positive_loss: 0.08692142367362976
	train_negative_loss: 0.8197215795516968
	train_correct_acc: 0.9103257767135342
	train_incorrect_acc: 0.9334764362809691
	train_positive_acc: 0.9998098797246571
	train_negative_acc: 0.8385897683253581
	train_correct_nonzero: 25100
	train_incorrect_nonzero: 15000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 4.683836959884502e-05
	val_negative_loss: 1.7647801637649536
	val_positive_acc: 1.0
	val_negative_acc: 0.2362337116435477
test:
	test_positive_loss: 0.006248967722058296
	test_negative_loss: 2.2931735515594482
	test_positive_acc: 0.9986702127659575
	test_negative_acc: 0.19305144463015597
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.1320406198501587
	train_incorrect_loss: 0.1650615930557251
	train_positive_loss: 0.07102259248495102
	train_negative_loss: 0.6567662954330444
	train_correct_acc: 0.9347445664297568
	train_incorrect_acc: 0.9400957666646109
	train_positive_acc: 0.9997475377213532
	train_negative_acc: 0.872978436886611
	train_correct_nonzero: 25100
	train_incorrect_nonzero: 15000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.84458417101996e-06
	val_negative_loss: 2.5161948204040527
	val_positive_acc: 1.0
	val_negative_acc: 0.32597730138713743
test:
	test_positive_loss: 0.0013945025857537985
	test_negative_loss: 3.1134774684906006
	test_positive_acc: 0.9986702127659575
	test_negative_acc: 0.23974380533184772
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.10253056138753891
	train_incorrect_loss: 0.13500359654426575
	train_positive_loss: 0.05790901556611061
	train_negative_loss: 0.5097276568412781
	train_correct_acc: 0.9505172663396739
	train_incorrect_acc: 0.9513563620993177
	train_positive_acc: 0.999845394565117
	train_negative_acc: 0.9012669664561682
	train_correct_nonzero: 25100
	train_incorrect_nonzero: 15000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.14967297296198e-08
	val_negative_loss: 3.1945908069610596
	val_positive_acc: 1.0
	val_negative_acc: 0.24905422446406053
test:
	test_positive_loss: 0.005359291099011898
	test_negative_loss: 4.024143218994141
	test_positive_acc: 0.9986702127659575
	test_negative_acc: 0.20993539512248316
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.08720459043979645
	train_incorrect_loss: 0.11164993047714233
	train_positive_loss: 0.04818274825811386
	train_negative_loss: 0.42665380239486694
	train_correct_acc: 0.9609143097488567
	train_incorrect_acc: 0.9598807527791169
	train_positive_acc: 0.9997857962046756
	train_negative_acc: 0.920844107979131
	train_correct_nonzero: 25100
	train_incorrect_nonzero: 15000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 9.771250475409943e-09
	val_negative_loss: 3.5637550354003906
	val_positive_acc: 1.0
	val_negative_acc: 0.18705338377469524
test:
	test_positive_loss: 0.007308993022888899
	test_negative_loss: 4.500438213348389
	test_positive_acc: 0.9986702127659575
	test_negative_acc: 0.14862295948338922
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.059711754322052
	train_incorrect_loss: 0.07932267338037491
	train_positive_loss: 0.03420824930071831
	train_negative_loss: 0.29111379384994507
	train_correct_acc: 0.9742646399876054
	train_incorrect_acc: 0.9725630846207421
	train_positive_acc: 0.9996865604602246
	train_negative_acc: 0.9472659298481185
	train_correct_nonzero: 25100
	train_incorrect_nonzero: 15000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.2702619400783988e-08
	val_negative_loss: 4.022068977355957
	val_positive_acc: 1.0
	val_negative_acc: 0.26649852879361074
test:
	test_positive_loss: 0.010347332805395126
	test_negative_loss: 5.311855316162109
	test_positive_acc: 0.9986702127659575
	test_negative_acc: 0.2551611090484008
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.247480154037476 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.775
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2330517768859863
	train_negative_loss: 2.279937982559204
	train_positive_acc: 0.7323999856677836
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.3475908637046814
	train_incorrect_loss: 0.24495305120944977
	train_positive_loss: 0.12969006597995758
	train_negative_loss: 1.6945350170135498
	train_correct_acc: 0.8139722497860552
	train_incorrect_acc: 0.9991468696679353
	train_positive_acc: 0.9984943302122053
	train_negative_acc: 0.7726339547949194
	train_correct_nonzero: 24600
	train_incorrect_nonzero: 15500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.002325671724975109
	val_negative_loss: 1.4575047492980957
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.004621990956366062
	test_negative_loss: 1.508649230003357
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.274090051651001
	train_incorrect_loss: 0.25183239579200745
	train_positive_loss: 0.1115395575761795
	train_negative_loss: 1.4652677774429321
	train_correct_acc: 0.8148103960985668
	train_incorrect_acc: 0.9999326009301072
	train_positive_acc: 1.0
	train_negative_acc: 0.7737682551548841
	train_correct_nonzero: 24600
	train_incorrect_nonzero: 15500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00012196793977636844
	val_negative_loss: 1.8505322933197021
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.00047125015407800674
	test_negative_loss: 1.8684884309768677
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.26215749979019165
	train_incorrect_loss: 0.24714545905590057
	train_positive_loss: 0.10890675336122513
	train_negative_loss: 1.4133994579315186
	train_correct_acc: 0.8164431477353145
	train_incorrect_acc: 0.9986479943251164
	train_positive_acc: 1.0
	train_negative_acc: 0.7737743149947309
	train_correct_nonzero: 24600
	train_incorrect_nonzero: 15500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00032996866502799094
	val_negative_loss: 1.453895092010498
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0011381471995264292
	test_negative_loss: 1.505134105682373
	test_positive_acc: 1.0
	test_negative_acc: 0.00910927868069635
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.237296462059021
	train_incorrect_loss: 0.23533892631530762
	train_positive_loss: 0.10329759120941162
	train_negative_loss: 1.2807673215866089
	train_correct_acc: 0.8365788653447048
	train_incorrect_acc: 0.9795519746108746
	train_positive_acc: 0.9998138669242671
	train_negative_acc: 0.7835893527937147
	train_correct_nonzero: 24600
	train_incorrect_nonzero: 15500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0005500107072293758
	val_negative_loss: 2.5521512031555176
	val_positive_acc: 1.0
	val_negative_acc: 0.01639344262295082
test:
	test_positive_loss: 0.0010112030431628227
	test_negative_loss: 2.69754695892334
	test_positive_acc: 1.0
	test_negative_acc: 0.034831734715637164
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.20048411190509796
	train_incorrect_loss: 0.21069598197937012
	train_positive_loss: 0.09224563091993332
	train_negative_loss: 1.0787476301193237
	train_correct_acc: 0.879183987640009
	train_incorrect_acc: 0.9516594653237807
	train_positive_acc: 0.9996953925002593
	train_negative_acc: 0.8146403509301623
	train_correct_nonzero: 24600
	train_incorrect_nonzero: 15500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00016467826208099723
	val_negative_loss: 1.9398863315582275
	val_positive_acc: 1.0
	val_negative_acc: 0.17065994115174443
test:
	test_positive_loss: 0.0007409905083477497
	test_negative_loss: 2.238762855529785
	test_positive_acc: 1.0
	test_negative_acc: 0.12011292800640719
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.16616271436214447
	train_incorrect_loss: 0.18508002161979675
	train_positive_loss: 0.08073971420526505
	train_negative_loss: 0.8851323127746582
	train_correct_acc: 0.9073128447907874
	train_incorrect_acc: 0.9467163208437593
	train_positive_acc: 0.9998507067900453
	train_negative_acc: 0.8453326674520709
	train_correct_nonzero: 24600
	train_incorrect_nonzero: 15500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.2228803320322186e-05
	val_negative_loss: 2.0729153156280518
	val_positive_acc: 1.0
	val_negative_acc: 0.23160992013451032
test:
	test_positive_loss: 0.0008893837803043425
	test_negative_loss: 2.561755657196045
	test_positive_acc: 1.0
	test_negative_acc: 0.19578780984943067
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.13288961350917816
	train_incorrect_loss: 0.15404105186462402
	train_positive_loss: 0.0671519935131073
	train_negative_loss: 0.7238748073577881
	train_correct_acc: 0.9306170207513546
	train_incorrect_acc: 0.9497610165273234
	train_positive_acc: 0.9997928768463612
	train_negative_acc: 0.8764284415353147
	train_correct_nonzero: 24600
	train_incorrect_nonzero: 15500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00046499050222337246
	val_negative_loss: 2.4337611198425293
	val_positive_acc: 1.0
	val_negative_acc: 0.18348045397225726
test:
	test_positive_loss: 0.0019476383458822966
	test_negative_loss: 2.859053134918213
	test_positive_acc: 1.0
	test_negative_acc: 0.18753155135993516
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.10447622835636139
	train_incorrect_loss: 0.12498873472213745
	train_positive_loss: 0.054795362055301666
	train_negative_loss: 0.5659915804862976
	train_correct_acc: 0.9492357671714422
	train_incorrect_acc: 0.9567765094769198
	train_positive_acc: 0.9998026190897646
	train_negative_acc: 0.9033575894481554
	train_correct_nonzero: 24600
	train_incorrect_nonzero: 15500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 7.49674582039006e-05
	val_negative_loss: 2.973888397216797
	val_positive_acc: 1.0
	val_negative_acc: 0.22803699033207228
test:
	test_positive_loss: 0.0037879429291933775
	test_negative_loss: 3.4870452880859375
	test_positive_acc: 0.9986702127659575
	test_negative_acc: 0.2364169243029472
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.07553403824567795
	train_incorrect_loss: 0.09627251327037811
	train_positive_loss: 0.042131487280130386
	train_negative_loss: 0.4015255570411682
	train_correct_acc: 0.9663533089458549
	train_incorrect_acc: 0.9662196380325415
	train_positive_acc: 0.9999491068247748
	train_negative_acc: 0.932489423444493
	train_correct_nonzero: 24600
	train_incorrect_nonzero: 15500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 8.726582336748834e-07
	val_negative_loss: 4.530353546142578
	val_positive_acc: 1.0
	val_negative_acc: 0.14964270701975618
test:
	test_positive_loss: 0.0012989523820579052
	test_negative_loss: 5.31645393371582
	test_positive_acc: 0.99875
	test_negative_acc: 0.12589288874108756
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.05971803143620491
	train_incorrect_loss: 0.07562590390443802
	train_positive_loss: 0.03317989781498909
	train_negative_loss: 0.32004186511039734
	train_correct_acc: 0.9733957181763627
	train_incorrect_acc: 0.9711891579739516
	train_positive_acc: 1.0
	train_negative_acc: 0.9447664410985325
	train_correct_nonzero: 24600
	train_incorrect_nonzero: 15500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.908492018922516e-08
	val_negative_loss: 4.63006591796875
	val_positive_acc: 1.0
	val_negative_acc: 0.24548129466162255
test:
	test_positive_loss: 0.006112558767199516
	test_negative_loss: 5.438509464263916
	test_positive_acc: 0.99875
	test_negative_acc: 0.25867193069237815
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.11338806152344 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.8
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2329845428466797
	train_negative_loss: 2.279938220977783
	train_positive_acc: 0.7351557951388837
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.34100669622421265
	train_incorrect_loss: 0.21508200466632843
	train_positive_loss: 0.11731205135583878
	train_negative_loss: 1.8324962854385376
	train_correct_acc: 0.8308739144562688
	train_incorrect_acc: 0.9991895261845387
	train_positive_acc: 0.9984943302122053
	train_negative_acc: 0.7974387557291883
	train_correct_nonzero: 24100
	train_incorrect_nonzero: 16000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.001834202092140913
	val_negative_loss: 1.5896775722503662
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.004504076670855284
	test_negative_loss: 1.6510648727416992
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.268309623003006
	train_incorrect_loss: 0.22076138854026794
	train_positive_loss: 0.09954231232404709
	train_negative_loss: 1.5762659311294556
	train_correct_acc: 0.8315512017845853
	train_incorrect_acc: 0.9997522305942984
	train_positive_acc: 1.0
	train_negative_acc: 0.7985324433200582
	train_correct_nonzero: 24100
	train_incorrect_nonzero: 16000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0002508080215193331
	val_negative_loss: 1.725350260734558
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0007423436036333442
	test_negative_loss: 1.8539446592330933
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.25351595878601074
	train_incorrect_loss: 0.2149832546710968
	train_positive_loss: 0.09623324126005173
	train_negative_loss: 1.4956614971160889
	train_correct_acc: 0.8332580130205838
	train_incorrect_acc: 0.9985441552316783
	train_positive_acc: 1.0
	train_negative_acc: 0.7983990166908845
	train_correct_nonzero: 24100
	train_incorrect_nonzero: 16000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0002514829393476248
	val_negative_loss: 1.6730244159698486
	val_positive_acc: 1.0
	val_negative_acc: 0.00819672131147541
test:
	test_positive_loss: 0.0008775248425081372
	test_negative_loss: 1.8153059482574463
	test_positive_acc: 1.0
	test_negative_acc: 0.01635823435351912
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.22974829375743866
	train_incorrect_loss: 0.2055085152387619
	train_positive_loss: 0.09181373566389084
	train_negative_loss: 1.3601759672164917
	train_correct_acc: 0.8512509461609232
	train_incorrect_acc: 0.9833055698364689
	train_positive_acc: 0.9998982950460713
	train_negative_acc: 0.8081149949159062
	train_correct_nonzero: 24100
	train_incorrect_nonzero: 16000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00015612004790455103
	val_negative_loss: 2.021862030029297
	val_positive_acc: 1.0
	val_negative_acc: 0.06305170239596469
test:
	test_positive_loss: 0.0011028338922187686
	test_negative_loss: 2.161088466644287
	test_positive_acc: 1.0
	test_negative_acc: 0.0494882950549462
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.19082221388816833
	train_incorrect_loss: 0.1813783347606659
	train_positive_loss: 0.08059055358171463
	train_negative_loss: 1.126328945159912
	train_correct_acc: 0.8907365838875867
	train_incorrect_acc: 0.9609807636483435
	train_positive_acc: 0.9999520429694994
	train_negative_acc: 0.8380498643625178
	train_correct_nonzero: 24100
	train_incorrect_nonzero: 16000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.059332084376365e-05
	val_negative_loss: 1.9211808443069458
	val_positive_acc: 1.0
	val_negative_acc: 0.17633459436738125
test:
	test_positive_loss: 0.0010580953676253557
	test_negative_loss: 2.3329386711120605
	test_positive_acc: 1.0
	test_negative_acc: 0.12731396775635162
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.1550981104373932
	train_incorrect_loss: 0.1580200344324112
	train_positive_loss: 0.07003448903560638
	train_negative_loss: 0.9121781587600708
	train_correct_acc: 0.9163936477858797
	train_incorrect_acc: 0.9564640354859648
	train_positive_acc: 0.9999577327866774
	train_negative_acc: 0.8644829552041934
	train_correct_nonzero: 24100
	train_incorrect_nonzero: 16000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 4.521947175817331e-06
	val_negative_loss: 2.3159451484680176
	val_positive_acc: 1.0
	val_negative_acc: 0.2547288776796973
test:
	test_positive_loss: 0.0004760776355396956
	test_negative_loss: 2.747009038925171
	test_positive_acc: 1.0
	test_negative_acc: 0.1836662142404201
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.13022662699222565
	train_incorrect_loss: 0.13501879572868347
	train_positive_loss: 0.059943102300167084
	train_negative_loss: 0.7703983187675476
	train_correct_acc: 0.9339466920425759
	train_incorrect_acc: 0.9583347293635798
	train_positive_acc: 0.9999049907886307
	train_negative_acc: 0.8879694334329683
	train_correct_nonzero: 24100
	train_incorrect_nonzero: 16000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 7.441175142730572e-08
	val_negative_loss: 3.4916906356811523
	val_positive_acc: 1.0
	val_negative_acc: 0.13892391761244222
test:
	test_positive_loss: 0.00017159189155790955
	test_negative_loss: 4.129538536071777
	test_positive_acc: 1.0
	test_negative_acc: 0.11148683013409605
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.09799949079751968
	train_incorrect_loss: 0.10848549753427505
	train_positive_loss: 0.0482657365500927
	train_negative_loss: 0.5877767205238342
	train_correct_acc: 0.9516089935520776
	train_incorrect_acc: 0.9667526495272716
	train_positive_acc: 0.9999491068247748
	train_negative_acc: 0.9152478041650451
	train_correct_nonzero: 24100
	train_incorrect_nonzero: 16000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 4.229195127436469e-08
	val_negative_loss: 3.5654497146606445
	val_positive_acc: 1.0
	val_negative_acc: 0.18705338377469524
test:
	test_positive_loss: 0.0008521651034243405
	test_negative_loss: 4.338771820068359
	test_positive_acc: 1.0
	test_negative_acc: 0.17461830540658868
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.07420045882463455
	train_incorrect_loss: 0.08364885300397873
	train_positive_loss: 0.03707507252693176
	train_negative_loss: 0.4381972551345825
	train_correct_acc: 0.966969145034225
	train_incorrect_acc: 0.9731951682714498
	train_positive_acc: 1.0
	train_negative_acc: 0.9388466101806073
	train_correct_nonzero: 24100
	train_incorrect_nonzero: 16000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0
	val_negative_loss: 6.546142578125
	val_positive_acc: 1.0
	val_negative_acc: 0.09226565783942833
test:
	test_positive_loss: 5.7664510677568614e-05
	test_negative_loss: 7.281119346618652
	test_positive_acc: 1.0
	test_negative_acc: 0.11025587193956668
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.05776761472225189
	train_incorrect_loss: 0.0665292888879776
	train_positive_loss: 0.029482021927833557
	train_negative_loss: 0.3406127095222473
	train_correct_acc: 0.9744234775592198
	train_incorrect_acc: 0.9761036592288589
	train_positive_acc: 0.9998974739231656
	train_negative_acc: 0.9501585014557847
	train_correct_nonzero: 24100
	train_incorrect_nonzero: 16000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0
	val_negative_loss: 6.03128719329834
	val_positive_acc: 1.0
	val_negative_acc: 0.158890290037831
test:
	test_positive_loss: 5.2304974815342575e-05
	test_negative_loss: 7.036602973937988
	test_positive_acc: 1.0
	test_negative_acc: 0.1742979597606134
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.038230657577515 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.825
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2329533100128174
	train_negative_loss: 2.279864549636841
	train_positive_acc: 0.7370659224225704
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.3297853469848633
	train_incorrect_loss: 0.18664278090000153
	train_positive_loss: 0.1049313023686409
	train_negative_loss: 1.9854471683502197
	train_correct_acc: 0.8483599789546941
	train_incorrect_acc: 0.9991687448046549
	train_positive_acc: 0.9984943302122053
	train_negative_acc: 0.8223232269968537
	train_correct_nonzero: 23600
	train_incorrect_nonzero: 16500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.001969494391232729
	val_negative_loss: 1.6929194927215576
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0035960411187261343
	test_negative_loss: 1.7475502490997314
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.2605096995830536
	train_incorrect_loss: 0.19054220616817474
	train_positive_loss: 0.08758983761072159
	train_negative_loss: 1.708680272102356
	train_correct_acc: 0.8492701287453438
	train_incorrect_acc: 1.0
	train_positive_acc: 1.0
	train_negative_acc: 0.8234924101047747
	train_correct_nonzero: 23600
	train_incorrect_nonzero: 16500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00040701747639104724
	val_negative_loss: 1.8955869674682617
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0010751246009021997
	test_negative_loss: 1.9484916925430298
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.24381855130195618
	train_incorrect_loss: 0.18575969338417053
	train_positive_loss: 0.08461901545524597
	train_negative_loss: 1.606539249420166
	train_correct_acc: 0.8504253255872779
	train_incorrect_acc: 0.9992724940259577
	train_positive_acc: 1.0
	train_negative_acc: 0.8232069856097233
	train_correct_nonzero: 23600
	train_incorrect_nonzero: 16500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00036679644836112857
	val_negative_loss: 1.752354621887207
	val_positive_acc: 1.0
	val_negative_acc: 0.00819672131147541
test:
	test_positive_loss: 0.0010251246858388186
	test_negative_loss: 1.8118488788604736
	test_positive_acc: 1.0
	test_negative_acc: 0.0033054602630074328
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.21705642342567444
	train_incorrect_loss: 0.1738303005695343
	train_positive_loss: 0.07923001050949097
	train_negative_loss: 1.4412363767623901
	train_correct_acc: 0.8676025951814067
	train_incorrect_acc: 0.9860959712440489
	train_positive_acc: 0.9998440982405031
	train_negative_acc: 0.8326010221097196
	train_correct_nonzero: 23600
	train_incorrect_nonzero: 16500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00026600249111652374
	val_negative_loss: 2.0124926567077637
	val_positive_acc: 1.0
	val_negative_acc: 0.0783942833123161
test:
	test_positive_loss: 0.001694145379588008
	test_negative_loss: 2.066542625427246
	test_positive_acc: 1.0
	test_negative_acc: 0.054925227934818924
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.17651328444480896
	train_incorrect_loss: 0.15309178829193115
	train_positive_loss: 0.06941445916891098
	train_negative_loss: 1.1660854816436768
	train_correct_acc: 0.9022251613866679
	train_incorrect_acc: 0.9678743473396133
	train_positive_acc: 0.9998532991458287
	train_negative_acc: 0.8591284291386827
	train_correct_nonzero: 23600
	train_incorrect_nonzero: 16500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0012288963189348578
	val_negative_loss: 2.3665831089019775
	val_positive_acc: 1.0
	val_negative_acc: 0.17065994115174443
test:
	test_positive_loss: 0.0019613478798419237
	test_negative_loss: 2.533508062362671
	test_positive_acc: 0.9989406779661016
	test_negative_acc: 0.1283789740005084
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.13843710720539093
	train_incorrect_loss: 0.13118605315685272
	train_positive_loss: 0.05930003896355629
	train_negative_loss: 0.8933872580528259
	train_correct_acc: 0.9287856857832825
	train_incorrect_acc: 0.961840298492172
	train_positive_acc: 0.9997760974128501
	train_negative_acc: 0.884848917061501
	train_correct_nonzero: 23600
	train_incorrect_nonzero: 16500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.23874806376989e-05
	val_negative_loss: 3.432748794555664
	val_positive_acc: 1.0
	val_negative_acc: 0.14501891551071877
test:
	test_positive_loss: 0.00022773051750846207
	test_negative_loss: 3.5253100395202637
	test_positive_acc: 1.0
	test_negative_acc: 0.12584240482087394
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.10564368963241577
	train_incorrect_loss: 0.1020236536860466
	train_positive_loss: 0.04639742523431778
	train_negative_loss: 0.6972579956054688
	train_correct_acc: 0.9498111198992075
	train_incorrect_acc: 0.9688896288058944
	train_positive_acc: 0.9998948945294263
	train_negative_acc: 0.9154519971856713
	train_correct_nonzero: 23600
	train_incorrect_nonzero: 16500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.188268601661548e-05
	val_negative_loss: 3.5016207695007324
	val_positive_acc: 1.0
	val_negative_acc: 0.18348045397225726
test:
	test_positive_loss: 0.004135073162615299
	test_negative_loss: 3.6691203117370605
	test_positive_acc: 0.9989406779661016
	test_negative_acc: 0.1768622770257502
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.08251596987247467
	train_incorrect_loss: 0.08474105596542358
	train_positive_loss: 0.03874890133738518
	train_negative_loss: 0.5525175333023071
	train_correct_acc: 0.9625040834006574
	train_incorrect_acc: 0.9734598137050446
	train_positive_acc: 0.9999020546439062
	train_negative_acc: 0.9336422443824466
	train_correct_nonzero: 23600
	train_incorrect_nonzero: 16500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.2849691916349002e-08
	val_negative_loss: 5.228724479675293
	val_positive_acc: 1.0
	val_negative_acc: 0.1414459857082808
test:
	test_positive_loss: 0.0006032587843947113
	test_negative_loss: 5.426527976989746
	test_positive_acc: 1.0
	test_negative_acc: 0.11989359258049602
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.06431736797094345
	train_incorrect_loss: 0.06718838214874268
	train_positive_loss: 0.030507037416100502
	train_negative_loss: 0.4240509569644928
	train_correct_acc: 0.9718683898497418
	train_incorrect_acc: 0.9770727165590657
	train_positive_acc: 0.999854210627278
	train_negative_acc: 0.9479572932076963
	train_correct_nonzero: 23600
	train_incorrect_nonzero: 16500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.2473859218052894e-08
	val_negative_loss: 6.966468811035156
	val_positive_acc: 1.0
	val_negative_acc: 0.1414459857082808
test:
	test_positive_loss: 0.002621376421302557
	test_negative_loss: 7.13886022567749
	test_positive_acc: 0.9989406779661016
	test_negative_acc: 0.09798975948272168
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.05152663215994835
	train_incorrect_loss: 0.05249987915158272
	train_positive_loss: 0.02415383979678154
	train_negative_loss: 0.3389386236667633
	train_correct_acc: 0.9786347634959136
	train_incorrect_acc: 0.9825188133587229
	train_positive_acc: 0.9998952834364306
	train_negative_acc: 0.9600031895729005
	train_correct_nonzero: 23600
	train_incorrect_nonzero: 16500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00025484192883595824
	val_negative_loss: 6.351070880889893
	val_positive_acc: 1.0
	val_negative_acc: 0.21269440941572088
test:
	test_positive_loss: 0.005785407964140177
	test_negative_loss: 6.099522590637207
	test_positive_acc: 0.9989406779661016
	test_negative_acc: 0.20558217275933327
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 40.40057063102722 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.85
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2329137325286865
	train_negative_loss: 2.2799253463745117
	train_positive_acc: 0.7389251857273365
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.3151025176048279
	train_incorrect_loss: 0.15989834070205688
	train_positive_loss: 0.09260545670986176
	train_negative_loss: 2.161811113357544
	train_correct_acc: 0.8666808221830568
	train_incorrect_acc: 0.9991300817723133
	train_positive_acc: 0.9984943302122053
	train_negative_acc: 0.8472232009805232
	train_correct_nonzero: 23100
	train_incorrect_nonzero: 17000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00211930088698864
	val_negative_loss: 1.8477513790130615
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0033054316882044077
	test_negative_loss: 1.9021122455596924
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.24709361791610718
	train_incorrect_loss: 0.1614980548620224
	train_positive_loss: 0.07546292245388031
	train_negative_loss: 1.8477413654327393
	train_correct_acc: 0.8676860199918843
	train_incorrect_acc: 1.0
	train_positive_acc: 1.0
	train_negative_acc: 0.8484294930623955
	train_correct_nonzero: 23100
	train_incorrect_nonzero: 17000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0006742524565197527
	val_negative_loss: 2.0810658931732178
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0012708494905382395
	test_negative_loss: 2.1525635719299316
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.2324361503124237
	train_incorrect_loss: 0.15733733773231506
	train_positive_loss: 0.07285308837890625
	train_negative_loss: 1.7463747262954712
	train_correct_acc: 0.8683282231597945
	train_incorrect_acc: 0.9997161820144395
	train_positive_acc: 1.0
	train_negative_acc: 0.8480129177644241
	train_correct_nonzero: 23100
	train_incorrect_nonzero: 17000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0005547492764890194
	val_negative_loss: 2.1543593406677246
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0008745515951886773
	test_negative_loss: 2.1547718048095703
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.20345793664455414
	train_incorrect_loss: 0.14822351932525635
	train_positive_loss: 0.06855068355798721
	train_negative_loss: 1.534314513206482
	train_correct_acc: 0.8803376541580187
	train_incorrect_acc: 0.9902488100381389
	train_positive_acc: 1.0
	train_negative_acc: 0.8539367482733738
	train_correct_nonzero: 23100
	train_incorrect_nonzero: 17000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0013603141997009516
	val_negative_loss: 2.1328628063201904
	val_positive_acc: 1.0
	val_negative_acc: 0.04203446826397646
test:
	test_positive_loss: 0.0015590798575431108
	test_negative_loss: 2.1851646900177
	test_positive_acc: 1.0
	test_negative_acc: 0.057629872232572515
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.16564153134822845
	train_incorrect_loss: 0.13145987689495087
	train_positive_loss: 0.06055442988872528
	train_negative_loss: 1.2478407621383667
	train_correct_acc: 0.9094127857762796
	train_incorrect_acc: 0.9720742869539672
	train_positive_acc: 1.0
	train_negative_acc: 0.8723496042363266
	train_correct_nonzero: 23100
	train_incorrect_nonzero: 17000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0014751270646229386
	val_negative_loss: 2.7330477237701416
	val_positive_acc: 1.0
	val_negative_acc: 0.09226565783942833
test:
	test_positive_loss: 0.0007464979426003993
	test_negative_loss: 2.6496024131774902
	test_positive_acc: 1.0
	test_negative_acc: 0.12466882487283949
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.13304638862609863
	train_incorrect_loss: 0.1122969314455986
	train_positive_loss: 0.052032217383384705
	train_negative_loss: 0.9836028546467424
	train_correct_acc: 0.9330929977686849
	train_incorrect_acc: 0.9709970497539526
	train_positive_acc: 0.9998626390882791
	train_negative_acc: 0.8983441486283994
	train_correct_nonzero: 23100
	train_incorrect_nonzero: 17000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 9.541361214360222e-05
	val_negative_loss: 4.042159080505371
	val_positive_acc: 1.0
	val_negative_acc: 0.05380411937788987
test:
	test_positive_loss: 0.00016727703041397035
	test_negative_loss: 4.102011680603027
	test_positive_acc: 1.0
	test_negative_acc: 0.09558736880437262
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.09381604194641113
	train_incorrect_loss: 0.08711497485637665
	train_positive_loss: 0.04030558839440346
	train_negative_loss: 0.7068808788992464
	train_correct_acc: 0.9572731416236984
	train_incorrect_acc: 0.9716507446770206
	train_positive_acc: 0.9999529478191314
	train_negative_acc: 0.9263995406141694
	train_correct_nonzero: 23100
	train_incorrect_nonzero: 17000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0001985027629416436
	val_negative_loss: 4.681186199188232
	val_positive_acc: 1.0
	val_negative_acc: 0.12147961328289197
test:
	test_positive_loss: 0.002552686259150505
	test_negative_loss: 4.782864570617676
	test_positive_acc: 0.9974154135338346
	test_negative_acc: 0.08314850061704387
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.07174795866012573
	train_incorrect_loss: 0.07076049596071243
	train_positive_loss: 0.03270260989665985
	train_negative_loss: 0.5492279529571533
	train_correct_acc: 0.9679520031137628
	train_incorrect_acc: 0.9744801963327302
	train_positive_acc: 0.9999520429694994
	train_negative_acc: 0.9415786727847087
	train_correct_nonzero: 23100
	train_incorrect_nonzero: 17000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.1712058949342463e-05
	val_negative_loss: 6.450709819793701
	val_positive_acc: 1.0
	val_negative_acc: 0.11685582177385456
test:
	test_positive_loss: 7.490160351153463e-05
	test_negative_loss: 6.670713424682617
	test_positive_acc: 1.0
	test_negative_acc: 0.1085593882614384
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.04916992411017418
	train_incorrect_loss: 0.051110368221998215
	train_positive_loss: 0.02342894859611988
	train_negative_loss: 0.3696371912956238
	train_correct_acc: 0.9795834307560182
	train_incorrect_acc: 0.9815550546637597
	train_positive_acc: 1.0
	train_negative_acc: 0.9610620612871474
	train_correct_nonzero: 23100
	train_incorrect_nonzero: 17000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.002438552677631378
	val_negative_loss: 5.8962554931640625
	val_positive_acc: 1.0
	val_negative_acc: 0.18810424548129467
test:
	test_positive_loss: 0.004674355499446392
	test_negative_loss: 6.282546043395996
	test_positive_acc: 0.9975737215378873
	test_negative_acc: 0.1452012868602791
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.039075691252946854
	train_incorrect_loss: 0.041378676891326904
	train_positive_loss: 0.01907256990671158
	train_negative_loss: 0.2902963484439533
	train_correct_acc: 0.9840091423709935
	train_incorrect_acc: 0.9848424456945867
	train_positive_acc: 0.9998511809843649
	train_negative_acc: 0.9689937313898273
	train_correct_nonzero: 23100
	train_incorrect_nonzero: 17000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.001199234451633e-05
	val_negative_loss: 8.564860343933105
	val_positive_acc: 1.0
	val_negative_acc: 0.10046237915090374
test:
	test_positive_loss: 9.03804975678213e-05
	test_negative_loss: 8.680683135986328
	test_positive_acc: 1.0
	test_negative_acc: 0.09424060682427987
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 40.47658133506775 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.875
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2328531742095947
	train_negative_loss: 2.2799809871606493
	train_positive_acc: 0.7410113677003686
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.30103540420532227
	train_incorrect_loss: 0.1308218389749527
	train_positive_loss: 0.08017140626907349
	train_negative_loss: 2.411853075027466
	train_correct_acc: 0.8858635983261752
	train_incorrect_acc: 0.9991498526411244
	train_positive_acc: 0.9984943302122053
	train_negative_acc: 0.8721546733428277
	train_correct_nonzero: 22600
	train_incorrect_nonzero: 17500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.003931188024580479
	val_negative_loss: 2.0698447227478027
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.004940310027450323
	test_negative_loss: 2.105708122253418
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.23474885523319244
	train_incorrect_loss: 0.13232754170894623
	train_positive_loss: 0.06348993629217148
	train_negative_loss: 2.040980339050293
	train_correct_acc: 0.8868144268117795
	train_incorrect_acc: 1.0
	train_positive_acc: 1.0
	train_negative_acc: 0.8733187356961942
	train_correct_nonzero: 22600
	train_incorrect_nonzero: 17500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.001641402137465775
	val_negative_loss: 1.9749019145965576
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0026970566250383854
	test_negative_loss: 2.0571999549865723
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.215824693441391
	train_incorrect_loss: 0.12929409742355347
	train_positive_loss: 0.06102234125137329
	train_negative_loss: 1.8994901180267334
	train_correct_acc: 0.8875047325113937
	train_incorrect_acc: 0.9995773552029091
	train_positive_acc: 1.0
	train_negative_acc: 0.8728184339473247
	train_correct_nonzero: 22600
	train_incorrect_nonzero: 17500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00029849971178919077
	val_negative_loss: 2.7060914039611816
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0006561878835782409
	test_negative_loss: 2.787529945373535
	test_positive_acc: 1.0
	test_negative_acc: 0.0029778786159954623
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.18696387112140656
	train_incorrect_loss: 0.12125326693058014
	train_positive_loss: 0.05710352212190628
	train_negative_loss: 1.6520017385482788
	train_correct_acc: 0.8984798666003999
	train_incorrect_acc: 0.9913083974800508
	train_positive_acc: 1.0
	train_negative_acc: 0.8781593628116678
	train_correct_nonzero: 22600
	train_incorrect_nonzero: 17500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.003483694279566407
	val_negative_loss: 2.494856357574463
	val_positive_acc: 1.0
	val_negative_acc: 0.01639344262295082
test:
	test_positive_loss: 0.004177243448793888
	test_negative_loss: 2.5958549976348877
	test_positive_acc: 1.0
	test_negative_acc: 0.004123942917547569
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.1471072882413864
	train_incorrect_loss: 0.1053609699010849
	train_positive_loss: 0.04930158331990242
	train_negative_loss: 1.2952488660812378
	train_correct_acc: 0.9237873435954328
	train_incorrect_acc: 0.980005355080243
	train_positive_acc: 1.0
	train_negative_acc: 0.8966535030581786
	train_correct_nonzero: 22600
	train_incorrect_nonzero: 17500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00021237158216536045
	val_negative_loss: 3.368234634399414
	val_positive_acc: 1.0
	val_negative_acc: 0.10046237915090374
test:
	test_positive_loss: 0.0006992026465013623
	test_negative_loss: 3.530571222305298
	test_positive_acc: 1.0
	test_negative_acc: 0.052042210325315905
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.12329699099063873
	train_incorrect_loss: 0.09359444677829742
	train_positive_loss: 0.043711256235837936
	train_negative_loss: 1.0623930549062788
	train_correct_acc: 0.9413170012197147
	train_incorrect_acc: 0.9770514718190004
	train_positive_acc: 0.9999057793369683
	train_negative_acc: 0.9137979773668475
	train_correct_nonzero: 22600
	train_incorrect_nonzero: 17500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 4.838660970563069e-06
	val_negative_loss: 3.5441720485687256
	val_positive_acc: 1.0
	val_negative_acc: 0.15069356872635561
test:
	test_positive_loss: 0.00046519996249116957
	test_negative_loss: 3.7888755798339844
	test_positive_acc: 1.0
	test_negative_acc: 0.13511124557804322
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.08162002265453339
	train_incorrect_loss: 0.06792397797107697
	train_positive_loss: 0.031838785856962204
	train_negative_loss: 0.7259825824620202
	train_correct_acc: 0.9639866877185816
	train_incorrect_acc: 0.9788795157249905
	train_positive_acc: 0.9999562497265608
	train_negative_acc: 0.9409567398904102
	train_correct_nonzero: 22600
	train_incorrect_nonzero: 17500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0003316639340482652
	val_negative_loss: 4.803919792175293
	val_positive_acc: 1.0
	val_negative_acc: 0.12042875157629256
test:
	test_positive_loss: 0.0010944469831883907
	test_negative_loss: 5.056619644165039
	test_positive_acc: 1.0
	test_negative_acc: 0.129053146099345
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.05857095867395401
	train_incorrect_loss: 0.05384156480431557
	train_positive_loss: 0.025168417021632195
	train_negative_loss: 0.5239316186879296
	train_correct_acc: 0.973818467463745
	train_incorrect_acc: 0.9821711741479735
	train_positive_acc: 1.0
	train_negative_acc: 0.95481964480833
	train_correct_nonzero: 22600
	train_incorrect_nonzero: 17500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.1861007806146517e-05
	val_negative_loss: 6.097656726837158
	val_positive_acc: 1.0
	val_negative_acc: 0.13787305590584278
test:
	test_positive_loss: 0.0005471922340802848
	test_negative_loss: 6.156960964202881
	test_positive_acc: 1.0
	test_negative_acc: 0.12877042971420039
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.045897211879491806
	train_incorrect_loss: 0.04085371270775795
	train_positive_loss: 0.018961001187562943
	train_negative_loss: 0.41201186180114746
	train_correct_acc: 0.9802883622235856
	train_incorrect_acc: 0.9859295414109677
	train_positive_acc: 1.0
	train_negative_acc: 0.9655432830808379
	train_correct_nonzero: 22600
	train_incorrect_nonzero: 17500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0004459384363144636
	val_negative_loss: 7.494889259338379
	val_positive_acc: 1.0
	val_negative_acc: 0.12505254308532998
test:
	test_positive_loss: 0.007897189818322659
	test_negative_loss: 7.6787309646606445
	test_positive_acc: 0.9962580061264271
	test_negative_acc: 0.09187580700525844
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.030377227813005447
	train_incorrect_loss: 0.029077578336000443
	train_positive_loss: 0.013614625670015812
	train_negative_loss: 0.26224937023485834
	train_correct_acc: 0.9885781088360848
	train_incorrect_acc: 0.990258959634406
	train_positive_acc: 0.9999529478191314
	train_negative_acc: 0.9786177505241608
	train_correct_nonzero: 22600
	train_incorrect_nonzero: 17500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.1243533865344943e-07
	val_negative_loss: 10.046266555786133
	val_positive_acc: 1.0
	val_negative_acc: 0.0794451450189155
test:
	test_positive_loss: 0.00039600336458534
	test_negative_loss: 9.937719345092773
	test_positive_acc: 1.0
	test_negative_acc: 0.08913445784443051
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 40.9827241897583 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.9
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.232800006866455
	train_negative_loss: 2.27990967200445
	train_positive_acc: 0.7427453789211751
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.271523654460907
	train_incorrect_loss: 0.10668982565402985
	train_positive_loss: 0.06778205186128616
	train_negative_loss: 2.652023652989661
	train_correct_acc: 0.9059752457088273
	train_incorrect_acc: 0.9991133277916321
	train_positive_acc: 0.9984943302122053
	train_negative_acc: 0.8970377325813763
	train_correct_nonzero: 22100
	train_incorrect_nonzero: 18000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0032469620928168297
	val_negative_loss: 2.266190528869629
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.004021907690912485
	test_negative_loss: 2.3094446659088135
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.21169553697109222
	train_incorrect_loss: 0.10497421026229858
	train_positive_loss: 0.05128326639533043
	train_negative_loss: 2.241623634981332
	train_correct_acc: 0.9070963411721812
	train_incorrect_acc: 1.0
	train_positive_acc: 1.0
	train_negative_acc: 0.8981108387964917
	train_correct_nonzero: 22100
	train_incorrect_nonzero: 18000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0013820268213748932
	val_negative_loss: 2.2233428955078125
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.002240430796518922
	test_negative_loss: 2.2990927696228027
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.19109046459197998
	train_incorrect_loss: 0.10213097184896469
	train_positive_loss: 0.04892277345061302
	train_negative_loss: 2.036009357869625
	train_correct_acc: 0.9077234889017212
	train_incorrect_acc: 0.9997270873531021
	train_positive_acc: 1.0
	train_negative_acc: 0.898136331091651
	train_correct_nonzero: 22100
	train_incorrect_nonzero: 18000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0006638905615545809
	val_negative_loss: 2.4772825241088867
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0015275240875780582
	test_negative_loss: 2.5933618545532227
	test_positive_acc: 1.0
	test_negative_acc: 0.001358695652173913
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.16190271079540253
	train_incorrect_loss: 0.09520595520734787
	train_positive_loss: 0.045585695654153824
	train_negative_loss: 1.7236425880352058
	train_correct_acc: 0.9181136264871297
	train_incorrect_acc: 0.9933076404131154
	train_positive_acc: 0.9999622156729389
	train_negative_acc: 0.903755373842204
	train_correct_nonzero: 22100
	train_incorrect_nonzero: 18000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0033926863688975573
	val_negative_loss: 2.874300241470337
	val_positive_acc: 1.0
	val_negative_acc: 0.02101723413198823
test:
	test_positive_loss: 0.0028182859532535076
	test_negative_loss: 2.9020092487335205
	test_positive_acc: 1.0
	test_negative_acc: 0.010071279814195675
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.12218575924634933
	train_incorrect_loss: 0.08283481001853943
	train_positive_loss: 0.03927569091320038
	train_negative_loss: 1.3043327074870468
	train_correct_acc: 0.9389780115562667
	train_incorrect_acc: 0.9833415860163741
	train_positive_acc: 0.999955468471678
	train_negative_acc: 0.9182569710244638
	train_correct_nonzero: 22100
	train_incorrect_nonzero: 18000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0001791835529729724
	val_negative_loss: 3.9997620582580566
	val_positive_acc: 1.0
	val_negative_acc: 0.04203446826397646
test:
	test_positive_loss: 0.0002421619137749076
	test_negative_loss: 4.145509719848633
	test_positive_acc: 1.0
	test_negative_acc: 0.027917512046002194
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.09095270186662674
	train_incorrect_loss: 0.07001719623804092
	train_positive_loss: 0.03303685411810875
	train_negative_loss: 0.971929171311676
	train_correct_acc: 0.9561398755189844
	train_incorrect_acc: 0.9806079008928034
	train_positive_acc: 1.0
	train_negative_acc: 0.934376758631897
	train_correct_nonzero: 22100
	train_incorrect_nonzero: 18000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00011400332732591778
	val_negative_loss: 5.922588348388672
	val_positive_acc: 1.0
	val_negative_acc: 0.05380411937788987
test:
	test_positive_loss: 3.4696407965384424e-05
	test_negative_loss: 6.153966903686523
	test_positive_acc: 1.0
	test_negative_acc: 0.02172957647205806
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.058092523366212845
	train_incorrect_loss: 0.048572637140750885
	train_positive_loss: 0.023072069510817528
	train_negative_loss: 0.6321926326748339
	train_correct_acc: 0.9740822920235341
	train_incorrect_acc: 0.9847365987629704
	train_positive_acc: 1.0
	train_negative_acc: 0.957473393049926
	train_correct_nonzero: 22100
	train_incorrect_nonzero: 18000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 5.863040314579848e-06
	val_negative_loss: 6.776474475860596
	val_positive_acc: 1.0
	val_negative_acc: 0.08764186633039092
test:
	test_positive_loss: 0.0001317255082540214
	test_negative_loss: 6.928896427154541
	test_positive_acc: 1.0
	test_negative_acc: 0.07459590719141132
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.04206538945436478
	train_incorrect_loss: 0.038280948996543884
	train_positive_loss: 0.01812117174267769
	train_negative_loss: 0.45852475108635105
	train_correct_acc: 0.9813525880173108
	train_incorrect_acc: 0.9868704635622229
	train_positive_acc: 1.0
	train_negative_acc: 0.9674228367581807
	train_correct_nonzero: 22100
	train_incorrect_nonzero: 18000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.004133975598961115
	val_negative_loss: 7.4982781410217285
	val_positive_acc: 1.0
	val_negative_acc: 0.0794451450189155
test:
	test_positive_loss: 0.00038834987208247185
	test_negative_loss: 7.4988861083984375
	test_positive_acc: 1.0
	test_negative_acc: 0.08301867915350496
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.02424265630543232
	train_incorrect_loss: 0.023756518959999084
	train_positive_loss: 0.011252790689468384
	train_negative_loss: 0.2622096538543701
	train_correct_acc: 0.9904427872846435
	train_incorrect_acc: 0.9920624079840656
	train_positive_acc: 1.0
	train_negative_acc: 0.982298381983931
	train_correct_nonzero: 22100
	train_incorrect_nonzero: 18000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.1517000732274028e-06
	val_negative_loss: 12.546260833740234
	val_positive_acc: 1.0
	val_negative_acc: 0.01639344262295082
test:
	test_positive_loss: 8.95568177838868e-07
	test_negative_loss: 12.651372909545898
	test_positive_acc: 1.0
	test_negative_acc: 0.027842313650778126
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.0231095589697361
	train_incorrect_loss: 0.02175707370042801
	train_positive_loss: 0.010451900772750378
	train_negative_loss: 0.234643707589127
	train_correct_acc: 0.9911597378735199
	train_incorrect_acc: 0.9922226406984538
	train_positive_acc: 0.9999501246882794
	train_negative_acc: 0.9834657561662532
	train_correct_nonzero: 22100
	train_incorrect_nonzero: 18000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.001214167452417314
	val_negative_loss: 8.30613899230957
	val_positive_acc: 1.0
	val_negative_acc: 0.09583858764186634
test:
	test_positive_loss: 0.00014891156752128154
	test_negative_loss: 8.27155590057373
	test_positive_acc: 1.0
	test_negative_acc: 0.12972196281434029
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 41.0652551651001 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.925
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2327868938446045
	train_negative_loss: 2.2799820700272693
	train_positive_acc: 0.7438402610282191
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.24145278334617615
	train_incorrect_loss: 0.0824257880449295
	train_positive_loss: 0.055697910487651825
	train_negative_loss: 3.0183497321514685
	train_correct_acc: 0.9269135633480103
	train_incorrect_acc: 0.9991133277916321
	train_positive_acc: 0.9984943302122053
	train_negative_acc: 0.9220141355382773
	train_correct_nonzero: 21600
	train_incorrect_nonzero: 18500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0026321052573621273
	val_negative_loss: 2.767289638519287
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0031739752739667892
	test_negative_loss: 2.79495906829834
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.18557491898536682
	train_incorrect_loss: 0.07775477319955826
	train_positive_loss: 0.03877774998545647
	train_negative_loss: 2.545464694801003
	train_correct_acc: 0.9279926538067007
	train_incorrect_acc: 1.0
	train_positive_acc: 1.0
	train_negative_acc: 0.923028138644271
	train_correct_nonzero: 21600
	train_incorrect_nonzero: 18500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0015077986754477024
	val_negative_loss: 2.4343442916870117
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.002489945851266384
	test_negative_loss: 2.5153188705444336
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.1664922684431076
	train_incorrect_loss: 0.07590846717357635
	train_positive_loss: 0.037155233323574066
	train_negative_loss: 2.2971546724060463
	train_correct_acc: 0.9280666364304483
	train_incorrect_acc: 0.9998915754093028
	train_positive_acc: 1.0
	train_negative_acc: 0.922591265945562
	train_correct_nonzero: 21600
	train_incorrect_nonzero: 18500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0011357865296304226
	val_negative_loss: 2.9768104553222656
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.002139295684173703
	test_negative_loss: 3.1612296104431152
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.137309730052948
	train_incorrect_loss: 0.0702192559838295
	train_positive_loss: 0.034457143396139145
	train_negative_loss: 1.8769204228965923
	train_correct_acc: 0.9343106033537748
	train_incorrect_acc: 0.9968932533142119
	train_positive_acc: 1.0
	train_negative_acc: 0.9265086329108279
	train_correct_nonzero: 21600
	train_incorrect_nonzero: 18500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0016220648540183902
	val_negative_loss: 3.2644760608673096
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.005215591751039028
	test_negative_loss: 3.4347572326660156
	test_positive_acc: 1.0
	test_negative_acc: 0.018247669048748888
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.09763304144144058
	train_incorrect_loss: 0.057997800409793854
	train_positive_loss: 0.028155306354165077
	train_negative_loss: 1.3493676640450805
	train_correct_acc: 0.9543997484145447
	train_incorrect_acc: 0.9895236849808137
	train_positive_acc: 1.0
	train_negative_acc: 0.9412334547129446
	train_correct_nonzero: 21600
	train_incorrect_nonzero: 18500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.808384488162119e-05
	val_negative_loss: 5.247026443481445
	val_positive_acc: 1.0
	val_negative_acc: 0.00819672131147541
test:
	test_positive_loss: 0.0007006849627941847
	test_negative_loss: 5.683774948120117
	test_positive_acc: 1.0
	test_negative_acc: 0.02054182314838411
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.06636445969343185
	train_incorrect_loss: 0.04618452861905098
	train_positive_loss: 0.02229456976056099
	train_negative_loss: 0.9355808722344462
	train_correct_acc: 0.9702389738215017
	train_incorrect_acc: 0.987097257740532
	train_positive_acc: 0.9999035204913288
	train_negative_acc: 0.9560201877312773
	train_correct_nonzero: 21600
	train_incorrect_nonzero: 18500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.7821238884607737e-07
	val_negative_loss: 7.192585468292236
	val_positive_acc: 1.0
	val_negative_acc: 0.03278688524590164
test:
	test_positive_loss: 8.922476263251156e-05
	test_negative_loss: 8.001005172729492
	test_positive_acc: 1.0
	test_negative_acc: 0.022663885757411784
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.04521424323320389
	train_incorrect_loss: 0.033449430018663406
	train_positive_loss: 0.016309594735503197
	train_negative_loss: 0.6288751705735446
	train_correct_acc: 0.9806610342495397
	train_incorrect_acc: 0.9897661788526408
	train_positive_acc: 0.9999058621253134
	train_negative_acc: 0.9696945009400598
	train_correct_nonzero: 21600
	train_incorrect_nonzero: 18500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 5.62824061489664e-05
	val_negative_loss: 5.741798400878906
	val_positive_acc: 1.0
	val_negative_acc: 0.08764186633039092
test:
	test_positive_loss: 0.002851196564733982
	test_negative_loss: 6.520163536071777
	test_positive_acc: 0.9987980769230769
	test_negative_acc: 0.08482480032824494
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.031070802360773087
	train_incorrect_loss: 0.024625154212117195
	train_positive_loss: 0.012008276768028736
	train_negative_loss: 0.43385620725552587
	train_correct_acc: 0.9880608387959549
	train_incorrect_acc: 0.9921932915012771
	train_positive_acc: 0.999946941157744
	train_negative_acc: 0.9798275668448454
	train_correct_nonzero: 21600
	train_incorrect_nonzero: 18500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 4.740306280837103e-08
	val_negative_loss: 7.104213714599609
	val_positive_acc: 1.0
	val_negative_acc: 0.03278688524590164
test:
	test_positive_loss: 0.00017787264368962497
	test_negative_loss: 8.05142593383789
	test_positive_acc: 1.0
	test_negative_acc: 0.06170564102810197
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.01858382113277912
	train_incorrect_loss: 0.015862947329878807
	train_positive_loss: 0.007743882015347481
	train_negative_loss: 0.2561875367564836
	train_correct_acc: 0.9923610615142706
	train_incorrect_acc: 0.9947724602616336
	train_positive_acc: 0.9999376558603492
	train_negative_acc: 0.9870582399959208
	train_correct_nonzero: 21600
	train_incorrect_nonzero: 18500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 2.2300817192899558e-07
	val_negative_loss: 10.416056632995605
	val_positive_acc: 1.0
	val_negative_acc: 0.03278688524590164
test:
	test_positive_loss: 0.00038536006468348205
	test_negative_loss: 11.149868965148926
	test_positive_acc: 1.0
	test_negative_acc: 0.05698758826816737
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.009409663267433643
	train_incorrect_loss: 0.009232272394001484
	train_positive_loss: 0.0044213831424713135
	train_negative_loss: 0.13251260032881876
	train_correct_acc: 0.9966828055482988
	train_incorrect_acc: 0.996757878382798
	train_positive_acc: 1.0
	train_negative_acc: 0.9933608367734393
	train_correct_nonzero: 21600
	train_incorrect_nonzero: 18500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.9542503171265935e-09
	val_negative_loss: 12.602729797363281
	val_positive_acc: 1.0
	val_negative_acc: 0.00819672131147541
test:
	test_positive_loss: 5.520306876860559e-05
	test_negative_loss: 13.460402488708496
	test_positive_acc: 1.0
	test_negative_acc: 0.013726459558507192
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 40.785332918167114 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.95
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2327494621276855
	train_negative_loss: 2.279500835615656
	train_positive_acc: 0.7457138524967531
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.1959562599658966
	train_incorrect_loss: 0.05990002304315567
	train_positive_loss: 0.04334312677383423
	train_negative_loss: 3.4438950925503136
	train_correct_acc: 0.9488408587607029
	train_incorrect_acc: 0.999078390979074
	train_positive_acc: 0.9984943302122053
	train_negative_acc: 0.9468900997556936
	train_correct_nonzero: 21100
	train_incorrect_nonzero: 19000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0025841023307293653
	val_negative_loss: 3.183544635772705
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.00290312641300261
	test_negative_loss: 3.2205474376678467
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.14393576979637146
	train_incorrect_loss: 0.05116323009133339
	train_positive_loss: 0.02602122537791729
	train_negative_loss: 2.8496761046430117
	train_correct_acc: 0.9500221947353232
	train_incorrect_acc: 1.0
	train_positive_acc: 1.0
	train_negative_acc: 0.9478368653711662
	train_correct_nonzero: 21100
	train_incorrect_nonzero: 19000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.000940183294005692
	val_negative_loss: 3.2030436992645264
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0013068922562524676
	test_negative_loss: 3.3617615699768066
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.12182746827602386
	train_incorrect_loss: 0.04982728138566017
	train_positive_loss: 0.02471061982214451
	train_negative_loss: 2.4042407898902893
	train_correct_acc: 0.9507060696083137
	train_incorrect_acc: 0.998751866024493
	train_positive_acc: 1.0
	train_negative_acc: 0.9472196399886685
	train_correct_nonzero: 21100
	train_incorrect_nonzero: 19000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0035040159709751606
	val_negative_loss: 2.1034326553344727
	val_positive_acc: 1.0
	val_negative_acc: 0.037410676754939046
test:
	test_positive_loss: 0.00574664119631052
	test_negative_loss: 2.3197786808013916
	test_positive_acc: 1.0
	test_negative_acc: 0.021211966026741712
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.08625650405883789
	train_incorrect_loss: 0.043230436742305756
	train_positive_loss: 0.021167883649468422
	train_negative_loss: 1.6986244843615033
	train_correct_acc: 0.9619303110830023
	train_incorrect_acc: 0.995346750024607
	train_positive_acc: 1.0
	train_negative_acc: 0.9556867407784466
	train_correct_nonzero: 21100
	train_incorrect_nonzero: 19000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00028516852762550116
	val_negative_loss: 3.941347122192383
	val_positive_acc: 1.0
	val_negative_acc: 0.05842791088692728
test:
	test_positive_loss: 0.0012941875029355288
	test_negative_loss: 4.36823034286499
	test_positive_acc: 1.0
	test_negative_acc: 0.018252027235580254
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.050104472786188126
	train_incorrect_loss: 0.03060082532465458
	train_positive_loss: 0.015190293081104755
	train_negative_loss: 0.9806068326218551
	train_correct_acc: 0.9780792250298437
	train_incorrect_acc: 0.9934412717565893
	train_positive_acc: 0.9999457877046515
	train_negative_acc: 0.9707921004369877
	train_correct_nonzero: 21100
	train_incorrect_nonzero: 19000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.673122773761861e-05
	val_negative_loss: 7.049578666687012
	val_positive_acc: 1.0
	val_negative_acc: 0.045607398066414465
test:
	test_positive_loss: 0.0005036316579207778
	test_negative_loss: 7.459813594818115
	test_positive_acc: 1.0
	test_negative_acc: 0.017389383150886478
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.028647517785429955
	train_incorrect_loss: 0.019078798592090607
	train_positive_loss: 0.009405631572008133
	train_negative_loss: 0.5860649671492788
	train_correct_acc: 0.9886361872030303
	train_incorrect_acc: 0.9944910449955754
	train_positive_acc: 1.0
	train_negative_acc: 0.9827098920986046
	train_correct_nonzero: 21100
	train_incorrect_nonzero: 19000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.7456459267559694e-08
	val_negative_loss: 10.92271614074707
	val_positive_acc: 1.0
	val_negative_acc: 0.01639344262295082
test:
	test_positive_loss: 2.1785097032989142e-06
	test_negative_loss: 11.747011184692383
	test_positive_acc: 1.0
	test_negative_acc: 0.006587841383176853
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.016420014202594757
	train_incorrect_loss: 0.013617047108709812
	train_positive_loss: 0.0067661600187420845
	train_negative_loss: 0.3291768333008403
	train_correct_acc: 0.9932634092453598
	train_incorrect_acc: 0.9957743513772461
	train_positive_acc: 0.999894987708035
	train_negative_acc: 0.9889798642206712
	train_correct_nonzero: 21100
	train_incorrect_nonzero: 19000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 5.283989423787716e-08
	val_negative_loss: 9.304422378540039
	val_positive_acc: 1.0
	val_negative_acc: 0.05023118957545187
test:
	test_positive_loss: 2.473018321325071e-05
	test_negative_loss: 10.48684024810791
	test_positive_acc: 1.0
	test_negative_acc: 0.027567228598585
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.007020940072834492
	train_incorrect_loss: 0.00540540274232626
	train_positive_loss: 0.002700693905353546
	train_negative_loss: 0.1312873315830055
	train_correct_acc: 0.9972647546858161
	train_incorrect_acc: 0.9985543240818153
	train_positive_acc: 0.9998970658460233
	train_negative_acc: 0.9958554740670102
	train_correct_nonzero: 21100
	train_incorrect_nonzero: 19000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0
	val_negative_loss: 13.296524047851562
	val_positive_acc: 1.0
	val_negative_acc: 0.045607398066414465
test:
	test_positive_loss: 1.6779543443590228e-07
	test_negative_loss: 13.742746353149414
	test_positive_acc: 1.0
	test_negative_acc: 0.03937353930297932
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.01389937475323677
	train_incorrect_loss: 0.010487701743841171
	train_positive_loss: 0.00511445477604866
	train_negative_loss: 0.3126920698595345
	train_correct_acc: 0.9948428138319679
	train_incorrect_acc: 0.9968245523644973
	train_positive_acc: 0.999955468471678
	train_negative_acc: 0.9916748793114458
	train_correct_nonzero: 21100
	train_incorrect_nonzero: 19000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0
	val_negative_loss: 12.472652435302734
	val_positive_acc: 1.0
	val_negative_acc: 0.045607398066414465
test:
	test_positive_loss: 2.0309682895458536e-06
	test_negative_loss: 13.359964370727539
	test_positive_acc: 1.0
	test_negative_acc: 0.028100100358109895
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.00035015848698094487
	train_incorrect_loss: 0.00030933693051338196
	train_positive_loss: 0.00014934844512026757
	train_negative_loss: 0.007212552991599208
	train_correct_acc: 0.9999501246882794
	train_incorrect_acc: 1.0
	train_positive_acc: 1.0
	train_negative_acc: 0.9999520429694994
	train_correct_nonzero: 21100
	train_incorrect_nonzero: 19000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0
	val_negative_loss: 14.411172866821289
	val_positive_acc: 1.0
	val_negative_acc: 0.045607398066414465
test:
	test_positive_loss: 2.8812007712986087e-06
	test_negative_loss: 15.30921745300293
	test_positive_acc: 1.0
	test_negative_acc: 0.03326295821032496
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 40.819284200668335 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.975
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.232708215713501
	train_negative_loss: 2.2788845256818178
	train_positive_acc: 0.7474361074028508
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.13730396330356598
	train_incorrect_loss: 0.03837659955024719
	train_positive_loss: 0.031203916296362877
	train_negative_loss: 4.261907170657005
	train_correct_acc: 0.9717993223739526
	train_incorrect_acc: 0.999078390979074
	train_positive_acc: 0.9984943302122053
	train_negative_acc: 0.9718190533388131
	train_correct_nonzero: 20600
	train_incorrect_nonzero: 19500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00195842026732862
	val_negative_loss: 3.638059139251709
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0021750433370471
	test_negative_loss: 3.6838083267211914
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.09473885595798492
	train_incorrect_loss: 0.025842098519206047
	train_positive_loss: 0.013529901392757893
	train_negative_loss: 3.5239448867096805
	train_correct_acc: 0.9730903975323432
	train_incorrect_acc: 1.0
	train_positive_acc: 1.0
	train_negative_acc: 0.9727485695479161
	train_correct_nonzero: 20600
	train_incorrect_nonzero: 19500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0002645959029905498
	val_negative_loss: 4.388352394104004
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.00047099924995563924
	test_negative_loss: 4.553226470947266
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.07602594047784805
	train_incorrect_loss: 0.025356732308864594
	train_positive_loss: 0.01280386932194233
	train_negative_loss: 2.7787919662323506
	train_correct_acc: 0.9733321013711347
	train_incorrect_acc: 0.9997428156252066
	train_positive_acc: 1.0
	train_negative_acc: 0.9726767292739954
	train_correct_nonzero: 20600
	train_incorrect_nonzero: 19500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0010235067456960678
	val_negative_loss: 3.4009149074554443
	val_positive_acc: 1.0
	val_negative_acc: 0.00819672131147541
test:
	test_positive_loss: 0.0021954718977212906
	test_negative_loss: 3.528444766998291
	test_positive_acc: 1.0
	test_negative_acc: 0.00125
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.04290596395730972
	train_incorrect_loss: 0.0194700974971056
	train_positive_loss: 0.00978612806648016
	train_negative_loss: 1.6129630529117904
	train_correct_acc: 0.9822539583164391
	train_incorrect_acc: 0.9982352882172256
	train_positive_acc: 1.0
	train_negative_acc: 0.9800805373921656
	train_correct_nonzero: 20600
	train_incorrect_nonzero: 19500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.002045595785602927
	val_negative_loss: 6.395888328552246
	val_positive_acc: 1.0
	val_negative_acc: 0.01639344262295082
test:
	test_positive_loss: 0.0005252994014881551
	test_negative_loss: 6.782830238342285
	test_positive_acc: 1.0
	test_negative_acc: 0.0059141559151813464
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.01939411833882332
	train_incorrect_loss: 0.011125998571515083
	train_positive_loss: 0.005569769069552422
	train_negative_loss: 0.6860361561459187
	train_correct_acc: 0.9921479410126706
	train_incorrect_acc: 0.9970472396985324
	train_positive_acc: 1.0
	train_negative_acc: 0.9890706500961309
	train_correct_nonzero: 20600
	train_incorrect_nonzero: 19500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.00036091075162403286
	val_negative_loss: 10.35584545135498
	val_positive_acc: 1.0
	val_negative_acc: 0.00819672131147541
test:
	test_positive_loss: 0.0002443357661832124
	test_negative_loss: 10.660428047180176
	test_positive_acc: 1.0
	test_negative_acc: 0.003631168359941945
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.009739616885781288
	train_incorrect_loss: 0.006872529163956642
	train_positive_loss: 0.00340654538013041
	train_negative_loss: 0.3683990162905318
	train_correct_acc: 0.9957944002936249
	train_incorrect_acc: 0.9979683953105943
	train_positive_acc: 0.999955468471678
	train_negative_acc: 0.9937344438976626
	train_correct_nonzero: 20600
	train_incorrect_nonzero: 19500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.6870595572981983e-05
	val_negative_loss: 13.074581146240234
	val_positive_acc: 1.0
	val_negative_acc: 0.00819672131147541
test:
	test_positive_loss: 7.541918421338778e-06
	test_negative_loss: 13.676413536071777
	test_positive_acc: 1.0
	test_negative_acc: 0.0050091537212366335
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.006462967488914728
	train_incorrect_loss: 0.003971869591623545
	train_positive_loss: 0.0020050688181072474
	train_negative_loss: 0.2283512505312182
	train_correct_acc: 0.9976201603303921
	train_incorrect_acc: 0.9987364276299447
	train_positive_acc: 1.0
	train_negative_acc: 0.9963475007049856
	train_correct_nonzero: 20600
	train_incorrect_nonzero: 19500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.006037725601345301
	val_negative_loss: 11.080879211425781
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 0.05023118957545187
test:
	test_positive_loss: 6.398920231731609e-05
	test_negative_loss: 11.289478302001953
	test_positive_acc: 1.0
	test_negative_acc: 0.028246121369735252
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.0012454079696908593
	train_incorrect_loss: 0.0009590591653250158
	train_positive_loss: 0.0004770105588249862
	train_negative_loss: 0.05246911315711687
	train_correct_acc: 0.9996595156154873
	train_incorrect_acc: 0.9998467506447556
	train_positive_acc: 1.0
	train_negative_acc: 0.9995035051574376
	train_correct_nonzero: 20600
	train_incorrect_nonzero: 19500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0036137900315225124
	val_negative_loss: 15.247159957885742
	val_positive_acc: 1.0
	val_negative_acc: 0.01639344262295082
test:
	test_positive_loss: 7.756361242172716e-07
	test_negative_loss: 15.643796920776367
	test_positive_acc: 1.0
	test_negative_acc: 0.011169727620607701
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 5.4983403970254585e-05
	train_incorrect_loss: 5.3608338930644095e-05
	train_positive_loss: 2.6449331926414743e-05
	train_negative_loss: 0.0020258284928658696
	train_correct_acc: 1.0
	train_incorrect_acc: 1.0
	train_positive_acc: 1.0
	train_negative_acc: 1.0
	train_correct_nonzero: 20600
	train_incorrect_nonzero: 19500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.003622539807111025
	val_negative_loss: 16.53254508972168
	val_positive_acc: 1.0
	val_negative_acc: 0.01639344262295082
test:
	test_positive_loss: 2.7066749908044585e-07
	test_negative_loss: 16.93073844909668
	test_positive_acc: 1.0
	test_negative_acc: 0.005928298313321898
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 3.2699019357096404e-05
	train_incorrect_loss: 2.9569333491963334e-05
	train_positive_loss: 1.466318190068705e-05
	train_negative_loss: 0.001155060516075691
	train_correct_acc: 1.0
	train_incorrect_acc: 1.0
	train_positive_acc: 1.0
	train_negative_acc: 1.0
	train_correct_nonzero: 20600
	train_incorrect_nonzero: 19500
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.004287754185497761
	val_negative_loss: 17.317325592041016
	val_positive_acc: 1.0
	val_negative_acc: 0.01639344262295082
test:
	test_positive_loss: 1.8405862078907376e-07
	test_negative_loss: 17.75887680053711
	test_positive_acc: 1.0
	test_negative_acc: 0.008631786685414922
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 40.96231484413147 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 1.0
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2326619625091553
	train_negative_loss: 2.2734428723653157
	train_positive_acc: 0.7493136951181456
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.04004533588886261
	train_incorrect_loss: 0.01910974271595478
	train_positive_loss: 0.019192256033420563
	train_negative_loss: 8.202465894270917
	train_correct_acc: 0.9959659200338675
	train_incorrect_acc: 0.999097999681647
	train_positive_acc: 0.9984943302122053
	train_negative_acc: 0.996641091597907
	train_correct_nonzero: 20100
	train_incorrect_nonzero: 20000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0006782483542338014
	val_negative_loss: 6.343661308288574
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0007211585761979222
	test_negative_loss: 6.484007835388184
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.012821436859667301
	train_incorrect_loss: 0.002029982628300786
	train_positive_loss: 0.0011403615353628993
	train_negative_loss: 5.02920944639977
	train_correct_acc: 0.9974888232666121
	train_incorrect_acc: 1.0
	train_positive_acc: 1.0
	train_negative_acc: 0.9975288731272124
	train_correct_nonzero: 20100
	train_incorrect_nonzero: 20000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 0.0001455735182389617
	val_negative_loss: 7.342445373535156
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.0001760777086019516
	test_negative_loss: 7.529717445373535
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.008255891501903534
	train_incorrect_loss: 0.001913080457597971
	train_positive_loss: 0.0009849341586232185
	train_negative_loss: 3.3282285047338362
	train_correct_acc: 0.997701060520774
	train_incorrect_acc: 1.0
	train_positive_acc: 1.0
	train_negative_acc: 0.9977072693665181
	train_correct_nonzero: 20100
	train_incorrect_nonzero: 20000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.413762106494687e-06
	val_negative_loss: 13.249242782592773
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 1.7039615158864763e-06
	test_negative_loss: 13.549280166625977
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.0040379674173891544
	train_incorrect_loss: 0.0014413021272048354
	train_positive_loss: 0.0007353068212978542
	train_negative_loss: 1.6472639766676973
	train_correct_acc: 0.9986652920428315
	train_incorrect_acc: 0.9997952370845935
	train_positive_acc: 1.0
	train_negative_acc: 0.998438428396811
	train_correct_nonzero: 20100
	train_incorrect_nonzero: 20000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 6.809017349951318e-07
	val_negative_loss: 14.967567443847656
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 5.532094178306579e-07
	test_negative_loss: 15.23886489868164
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.0006028389907442033
	train_incorrect_loss: 0.00030459006666205823
	train_positive_loss: 0.00014834235480520874
	train_negative_loss: 0.24937934493075828
	train_correct_acc: 0.9998029731055657
	train_incorrect_acc: 1.0
	train_positive_acc: 1.0
	train_negative_acc: 0.999799190806278
	train_correct_nonzero: 20100
	train_incorrect_nonzero: 20000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 8.914381055546983e-08
	val_negative_loss: 18.76268768310547
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 8.559514697026316e-08
	test_negative_loss: 19.10015106201172
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 1.2968264854862355e-05
	train_incorrect_loss: 1.255378720088629e-05
	train_positive_loss: 6.242334166017827e-06
	train_negative_loss: 0.005189030198380351
	train_correct_acc: 1.0
	train_incorrect_acc: 1.0
	train_positive_acc: 1.0
	train_negative_acc: 1.0
	train_correct_nonzero: 20100
	train_incorrect_nonzero: 20000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.3930296915987128e-08
	val_negative_loss: 20.747802734375
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 1.1872494098952302e-08
	test_negative_loss: 21.09616470336914
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 2.5414478841412347e-06
	train_incorrect_loss: 3.6718868159368867e-06
	train_positive_loss: 1.840418576648517e-06
	train_negative_loss: 0.0010118477283261502
	train_correct_acc: 1.0
	train_incorrect_acc: 1.0
	train_positive_acc: 1.0
	train_negative_acc: 1.0
	train_correct_nonzero: 20100
	train_incorrect_nonzero: 20000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 7.942274393712978e-09
	val_negative_loss: 21.340585708618164
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 6.407272934438879e-09
	test_negative_loss: 21.68752098083496
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 1.1713062804119545e-06
	train_incorrect_loss: 1.8821536968971486e-06
	train_positive_loss: 9.33405544856214e-07
	train_negative_loss: 0.00046672654017406194
	train_correct_acc: 1.0
	train_incorrect_acc: 1.0
	train_positive_acc: 1.0
	train_negative_acc: 1.0
	train_correct_nonzero: 20100
	train_incorrect_nonzero: 20000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 4.459700164716196e-09
	val_negative_loss: 21.818769454956055
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 3.668536141532286e-09
	test_negative_loss: 22.16808319091797
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 5.986041742289672e-07
	train_incorrect_loss: 1.2270393199287355e-06
	train_positive_loss: 6.148161446617451e-07
	train_negative_loss: 0.00023475097949206733
	train_correct_acc: 1.0
	train_incorrect_acc: 1.0
	train_positive_acc: 1.0
	train_negative_acc: 1.0
	train_correct_nonzero: 20100
	train_incorrect_nonzero: 20000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 3.482574673085992e-09
	val_negative_loss: 22.071151733398438
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 3.0972437947696108e-09
	test_negative_loss: 22.41976547241211
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 4.009124836557021e-07
	train_incorrect_loss: 8.373731361643877e-07
	train_positive_loss: 4.131069886170735e-07
	train_negative_loss: 0.0001595241937858797
	train_correct_acc: 1.0
	train_incorrect_acc: 1.0
	train_positive_acc: 1.0
	train_negative_acc: 1.0
	train_correct_nonzero: 20100
	train_incorrect_nonzero: 20000
	train_positive_nonzero: 20050
	train_negative_nonzero: 20050
val:
	val_positive_loss: 1.9542505391711984e-09
	val_negative_loss: 22.588550567626953
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 1.1688715551017026e-09
	test_negative_loss: 22.939373016357422
	test_positive_acc: 1.0
	test_negative_acc: 0.0
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 40.79580283164978 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.0
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.235910654067993
	train_negative_loss: 2.2804512977600098
	train_positive_acc: 0.6210397876146286
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.10729065537452698
	train_incorrect_loss: nan
	train_positive_loss: 0.08616113662719727
	train_negative_loss: 0.12869977951049805
	train_correct_acc: 0.9688029925187033
	train_incorrect_acc: nan
	train_positive_acc: 0.9779692404532906
	train_negative_acc: 0.9593284739291089
	train_correct_nonzero: 23581
	train_incorrect_nonzero: 0
	train_positive_nonzero: 10967
	train_negative_nonzero: 12614
val:
	val_positive_loss: 0.009619243443012238
	val_negative_loss: 0.017134597525000572
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.008234353736042976
	test_negative_loss: 0.03213120251893997
	test_positive_acc: 0.9959492020492408
	test_negative_acc: 0.9880309215364368
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.016909191384911537
	train_incorrect_loss: nan
	train_positive_loss: 0.015471245162189007
	train_negative_loss: 0.01785995066165924
	train_correct_acc: 0.9952618453865337
	train_incorrect_acc: nan
	train_positive_acc: 0.9950448267112769
	train_negative_acc: 0.995681153652688
	train_correct_nonzero: 28399
	train_incorrect_nonzero: 0
	train_positive_nonzero: 13049
	train_negative_nonzero: 15350
val:
	val_positive_loss: 0.0038765608333051205
	val_negative_loss: 0.006628151051700115
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.022716442123055458
	test_negative_loss: 0.024645306169986725
	test_positive_acc: 0.9887440399879235
	test_negative_acc: 0.991899670871605
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.008754405193030834
	train_incorrect_loss: nan
	train_positive_loss: 0.011591787450015545
	train_negative_loss: 0.005702377762645483
	train_correct_acc: 0.9974064837905238
	train_incorrect_acc: nan
	train_positive_acc: 0.9963377785393741
	train_negative_acc: 0.9985771039720586
	train_correct_nonzero: 29097
	train_incorrect_nonzero: 0
	train_positive_nonzero: 9981
	train_negative_nonzero: 19116
val:
	val_positive_loss: 0.0018359903478994966
	val_negative_loss: 0.0027595763094723225
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.00465292576700449
	test_negative_loss: 0.051635827869176865
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9833948109516508
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.005812699440866709
	train_incorrect_loss: nan
	train_positive_loss: 0.007889932952821255
	train_negative_loss: 0.0037221878301352262
	train_correct_acc: 0.9981546134663342
	train_incorrect_acc: nan
	train_positive_acc: 0.997440572276984
	train_negative_acc: 0.9989370734481097
	train_correct_nonzero: 27349
	train_incorrect_nonzero: 0
	train_positive_nonzero: 9463
	train_negative_nonzero: 17886
val:
	val_positive_loss: 0.023541292175650597
	val_negative_loss: 0.001886626472696662
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01645895093679428
	test_negative_loss: 0.020643487572669983
	test_positive_acc: 0.9918015323430605
	test_negative_acc: 0.9933531592436982
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.005086262244731188
	train_incorrect_loss: nan
	train_positive_loss: 0.007887688465416431
	train_negative_loss: 0.0022114973980933428
	train_correct_acc: 0.9981795511221945
	train_incorrect_acc: nan
	train_positive_acc: 0.9972985872072962
	train_negative_acc: 0.999145224164907
	train_correct_nonzero: 19340
	train_incorrect_nonzero: 0
	train_positive_nonzero: 5727
	train_negative_nonzero: 13613
val:
	val_positive_loss: 0.01830161176621914
	val_negative_loss: 6.721061799908057e-05
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01359911821782589
	test_negative_loss: 0.025931892916560173
	test_positive_acc: 0.9947917946418333
	test_negative_acc: 0.9938596779188213
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.008265861310064793
	train_incorrect_loss: nan
	train_positive_loss: 0.016430774703621864
	train_negative_loss: 0.0001376041182084009
	train_correct_acc: 0.9976059850374065
	train_incorrect_acc: nan
	train_positive_acc: 0.995241919414501
	train_negative_acc: 1.0
	train_correct_nonzero: 13725
	train_incorrect_nonzero: 0
	train_positive_nonzero: 6578
	train_negative_nonzero: 7147
val:
	val_positive_loss: 0.004800339229404926
	val_negative_loss: 2.1813445982843405e-06
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.045368365943431854
	test_negative_loss: 0.020683854818344116
	test_positive_acc: 0.989761349513054
	test_negative_acc: 0.9933531592436982
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.007860643789172173
	train_incorrect_loss: nan
	train_positive_loss: 0.01554049365222454
	train_negative_loss: 8.696305485500488e-06
	train_correct_acc: 0.9980548628428928
	train_incorrect_acc: nan
	train_positive_acc: 0.9961610823081654
	train_negative_acc: 1.0
	train_correct_nonzero: 9990
	train_incorrect_nonzero: 0
	train_positive_nonzero: 5425
	train_negative_nonzero: 4565
val:
	val_positive_loss: 0.007358689326792955
	val_negative_loss: 1.2106929716537707e-06
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04656091332435608
	test_negative_loss: 0.02043525129556656
	test_positive_acc: 0.989761349513054
	test_negative_acc: 0.9933531592436982
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.0067845722660422325
	train_incorrect_loss: nan
	train_positive_loss: 0.01332134660333395
	train_negative_loss: 1.0451570233271923e-05
	train_correct_acc: 0.9984039900249377
	train_incorrect_acc: nan
	train_positive_acc: 0.9968311308760628
	train_negative_acc: 1.0
	train_correct_nonzero: 7339
	train_incorrect_nonzero: 0
	train_positive_nonzero: 3539
	train_negative_nonzero: 3800
val:
	val_positive_loss: 0.0004935173783451319
	val_negative_loss: 1.304917077504797e-06
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.029708730056881905
	test_negative_loss: 0.03189302235841751
	test_positive_acc: 0.9948527108211707
	test_negative_acc: 0.9933531592436982
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.0057707796804606915
	train_incorrect_loss: nan
	train_positive_loss: 0.011601695790886879
	train_negative_loss: 8.203839570342097e-06
	train_correct_acc: 0.9986034912718206
	train_incorrect_acc: nan
	train_positive_acc: 0.9972091920408097
	train_negative_acc: 1.0
	train_correct_nonzero: 4952
	train_incorrect_nonzero: 0
	train_positive_nonzero: 1825
	train_negative_nonzero: 3127
val:
	val_positive_loss: 0.001158626051619649
	val_negative_loss: 6.10818119639589e-07
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.034527793526649475
	test_negative_loss: 0.029218360781669617
	test_positive_acc: 0.9920348283490328
	test_negative_acc: 0.9933531592436982
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.006152530666440725
	train_incorrect_loss: nan
	train_positive_loss: 0.012214472517371178
	train_negative_loss: 3.843462764052674e-06
	train_correct_acc: 0.9984788029925188
	train_incorrect_acc: nan
	train_positive_acc: 0.9969745345798263
	train_negative_acc: 1.0
	train_correct_nonzero: 4982
	train_incorrect_nonzero: 0
	train_positive_nonzero: 2400
	train_negative_nonzero: 2582
val:
	val_positive_loss: 0.0018574302084743977
	val_negative_loss: 3.7283194842530065e-07
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.035938069224357605
	test_negative_loss: 0.028005016967654228
	test_positive_acc: 0.9920348283490328
	test_negative_acc: 0.9933531592436982
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 91.87298798561096 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.025
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2357494831085205
	train_negative_loss: 2.280472755432129
	train_positive_acc: 0.6270972681850142
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.12539386749267578
	train_incorrect_loss: 2.8724347149178744
	train_positive_loss: 0.16391238570213318
	train_negative_loss: 0.1554843634366989
	train_correct_acc: 0.9673035685140413
	train_incorrect_acc: 0.0483963344788087
	train_positive_acc: 0.9750240030597342
	train_negative_acc: 0.9362060426971095
	train_correct_nonzero: 24081
	train_incorrect_nonzero: 134
	train_positive_nonzero: 9274
	train_negative_nonzero: 14941
val:
	val_positive_loss: 0.010936636477708817
	val_negative_loss: 0.06920960545539856
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.011906031519174576
	test_negative_loss: 0.08467777818441391
	test_positive_acc: 1.0
	test_negative_acc: 0.980705074532339
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.024489177390933037
	train_incorrect_loss: 4.305030332072406
	train_positive_loss: 0.11979016661643982
	train_negative_loss: 0.032521236687898636
	train_correct_acc: 0.9951188490850519
	train_incorrect_acc: 0.02098108747044917
	train_positive_acc: 0.9949674832048011
	train_negative_acc: 0.9711769593164358
	train_correct_nonzero: 27161
	train_incorrect_nonzero: 38
	train_positive_nonzero: 8866
	train_negative_nonzero: 18333
val:
	val_positive_loss: 0.007522302214056253
	val_negative_loss: 0.004220512695610523
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.017001407220959663
	test_negative_loss: 0.02404455468058586
	test_positive_acc: 0.9950493421052631
	test_negative_acc: 0.994532404526717
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.0223830733448267
	train_incorrect_loss: 5.058482174678668
	train_positive_loss: 0.1416727602481842
	train_negative_loss: 0.02656196989119053
	train_correct_acc: 0.9960140431709162
	train_incorrect_acc: 0.007134703196347031
	train_positive_acc: 0.9942162168994126
	train_negative_acc: 0.973283356229842
	train_correct_nonzero: 30199
	train_incorrect_nonzero: 28
	train_positive_nonzero: 11746
	train_negative_nonzero: 18481
val:
	val_positive_loss: 0.0004825727082788944
	val_negative_loss: 0.06443265080451965
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.0013296467950567603
	test_negative_loss: 0.13798199594020844
	test_positive_acc: 1.0
	test_negative_acc: 0.9646574165743002
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.013422909192740917
	train_incorrect_loss: 5.931022192678742
	train_positive_loss: 0.1581009179353714
	train_negative_loss: 0.012832948006689548
	train_correct_acc: 0.9967407279685175
	train_incorrect_acc: 0.010135135135135136
	train_positive_acc: 0.9954959669818773
	train_negative_acc: 0.9734127741735541
	train_correct_nonzero: 28095
	train_incorrect_nonzero: 15
	train_positive_nonzero: 8983
	train_negative_nonzero: 19127
val:
	val_positive_loss: 0.001568666659295559
	val_negative_loss: 0.006038065068423748
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0037088782992213964
	test_negative_loss: 0.036426130682229996
	test_positive_acc: 0.9989035087719298
	test_negative_acc: 0.9902799745667398
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.00986514799296856
	train_incorrect_loss: 10.405130772671457
	train_positive_loss: 0.27216842770576477
	train_negative_loss: 0.0015004377346485853
	train_correct_acc: 0.9973489346685268
	train_incorrect_acc: 0.003389830508474576
	train_positive_acc: 0.9950319760902898
	train_negative_acc: 0.9746725347216718
	train_correct_nonzero: 22608
	train_incorrect_nonzero: 3
	train_positive_nonzero: 3825
	train_negative_nonzero: 18786
val:
	val_positive_loss: 0.026890313252806664
	val_negative_loss: 9.047589264810085e-05
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01614990457892418
	test_negative_loss: 0.012375984340906143
	test_positive_acc: 0.9950493421052631
	test_negative_acc: 0.9950389232018403
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.012526781298220158
	train_incorrect_loss: 7.542939311100377
	train_positive_loss: 0.19686338305473328
	train_negative_loss: 0.008352755568921566
	train_correct_acc: 0.9969399042165769
	train_incorrect_acc: 0.001736111111111111
	train_positive_acc: 0.9949606933879983
	train_negative_acc: 0.9741800607961485
	train_correct_nonzero: 24763
	train_incorrect_nonzero: 15
	train_positive_nonzero: 6205
	train_negative_nonzero: 18573
val:
	val_positive_loss: 0.016575975343585014
	val_negative_loss: 0.0008125037420541048
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.025984033942222595
	test_negative_loss: 0.01656724326312542
	test_positive_acc: 0.990644124935653
	test_negative_acc: 0.99598589289881
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.011108488775789738
	train_incorrect_loss: 10.772343473301994
	train_positive_loss: 0.28297391533851624
	train_negative_loss: 0.0002753275039140135
	train_correct_acc: 0.9970923429433682
	train_incorrect_acc: 0.0
	train_positive_acc: 0.9942123687810639
	train_negative_acc: 0.9751728627895992
	train_correct_nonzero: 25343
	train_incorrect_nonzero: 0
	train_positive_nonzero: 6098
	train_negative_nonzero: 19245
val:
	val_positive_loss: 0.007848263718187809
	val_negative_loss: 6.317085353657603e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02786729484796524
	test_negative_loss: 0.024545252323150635
	test_positive_acc: 0.9919739121696955
	test_negative_acc: 0.99598589289881
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.012104185298085213
	train_incorrect_loss: 13.141844762559609
	train_positive_loss: 0.3445441722869873
	train_negative_loss: 4.367034853203222e-05
	train_correct_acc: 0.9974732687073145
	train_incorrect_acc: 0.0
	train_positive_acc: 0.9950098807500477
	train_negative_acc: 0.9751136274868784
	train_correct_nonzero: 21031
	train_incorrect_nonzero: 0
	train_positive_nonzero: 3285
	train_negative_nonzero: 17746
val:
	val_positive_loss: 0.008869582787156105
	val_negative_loss: 2.0820933059439994e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.031814511865377426
	test_negative_loss: 0.027571987360715866
	test_positive_acc: 0.9919739121696955
	test_negative_acc: 0.99598589289881
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.013631791807711124
	train_incorrect_loss: 14.2867968507009
	train_positive_loss: 0.3763527572154999
	train_negative_loss: 1.5617530152667314e-05
	train_correct_acc: 0.9972182207764101
	train_incorrect_acc: 0.0
	train_positive_acc: 0.9945627948168306
	train_negative_acc: 0.9750252240443944
	train_correct_nonzero: 19124
	train_incorrect_nonzero: 0
	train_positive_nonzero: 3318
	train_negative_nonzero: 15806
val:
	val_positive_loss: 0.00872925017029047
	val_negative_loss: 1.0951561307592783e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.033701978623867035
	test_negative_loss: 0.02992061898112297
	test_positive_acc: 0.9919739121696955
	test_negative_acc: 0.99598589289881
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.0147616658359766
	train_incorrect_loss: 15.179774958226416
	train_positive_loss: 0.39794060587882996
	train_negative_loss: 8.714786417840514e-06
	train_correct_acc: 0.9972509794564607
	train_incorrect_acc: 0.0
	train_positive_acc: 0.9946018647431126
	train_negative_acc: 0.9750694406664935
	train_correct_nonzero: 16907
	train_incorrect_nonzero: 0
	train_positive_nonzero: 2600
	train_negative_nonzero: 14307
val:
	val_positive_loss: 0.0119382468983531
	val_negative_loss: 6.741512606822653e-06
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03593481332063675
	test_negative_loss: 0.031036419793963432
	test_positive_acc: 0.9904858169316003
	test_negative_acc: 0.99598589289881
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.04568815231323 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.05
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.235595464706421
	train_negative_loss: 2.2804431915283203
	train_positive_acc: 0.6345275283621715
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.13275688886642456
	train_incorrect_loss: 2.7186805701480723
	train_positive_loss: 0.22835515439510345
	train_negative_loss: 0.1645887792110443
	train_correct_acc: 0.9694355863522653
	train_incorrect_acc: 0.06163522012578618
	train_positive_acc: 0.9778153994938781
	train_negative_acc: 0.9156317353291267
	train_correct_nonzero: 24935
	train_incorrect_nonzero: 226
	train_positive_nonzero: 9525
	train_negative_nonzero: 15636
val:
	val_positive_loss: 0.03412771224975586
	val_negative_loss: 0.022819317877292633
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04076261445879936
	test_negative_loss: 0.030623774975538254
	test_positive_acc: 0.9836898973686913
	test_negative_acc: 0.9925575945854881
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.02808300033211708
	train_incorrect_loss: 4.167856736485207
	train_positive_loss: 0.21487261354923248
	train_negative_loss: 0.03710711747407913
	train_correct_acc: 0.9951110679068905
	train_incorrect_acc: 0.0035938903863432163
	train_positive_acc: 0.994465214239043
	train_negative_acc: 0.9464580173782916
	train_correct_nonzero: 28304
	train_incorrect_nonzero: 68
	train_positive_nonzero: 10478
	train_negative_nonzero: 17894
val:
	val_positive_loss: 0.00454070046544075
	val_negative_loss: 0.007532447576522827
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.010399562306702137
	test_negative_loss: 0.02446660026907921
	test_positive_acc: 0.996299342105263
	test_negative_acc: 0.9926384651327775
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.021974746137857437
	train_incorrect_loss: 5.070762614993488
	train_positive_loss: 0.25665923953056335
	train_negative_loss: 0.027113348245620728
	train_correct_acc: 0.9960425756981985
	train_incorrect_acc: 0.00980392156862745
	train_positive_acc: 0.9945067771948636
	train_negative_acc: 0.9487494394586483
	train_correct_nonzero: 28712
	train_incorrect_nonzero: 49
	train_positive_nonzero: 10501
	train_negative_nonzero: 18260
val:
	val_positive_loss: 0.005438816733658314
	val_negative_loss: 0.004155391827225685
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02021930366754532
	test_negative_loss: 0.023335829377174377
	test_positive_acc: 0.9927083097603993
	test_negative_acc: 0.9921739139606792
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.01412616390734911
	train_incorrect_loss: 5.77901207793494
	train_positive_loss: 0.28860679268836975
	train_negative_loss: 0.012038719840347767
	train_correct_acc: 0.9964487822413898
	train_incorrect_acc: 0.012399463806970509
	train_positive_acc: 0.9945248532250641
	train_negative_acc: 0.9494600085754062
	train_correct_nonzero: 28003
	train_incorrect_nonzero: 23
	train_positive_nonzero: 9476
	train_negative_nonzero: 18550
val:
	val_positive_loss: 0.005240252707153559
	val_negative_loss: 0.007198022678494453
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02715390920639038
	test_negative_loss: 0.01780843362212181
	test_positive_acc: 0.9885747118768013
	test_negative_acc: 0.9948066476157911
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.01891571283340454
	train_incorrect_loss: 6.019558295847264
	train_positive_loss: 0.30321019887924194
	train_negative_loss: 0.022369008511304855
	train_correct_acc: 0.9967038238829823
	train_incorrect_acc: 0.024843610366398566
	train_positive_acc: 0.9948486278974863
	train_negative_acc: 0.949688943861195
	train_correct_nonzero: 26171
	train_incorrect_nonzero: 57
	train_positive_nonzero: 8037
	train_negative_nonzero: 18191
val:
	val_positive_loss: 0.00033090519718825817
	val_negative_loss: 0.16610951721668243
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.004046425223350525
	test_negative_loss: 0.2074332982301712
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9776368669465125
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.013952208682894707
	train_incorrect_loss: 9.544248410029779
	train_positive_loss: 0.479438841342926
	train_negative_loss: 0.00788583979010582
	train_correct_acc: 0.9975434565208643
	train_incorrect_acc: 0.01860036832412523
	train_positive_acc: 0.9955690848688561
	train_negative_acc: 0.9507220078456369
	train_correct_nonzero: 21726
	train_incorrect_nonzero: 3
	train_positive_nonzero: 2737
	train_negative_nonzero: 18992
val:
	val_positive_loss: 0.003722286317497492
	val_negative_loss: 2.1847175958100706e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03556887432932854
	test_negative_loss: 0.01921190693974495
	test_positive_acc: 0.9900628071148965
	test_negative_acc: 0.9933531592436982
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.014458805322647095
	train_incorrect_loss: 9.48858527686022
	train_positive_loss: 0.4835231304168701
	train_negative_loss: 0.0017378422198817134
	train_correct_acc: 0.9965195818576665
	train_incorrect_acc: 0.01700138941518252
	train_positive_acc: 0.9934197377548284
	train_negative_acc: 0.9508131220883771
	train_correct_nonzero: 21795
	train_incorrect_nonzero: 18
	train_positive_nonzero: 3183
	train_negative_nonzero: 18630
val:
	val_positive_loss: 0.0002252375998068601
	val_negative_loss: 0.0006230272701941431
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.018839336931705475
	test_negative_loss: 0.02866736240684986
	test_positive_acc: 0.9964576501093159
	test_negative_acc: 0.9923253189994389
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.01730498857796192
	train_incorrect_loss: 8.414903178319825
	train_positive_loss: 0.42977768182754517
	train_negative_loss: 0.001971527235582471
	train_correct_acc: 0.9953938843054996
	train_incorrect_acc: 0.00934065934065934
	train_positive_acc: 0.9913359530265929
	train_negative_acc: 0.9503471885990551
	train_correct_nonzero: 20749
	train_incorrect_nonzero: 2
	train_positive_nonzero: 1715
	train_negative_nonzero: 19036
val:
	val_positive_loss: 0.03611724078655243
	val_negative_loss: 0.00017791337450034916
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04510269686579704
	test_negative_loss: 0.010014897212386131
	test_positive_acc: 0.985803092590789
	test_negative_acc: 0.997439381270903
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.02204873599112034
	train_incorrect_loss: 10.818396077284941
	train_positive_loss: 0.5535433292388916
	train_negative_loss: 0.00012059583968948573
	train_correct_acc: 0.9947789434202344
	train_incorrect_acc: 0.007094594594594595
	train_positive_acc: 0.9899326598178636
	train_negative_acc: 0.9506413817225986
	train_correct_nonzero: 19941
	train_incorrect_nonzero: 0
	train_positive_nonzero: 932
	train_negative_nonzero: 19009
val:
	val_positive_loss: 0.04743495211005211
	val_negative_loss: 4.5443222916219383e-05
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05246005207300186
	test_negative_loss: 0.011427216231822968
	test_positive_acc: 0.9859754724174241
	test_negative_acc: 0.997439381270903
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.02458413690328598
	train_incorrect_loss: 11.931038980522464
	train_positive_loss: 0.6150510907173157
	train_negative_loss: 4.7326579078799114e-05
	train_correct_acc: 0.9946653171392487
	train_incorrect_acc: 0.013306451612903227
	train_positive_acc: 0.9895663589091015
	train_negative_acc: 0.9507701020698341
	train_correct_nonzero: 19478
	train_incorrect_nonzero: 0
	train_positive_nonzero: 677
	train_negative_nonzero: 18801
val:
	val_positive_loss: 0.0513845831155777
	val_negative_loss: 2.079471232718788e-05
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05507579445838928
	test_negative_loss: 0.011597407050430775
	test_positive_acc: 0.984487377179329
	test_negative_acc: 0.997439381270903
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.21048736572266 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.075
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2354838848114014
	train_negative_loss: 2.280458927154541
	train_positive_acc: 0.6395294747643672
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.13870161771774292
	train_incorrect_loss: 2.6487170498999184
	train_positive_loss: 0.28512483835220337
	train_negative_loss: 0.17265616357326508
	train_correct_acc: 0.9666054907937122
	train_incorrect_acc: 0.05845207648276702
	train_positive_acc: 0.9737028486815391
	train_negative_acc: 0.8907827773619303
	train_correct_nonzero: 23162
	train_incorrect_nonzero: 329
	train_positive_nonzero: 8211
	train_negative_nonzero: 15280
val:
	val_positive_loss: 0.10257209837436676
	val_negative_loss: 0.053966816514730453
	val_positive_acc: 0.9661622530474989
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.07871086895465851
	test_negative_loss: 0.05704444646835327
	test_positive_acc: 0.9769588452771968
	test_negative_acc: 0.9990530303030303
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.02951628342270851
	train_incorrect_loss: 4.241415955584783
	train_positive_loss: 0.3185771703720093
	train_negative_loss: 0.03439265489578247
	train_correct_acc: 0.9937158284660663
	train_incorrect_acc: 0.015644078144078144
	train_positive_acc: 0.9918544545132499
	train_negative_acc: 0.9227366881996876
	train_correct_nonzero: 27840
	train_incorrect_nonzero: 66
	train_positive_nonzero: 10026
	train_negative_nonzero: 17880
val:
	val_positive_loss: 0.00036741499206982553
	val_negative_loss: 0.018276475369930267
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0021303060930222273
	test_negative_loss: 0.07675721496343613
	test_positive_acc: 1.0
	test_negative_acc: 0.9706708327841341
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.025691857561469078
	train_incorrect_loss: 4.421437493221244
	train_positive_loss: 0.3223932087421417
	train_negative_loss: 0.035364825278520584
	train_correct_acc: 0.9959112793519538
	train_incorrect_acc: 0.01673247188322565
	train_positive_acc: 0.9948244991466267
	train_negative_acc: 0.9243220296813113
	train_correct_nonzero: 26893
	train_incorrect_nonzero: 78
	train_positive_nonzero: 9139
	train_negative_nonzero: 17832
val:
	val_positive_loss: 0.03624334931373596
	val_negative_loss: 0.00427571777254343
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.031198404729366302
	test_negative_loss: 0.017866071313619614
	test_positive_acc: 0.9880996092661373
	test_negative_acc: 0.9960085706927142
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.015607980079948902
	train_incorrect_loss: 5.660565619087461
	train_positive_loss: 0.41213107109069824
	train_negative_loss: 0.012628688476979733
	train_correct_acc: 0.9962663296177446
	train_incorrect_acc: 0.014152767706067198
	train_positive_acc: 0.9943973169540261
	train_negative_acc: 0.9247145031056989
	train_correct_nonzero: 27234
	train_incorrect_nonzero: 41
	train_positive_nonzero: 9192
	train_negative_nonzero: 18083
val:
	val_positive_loss: 0.025905031710863113
	val_negative_loss: 0.020022911950945854
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.051489364355802536
	test_negative_loss: 0.022242452949285507
	test_positive_acc: 0.976426968911386
	test_negative_acc: 0.9988207547169812
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.015496185049414635
	train_incorrect_loss: 6.561913361404148
	train_positive_loss: 0.47338706254959106
	train_negative_loss: 0.008895229548215866
	train_correct_acc: 0.996398806370911
	train_incorrect_acc: 0.009045403271291594
	train_positive_acc: 0.9935923277347637
	train_negative_acc: 0.9252534834382232
	train_correct_nonzero: 26028
	train_incorrect_nonzero: 30
	train_positive_nonzero: 7917
	train_negative_nonzero: 18141
val:
	val_positive_loss: 0.005614332389086485
	val_negative_loss: 0.009691163897514343
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.027821261435747147
	test_negative_loss: 0.020767509937286377
	test_positive_acc: 0.9904255943010567
	test_negative_acc: 0.9933531592436982
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.012263358570635319
	train_incorrect_loss: 7.155052254824844
	train_positive_loss: 0.5167961716651917
	train_negative_loss: 0.006369256414473057
	train_correct_acc: 0.9968065800855813
	train_incorrect_acc: 0.01351326790258088
	train_positive_acc: 0.9946856039305855
	train_negative_acc: 0.9254311971394222
	train_correct_nonzero: 24605
	train_incorrect_nonzero: 12
	train_positive_nonzero: 6104
	train_negative_nonzero: 18513
val:
	val_positive_loss: 0.014380697160959244
	val_negative_loss: 0.004098237492144108
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.051824383437633514
	test_negative_loss: 0.0070156375877559185
	test_positive_acc: 0.9797979559767498
	test_negative_acc: 0.998641304347826
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.013843662105500698
	train_incorrect_loss: 7.59077110592323
	train_positive_loss: 0.5458663702011108
	train_negative_loss: 0.004102771636098623
	train_correct_acc: 0.9962437392618195
	train_incorrect_acc: 0.01103676913803496
	train_positive_acc: 0.9932728201766439
	train_negative_acc: 0.9253539117419898
	train_correct_nonzero: 23799
	train_incorrect_nonzero: 3
	train_positive_nonzero: 5279
	train_negative_nonzero: 18523
val:
	val_positive_loss: 0.005685746669769287
	val_negative_loss: 0.00048706185771152377
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.028806114569306374
	test_negative_loss: 0.013676553964614868
	test_positive_acc: 0.9899459630648465
	test_negative_acc: 0.9948066476157911
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.014713329263031483
	train_incorrect_loss: 10.129517914680765
	train_positive_loss: 0.7274540066719055
	train_negative_loss: 0.0008853357867337763
	train_correct_acc: 0.9961431840410785
	train_incorrect_acc: 0.012078754578754578
	train_positive_acc: 0.9928064021872627
	train_negative_acc: 0.9256540902733325
	train_correct_nonzero: 20422
	train_incorrect_nonzero: 0
	train_positive_nonzero: 1976
	train_negative_nonzero: 18446
val:
	val_positive_loss: 0.002389525528997183
	val_negative_loss: 4.239429108565673e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.026493526995182037
	test_negative_loss: 0.010573288425803185
	test_positive_acc: 0.9935898715649102
	test_negative_acc: 0.997187815975733
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.014663931913673878
	train_incorrect_loss: 12.828710316913202
	train_positive_loss: 0.9193652272224426
	train_negative_loss: 4.328167051426135e-05
	train_correct_acc: 0.9968941799607571
	train_incorrect_acc: 0.00662151765468092
	train_positive_acc: 0.9940684596657278
	train_negative_acc: 0.9254144213570551
	train_correct_nonzero: 17828
	train_incorrect_nonzero: 0
	train_positive_nonzero: 620
	train_negative_nonzero: 17208
val:
	val_positive_loss: 0.0019915371667593718
	val_negative_loss: 1.8429462215863168e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.028085758909583092
	test_negative_loss: 0.01635274477303028
	test_positive_acc: 0.9935898715649102
	test_negative_acc: 0.9960085706927142
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.01681165024638176
	train_incorrect_loss: 13.904963874028233
	train_positive_loss: 0.9992925524711609
	train_negative_loss: 1.6622567272861488e-05
	train_correct_acc: 0.9965112886161047
	train_incorrect_acc: 0.009838846480067854
	train_positive_acc: 0.993346240123314
	train_negative_acc: 0.9257704563754998
	train_correct_nonzero: 16785
	train_incorrect_nonzero: 0
	train_positive_nonzero: 1222
	train_negative_nonzero: 15563
val:
	val_positive_loss: 0.00025134847965091467
	val_negative_loss: 1.569749292684719e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.021841788664460182
	test_negative_loss: 0.028248576447367668
	test_positive_acc: 0.996630029935951
	test_negative_acc: 0.9948066476157911
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.14065337181091 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.1
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.235337495803833
	train_negative_loss: 2.2804651260375977
	train_positive_acc: 0.6451661559634939
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.1395689696073532
	train_incorrect_loss: 2.6669888849556447
	train_positive_loss: 0.34146204590797424
	train_negative_loss: 0.175790473818779
	train_correct_acc: 0.9671803097082848
	train_incorrect_acc: 0.04381150793650794
	train_positive_acc: 0.9741114287170011
	train_negative_acc: 0.8674629904207177
	train_correct_nonzero: 23909
	train_incorrect_nonzero: 355
	train_positive_nonzero: 8889
	train_negative_nonzero: 15375
val:
	val_positive_loss: 0.04097968712449074
	val_negative_loss: 0.020921742543578148
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03829457610845566
	test_negative_loss: 0.028566405177116394
	test_positive_acc: 0.9903932243390077
	test_negative_acc: 0.9964924115739333
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.031475357711315155
	train_incorrect_loss: 4.039475299249068
	train_positive_loss: 0.38464024662971497
	train_negative_loss: 0.04215423762798309
	train_correct_acc: 0.9941118026989245
	train_incorrect_acc: 0.011989815390319167
	train_positive_acc: 0.9933919673630061
	train_negative_acc: 0.8970361438847609
	train_correct_nonzero: 27903
	train_incorrect_nonzero: 101
	train_positive_nonzero: 10737
	train_negative_nonzero: 17267
val:
	val_positive_loss: 0.006805241573601961
	val_negative_loss: 0.010012825950980186
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.027088046073913574
	test_negative_loss: 0.02550981380045414
	test_positive_acc: 0.9893191654192041
	test_negative_acc: 0.9936274023327722
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02212967723608017
	train_incorrect_loss: 4.638269424438477
	train_positive_loss: 0.43118777871131897
	train_negative_loss: 0.03242781385779381
	train_correct_acc: 0.9960241433133336
	train_incorrect_acc: 0.01686665371204025
	train_positive_acc: 0.9961860622024054
	train_negative_acc: 0.8986378843818086
	train_correct_nonzero: 26767
	train_incorrect_nonzero: 73
	train_positive_nonzero: 9542
	train_negative_nonzero: 17298
val:
	val_positive_loss: 0.00020076896180398762
	val_negative_loss: 0.00400376645848155
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.006752416491508484
	test_negative_loss: 0.03509598225355148
	test_positive_acc: 0.9959492020492408
	test_negative_acc: 0.9887456156473573
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.017327817156910896
	train_incorrect_loss: 5.654064011155513
	train_positive_loss: 0.5309662222862244
	train_negative_loss: 0.018631311133503914
	train_correct_acc: 0.9966619014909488
	train_incorrect_acc: 0.009363686995265942
	train_positive_acc: 0.9947978906675815
	train_negative_acc: 0.9001310747852409
	train_correct_nonzero: 23723
	train_incorrect_nonzero: 31
	train_positive_nonzero: 5949
	train_negative_nonzero: 17805
val:
	val_positive_loss: 0.015316540375351906
	val_negative_loss: 0.0021289235446602106
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02212567627429962
	test_negative_loss: 0.013724502176046371
	test_positive_acc: 0.9893339023051093
	test_negative_acc: 0.9950389232018403
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.011097060516476631
	train_incorrect_loss: 8.707474296254324
	train_positive_loss: 0.8072661757469177
	train_negative_loss: 0.0025298306718468666
	train_correct_acc: 0.9971102110263764
	train_incorrect_acc: 0.004822572303775311
	train_positive_acc: 0.994877490791211
	train_negative_acc: 0.900296296634338
	train_correct_nonzero: 25788
	train_incorrect_nonzero: 7
	train_positive_nonzero: 7803
	train_negative_nonzero: 17992
val:
	val_positive_loss: 0.003370916470885277
	val_negative_loss: 9.090603271033615e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.032609034329652786
	test_negative_loss: 0.011295362375676632
	test_positive_acc: 0.9892541150710668
	test_negative_acc: 0.99598589289881
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.012782658450305462
	train_incorrect_loss: 11.965193399275192
	train_positive_loss: 1.1126025915145874
	train_negative_loss: 9.95448135654442e-05
	train_correct_acc: 0.9967752721865907
	train_incorrect_acc: 0.00392015392015392
	train_positive_acc: 0.9938692467812661
	train_negative_acc: 0.900888407114314
	train_correct_nonzero: 20893
	train_incorrect_nonzero: 2
	train_positive_nonzero: 3108
	train_negative_nonzero: 17787
val:
	val_positive_loss: 0.0032920106314122677
	val_negative_loss: 1.9098964912700467e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.037508826702833176
	test_negative_loss: 0.011064538732171059
	test_positive_acc: 0.9892541150710668
	test_negative_acc: 0.99598589289881
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.014698423445224762
	train_incorrect_loss: 13.518878620877974
	train_positive_loss: 1.2463473081588745
	train_negative_loss: 3.2662952435202897e-05
	train_correct_acc: 0.9966304896564813
	train_incorrect_acc: 0.00415617128463476
	train_positive_acc: 0.9935777769003701
	train_negative_acc: 0.9005530273372078
	train_correct_nonzero: 17988
	train_incorrect_nonzero: 0
	train_positive_nonzero: 1704
	train_negative_nonzero: 16284
val:
	val_positive_loss: 0.009069920517504215
	val_negative_loss: 7.518276561313542e-06
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.042264729738235474
	test_negative_loss: 0.01338124554604292
	test_positive_acc: 0.9880041150710668
	test_negative_acc: 0.99598589289881
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.017452960833907127
	train_incorrect_loss: 14.455433858633041
	train_positive_loss: 1.3424018621444702
	train_negative_loss: 1.0986870620399714e-05
	train_correct_acc: 0.9962765400376731
	train_incorrect_acc: 0.003208333333333333
	train_positive_acc: 0.9929482067780029
	train_negative_acc: 0.9002778401777516
	train_correct_nonzero: 17494
	train_incorrect_nonzero: 0
	train_positive_nonzero: 2775
	train_negative_nonzero: 14719
val:
	val_positive_loss: 0.007688491605222225
	val_negative_loss: 4.754422661790159e-06
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.044073864817619324
	test_negative_loss: 0.013101641088724136
	test_positive_acc: 0.9880041150710668
	test_negative_acc: 0.99598589289881
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.018124207854270935
	train_incorrect_loss: 15.052951775510005
	train_positive_loss: 1.3934040069580078
	train_negative_loss: 7.591974281240255e-06
	train_correct_acc: 0.9964027465803018
	train_incorrect_acc: 0.0027178041661668866
	train_positive_acc: 0.9931722101212253
	train_negative_acc: 0.9003803451728031
	train_correct_nonzero: 15684
	train_incorrect_nonzero: 0
	train_positive_nonzero: 2300
	train_negative_nonzero: 13384
val:
	val_positive_loss: 0.004924529232084751
	val_negative_loss: 3.355583430675324e-06
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04200184717774391
	test_negative_loss: 0.014628777280449867
	test_positive_acc: 0.9893339023051093
	test_negative_acc: 0.99598589289881
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.018796095624566078
	train_incorrect_loss: 15.486205499778766
	train_positive_loss: 1.4372552633285522
	train_negative_loss: 5.402587248681812e-06
	train_correct_acc: 0.996296748105948
	train_incorrect_acc: 0.002818759745711887
	train_positive_acc: 0.9930199789136167
	train_negative_acc: 0.9006256184897645
	train_correct_nonzero: 13541
	train_incorrect_nonzero: 0
	train_positive_nonzero: 1490
	train_negative_nonzero: 12051
val:
	val_positive_loss: 0.0059689064510166645
	val_negative_loss: 2.225709749836824e-06
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04507112503051758
	test_negative_loss: 0.014202464371919632
	test_positive_acc: 0.9893339023051093
	test_negative_acc: 0.99598589289881
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.14999866485596 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.125
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2352235317230225
	train_negative_loss: 2.2804722785949707
	train_positive_acc: 0.6501459646011946
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.15040113031864166
	train_incorrect_loss: 2.5231105387210846
	train_positive_loss: 0.3896534740924835
	train_negative_loss: 0.18593290448188782
	train_correct_acc: 0.9648100689655986
	train_incorrect_acc: 0.04681259018759018
	train_positive_acc: 0.9731959212919672
	train_negative_acc: 0.8412031393719441
	train_correct_nonzero: 23636
	train_incorrect_nonzero: 452
	train_positive_nonzero: 8973
	train_negative_nonzero: 15115
val:
	val_positive_loss: 0.01827796921133995
	val_negative_loss: 0.02883252501487732
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02590671181678772
	test_negative_loss: 0.0382450595498085
	test_positive_acc: 0.9903932243390077
	test_negative_acc: 0.9925575945854881
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.038895998150110245
	train_incorrect_loss: 3.8867551735043526
	train_positive_loss: 0.45954829454421997
	train_negative_loss: 0.050517670810222626
	train_correct_acc: 0.9928352265559844
	train_incorrect_acc: 0.00513997113997114
	train_positive_acc: 0.9903426452728785
	train_negative_acc: 0.8725784503951034
	train_correct_nonzero: 24673
	train_incorrect_nonzero: 108
	train_positive_nonzero: 7928
	train_negative_nonzero: 16853
val:
	val_positive_loss: 0.0007680566050112247
	val_negative_loss: 0.005484709050506353
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.007543427869677544
	test_negative_loss: 0.03179819509387016
	test_positive_acc: 0.9959492020492408
	test_negative_acc: 0.9915011873527837
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.030293747782707214
	train_incorrect_loss: 4.355224609375
	train_positive_loss: 0.5051413774490356
	train_negative_loss: 0.03942682966589928
	train_correct_acc: 0.9943403864129949
	train_incorrect_acc: 0.004762084687271719
	train_positive_acc: 0.9917322886305704
	train_negative_acc: 0.8740691480512853
	train_correct_nonzero: 24023
	train_incorrect_nonzero: 91
	train_positive_nonzero: 7106
	train_negative_nonzero: 17008
val:
	val_positive_loss: 0.002596450038254261
	val_negative_loss: 0.012505517341196537
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.024416889995336533
	test_negative_loss: 0.024940673261880875
	test_positive_acc: 0.9891913012620847
	test_negative_acc: 0.99598589289881
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.01950128935277462
	train_incorrect_loss: 5.594193323850631
	train_positive_loss: 0.6481664180755615
	train_negative_loss: 0.01241028681397438
	train_correct_acc: 0.9943263839730521
	train_incorrect_acc: 0.006594516594516595
	train_positive_acc: 0.9904277350052816
	train_negative_acc: 0.8753127567165706
	train_correct_nonzero: 23109
	train_incorrect_nonzero: 21
	train_positive_nonzero: 5715
	train_negative_nonzero: 17415
val:
	val_positive_loss: 0.00014216857380233705
	val_negative_loss: 0.005550875328481197
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.006363939493894577
	test_negative_loss: 0.04181757569313049
	test_positive_acc: 0.9968319774718398
	test_negative_acc: 0.9885296617519478
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.020283520221710205
	train_incorrect_loss: 6.284849166870117
	train_positive_loss: 0.6986990571022034
	train_negative_loss: 0.025571124628186226
	train_correct_acc: 0.9963984309465257
	train_incorrect_acc: 0.006869730435815223
	train_positive_acc: 0.9950274958271524
	train_negative_acc: 0.8741842942031516
	train_correct_nonzero: 22489
	train_incorrect_nonzero: 72
	train_positive_nonzero: 5438
	train_negative_nonzero: 17123
val:
	val_positive_loss: 0.0057931761257350445
	val_negative_loss: 0.0010625526774674654
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.034009434282779694
	test_negative_loss: 0.008160538971424103
	test_positive_acc: 0.9869482662730391
	test_negative_acc: 0.99598589289881
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.01516883447766304
	train_incorrect_loss: 10.057032585144043
	train_positive_loss: 1.1462143659591675
	train_negative_loss: 0.000847557676024735
	train_correct_acc: 0.9962254383795653
	train_incorrect_acc: 0.0036189288683054262
	train_positive_acc: 0.9931430785710416
	train_negative_acc: 0.8756685633664416
	train_correct_nonzero: 20552
	train_incorrect_nonzero: 2
	train_positive_nonzero: 3029
	train_negative_nonzero: 17525
val:
	val_positive_loss: 0.0021644302178174257
	val_negative_loss: 6.0845126427011564e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0543590784072876
	test_negative_loss: 0.007048746570944786
	test_positive_acc: 0.986980636235088
	test_negative_acc: 0.997344588550984
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.02083689719438553
	train_incorrect_loss: 12.278770446777344
	train_positive_loss: 1.391454815864563
	train_negative_loss: 5.392171806306578e-05
	train_correct_acc: 0.9953576947176535
	train_incorrect_acc: 0.0021663014181717423
	train_positive_acc: 0.9913436715669186
	train_negative_acc: 0.8756895263585881
	train_correct_nonzero: 20512
	train_incorrect_nonzero: 2
	train_positive_nonzero: 3219
	train_negative_nonzero: 17295
val:
	val_positive_loss: 6.61091908114031e-05
	val_negative_loss: 1.511229947936954e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.06000257655978203
	test_negative_loss: 0.004941792227327824
	test_positive_acc: 0.9869434670409161
	test_negative_acc: 0.997344588550984
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.026783550158143044
	train_incorrect_loss: 7.688942909240723
	train_positive_loss: 0.8812212944030762
	train_negative_loss: 0.009465624578297138
	train_correct_acc: 0.9923634093214707
	train_incorrect_acc: 0.0017317816569686892
	train_positive_acc: 0.9863095898465252
	train_negative_acc: 0.8747001234045951
	train_correct_nonzero: 20313
	train_incorrect_nonzero: 28
	train_positive_nonzero: 3086
	train_negative_nonzero: 17255
val:
	val_positive_loss: 0.01674972102046013
	val_negative_loss: 0.0004327015485614538
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.052826717495918274
	test_negative_loss: 0.0055726272985339165
	test_positive_acc: 0.9809254470881436
	test_negative_acc: 0.997344588550984
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.027358761057257652
	train_incorrect_loss: 10.159098885710675
	train_positive_loss: 1.1666839122772217
	train_negative_loss: 0.00020203707390464842
	train_correct_acc: 0.9926983047574536
	train_incorrect_acc: 0.000278473962684489
	train_positive_acc: 0.9863306528904623
	train_negative_acc: 0.8751814705816908
	train_correct_nonzero: 22812
	train_incorrect_nonzero: 0
	train_positive_nonzero: 5274
	train_negative_nonzero: 17538
val:
	val_positive_loss: 0.00892451498657465
	val_negative_loss: 7.552337774541229e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05738653242588043
	test_negative_loss: 0.008568228222429752
	test_positive_acc: 0.9832347691220418
	test_negative_acc: 0.99598589289881
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.021676313132047653
	train_incorrect_loss: 9.258264541625977
	train_positive_loss: 1.0573515892028809
	train_negative_loss: 0.00210057501681149
	train_correct_acc: 0.9943110868916314
	train_incorrect_acc: 0.002734235838973994
	train_positive_acc: 0.9895968318148933
	train_negative_acc: 0.8756454678680795
	train_correct_nonzero: 23451
	train_incorrect_nonzero: 12
	train_positive_nonzero: 5996
	train_negative_nonzero: 17467
val:
	val_positive_loss: 0.0020636015105992556
	val_negative_loss: 0.00011046245344914496
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04999367520213127
	test_negative_loss: 0.011701611801981926
	test_positive_acc: 0.9857306362350879
	test_negative_acc: 0.99598589289881
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.50817036628723 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.15
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.235092878341675
	train_negative_loss: 2.280439853668213
	train_positive_acc: 0.6557906113916965
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.1628161072731018
	train_incorrect_loss: 2.4029111862182617
	train_positive_loss: 0.4243771433830261
	train_negative_loss: 0.20498058199882507
	train_correct_acc: 0.9618711281988334
	train_incorrect_acc: 0.0475436242892602
	train_positive_acc: 0.972105633677497
	train_negative_acc: 0.81485754354267
	train_correct_nonzero: 23788
	train_incorrect_nonzero: 576
	train_positive_nonzero: 9687
	train_negative_nonzero: 14677
val:
	val_positive_loss: 0.01420086994767189
	val_negative_loss: 0.030826706439256668
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.026017453521490097
	test_negative_loss: 0.044734273105859756
	test_positive_acc: 0.9926230636431503
	test_negative_acc: 0.9867210597434911
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03398706018924713
	train_incorrect_loss: 3.9690017700195312
	train_positive_loss: 0.5431491732597351
	train_negative_loss: 0.04211762174963951
	train_correct_acc: 0.9938054805016324
	train_incorrect_acc: 0.0072010283980358785
	train_positive_acc: 0.9921008970382194
	train_negative_acc: 0.8482428381996006
	train_correct_nonzero: 26324
	train_incorrect_nonzero: 139
	train_positive_nonzero: 10002
	train_negative_nonzero: 16461
val:
	val_positive_loss: 0.013257844373583794
	val_negative_loss: 0.003940744325518608
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.016467031091451645
	test_negative_loss: 0.01599820703268051
	test_positive_acc: 0.9938121474638132
	test_negative_acc: 0.9946838095654766
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.024897834286093712
	train_incorrect_loss: 5.19044303894043
	train_positive_loss: 0.6960954666137695
	train_negative_loss: 0.02353249117732048
	train_correct_acc: 0.993966686407631
	train_incorrect_acc: 0.0074560701632727456
	train_positive_acc: 0.9911113616372768
	train_negative_acc: 0.8502248957010244
	train_correct_nonzero: 28706
	train_incorrect_nonzero: 48
	train_positive_nonzero: 11846
	train_negative_nonzero: 16908
val:
	val_positive_loss: 0.003680003574118018
	val_negative_loss: 0.006818010471761227
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.00955027062445879
	test_negative_loss: 0.03670259192585945
	test_positive_acc: 0.9946194148151982
	test_negative_acc: 0.9896428393816896
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.021774763241410255
	train_incorrect_loss: 5.961934566497803
	train_positive_loss: 0.7953459024429321
	train_negative_loss: 0.022344620898365974
	train_correct_acc: 0.9954048347283978
	train_incorrect_acc: 0.006896539315491935
	train_positive_acc: 0.9929914321578779
	train_negative_acc: 0.8501822703950047
	train_correct_nonzero: 23088
	train_incorrect_nonzero: 60
	train_positive_nonzero: 6375
	train_negative_nonzero: 16773
val:
	val_positive_loss: 0.0049887485802173615
	val_negative_loss: 0.0263526551425457
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.008934004232287407
	test_negative_loss: 0.04881227761507034
	test_positive_acc: 0.996630029935951
	test_negative_acc: 0.9919944635915241
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.023105040192604065
	train_incorrect_loss: 5.9308319091796875
	train_positive_loss: 0.7873755693435669
	train_negative_loss: 0.021371671929955482
	train_correct_acc: 0.995333635133267
	train_incorrect_acc: 0.008378819850141547
	train_positive_acc: 0.9921920924674087
	train_negative_acc: 0.8504291998820322
	train_correct_nonzero: 24838
	train_incorrect_nonzero: 50
	train_positive_nonzero: 8045
	train_negative_nonzero: 16843
val:
	val_positive_loss: 0.015913458541035652
	val_negative_loss: 0.005237409844994545
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02296627126634121
	test_negative_loss: 0.016229107975959778
	test_positive_acc: 0.9921462919963306
	test_negative_acc: 0.9948066476157911
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.01252327673137188
	train_incorrect_loss: 6.57344388961792
	train_positive_loss: 0.8765738010406494
	train_negative_loss: 0.005963006056845188
	train_correct_acc: 0.9963777798151459
	train_incorrect_acc: 0.01096483178777443
	train_positive_acc: 0.9938773584885003
	train_negative_acc: 0.8514748417392793
	train_correct_nonzero: 23825
	train_incorrect_nonzero: 16
	train_positive_nonzero: 6823
	train_negative_nonzero: 17018
val:
	val_positive_loss: 0.014182653278112411
	val_negative_loss: 0.0005213762633502483
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.022427652031183243
	test_negative_loss: 0.015209116041660309
	test_positive_acc: 0.9908962919963307
	test_negative_acc: 0.99598589289881
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.010444995015859604
	train_incorrect_loss: 6.502019882202148
	train_positive_loss: 0.8479606509208679
	train_negative_loss: 0.006077713333070278
	train_correct_acc: 0.9974927942125928
	train_incorrect_acc: 0.009089497368799115
	train_positive_acc: 0.9956676753650814
	train_negative_acc: 0.8516530546996892
	train_correct_nonzero: 20820
	train_incorrect_nonzero: 15
	train_positive_nonzero: 3823
	train_negative_nonzero: 17012
val:
	val_positive_loss: 0.0067193577997386456
	val_negative_loss: 0.0009239775827154517
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.025574304163455963
	test_negative_loss: 0.011923907324671745
	test_positive_acc: 0.9910959359792193
	test_negative_acc: 0.997344588550984
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.009478348307311535
	train_incorrect_loss: 7.912189960479736
	train_positive_loss: 1.0447046756744385
	train_negative_loss: 0.001695911050774157
	train_correct_acc: 0.9978731248790537
	train_incorrect_acc: 0.008048117025673136
	train_positive_acc: 0.9960323106434037
	train_negative_acc: 0.8514987978259959
	train_correct_nonzero: 19487
	train_incorrect_nonzero: 9
	train_positive_nonzero: 2447
	train_negative_nonzero: 17049
val:
	val_positive_loss: 8.250184464486665e-07
	val_negative_loss: 0.02750786393880844
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 6.124695210019127e-05
	test_negative_loss: 0.16996529698371887
	test_positive_acc: 1.0
	test_negative_acc: 0.9685741569078301
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.01678980141878128
	train_incorrect_loss: 6.227178573608398
	train_positive_loss: 0.8255280256271362
	train_negative_loss: 0.01412205956876278
	train_correct_acc: 0.9964949477010632
	train_incorrect_acc: 0.009375730946803267
	train_positive_acc: 0.9940210879304047
	train_negative_acc: 0.8514895970934586
	train_correct_nonzero: 21535
	train_incorrect_nonzero: 91
	train_positive_nonzero: 4943
	train_negative_nonzero: 16683
val:
	val_positive_loss: 0.0002196096902480349
	val_negative_loss: 0.002716401591897011
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0102893877774477
	test_negative_loss: 0.035673316568136215
	test_positive_acc: 0.9959492020492408
	test_negative_acc: 0.9866194006673688
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.01645287312567234
	train_incorrect_loss: 5.724184513092041
	train_positive_loss: 0.7619555592536926
	train_negative_loss: 0.015842387452721596
	train_correct_acc: 0.9965670005119455
	train_incorrect_acc: 0.008457807086236014
	train_positive_acc: 0.9945395650391972
	train_negative_acc: 0.8507337814837498
	train_correct_nonzero: 26437
	train_incorrect_nonzero: 75
	train_positive_nonzero: 9715
	train_negative_nonzero: 16797
val:
	val_positive_loss: 0.013387180864810944
	val_negative_loss: 0.0015302146784961224
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.029676172882318497
	test_negative_loss: 0.01483933161944151
	test_positive_acc: 0.9896402107031732
	test_negative_acc: 0.99598589289881
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.06803250312805 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.175
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.234931230545044
	train_negative_loss: 2.2804722785949707
	train_positive_acc: 0.6614058608035442
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.15554450452327728
	train_incorrect_loss: 2.4861574172973633
	train_positive_loss: 0.47505274415016174
	train_negative_loss: 0.1958514302968979
	train_correct_acc: 0.9648299351360912
	train_incorrect_acc: 0.0495318549557951
	train_positive_acc: 0.974936118759661
	train_negative_acc: 0.7946833428643943
	train_correct_nonzero: 22626
	train_incorrect_nonzero: 569
	train_positive_nonzero: 8576
	train_negative_nonzero: 14619
val:
	val_positive_loss: 0.03581922501325607
	val_negative_loss: 0.03192947432398796
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04147190600633621
	test_negative_loss: 0.03522975742816925
	test_positive_acc: 0.9892358169316002
	test_negative_acc: 0.9964395863570392
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.04387538880109787
	train_incorrect_loss: 3.180079698562622
	train_positive_loss: 0.49243423342704773
	train_negative_loss: 0.06813519448041916
	train_correct_acc: 0.9938130529477842
	train_incorrect_acc: 0.012226634545836541
	train_positive_acc: 0.9933177319794839
	train_negative_acc: 0.823581627309149
	train_correct_nonzero: 23589
	train_incorrect_nonzero: 215
	train_positive_nonzero: 8037
	train_negative_nonzero: 15767
val:
	val_positive_loss: 0.0005973003571853042
	val_negative_loss: 0.05001520365476608
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.003932079300284386
	test_negative_loss: 0.08785132318735123
	test_positive_acc: 0.9970652734778122
	test_negative_acc: 0.9761541432548388
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.029361005872488022
	train_incorrect_loss: 4.339855194091797
	train_positive_loss: 0.6596901416778564
	train_negative_loss: 0.03922587260603905
	train_correct_acc: 0.9944726626180873
	train_incorrect_acc: 0.009127182370544553
	train_positive_acc: 0.9923001793836946
	train_negative_acc: 0.8255458111389985
	train_correct_nonzero: 24379
	train_incorrect_nonzero: 105
	train_positive_nonzero: 8306
	train_negative_nonzero: 16178
val:
	val_positive_loss: 0.006270475685596466
	val_negative_loss: 0.006985505577176809
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03456690162420273
	test_negative_loss: 0.021112821996212006
	test_positive_acc: 0.9866175784423512
	test_negative_acc: 0.9948066476157911
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.018957918509840965
	train_incorrect_loss: 7.458494186401367
	train_positive_loss: 1.1364588737487793
	train_negative_loss: 0.005068532191216946
	train_correct_acc: 0.9941117829417871
	train_incorrect_acc: 0.0026301766950146003
	train_positive_acc: 0.9897880526047642
	train_negative_acc: 0.8255221153046396
	train_correct_nonzero: 20213
	train_incorrect_nonzero: 14
	train_positive_nonzero: 3775
	train_negative_nonzero: 16452
val:
	val_positive_loss: 0.00011671162792481482
	val_negative_loss: 0.0014258439186960459
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.013708168640732765
	test_negative_loss: 0.034479424357414246
	test_positive_acc: 0.9959492020492408
	test_negative_acc: 0.9936274023327722
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.020516294986009598
	train_incorrect_loss: 7.1993818283081055
	train_positive_loss: 1.09321129322052
	train_negative_loss: 0.010446075350046158
	train_correct_acc: 0.9944251509396197
	train_incorrect_acc: 0.005879358934221777
	train_positive_acc: 0.9907057665171216
	train_negative_acc: 0.8251459434922862
	train_correct_nonzero: 21257
	train_incorrect_nonzero: 46
	train_positive_nonzero: 4892
	train_negative_nonzero: 16411
val:
	val_positive_loss: 0.000858247047290206
	val_negative_loss: 0.0028537374455481768
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02375790663063526
	test_negative_loss: 0.025089241564273834
	test_positive_acc: 0.9934017847772472
	test_negative_acc: 0.9894646185182742
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.017859701067209244
	train_incorrect_loss: 7.27646017074585
	train_positive_loss: 1.1020375490188599
	train_negative_loss: 0.008908711373806
	train_correct_acc: 0.9949630483345466
	train_incorrect_acc: 0.00879858573125406
	train_positive_acc: 0.9918472250203787
	train_negative_acc: 0.8260541301346018
	train_correct_nonzero: 24690
	train_incorrect_nonzero: 33
	train_positive_nonzero: 8291
	train_negative_nonzero: 16432
val:
	val_positive_loss: 0.0023973905481398106
	val_negative_loss: 0.021684477105736732
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.021773163229227066
	test_negative_loss: 0.021461132913827896
	test_positive_acc: 0.9897168338435383
	test_negative_acc: 0.9924061895467284
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.017827240750193596
	train_incorrect_loss: 7.435165882110596
	train_positive_loss: 1.1140533685684204
	train_negative_loss: 0.01428377628326416
	train_correct_acc: 0.9956874632553305
	train_incorrect_acc: 0.009024779598345684
	train_positive_acc: 0.9935251954007808
	train_negative_acc: 0.8255701240669521
	train_correct_nonzero: 23118
	train_incorrect_nonzero: 45
	train_positive_nonzero: 6798
	train_negative_nonzero: 16365
val:
	val_positive_loss: 0.018479129299521446
	val_negative_loss: 0.01092003658413887
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.035385772585868835
	test_negative_loss: 0.021898940205574036
	test_positive_acc: 0.9847620091641374
	test_negative_acc: 0.9948066476157911
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.021899918094277382
	train_incorrect_loss: 5.516233921051025
	train_positive_loss: 0.8319652080535889
	train_negative_loss: 0.025545762851834297
	train_correct_acc: 0.996557279703617
	train_incorrect_acc: 0.011251840428897783
	train_positive_acc: 0.9942164894387338
	train_negative_acc: 0.8265376683180363
	train_correct_nonzero: 26350
	train_incorrect_nonzero: 57
	train_positive_nonzero: 10026
	train_negative_nonzero: 16381
val:
	val_positive_loss: 0.0010686691384762526
	val_negative_loss: 0.005914338864386082
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.015655716881155968
	test_negative_loss: 0.030675562098622322
	test_positive_acc: 0.9922443773698398
	test_negative_acc: 0.9906558767319362
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.008955209515988827
	train_incorrect_loss: 8.268428802490234
	train_positive_loss: 1.241519808769226
	train_negative_loss: 0.0015504880575463176
	train_correct_acc: 0.9979284451002122
	train_incorrect_acc: 0.009741027883172522
	train_positive_acc: 0.9963645733818464
	train_negative_acc: 0.8272230282752902
	train_correct_nonzero: 21656
	train_incorrect_nonzero: 6
	train_positive_nonzero: 5108
	train_negative_nonzero: 16554
val:
	val_positive_loss: 0.004889793694019318
	val_negative_loss: 0.0006720843375660479
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.033196210861206055
	test_negative_loss: 0.018757907673716545
	test_positive_acc: 0.9874587684233966
	test_negative_acc: 0.9936274023327722
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.011291048489511013
	train_incorrect_loss: 9.74846363067627
	train_positive_loss: 1.4646297693252563
	train_negative_loss: 0.00043057979200966656
	train_correct_acc: 0.9972998111023093
	train_incorrect_acc: 0.007050519403827311
	train_positive_acc: 0.9951905043185306
	train_negative_acc: 0.8266372179252964
	train_correct_nonzero: 20284
	train_incorrect_nonzero: 1
	train_positive_nonzero: 3740
	train_negative_nonzero: 16545
val:
	val_positive_loss: 0.002463331911712885
	val_negative_loss: 8.410896407440305e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.049967531114816666
	test_negative_loss: 0.014777962118387222
	test_positive_acc: 0.988543719475103
	test_negative_acc: 0.9962601359878842
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.37038803100586 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.2
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.234855890274048
	train_negative_loss: 2.2804818153381348
	train_positive_acc: 0.665159741755368
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.16081184148788452
	train_incorrect_loss: 2.338822364807129
	train_positive_loss: 0.49411097168922424
	train_negative_loss: 0.20774175226688385
	train_correct_acc: 0.9629498721610178
	train_incorrect_acc: 0.04842049275045732
	train_positive_acc: 0.9748041306256131
	train_negative_acc: 0.7688220620530477
	train_correct_nonzero: 21784
	train_incorrect_nonzero: 671
	train_positive_nonzero: 8244
	train_negative_nonzero: 14211
val:
	val_positive_loss: 0.03569496050477028
	val_negative_loss: 0.1355365812778473
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.03179685026407242
	test_negative_loss: 0.13521289825439453
	test_positive_acc: 0.996299342105263
	test_negative_acc: 0.9864468166544169
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.0371987484395504
	train_incorrect_loss: 3.677837371826172
	train_positive_loss: 0.6340020298957825
	train_negative_loss: 0.05162486061453819
	train_correct_acc: 0.993252666712044
	train_incorrect_acc: 0.015182546374786362
	train_positive_acc: 0.993688675150021
	train_negative_acc: 0.7983565581097392
	train_correct_nonzero: 24141
	train_incorrect_nonzero: 165
	train_positive_nonzero: 8774
	train_negative_nonzero: 15532
val:
	val_positive_loss: 0.009199542924761772
	val_negative_loss: 0.018436148762702942
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.025202706456184387
	test_negative_loss: 0.03573400899767876
	test_positive_acc: 0.9939528508771929
	test_negative_acc: 0.9908718306273459
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02729383297264576
	train_incorrect_loss: 4.393971920013428
	train_positive_loss: 0.7486162185668945
	train_negative_loss: 0.03458564728498459
	train_correct_acc: 0.9953628945960152
	train_incorrect_acc: 0.010312776355390407
	train_positive_acc: 0.9937101889684463
	train_negative_acc: 0.8015635850559236
	train_correct_nonzero: 25426
	train_incorrect_nonzero: 114
	train_positive_nonzero: 9763
	train_negative_nonzero: 15777
val:
	val_positive_loss: 0.008615397848188877
	val_negative_loss: 0.010864281095564365
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.022346636280417442
	test_negative_loss: 0.020824722945690155
	test_positive_acc: 0.9896645901357972
	test_negative_acc: 0.9941485658237111
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.03095746785402298
	train_incorrect_loss: 5.239317417144775
	train_positive_loss: 0.8893342614173889
	train_negative_loss: 0.04155369848012924
	train_correct_acc: 0.9949099703476733
	train_incorrect_acc: 0.010907989972808577
	train_positive_acc: 0.9925143296744794
	train_negative_acc: 0.8012180649191333
	train_correct_nonzero: 25132
	train_incorrect_nonzero: 139
	train_positive_nonzero: 9521
	train_negative_nonzero: 15750
val:
	val_positive_loss: 0.0019832709804177284
	val_negative_loss: 0.06277713924646378
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01650339737534523
	test_negative_loss: 0.08308170735836029
	test_positive_acc: 0.9937520528084363
	test_negative_acc: 0.9933531592436982
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.01915840059518814
	train_incorrect_loss: 5.062171459197998
	train_positive_loss: 0.8535732626914978
	train_negative_loss: 0.021005826070904732
	train_correct_acc: 0.9957222897278797
	train_incorrect_acc: 0.011642116868022693
	train_positive_acc: 0.9934776115668994
	train_negative_acc: 0.8012924609093796
	train_correct_nonzero: 21865
	train_incorrect_nonzero: 81
	train_positive_nonzero: 6118
	train_negative_nonzero: 15828
val:
	val_positive_loss: 0.008737661875784397
	val_negative_loss: 0.02251378819346428
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.02022329904139042
	test_negative_loss: 0.03256996348500252
	test_positive_acc: 0.9897783824703343
	test_negative_acc: 0.993144983807901
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.01645897515118122
	train_incorrect_loss: 5.684067249298096
	train_positive_loss: 0.9692379236221313
	train_negative_loss: 0.011789633892476559
	train_correct_acc: 0.9961382457702912
	train_incorrect_acc: 0.00862718707628492
	train_positive_acc: 0.9935156021727529
	train_negative_acc: 0.8016592821559757
	train_correct_nonzero: 21433
	train_incorrect_nonzero: 36
	train_positive_nonzero: 5505
	train_negative_nonzero: 15964
val:
	val_positive_loss: 0.004963937681168318
	val_negative_loss: 0.002138901734724641
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.027213141322135925
	test_negative_loss: 0.022050727158784866
	test_positive_acc: 0.9893339023051093
	test_negative_acc: 0.9925575945854881
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.01446827407926321
	train_incorrect_loss: 5.778275966644287
	train_positive_loss: 0.9798738956451416
	train_negative_loss: 0.009248200803995132
	train_correct_acc: 0.9966541187515991
	train_incorrect_acc: 0.00800580688361237
	train_positive_acc: 0.9943084686967975
	train_negative_acc: 0.8014912820008385
	train_correct_nonzero: 18608
	train_incorrect_nonzero: 36
	train_positive_nonzero: 2701
	train_negative_nonzero: 15943
val:
	val_positive_loss: 0.004020321182906628
	val_negative_loss: 0.0016086080577224493
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03886333107948303
	test_negative_loss: 0.010796552523970604
	test_positive_acc: 0.9872937194751029
	test_negative_acc: 0.99598589289881
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.012485508807003498
	train_incorrect_loss: 6.497494220733643
	train_positive_loss: 1.0940264463424683
	train_negative_loss: 0.005905176512897015
	train_correct_acc: 0.9972100430665649
	train_incorrect_acc: 0.010794317901549822
	train_positive_acc: 0.9950991590123458
	train_negative_acc: 0.8021173544215295
	train_correct_nonzero: 17228
	train_incorrect_nonzero: 33
	train_positive_nonzero: 1276
	train_negative_nonzero: 15985
val:
	val_positive_loss: 0.0034583176020532846
	val_negative_loss: 0.0006347571033984423
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04429136961698532
	test_negative_loss: 0.012434806674718857
	test_positive_acc: 0.9861222402451131
	test_negative_acc: 0.99598589289881
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.015143025666475296
	train_incorrect_loss: 8.936777114868164
	train_positive_loss: 1.5079466104507446
	train_negative_loss: 0.00033646353404037654
	train_correct_acc: 0.9962292376597501
	train_incorrect_acc: 0.007266801499968583
	train_positive_acc: 0.9932221073060227
	train_negative_acc: 0.8019467818705565
	train_correct_nonzero: 16621
	train_incorrect_nonzero: 1
	train_positive_nonzero: 571
	train_negative_nonzero: 16051
val:
	val_positive_loss: 0.005266604013741016
	val_negative_loss: 0.0001602521224413067
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.057607512921094894
	test_negative_loss: 0.012638119980692863
	test_positive_acc: 0.9834322219300947
	test_negative_acc: 0.99598589289881
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.018458792939782143
	train_incorrect_loss: 10.157867431640625
	train_positive_loss: 1.7156699895858765
	train_negative_loss: 0.00010774097609100863
	train_correct_acc: 0.9957044290044512
	train_incorrect_acc: 0.00637132780670994
	train_positive_acc: 0.9923108065691123
	train_negative_acc: 0.801687440138968
	train_correct_nonzero: 16909
	train_incorrect_nonzero: 2
	train_positive_nonzero: 859
	train_negative_nonzero: 16052
val:
	val_positive_loss: 0.0027939113788306713
	val_negative_loss: 7.551058661192656e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.06037429720163345
	test_negative_loss: 0.012385392561554909
	test_positive_acc: 0.9834322219300947
	test_negative_acc: 0.99598589289881
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 91.84111738204956 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.225
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.234710454940796
	train_negative_loss: 2.2804484367370605
	train_positive_acc: 0.6701711000477298
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.17394228279590607
	train_incorrect_loss: 2.315319299697876
	train_positive_loss: 0.5365869402885437
	train_negative_loss: 0.22692547738552094
	train_correct_acc: 0.9585358226675624
	train_incorrect_acc: 0.056707651617049944
	train_positive_acc: 0.971233560530618
	train_negative_acc: 0.7429720520159461
	train_correct_nonzero: 21940
	train_incorrect_nonzero: 762
	train_positive_nonzero: 8669
	train_negative_nonzero: 14033
val:
	val_positive_loss: 0.03043564036488533
	val_negative_loss: 0.04772420972585678
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.043058961629867554
	test_negative_loss: 0.05513864755630493
	test_positive_acc: 0.9823592886106884
	test_negative_acc: 0.9936274023327722
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.04173438251018524
	train_incorrect_loss: 3.6269519329071045
	train_positive_loss: 0.68684321641922
	train_negative_loss: 0.05724000930786133
	train_correct_acc: 0.9922968233602475
	train_incorrect_acc: 0.012483739293166964
	train_positive_acc: 0.9912172246399436
	train_negative_acc: 0.7743599584059938
	train_correct_nonzero: 24553
	train_incorrect_nonzero: 193
	train_positive_nonzero: 9683
	train_negative_nonzero: 15063
val:
	val_positive_loss: 0.0023902368266135454
	val_negative_loss: 0.02034553326666355
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.007335142232477665
	test_negative_loss: 0.06724198162555695
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9757997093547219
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02501855418086052
	train_incorrect_loss: 4.420709133148193
	train_positive_loss: 0.8194261193275452
	train_negative_loss: 0.03228873759508133
	train_correct_acc: 0.9952668952206911
	train_incorrect_acc: 0.011615357190370896
	train_positive_acc: 0.9944039693299606
	train_negative_acc: 0.7765381822636759
	train_correct_nonzero: 26936
	train_incorrect_nonzero: 109
	train_positive_nonzero: 11700
	train_negative_nonzero: 15345
val:
	val_positive_loss: 0.0018222721992060542
	val_negative_loss: 0.02509024739265442
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.007240955717861652
	test_negative_loss: 0.053852953016757965
	test_positive_acc: 0.9975541413373861
	test_negative_acc: 0.9851161663326384
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.024102259427309036
	train_incorrect_loss: 5.066213130950928
	train_positive_loss: 0.9414380788803101
	train_negative_loss: 0.02631263993680477
	train_correct_acc: 0.9948746083556307
	train_incorrect_acc: 0.008166481253983088
	train_positive_acc: 0.992393614227135
	train_negative_acc: 0.776261054991454
	train_correct_nonzero: 25063
	train_incorrect_nonzero: 106
	train_positive_nonzero: 9879
	train_negative_nonzero: 15290
val:
	val_positive_loss: 0.0018943106988444924
	val_negative_loss: 0.05267203226685524
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.013427791185677052
	test_negative_loss: 0.06891477108001709
	test_positive_acc: 0.9920719975432046
	test_negative_acc: 0.9925856399158834
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.02079135552048683
	train_incorrect_loss: 5.846102714538574
	train_positive_loss: 1.0822863578796387
	train_negative_loss: 0.024142557755112648
	train_correct_acc: 0.9960196615368808
	train_incorrect_acc: 0.009833100822538991
	train_positive_acc: 0.9944780099501359
	train_negative_acc: 0.7761373061787527
	train_correct_nonzero: 25495
	train_incorrect_nonzero: 114
	train_positive_nonzero: 10236
	train_negative_nonzero: 15373
val:
	val_positive_loss: 0.0016585103003308177
	val_negative_loss: 0.006444619968533516
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.023056957870721817
	test_negative_loss: 0.027805788442492485
	test_positive_acc: 0.9903932243390077
	test_negative_acc: 0.9938596779188213
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.01750469207763672
	train_incorrect_loss: 5.343031406402588
	train_positive_loss: 0.9907419681549072
	train_negative_loss: 0.019575446844100952
	train_correct_acc: 0.9967066657414096
	train_incorrect_acc: 0.00877566534341779
	train_positive_acc: 0.9952195843349423
	train_negative_acc: 0.7766802616075459
	train_correct_nonzero: 24884
	train_incorrect_nonzero: 71
	train_positive_nonzero: 9581
	train_negative_nonzero: 15374
val:
	val_positive_loss: 0.006842959672212601
	val_negative_loss: 0.004025054629892111
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.021737046539783478
	test_negative_loss: 0.024326343089342117
	test_positive_acc: 0.990234916334955
	test_negative_acc: 0.9938596779188213
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.01131934393197298
	train_incorrect_loss: 8.192434310913086
	train_positive_loss: 1.5121315717697144
	train_negative_loss: 0.001145441783592105
	train_correct_acc: 0.9971865170110671
	train_incorrect_acc: 0.009293811578540931
	train_positive_acc: 0.9950991002863023
	train_negative_acc: 0.7775691173600169
	train_correct_nonzero: 22035
	train_incorrect_nonzero: 10
	train_positive_nonzero: 6486
	train_negative_nonzero: 15559
val:
	val_positive_loss: 0.007065984420478344
	val_negative_loss: 0.00030696115572936833
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04576895385980606
	test_negative_loss: 0.021319132298231125
	test_positive_acc: 0.9878871586428524
	test_negative_acc: 0.9924061895467284
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.015778610482811928
	train_incorrect_loss: 10.198317527770996
	train_positive_loss: 1.8898403644561768
	train_negative_loss: 0.00012062588211847469
	train_correct_acc: 0.9961473825026173
	train_incorrect_acc: 0.008695984051326346
	train_positive_acc: 0.9931473885643759
	train_negative_acc: 0.7771681070219167
	train_correct_nonzero: 23306
	train_incorrect_nonzero: 20
	train_positive_nonzero: 7764
	train_negative_nonzero: 15562
val:
	val_positive_loss: 0.004104853607714176
	val_negative_loss: 0.000144129604450427
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.045586127787828445
	test_negative_loss: 0.0254452396184206
	test_positive_acc: 0.9892169458768949
	test_negative_acc: 0.9924061895467284
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.016749851405620575
	train_incorrect_loss: 11.32846450805664
	train_positive_loss: 2.0974056720733643
	train_negative_loss: 4.9377966206520796e-05
	train_correct_acc: 0.9963982563795669
	train_incorrect_acc: 0.007904586041963188
	train_positive_acc: 0.9936406635060586
	train_negative_acc: 0.7774774256794925
	train_correct_nonzero: 22031
	train_incorrect_nonzero: 18
	train_positive_nonzero: 6550
	train_negative_nonzero: 15499
val:
	val_positive_loss: 0.0034750187769532204
	val_negative_loss: 7.629740139236674e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04621105641126633
	test_negative_loss: 0.028697151690721512
	test_positive_acc: 0.9905467331109374
	test_negative_acc: 0.9924061895467284
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.01718362420797348
	train_incorrect_loss: 12.13762092590332
	train_positive_loss: 2.2472496032714844
	train_negative_loss: 2.614178265503142e-05
	train_correct_acc: 0.9965114622014056
	train_incorrect_acc: 0.008430009527594514
	train_positive_acc: 0.9938610932342392
	train_negative_acc: 0.7775709706998953
	train_correct_nonzero: 20088
	train_incorrect_nonzero: 16
	train_positive_nonzero: 4703
	train_negative_nonzero: 15401
val:
	val_positive_loss: 0.004611153621226549
	val_negative_loss: 4.3031497625634074e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05048735439777374
	test_negative_loss: 0.02845475822687149
	test_positive_acc: 0.9892169458768949
	test_negative_acc: 0.9924061895467284
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.40000772476196 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.25
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2346014976501465
	train_negative_loss: 2.2804691791534424
	train_positive_acc: 0.6736668358308302
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.1674460768699646
	train_incorrect_loss: 2.3498148918151855
	train_positive_loss: 0.578709602355957
	train_negative_loss: 0.21244023740291595
	train_correct_acc: 0.9660818194262459
	train_incorrect_acc: 0.04777981565859008
	train_positive_acc: 0.9756811855883389
	train_negative_acc: 0.7275527274909419
	train_correct_nonzero: 21435
	train_incorrect_nonzero: 747
	train_positive_nonzero: 8468
	train_negative_nonzero: 13714
val:
	val_positive_loss: 0.02834705263376236
	val_negative_loss: 0.03596700727939606
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.023639269173145294
	test_negative_loss: 0.056971874088048935
	test_positive_acc: 0.9948160460992908
	test_negative_acc: 0.9830916104287721
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03698832169175148
	train_incorrect_loss: 3.8197999000549316
	train_positive_loss: 0.7862376570701599
	train_negative_loss: 0.04583683982491493
	train_correct_acc: 0.9930481133109904
	train_incorrect_acc: 0.011390970514832685
	train_positive_acc: 0.991263360884653
	train_negative_acc: 0.750539239729608
	train_correct_nonzero: 23807
	train_incorrect_nonzero: 162
	train_positive_nonzero: 9236
	train_negative_nonzero: 14733
val:
	val_positive_loss: 0.004471548367291689
	val_negative_loss: 0.009708350524306297
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01585197076201439
	test_negative_loss: 0.034301429986953735
	test_positive_acc: 0.9938919346978556
	test_negative_acc: 0.9875166244017011
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02253745310008526
	train_incorrect_loss: 4.83286190032959
	train_positive_loss: 0.9808865785598755
	train_negative_loss: 0.021958597004413605
	train_correct_acc: 0.9947273086971992
	train_incorrect_acc: 0.01088657126976576
	train_positive_acc: 0.9926884097531169
	train_negative_acc: 0.7525676483008086
	train_correct_nonzero: 24796
	train_incorrect_nonzero: 64
	train_positive_nonzero: 9923
	train_negative_nonzero: 14937
val:
	val_positive_loss: 0.02066725865006447
	val_negative_loss: 0.0038027698174118996
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.018405089154839516
	test_negative_loss: 0.016444774344563484
	test_positive_acc: 0.9935033433866267
	test_negative_acc: 0.9936274023327722
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.016326317563652992
	train_incorrect_loss: 5.870598316192627
	train_positive_loss: 1.1844850778579712
	train_negative_loss: 0.012595159932971
	train_correct_acc: 0.9956857832521794
	train_incorrect_acc: 0.010045816205726027
	train_positive_acc: 0.9936304625348821
	train_negative_acc: 0.7524999515742488
	train_correct_nonzero: 24205
	train_incorrect_nonzero: 42
	train_positive_nonzero: 9244
	train_negative_nonzero: 15003
val:
	val_positive_loss: 0.016918785870075226
	val_negative_loss: 0.0031471853144466877
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.036898910999298096
	test_negative_loss: 0.01704985648393631
	test_positive_acc: 0.9871402263001754
	test_negative_acc: 0.9949083066919134
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.018669698387384415
	train_incorrect_loss: 7.499680995941162
	train_positive_loss: 1.515820026397705
	train_negative_loss: 0.004401243291795254
	train_correct_acc: 0.9945090907584254
	train_incorrect_acc: 0.011061248174347777
	train_positive_acc: 0.9912146695208368
	train_negative_acc: 0.7522677490885528
	train_correct_nonzero: 21642
	train_incorrect_nonzero: 14
	train_positive_nonzero: 6610
	train_negative_nonzero: 15046
val:
	val_positive_loss: 0.0002297874161740765
	val_negative_loss: 0.012814133428037167
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.008838922716677189
	test_negative_loss: 0.05643483251333237
	test_positive_acc: 0.9966909461152882
	test_negative_acc: 0.9831413563914095
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.019019924104213715
	train_incorrect_loss: 8.386609077453613
	train_positive_loss: 1.7040586471557617
	train_negative_loss: 0.01840026117861271
	train_correct_acc: 0.9964090770388211
	train_incorrect_acc: 0.013708009647533903
	train_positive_acc: 0.994934791229449
	train_negative_acc: 0.7530266709416568
	train_correct_nonzero: 21079
	train_incorrect_nonzero: 78
	train_positive_nonzero: 6583
	train_negative_nonzero: 14574
val:
	val_positive_loss: 0.00354191311635077
	val_negative_loss: 0.012104212306439877
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.013825224712491035
	test_negative_loss: 0.04044615477323532
	test_positive_acc: 0.9943316156309577
	test_negative_acc: 0.9914233960597509
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.01892920956015587
	train_incorrect_loss: 7.899375915527344
	train_positive_loss: 1.5912803411483765
	train_negative_loss: 0.018609141930937767
	train_correct_acc: 0.9965085190764084
	train_incorrect_acc: 0.014125792793095124
	train_positive_acc: 0.9947235798721733
	train_negative_acc: 0.7532506823150114
	train_correct_nonzero: 20123
	train_incorrect_nonzero: 65
	train_positive_nonzero: 5313
	train_negative_nonzero: 14875
val:
	val_positive_loss: 0.0035433131270110607
	val_negative_loss: 0.000650470145046711
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.017315957695245743
	test_negative_loss: 0.028896968811750412
	test_positive_acc: 0.9951419346978557
	test_negative_acc: 0.9914233960597509
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.014032568782567978
	train_incorrect_loss: 7.96898889541626
	train_positive_loss: 1.6089954376220703
	train_negative_loss: 0.005609380546957254
	train_correct_acc: 0.9963907057122454
	train_incorrect_acc: 0.018866817910327554
	train_positive_acc: 0.994524342950044
	train_negative_acc: 0.7540260465276674
	train_correct_nonzero: 22206
	train_incorrect_nonzero: 38
	train_positive_nonzero: 7175
	train_negative_nonzero: 15069
val:
	val_positive_loss: 0.006261252332478762
	val_negative_loss: 0.0028975459281355143
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03374721482396126
	test_negative_loss: 0.020196862518787384
	test_positive_acc: 0.9914535105282763
	test_negative_acc: 0.9949083066919134
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.014138552360236645
	train_incorrect_loss: 9.942277908325195
	train_positive_loss: 2.0042402744293213
	train_negative_loss: 0.0008192569366656244
	train_correct_acc: 0.9970766882421606
	train_incorrect_acc: 0.015548553542867292
	train_positive_acc: 0.9948933726656596
	train_negative_acc: 0.7545470818790461
	train_correct_nonzero: 18717
	train_incorrect_nonzero: 17
	train_positive_nonzero: 3696
	train_negative_nonzero: 15038
val:
	val_positive_loss: 0.022786565124988556
	val_negative_loss: 0.002391110872849822
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04685935378074646
	test_negative_loss: 0.020676255226135254
	test_positive_acc: 0.9874458506866821
	test_negative_acc: 0.9922755730368016
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.020373668521642685
	train_incorrect_loss: 10.059793472290039
	train_positive_loss: 2.0355539321899414
	train_negative_loss: 0.0004128639120608568
	train_correct_acc: 0.9957548065355933
	train_incorrect_acc: 0.011789223102464766
	train_positive_acc: 0.9926824061552414
	train_negative_acc: 0.7537198526442398
	train_correct_nonzero: 17156
	train_incorrect_nonzero: 9
	train_positive_nonzero: 2129
	train_negative_nonzero: 15036
val:
	val_positive_loss: 0.06794236600399017
	val_negative_loss: 0.0020852021407335997
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05835692957043648
	test_negative_loss: 0.024669213220477104
	test_positive_acc: 0.9837884432792747
	test_negative_acc: 0.9960085706927142
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.34099912643433 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.275
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2345149517059326
	train_negative_loss: 2.280454635620117
	train_positive_acc: 0.6773676136085398
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.1778976023197174
	train_incorrect_loss: 2.160609483718872
	train_positive_loss: 0.5729150176048279
	train_negative_loss: 0.24236632883548737
	train_correct_acc: 0.9609078669743596
	train_incorrect_acc: 0.06361340539092752
	train_positive_acc: 0.9766402021044355
	train_negative_acc: 0.698230632956822
	train_correct_nonzero: 19942
	train_incorrect_nonzero: 871
	train_positive_nonzero: 7418
	train_negative_nonzero: 13395
val:
	val_positive_loss: 0.02149060368537903
	val_negative_loss: 0.04368408024311066
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03305106610059738
	test_negative_loss: 0.05195567011833191
	test_positive_acc: 0.9903134371049651
	test_negative_acc: 0.9897942444204493
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03926153853535652
	train_incorrect_loss: 3.661525011062622
	train_positive_loss: 0.8083011507987976
	train_negative_loss: 0.05795980989933014
	train_correct_acc: 0.9931106649254122
	train_incorrect_acc: 0.013315868248175891
	train_positive_acc: 0.9921260483551445
	train_negative_acc: 0.7259878849038857
	train_correct_nonzero: 22047
	train_incorrect_nonzero: 198
	train_positive_nonzero: 7940
	train_negative_nonzero: 14305
val:
	val_positive_loss: 0.011951791122555733
	val_negative_loss: 0.009499755688011646
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.011996181681752205
	test_negative_loss: 0.03642135113477707
	test_positive_acc: 0.9965374373433584
	test_negative_acc: 0.9901571365164253
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.022081008180975914
	train_incorrect_loss: 4.652479648590088
	train_positive_loss: 1.0103981494903564
	train_negative_loss: 0.028301747515797615
	train_correct_acc: 0.9949679022933152
	train_incorrect_acc: 0.01360537765851796
	train_positive_acc: 0.9945190796194386
	train_negative_acc: 0.7271662529168275
	train_correct_nonzero: 25937
	train_incorrect_nonzero: 82
	train_positive_nonzero: 11598
	train_negative_nonzero: 14421
val:
	val_positive_loss: 0.0038722732570022345
	val_negative_loss: 0.025755997747182846
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.01097162626683712
	test_negative_loss: 0.039684370160102844
	test_positive_acc: 0.9945780788363622
	test_negative_acc: 0.9841333728456609
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.01992601715028286
	train_incorrect_loss: 4.426567554473877
	train_positive_loss: 0.9607323408126831
	train_negative_loss: 0.030153602361679077
	train_correct_acc: 0.9968187293773092
	train_incorrect_acc: 0.014555825336053558
	train_positive_acc: 0.996502842124763
	train_negative_acc: 0.7281582320669528
	train_correct_nonzero: 23544
	train_incorrect_nonzero: 93
	train_positive_nonzero: 9199
	train_negative_nonzero: 14438
val:
	val_positive_loss: 0.0008955552475526929
	val_negative_loss: 0.007352914661169052
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.010765118524432182
	test_negative_loss: 0.032694682478904724
	test_positive_acc: 0.996299342105263
	test_negative_acc: 0.9880759682937186
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.01710178330540657
	train_incorrect_loss: 6.417859077453613
	train_positive_loss: 1.3949568271636963
	train_negative_loss: 0.01430439855903387
	train_correct_acc: 0.9957317465053201
	train_incorrect_acc: 0.013475368483359342
	train_positive_acc: 0.9940665093033522
	train_negative_acc: 0.7275621563462173
	train_correct_nonzero: 22745
	train_incorrect_nonzero: 74
	train_positive_nonzero: 8365
	train_negative_nonzero: 14454
val:
	val_positive_loss: 0.0022542711813002825
	val_negative_loss: 0.009435968473553658
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.009713781997561455
	test_negative_loss: 0.03480496257543564
	test_positive_acc: 0.9953198229024096
	test_negative_acc: 0.9896270393490999
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.01599583402276039
	train_incorrect_loss: 5.806243896484375
	train_positive_loss: 1.2603799104690552
	train_negative_loss: 0.017298489809036255
	train_correct_acc: 0.9966282315150722
	train_incorrect_acc: 0.013393477749325745
	train_positive_acc: 0.9950249065060363
	train_negative_acc: 0.7287182034238225
	train_correct_nonzero: 23905
	train_incorrect_nonzero: 46
	train_positive_nonzero: 9443
	train_negative_nonzero: 14508
val:
	val_positive_loss: 0.011111066676676273
	val_negative_loss: 0.0011662456672638655
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.021679136902093887
	test_negative_loss: 0.02749556675553322
	test_positive_acc: 0.9940454434697856
	test_negative_acc: 0.9919944635915242
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.016797909513115883
	train_incorrect_loss: 6.007408142089844
	train_positive_loss: 1.3108175992965698
	train_negative_loss: 0.02320009283721447
	train_correct_acc: 0.9969481831766591
	train_incorrect_acc: 0.016627369963843022
	train_positive_acc: 0.9962545189496692
	train_negative_acc: 0.7286975161866883
	train_correct_nonzero: 22306
	train_incorrect_nonzero: 70
	train_positive_nonzero: 7897
	train_negative_nonzero: 14479
val:
	val_positive_loss: 0.011403935961425304
	val_negative_loss: 0.020585574209690094
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.011103829368948936
	test_negative_loss: 0.05316298454999924
	test_positive_acc: 0.9944726469875094
	test_negative_acc: 0.9810353923124124
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.011177566833794117
	train_incorrect_loss: 6.677454471588135
	train_positive_loss: 1.4487074613571167
	train_negative_loss: 0.0060716839507222176
	train_correct_acc: 0.9977524608657964
	train_incorrect_acc: 0.019759076342849107
	train_positive_acc: 0.9963273425700339
	train_negative_acc: 0.7305207970821113
	train_correct_nonzero: 23065
	train_incorrect_nonzero: 20
	train_positive_nonzero: 8521
	train_negative_nonzero: 14564
val:
	val_positive_loss: 0.0004003116628155112
	val_negative_loss: 0.0016249129548668861
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01786593534052372
	test_negative_loss: 0.035244010388851166
	test_positive_acc: 0.9925573482316903
	test_negative_acc: 0.9874677905424729
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.011330229230225086
	train_incorrect_loss: 9.732192993164062
	train_positive_loss: 2.1124887466430664
	train_negative_loss: 0.0008369646966457367
	train_correct_acc: 0.9977862958172489
	train_incorrect_acc: 0.01820746073890303
	train_positive_acc: 0.996207699497802
	train_negative_acc: 0.7306844346066149
	train_correct_nonzero: 19273
	train_incorrect_nonzero: 21
	train_positive_nonzero: 4743
	train_negative_nonzero: 14551
val:
	val_positive_loss: 0.011003026738762856
	val_negative_loss: 0.005345318000763655
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02987390011548996
	test_negative_loss: 0.028620902448892593
	test_positive_acc: 0.986729751235445
	test_negative_acc: 0.9919944635915242
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.014620926231145859
	train_incorrect_loss: 8.20647144317627
	train_positive_loss: 1.78402841091156
	train_negative_loss: 0.0011408916907384992
	train_correct_acc: 0.9963365300089102
	train_incorrect_acc: 0.012798381042782154
	train_positive_acc: 0.993691499628599
	train_negative_acc: 0.7294132051344192
	train_correct_nonzero: 18904
	train_incorrect_nonzero: 3
	train_positive_nonzero: 4354
	train_negative_nonzero: 14553
val:
	val_positive_loss: 0.051282577216625214
	val_negative_loss: 0.00022448367963079363
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.07025732100009918
	test_negative_loss: 0.03132482245564461
	test_positive_acc: 0.9842778281585219
	test_negative_acc: 0.9906426342955534
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.06963539123535 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.3
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2344160079956055
	train_negative_loss: 2.2803797721862793
	train_positive_acc: 0.6797156146726531
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.1799125075340271
	train_incorrect_loss: 2.2208092212677
	train_positive_loss: 0.6184866428375244
	train_negative_loss: 0.2420140653848648
	train_correct_acc: 0.962865332591184
	train_incorrect_acc: 0.05907008008698274
	train_positive_acc: 0.9760214092414238
	train_negative_acc: 0.6798070863816422
	train_correct_nonzero: 20681
	train_incorrect_nonzero: 906
	train_positive_nonzero: 8518
	train_negative_nonzero: 13069
val:
	val_positive_loss: 0.04100770503282547
	val_negative_loss: 0.04288366809487343
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04512709751725197
	test_negative_loss: 0.053615815937519073
	test_positive_acc: 0.989394124935653
	test_negative_acc: 0.9928598830049576
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.04060385748744011
	train_incorrect_loss: 3.547332763671875
	train_positive_loss: 0.8336701989173889
	train_negative_loss: 0.06362006068229675
	train_correct_acc: 0.9926336170302505
	train_incorrect_acc: 0.01602102366205787
	train_positive_acc: 0.9929631196966824
	train_negative_acc: 0.7007237027838054
	train_correct_nonzero: 21960
	train_incorrect_nonzero: 214
	train_positive_nonzero: 8408
	train_negative_nonzero: 13766
val:
	val_positive_loss: 0.007118335925042629
	val_negative_loss: 0.013553268276154995
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0254543274641037
	test_negative_loss: 0.031654223799705505
	test_positive_acc: 0.9918813195771029
	test_negative_acc: 0.9884713725582831
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.025463763624429703
	train_incorrect_loss: 4.600211143493652
	train_positive_loss: 1.0742573738098145
	train_negative_loss: 0.03334527090191841
	train_correct_acc: 0.9946592998742051
	train_incorrect_acc: 0.012633386196768761
	train_positive_acc: 0.9934315598628138
	train_negative_acc: 0.7026397758239313
	train_correct_nonzero: 22303
	train_incorrect_nonzero: 99
	train_positive_nonzero: 8508
	train_negative_nonzero: 13894
val:
	val_positive_loss: 0.0001061177026713267
	val_negative_loss: 0.023863110691308975
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0034768893383443356
	test_negative_loss: 0.08590133488178253
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9777294725386692
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.018798070028424263
	train_incorrect_loss: 5.228362083435059
	train_positive_loss: 1.2139904499053955
	train_negative_loss: 0.02116909623146057
	train_correct_acc: 0.9956639693303763
	train_incorrect_acc: 0.010980486590899414
	train_positive_acc: 0.9938936073221719
	train_negative_acc: 0.7033592192275485
	train_correct_nonzero: 20130
	train_incorrect_nonzero: 78
	train_positive_nonzero: 6207
	train_negative_nonzero: 14001
val:
	val_positive_loss: 4.2904932342935354e-05
	val_negative_loss: 0.03232038393616676
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.002155829453840852
	test_negative_loss: 0.09629465639591217
	test_positive_acc: 1.0
	test_negative_acc: 0.9792157623702382
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.019014067947864532
	train_incorrect_loss: 7.02587890625
	train_positive_loss: 1.6365412473678589
	train_negative_loss: 0.008767718449234962
	train_correct_acc: 0.9953473016030797
	train_incorrect_acc: 0.007082944577347115
	train_positive_acc: 0.9927990420012593
	train_negative_acc: 0.701831634239597
	train_correct_nonzero: 18924
	train_incorrect_nonzero: 20
	train_positive_nonzero: 4918
	train_negative_nonzero: 14026
val:
	val_positive_loss: 0.007442996837198734
	val_negative_loss: 0.00035240568104200065
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.045810990035533905
	test_negative_loss: 0.018948640674352646
	test_positive_acc: 0.9865945406029817
	test_negative_acc: 0.9934548183198204
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.01955171674489975
	train_incorrect_loss: 10.535141944885254
	train_positive_loss: 2.454486131668091
	train_negative_loss: 0.00016649271128699183
	train_correct_acc: 0.9957863180753135
	train_incorrect_acc: 0.007479969563768512
	train_positive_acc: 0.9928348075002545
	train_negative_acc: 0.7029992422290167
	train_correct_nonzero: 17250
	train_incorrect_nonzero: 5
	train_positive_nonzero: 3208
	train_negative_nonzero: 14047
val:
	val_positive_loss: 9.191932622343302e-05
	val_negative_loss: 0.0003387460019439459
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02423633448779583
	test_negative_loss: 0.043747417628765106
	test_positive_acc: 0.9916432243390076
	test_negative_acc: 0.9892023883598433
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.01962955854833126
	train_incorrect_loss: 11.86047077178955
	train_positive_loss: 2.7529304027557373
	train_negative_loss: 7.471389108104631e-05
	train_correct_acc: 0.996548560560277
	train_incorrect_acc: 0.007134918637701927
	train_positive_acc: 0.9941191505577993
	train_negative_acc: 0.7026309931853338
	train_correct_nonzero: 14624
	train_incorrect_nonzero: 3
	train_positive_nonzero: 764
	train_negative_nonzero: 13863
val:
	val_positive_loss: 0.0008070556214079261
	val_negative_loss: 5.34912760485895e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05411151796579361
	test_negative_loss: 0.02326987311244011
	test_positive_acc: 0.9879243278370242
	test_negative_acc: 0.9934548183198204
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.021678106859326363
	train_incorrect_loss: 12.764541625976562
	train_positive_loss: 2.9668989181518555
	train_negative_loss: 3.13357450067997e-05
	train_correct_acc: 0.9963660160536569
	train_incorrect_acc: 0.006993881220755984
	train_positive_acc: 0.9938060280836917
	train_negative_acc: 0.7025505951160556
	train_correct_nonzero: 14081
	train_incorrect_nonzero: 1
	train_positive_nonzero: 674
	train_negative_nonzero: 13408
val:
	val_positive_loss: 0.0005474442732520401
	val_negative_loss: 5.028157465858385e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05135899782180786
	test_negative_loss: 0.027028249576687813
	test_positive_acc: 0.9879243278370242
	test_negative_acc: 0.9934548183198204
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.023178376257419586
	train_incorrect_loss: 13.504817008972168
	train_positive_loss: 3.139113187789917
	train_negative_loss: 1.7078686141758226e-05
	train_correct_acc: 0.9964224945377836
	train_incorrect_acc: 0.0067533744385539045
	train_positive_acc: 0.9938896013852032
	train_negative_acc: 0.7030403639646922
	train_correct_nonzero: 13469
	train_incorrect_nonzero: 3
	train_positive_nonzero: 716
	train_negative_nonzero: 12756
val:
	val_positive_loss: 0.0005523869767785072
	val_negative_loss: 3.257966454839334e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05502361059188843
	test_negative_loss: 0.027357958257198334
	test_positive_acc: 0.9879243278370242
	test_negative_acc: 0.9934548183198204
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.02357863448560238
	train_incorrect_loss: 14.013118743896484
	train_positive_loss: 3.2553303241729736
	train_negative_loss: 1.2955625606991816e-05
	train_correct_acc: 0.9967142563448342
	train_incorrect_acc: 0.006458843683023944
	train_positive_acc: 0.994403133100049
	train_negative_acc: 0.7029121762945394
	train_correct_nonzero: 12582
	train_incorrect_nonzero: 2
	train_positive_nonzero: 589
	train_negative_nonzero: 11995
val:
	val_positive_loss: 0.00034248546580784023
	val_negative_loss: 2.8463638955145143e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0476423054933548
	test_negative_loss: 0.03275682404637337
	test_positive_acc: 0.9879243278370242
	test_negative_acc: 0.9913286033398319
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 91.92438650131226 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.325
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2343177795410156
	train_negative_loss: 2.2804057598114014
	train_positive_acc: 0.6832916175188505
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.18428073823451996
	train_incorrect_loss: 2.234013319015503
	train_positive_loss: 0.6572455763816833
	train_negative_loss: 0.24490775167942047
	train_correct_acc: 0.952855275653513
	train_incorrect_acc: 0.07584440088336492
	train_positive_acc: 0.969803672401777
	train_negative_acc: 0.6525481520878466
	train_correct_nonzero: 19618
	train_incorrect_nonzero: 944
	train_positive_nonzero: 7954
	train_negative_nonzero: 12608
val:
	val_positive_loss: 0.015059718862175941
	val_negative_loss: 0.058583155274391174
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.019697239622473717
	test_negative_loss: 0.07920365035533905
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9812761420641123
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.04586942866444588
	train_incorrect_loss: 3.339750051498413
	train_positive_loss: 0.8380473852157593
	train_negative_loss: 0.07520702481269836
	train_correct_acc: 0.9933132555926889
	train_incorrect_acc: 0.012938106452306046
	train_positive_acc: 0.9918990898056481
	train_negative_acc: 0.6777261195363979
	train_correct_nonzero: 20277
	train_incorrect_nonzero: 264
	train_positive_nonzero: 7223
	train_negative_nonzero: 13318
val:
	val_positive_loss: 0.0021882399450987577
	val_negative_loss: 0.04168105125427246
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.012070372700691223
	test_negative_loss: 0.06583012640476227
	test_positive_acc: 0.9967281153094601
	test_negative_acc: 0.9842639893555878
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.0319100059568882
	train_incorrect_loss: 3.967752695083618
	train_positive_loss: 0.984373927116394
	train_negative_loss: 0.049321942031383514
	train_correct_acc: 0.9945740760138915
	train_incorrect_acc: 0.011580608620437706
	train_positive_acc: 0.993473181154282
	train_negative_acc: 0.6775537607865616
	train_correct_nonzero: 21601
	train_incorrect_nonzero: 180
	train_positive_nonzero: 8388
	train_negative_nonzero: 13393
val:
	val_positive_loss: 0.003938739188015461
	val_negative_loss: 0.051481299102306366
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.008659245446324348
	test_negative_loss: 0.07075941562652588
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9765341948558981
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.02210594154894352
	train_incorrect_loss: 4.639098644256592
	train_positive_loss: 1.1430912017822266
	train_negative_loss: 0.0317024365067482
	train_correct_acc: 0.9956229809706806
	train_incorrect_acc: 0.016607555983452454
	train_positive_acc: 0.9953848873600438
	train_negative_acc: 0.6789992608266925
	train_correct_nonzero: 22344
	train_incorrect_nonzero: 112
	train_positive_nonzero: 8968
	train_negative_nonzero: 13488
val:
	val_positive_loss: 0.021202344447374344
	val_negative_loss: 0.018743429332971573
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01352270320057869
	test_negative_loss: 0.05318692326545715
	test_positive_acc: 0.9944611068111455
	test_negative_acc: 0.9793331364437823
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.015719419345259666
	train_incorrect_loss: 5.461121559143066
	train_positive_loss: 1.3454738855361938
	train_negative_loss: 0.016087761148810387
	train_correct_acc: 0.9966286462300109
	train_incorrect_acc: 0.020104256642589267
	train_positive_acc: 0.9955933204296091
	train_negative_acc: 0.6806768499055295
	train_correct_nonzero: 23206
	train_incorrect_nonzero: 58
	train_positive_nonzero: 9716
	train_negative_nonzero: 13548
val:
	val_positive_loss: 0.0032301940955221653
	val_negative_loss: 0.0034903427585959435
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.019856121391057968
	test_negative_loss: 0.021914042532444
	test_positive_acc: 0.9894867175282456
	test_negative_acc: 0.9938596779188213
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.01872505620121956
	train_incorrect_loss: 6.573022842407227
	train_positive_loss: 1.625485897064209
	train_negative_loss: 0.019268285483121872
	train_correct_acc: 0.9964986732836432
	train_incorrect_acc: 0.01921330917574828
	train_positive_acc: 0.994786287379398
	train_negative_acc: 0.6814451866904363
	train_correct_nonzero: 18572
	train_incorrect_nonzero: 154
	train_positive_nonzero: 5298
	train_negative_nonzero: 13428
val:
	val_positive_loss: 0.09600609540939331
	val_negative_loss: 0.001690814970061183
	val_positive_acc: 0.9661622530474989
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.06096974387764931
	test_negative_loss: 0.00544670270755887
	test_positive_acc: 0.9784593190178549
	test_negative_acc: 0.9987980769230769
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.021347898989915848
	train_incorrect_loss: 6.886358261108398
	train_positive_loss: 1.7016563415527344
	train_negative_loss: 0.007314927410334349
	train_correct_acc: 0.9941043029852303
	train_incorrect_acc: 0.010425793985084614
	train_positive_acc: 0.9905103042084725
	train_negative_acc: 0.6785914466587724
	train_correct_nonzero: 20610
	train_incorrect_nonzero: 11
	train_positive_nonzero: 7060
	train_negative_nonzero: 13561
val:
	val_positive_loss: 0.04133004695177078
	val_negative_loss: 0.0004919127095490694
	val_positive_acc: 0.9743589743589743
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04462161660194397
	test_negative_loss: 0.022117212414741516
	test_positive_acc: 0.9881008744483235
	test_negative_acc: 0.9939613369949437
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.020808152854442596
	train_incorrect_loss: 9.703442573547363
	train_positive_loss: 2.4019217491149902
	train_negative_loss: 0.00019931035058107227
	train_correct_acc: 0.9948135423569598
	train_incorrect_acc: 0.0075650023248888506
	train_positive_acc: 0.9912311565045222
	train_negative_acc: 0.6780638339059375
	train_correct_nonzero: 18931
	train_incorrect_nonzero: 10
	train_positive_nonzero: 5381
	train_negative_nonzero: 13560
val:
	val_positive_loss: 0.01639305241405964
	val_negative_loss: 0.0004966725246049464
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04129987955093384
	test_negative_loss: 0.03763510659337044
	test_positive_acc: 0.9905467331109374
	test_negative_acc: 0.9927820917119248
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.02524462901055813
	train_incorrect_loss: 10.979095458984375
	train_positive_loss: 2.7182698249816895
	train_negative_loss: 7.313437527045608e-05
	train_correct_acc: 0.9944799234326216
	train_incorrect_acc: 0.0071232716737560774
	train_positive_acc: 0.9908793566726373
	train_negative_acc: 0.6782355775507597
	train_correct_nonzero: 17670
	train_incorrect_nonzero: 9
	train_positive_nonzero: 4125
	train_negative_nonzero: 13554
val:
	val_positive_loss: 0.07113201916217804
	val_negative_loss: 8.690498361829668e-05
	val_positive_acc: 0.9743589743589743
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.06565830111503601
	test_negative_loss: 0.02422953024506569
	test_positive_acc: 0.9881008744483235
	test_negative_acc: 0.9949083066919134
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.028610678389668465
	train_incorrect_loss: 11.79427433013916
	train_positive_loss: 2.918393135070801
	train_negative_loss: 3.309478051960468e-05
	train_correct_acc: 0.9936151613598371
	train_incorrect_acc: 0.0072750011245675435
	train_positive_acc: 0.9893500372581713
	train_negative_acc: 0.6784534105645168
	train_correct_nonzero: 18480
	train_incorrect_nonzero: 10
	train_positive_nonzero: 4984
	train_negative_nonzero: 13506
val:
	val_positive_loss: 0.06369868665933609
	val_negative_loss: 6.586463132407516e-05
	val_positive_acc: 0.9743589743589743
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.06816968321800232
	test_negative_loss: 0.02551809698343277
	test_positive_acc: 0.9881008744483235
	test_negative_acc: 0.9949083066919134
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.03721022605896 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.35
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.234222412109375
	train_negative_loss: 2.280397415161133
	train_positive_acc: 0.6870120012317508
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.18410269916057587
	train_incorrect_loss: 2.1894655227661133
	train_positive_loss: 0.6749727129936218
	train_negative_loss: 0.24685169756412506
	train_correct_acc: 0.9562322332406431
	train_incorrect_acc: 0.06683612491690057
	train_positive_acc: 0.9691597040991021
	train_negative_acc: 0.6326115968294682
	train_correct_nonzero: 19828
	train_incorrect_nonzero: 1003
	train_positive_nonzero: 8496
	train_negative_nonzero: 12335
val:
	val_positive_loss: 0.03529838100075722
	val_negative_loss: 0.03835710138082504
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.044082991778850555
	test_negative_loss: 0.04748965799808502
	test_positive_acc: 0.9865153262841779
	test_negative_acc: 0.9902059703756535
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03517356887459755
	train_incorrect_loss: 4.019471168518066
	train_positive_loss: 1.0605374574661255
	train_negative_loss: 0.042902667075395584
	train_correct_acc: 0.9920002052914567
	train_incorrect_acc: 0.012489469380578025
	train_positive_acc: 0.990609638270664
	train_negative_acc: 0.6522775950624341
	train_correct_nonzero: 20530
	train_incorrect_nonzero: 141
	train_positive_nonzero: 7706
	train_negative_nonzero: 12965
val:
	val_positive_loss: 0.0009198997868224978
	val_negative_loss: 0.03495828062295914
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.003750629024580121
	test_negative_loss: 0.09477081149816513
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9697386773862882
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.03874938189983368
	train_incorrect_loss: 4.26214075088501
	train_positive_loss: 1.12173593044281
	train_negative_loss: 0.060130126774311066
	train_correct_acc: 0.9938104622426747
	train_incorrect_acc: 0.015035839568622733
	train_positive_acc: 0.9940029756564123
	train_negative_acc: 0.6523626476434212
	train_correct_nonzero: 22778
	train_incorrect_nonzero: 208
	train_positive_nonzero: 10138
	train_negative_nonzero: 12848
val:
	val_positive_loss: 0.1063486635684967
	val_negative_loss: 0.058530136942863464
	val_positive_acc: 0.9579655317360235
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.09052470326423645
	test_negative_loss: 0.06723552942276001
	test_positive_acc: 0.9781724872055994
	test_negative_acc: 0.997344588550984
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.021617909893393517
	train_incorrect_loss: 4.7973761558532715
	train_positive_loss: 1.2498794794082642
	train_negative_loss: 0.024102870374917984
	train_correct_acc: 0.9954558060090299
	train_incorrect_acc: 0.015467559012639475
	train_positive_acc: 0.9940786611195899
	train_negative_acc: 0.6548503245319018
	train_correct_nonzero: 21118
	train_incorrect_nonzero: 95
	train_positive_nonzero: 8197
	train_negative_nonzero: 13016
val:
	val_positive_loss: 0.014900803565979004
	val_negative_loss: 0.013923656195402145
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02285950258374214
	test_negative_loss: 0.03314400091767311
	test_positive_acc: 0.9855521919941437
	test_negative_acc: 0.9901493580568129
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.020585952326655388
	train_incorrect_loss: 5.902721405029297
	train_positive_loss: 1.5429798364639282
	train_negative_loss: 0.017522241920232773
	train_correct_acc: 0.993963273128758
	train_incorrect_acc: 0.016920117033886718
	train_positive_acc: 0.9924165958244989
	train_negative_acc: 0.6540207672300842
	train_correct_nonzero: 19377
	train_incorrect_nonzero: 61
	train_positive_nonzero: 6413
	train_negative_nonzero: 13025
val:
	val_positive_loss: 0.0008676006109453738
	val_negative_loss: 0.0421011820435524
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.0018689053831622005
	test_negative_loss: 0.10403226315975189
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9697121194704936
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.02186756208539009
	train_incorrect_loss: 6.158990859985352
	train_positive_loss: 1.6174620389938354
	train_negative_loss: 0.022908149287104607
	train_correct_acc: 0.9950106657985889
	train_incorrect_acc: 0.019271261044797216
	train_positive_acc: 0.992976722074586
	train_negative_acc: 0.6565126117067109
	train_correct_nonzero: 18666
	train_incorrect_nonzero: 69
	train_positive_nonzero: 5732
	train_negative_nonzero: 13003
val:
	val_positive_loss: 0.029193755239248276
	val_negative_loss: 0.0009074374102056026
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04257453978061676
	test_negative_loss: 0.014492304064333439
	test_positive_acc: 0.9873417963981799
	test_negative_acc: 0.9934479519636172
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.019429607316851616
	train_incorrect_loss: 9.29875659942627
	train_positive_loss: 2.424039363861084
	train_negative_loss: 0.00048279829206876457
	train_correct_acc: 0.9951675104190394
	train_incorrect_acc: 0.007154104424221633
	train_positive_acc: 0.9920497503614416
	train_negative_acc: 0.6531638248597096
	train_correct_nonzero: 18168
	train_incorrect_nonzero: 2
	train_positive_nonzero: 5119
	train_negative_nonzero: 13051
val:
	val_positive_loss: 0.03896820545196533
	val_negative_loss: 0.0004418747848831117
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03694116324186325
	test_negative_loss: 0.019042786210775375
	test_positive_acc: 0.991913689539152
	test_negative_acc: 0.9924061895467284
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.021457448601722717
	train_incorrect_loss: 10.713626861572266
	train_positive_loss: 2.797543525695801
	train_negative_loss: 0.00011130840721307322
	train_correct_acc: 0.9952256733771089
	train_incorrect_acc: 0.005994159978240025
	train_positive_acc: 0.9921260257282057
	train_negative_acc: 0.6526090806510866
	train_correct_nonzero: 19839
	train_incorrect_nonzero: 5
	train_positive_nonzero: 6807
	train_negative_nonzero: 13037
val:
	val_positive_loss: 0.032643575221300125
	val_negative_loss: 0.00036093301605433226
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03458929806947708
	test_negative_loss: 0.02384401112794876
	test_positive_acc: 0.991913689539152
	test_negative_acc: 0.9924061895467284
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.02247433178126812
	train_incorrect_loss: 11.656744003295898
	train_positive_loss: 3.043430805206299
	train_negative_loss: 5.767906623077579e-05
	train_correct_acc: 0.9952630621566841
	train_incorrect_acc: 0.006782726712623334
	train_positive_acc: 0.992186014341708
	train_negative_acc: 0.6530407451662567
	train_correct_nonzero: 16153
	train_incorrect_nonzero: 4
	train_positive_nonzero: 3228
	train_negative_nonzero: 12929
val:
	val_positive_loss: 0.04176117852330208
	val_negative_loss: 0.00019976447219960392
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03901525214314461
	test_negative_loss: 0.02196907065808773
	test_positive_acc: 0.9908171983110818
	test_negative_acc: 0.9933531592436982
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.02566768229007721
	train_incorrect_loss: 12.39404010772705
	train_positive_loss: 3.2334542274475098
	train_negative_loss: 3.126671799691394e-05
	train_correct_acc: 0.9949981712875664
	train_incorrect_acc: 0.0054188381563828394
	train_positive_acc: 0.9918192253868093
	train_negative_acc: 0.6529817482450349
	train_correct_nonzero: 17145
	train_incorrect_nonzero: 5
	train_positive_nonzero: 4444
	train_negative_nonzero: 12706
val:
	val_positive_loss: 0.05197383090853691
	val_negative_loss: 9.226909605786204e-05
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.046407584100961685
	test_negative_loss: 0.01867881417274475
	test_positive_acc: 0.9882854880001162
	test_negative_acc: 0.9948066476157911
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.26363897323608 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.375
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2341129779815674
	train_negative_loss: 2.2804253101348877
	train_positive_acc: 0.6900495560435597
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.1928946077823639
	train_incorrect_loss: 2.325334310531616
	train_positive_loss: 0.7480568289756775
	train_negative_loss: 0.2522132694721222
	train_correct_acc: 0.9442772415391016
	train_incorrect_acc: 0.08528823944919005
	train_positive_acc: 0.9628646774991372
	train_negative_acc: 0.6051963194681788
	train_correct_nonzero: 18850
	train_incorrect_nonzero: 1002
	train_positive_nonzero: 7912
	train_negative_nonzero: 11940
val:
	val_positive_loss: 0.021613970398902893
	val_negative_loss: 0.06657828390598297
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.030472492799162865
	test_negative_loss: 0.08476904034614563
	test_positive_acc: 0.9901358690017004
	test_negative_acc: 0.9872921272752643
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.0445687472820282
	train_incorrect_loss: 3.459878444671631
	train_positive_loss: 0.9584592580795288
	train_negative_loss: 0.07113499939441681
	train_correct_acc: 0.9928757343519115
	train_incorrect_acc: 0.014254861791468516
	train_positive_acc: 0.992565025814525
	train_negative_acc: 0.6277205016640847
	train_correct_nonzero: 20257
	train_incorrect_nonzero: 229
	train_positive_nonzero: 8046
	train_negative_nonzero: 12440
val:
	val_positive_loss: 0.0263836532831192
	val_negative_loss: 0.16749536991119385
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02898571640253067
	test_negative_loss: 0.1820051521062851
	test_positive_acc: 0.9886281935631039
	test_negative_acc: 0.9907543601135225
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02869553677737713
	train_incorrect_loss: 4.465636253356934
	train_positive_loss: 1.2257933616638184
	train_negative_loss: 0.03924514725804329
	train_correct_acc: 0.9939825521606588
	train_incorrect_acc: 0.01501647422462141
	train_positive_acc: 0.993479504210749
	train_negative_acc: 0.6290368980236135
	train_correct_nonzero: 23261
	train_incorrect_nonzero: 139
	train_positive_nonzero: 10926
	train_negative_nonzero: 12474
val:
	val_positive_loss: 7.794583507347852e-05
	val_negative_loss: 0.040142692625522614
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.0007953372551128268
	test_negative_loss: 0.15121057629585266
	test_positive_acc: 1.0
	test_negative_acc: 0.9537114991265556
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.031012076884508133
	train_incorrect_loss: 4.53465461730957
	train_positive_loss: 1.2405680418014526
	train_negative_loss: 0.04845057427883148
	train_correct_acc: 0.9950081152012005
	train_incorrect_acc: 0.01254775116642379
	train_positive_acc: 0.9937947679253198
	train_negative_acc: 0.6290136813882052
	train_correct_nonzero: 18046
	train_incorrect_nonzero: 194
	train_positive_nonzero: 5773
	train_negative_nonzero: 12467
val:
	val_positive_loss: 0.0360318087041378
	val_negative_loss: 0.0613187775015831
	val_positive_acc: 0.9743589743589743
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02850421331822872
	test_negative_loss: 0.06850673258304596
	test_positive_acc: 0.9870002164355893
	test_negative_acc: 0.9909246558442399
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.02044925093650818
	train_incorrect_loss: 5.642232894897461
	train_positive_loss: 1.553403615951538
	train_negative_loss: 0.016933633014559746
	train_correct_acc: 0.9951133030802791
	train_incorrect_acc: 0.009941558903067
	train_positive_acc: 0.992927908418475
	train_negative_acc: 0.6284807409828816
	train_correct_nonzero: 18540
	train_incorrect_nonzero: 71
	train_positive_nonzero: 6067
	train_negative_nonzero: 12544
val:
	val_positive_loss: 0.008331659249961376
	val_negative_loss: 0.014399456791579723
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.019247204065322876
	test_negative_loss: 0.058677591383457184
	test_positive_acc: 0.9914467851810377
	test_negative_acc: 0.9852675713713981
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.02758517488837242
	train_incorrect_loss: 5.474935054779053
	train_positive_loss: 1.503902554512024
	train_negative_loss: 0.02942574769258499
	train_correct_acc: 0.9943918814533603
	train_incorrect_acc: 0.010817941564810762
	train_positive_acc: 0.991896516095661
	train_negative_acc: 0.6290440484240357
	train_correct_nonzero: 17746
	train_incorrect_nonzero: 86
	train_positive_nonzero: 5295
	train_negative_nonzero: 12537
val:
	val_positive_loss: 0.013136306777596474
	val_negative_loss: 0.012209524400532246
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.018049675971269608
	test_negative_loss: 0.03618031367659569
	test_positive_acc: 0.9927015844131606
	test_negative_acc: 0.9889281452707691
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.02082538791000843
	train_incorrect_loss: 6.397221088409424
	train_positive_loss: 1.7604186534881592
	train_negative_loss: 0.004890728276222944
	train_correct_acc: 0.9941055080716015
	train_incorrect_acc: 0.011876271126031701
	train_positive_acc: 0.990905163397233
	train_negative_acc: 0.629635691268942
	train_correct_nonzero: 16287
	train_incorrect_nonzero: 14
	train_positive_nonzero: 3738
	train_negative_nonzero: 12563
val:
	val_positive_loss: 0.06463100761175156
	val_negative_loss: 0.00678734015673399
	val_positive_acc: 0.9743589743589743
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02918339893221855
	test_negative_loss: 0.03242066130042076
	test_positive_acc: 0.9838760255653878
	test_negative_acc: 0.9873899992494402
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.01582726649940014
	train_incorrect_loss: 6.77194881439209
	train_positive_loss: 1.8589423894882202
	train_negative_loss: 0.005062249954789877
	train_correct_acc: 0.9957795142939754
	train_incorrect_acc: 0.012078526177911414
	train_positive_acc: 0.9940246643212947
	train_negative_acc: 0.6291013274182332
	train_correct_nonzero: 17176
	train_incorrect_nonzero: 11
	train_positive_nonzero: 4630
	train_negative_nonzero: 12557
val:
	val_positive_loss: 0.0571608804166317
	val_negative_loss: 0.010981033556163311
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.013691084459424019
	test_negative_loss: 0.04145502299070358
	test_positive_acc: 0.9946194148151982
	test_negative_acc: 0.9885730316344055
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.012460644356906414
	train_incorrect_loss: 6.6370954513549805
	train_positive_loss: 1.819687843322754
	train_negative_loss: 0.006082864012569189
	train_correct_acc: 0.9968128131489745
	train_incorrect_acc: 0.014142023341746034
	train_positive_acc: 0.9953934401892931
	train_negative_acc: 0.6304994694908141
	train_correct_nonzero: 17661
	train_incorrect_nonzero: 43
	train_positive_nonzero: 5137
	train_negative_nonzero: 12567
val:
	val_positive_loss: 0.033355895429849625
	val_negative_loss: 0.005740144290030003
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02051350474357605
	test_negative_loss: 0.03164452314376831
	test_positive_acc: 0.9916676037716319
	test_negative_acc: 0.9878017252046444
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.011245766654610634
	train_incorrect_loss: 5.920653820037842
	train_positive_loss: 1.6215968132019043
	train_negative_loss: 0.007190200034528971
	train_correct_acc: 0.9972011522168803
	train_incorrect_acc: 0.019702513436982413
	train_positive_acc: 0.9961626449074893
	train_negative_acc: 0.6331216446886396
	train_correct_nonzero: 20029
	train_incorrect_nonzero: 43
	train_positive_nonzero: 7495
	train_negative_nonzero: 12577
val:
	val_positive_loss: 0.004997371695935726
	val_negative_loss: 0.004382261540740728
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.023965049535036087
	test_negative_loss: 0.04696688428521156
	test_positive_acc: 0.9883159318470494
	test_negative_acc: 0.9849575044923161
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.70876240730286 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.4
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2340149879455566
	train_negative_loss: 2.280461311340332
	train_positive_acc: 0.6933570569302053
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.19630606472492218
	train_incorrect_loss: 2.258723735809326
	train_positive_loss: 0.7579310536384583
	train_negative_loss: 0.25943106412887573
	train_correct_acc: 0.9522065443293598
	train_incorrect_acc: 0.08110896405735547
	train_positive_acc: 0.9687132984964034
	train_negative_acc: 0.5885854094416039
	train_correct_nonzero: 18824
	train_incorrect_nonzero: 1032
	train_positive_nonzero: 8260
	train_negative_nonzero: 11596
val:
	val_positive_loss: 0.0935211330652237
	val_negative_loss: 0.08371378481388092
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.08998610079288483
	test_negative_loss: 0.09143686294555664
	test_positive_acc: 0.9835565404306552
	test_negative_acc: 0.997344588550984
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03636422008275986
	train_incorrect_loss: 3.876819133758545
	train_positive_loss: 1.1240345239639282
	train_negative_loss: 0.049207653850317
	train_correct_acc: 0.9927791140319127
	train_incorrect_acc: 0.015178543088405666
	train_positive_acc: 0.9916628864169275
	train_negative_acc: 0.6040247661357961
	train_correct_nonzero: 20078
	train_incorrect_nonzero: 166
	train_positive_nonzero: 8256
	train_negative_nonzero: 11988
val:
	val_positive_loss: 0.0005281047197058797
	val_negative_loss: 0.020961955189704895
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.00919386651366949
	test_negative_loss: 0.06364602595567703
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9781053747038656
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.036967091262340546
	train_incorrect_loss: 4.166068077087402
	train_positive_loss: 1.2076197862625122
	train_negative_loss: 0.04953231289982796
	train_correct_acc: 0.9933969473880252
	train_incorrect_acc: 0.014773563545418806
	train_positive_acc: 0.991793347012167
	train_negative_acc: 0.6053235587552074
	train_correct_nonzero: 22280
	train_incorrect_nonzero: 200
	train_positive_nonzero: 10513
	train_negative_nonzero: 11967
val:
	val_positive_loss: 0.0005896724760532379
	val_negative_loss: 0.07802034169435501
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.00396036496385932
	test_negative_loss: 0.13888750970363617
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9570175613356224
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.015457830391824245
	train_incorrect_loss: 5.714840888977051
	train_positive_loss: 1.6393707990646362
	train_negative_loss: 0.01685066893696785
	train_correct_acc: 0.996516249423698
	train_incorrect_acc: 0.012149982801309642
	train_positive_acc: 0.995836043117453
	train_negative_acc: 0.6049188957946725
	train_correct_nonzero: 22379
	train_incorrect_nonzero: 63
	train_positive_nonzero: 10384
	train_negative_nonzero: 12058
val:
	val_positive_loss: 0.0022551207803189754
	val_negative_loss: 0.006658608093857765
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.015009623020887375
	test_negative_loss: 0.0344788134098053
	test_positive_acc: 0.9937195548712205
	test_negative_acc: 0.9867738849603851
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.01624130830168724
	train_incorrect_loss: 7.4665727615356445
	train_positive_loss: 2.139633893966675
	train_negative_loss: 0.004546221811324358
	train_correct_acc: 0.9955120642860992
	train_incorrect_acc: 0.010353764172534483
	train_positive_acc: 0.9931460509379275
	train_negative_acc: 0.6046206550712101
	train_correct_nonzero: 16125
	train_incorrect_nonzero: 12
	train_positive_nonzero: 4082
	train_negative_nonzero: 12055
val:
	val_positive_loss: 0.050093743950128555
	val_negative_loss: 0.002037946367636323
	val_positive_acc: 0.9743589743589743
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0344691276550293
	test_negative_loss: 0.028733570128679276
	test_positive_acc: 0.9887647301918197
	test_negative_acc: 0.9921621903209235
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.017806215211749077
	train_incorrect_loss: 6.981704235076904
	train_positive_loss: 2.006457805633545
	train_negative_loss: 0.011594153009355068
	train_correct_acc: 0.9954908370322866
	train_incorrect_acc: 0.011877310385724161
	train_positive_acc: 0.9938324083649296
	train_negative_acc: 0.6050339956148099
	train_correct_nonzero: 17605
	train_incorrect_nonzero: 22
	train_positive_nonzero: 5570
	train_negative_nonzero: 12057
val:
	val_positive_loss: 0.004455910995602608
	val_negative_loss: 0.03794718533754349
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.015799110755324364
	test_negative_loss: 0.06781718879938126
	test_positive_acc: 0.9921901236542894
	test_negative_acc: 0.9832670534704697
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.014722799882292747
	train_incorrect_loss: 6.863333702087402
	train_positive_loss: 1.9703658819198608
	train_negative_loss: 0.010831042192876339
	train_correct_acc: 0.9964887770248307
	train_incorrect_acc: 0.014807752111447374
	train_positive_acc: 0.995395507096333
	train_negative_acc: 0.6055303416683308
	train_correct_nonzero: 20815
	train_incorrect_nonzero: 33
	train_positive_nonzero: 8772
	train_negative_nonzero: 12076
val:
	val_positive_loss: 0.0005710024852305651
	val_negative_loss: 0.02291734702885151
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.02463734708726406
	test_negative_loss: 0.03803407773375511
	test_positive_acc: 0.9911721375992271
	test_negative_acc: 0.987858337523485
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.011587483808398247
	train_incorrect_loss: 8.08873462677002
	train_positive_loss: 2.319613218307495
	train_negative_loss: 0.00474351504817605
	train_correct_acc: 0.9971772762298255
	train_incorrect_acc: 0.015885671927374893
	train_positive_acc: 0.9958625121355317
	train_negative_acc: 0.6064329788560456
	train_correct_nonzero: 16860
	train_incorrect_nonzero: 37
	train_positive_nonzero: 4826
	train_negative_nonzero: 12071
val:
	val_positive_loss: 9.621238859836012e-06
	val_negative_loss: 0.035629063844680786
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.007341353222727776
	test_negative_loss: 0.11566883325576782
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9762861192372593
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.017252499237656593
	train_incorrect_loss: 8.61372184753418
	train_positive_loss: 2.472804546356201
	train_negative_loss: 0.0036736438050866127
	train_correct_acc: 0.9953905310918302
	train_incorrect_acc: 0.014509940468036957
	train_positive_acc: 0.992995650605442
	train_negative_acc: 0.6062720621398363
	train_correct_nonzero: 16572
	train_incorrect_nonzero: 41
	train_positive_nonzero: 4541
	train_negative_nonzero: 12072
val:
	val_positive_loss: 0.0011743305949494243
	val_negative_loss: 0.005047793034464121
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.028625085949897766
	test_negative_loss: 0.03615956008434296
	test_positive_acc: 0.9910923503651845
	test_negative_acc: 0.9924061895467284
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.012365599162876606
	train_incorrect_loss: 7.3300580978393555
	train_positive_loss: 2.102207660675049
	train_negative_loss: 0.00772992754355073
	train_correct_acc: 0.9967547212141357
	train_incorrect_acc: 0.017088304255409754
	train_positive_acc: 0.9956596603814594
	train_negative_acc: 0.60748880799172
	train_correct_nonzero: 19168
	train_incorrect_nonzero: 67
	train_positive_nonzero: 7137
	train_negative_nonzero: 12098
val:
	val_positive_loss: 2.3886059352662414e-05
	val_negative_loss: 0.02862086519598961
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.013558676466345787
	test_negative_loss: 0.08315006643533707
	test_positive_acc: 0.996299342105263
	test_negative_acc: 0.9804239650870616
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.30584120750427 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.425
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2339446544647217
	train_negative_loss: 2.2804436683654785
	train_positive_acc: 0.6968891955828773
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.19706980884075165
	train_incorrect_loss: 2.012148380279541
	train_positive_loss: 0.7066523432731628
	train_negative_loss: 0.2744349241256714
	train_correct_acc: 0.9574674847146659
	train_incorrect_acc: 0.07822239794990915
	train_positive_acc: 0.9735215828281827
	train_negative_acc: 0.5685296565561266
	train_correct_nonzero: 17264
	train_incorrect_nonzero: 1109
	train_positive_nonzero: 7070
	train_negative_nonzero: 11303
val:
	val_positive_loss: 0.03016284480690956
	val_negative_loss: 0.04542597383260727
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04925902932882309
	test_negative_loss: 0.055347613990306854
	test_positive_acc: 0.9879233063450589
	test_negative_acc: 0.989010925060045
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.05219186097383499
	train_incorrect_loss: 3.0796022415161133
	train_positive_loss: 0.9365438222885132
	train_negative_loss: 0.0914645865559578
	train_correct_acc: 0.9914582533502886
	train_incorrect_acc: 0.018993700138615427
	train_positive_acc: 0.9925287364832086
	train_negative_acc: 0.5785403519326728
	train_correct_nonzero: 21150
	train_incorrect_nonzero: 346
	train_positive_nonzero: 9996
	train_negative_nonzero: 11500
val:
	val_positive_loss: 0.004027095157653093
	val_negative_loss: 0.03231003135442734
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.010016091167926788
	test_negative_loss: 0.06282328069210052
	test_positive_acc: 0.9965374373433584
	test_negative_acc: 0.9781009078656724
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02921878732740879
	train_incorrect_loss: 4.228394508361816
	train_positive_loss: 1.270386815071106
	train_negative_loss: 0.03538312390446663
	train_correct_acc: 0.993456770573955
	train_incorrect_acc: 0.012844410397980724
	train_positive_acc: 0.9919833285258697
	train_negative_acc: 0.5798408682401757
	train_correct_nonzero: 20741
	train_incorrect_nonzero: 151
	train_positive_nonzero: 9381
	train_negative_nonzero: 11511
val:
	val_positive_loss: 0.008271876722574234
	val_negative_loss: 0.006788758561015129
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02048923447728157
	test_negative_loss: 0.02560443803668022
	test_positive_acc: 0.9914515844131605
	test_negative_acc: 0.9894844099085298
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.030072644352912903
	train_incorrect_loss: 6.061991214752197
	train_positive_loss: 1.836344838142395
	train_negative_loss: 0.014941439032554626
	train_correct_acc: 0.991151927337826
	train_incorrect_acc: 0.009553741034918796
	train_positive_acc: 0.9873148781077721
	train_negative_acc: 0.5793679878376813
	train_correct_nonzero: 18027
	train_incorrect_nonzero: 56
	train_positive_nonzero: 6531
	train_negative_nonzero: 11552
val:
	val_positive_loss: 0.003014181973412633
	val_negative_loss: 0.005964423064142466
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.026843871921300888
	test_negative_loss: 0.03968582674860954
	test_positive_acc: 0.992781371647203
	test_negative_acc: 0.9905330386816218
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.03190067782998085
	train_incorrect_loss: 6.618677139282227
	train_positive_loss: 1.996038556098938
	train_negative_loss: 0.01746862195432186
	train_correct_acc: 0.9913372192364207
	train_incorrect_acc: 0.012233941161191912
	train_positive_acc: 0.9876787339589597
	train_negative_acc: 0.5797657060923381
	train_correct_nonzero: 18727
	train_incorrect_nonzero: 99
	train_positive_nonzero: 7294
	train_negative_nonzero: 11532
val:
	val_positive_loss: 0.04323508217930794
	val_negative_loss: 0.005233095958828926
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04741781949996948
	test_negative_loss: 0.01996702328324318
	test_positive_acc: 0.9799210263139859
	test_negative_acc: 0.9964924115739333
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.023000817745923996
	train_incorrect_loss: 6.779943466186523
	train_positive_loss: 2.038784980773926
	train_negative_loss: 0.013164866715669632
	train_correct_acc: 0.9932542126030225
	train_incorrect_acc: 0.012958886350083295
	train_positive_acc: 0.990218518907704
	train_negative_acc: 0.5809237394929909
	train_correct_nonzero: 19214
	train_incorrect_nonzero: 40
	train_positive_nonzero: 7697
	train_negative_nonzero: 11557
val:
	val_positive_loss: 0.0013578017242252827
	val_negative_loss: 0.0007217730162665248
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02632826752960682
	test_negative_loss: 0.019325966015458107
	test_positive_acc: 0.9933646155830753
	test_negative_acc: 0.9950389232018403
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.01798826828598976
	train_incorrect_loss: 7.56985330581665
	train_positive_loss: 2.269972085952759
	train_negative_loss: 0.01030888594686985
	train_correct_acc: 0.9950780480922692
	train_incorrect_acc: 0.013531768914104526
	train_positive_acc: 0.993589569757683
	train_negative_acc: 0.5801706709520056
	train_correct_nonzero: 20842
	train_incorrect_nonzero: 36
	train_positive_nonzero: 9313
	train_negative_nonzero: 11565
val:
	val_positive_loss: 0.0021019447594881058
	val_negative_loss: 0.0005295651499181986
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02508934587240219
	test_negative_loss: 0.014033883810043335
	test_positive_acc: 0.9920719975432046
	test_negative_acc: 0.997439381270903
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.019239351153373718
	train_incorrect_loss: 11.356802940368652
	train_positive_loss: 3.3967394828796387
	train_negative_loss: 0.0002052774652838707
	train_correct_acc: 0.9957295583060621
	train_incorrect_acc: 0.009780533467402597
	train_positive_acc: 0.993303700164345
	train_negative_acc: 0.5796301363864005
	train_correct_nonzero: 18785
	train_incorrect_nonzero: 3
	train_positive_nonzero: 7633
	train_negative_nonzero: 11155
val:
	val_positive_loss: 0.003616227302700281
	val_negative_loss: 5.5208511184901e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03945807367563248
	test_negative_loss: 0.014919797889888287
	test_positive_acc: 0.9920719975432046
	test_negative_acc: 0.997439381270903
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.02332497201859951
	train_incorrect_loss: 13.432843208312988
	train_positive_loss: 4.017282009124756
	train_negative_loss: 3.9142934838309884e-05
	train_correct_acc: 0.9955106112680048
	train_incorrect_acc: 0.008722324870332379
	train_positive_acc: 0.9929835927795259
	train_negative_acc: 0.5794943725058226
	train_correct_nonzero: 17868
	train_incorrect_nonzero: 5
	train_positive_nonzero: 7932
	train_negative_nonzero: 9941
val:
	val_positive_loss: 0.0025219214148819447
	val_negative_loss: 2.0451652744668536e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04218056797981262
	test_negative_loss: 0.016217954456806183
	test_positive_acc: 0.9920719975432046
	test_negative_acc: 0.997439381270903
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.02222306653857231
	train_incorrect_loss: 14.249418258666992
	train_positive_loss: 4.256974220275879
	train_negative_loss: 3.143203866784461e-05
	train_correct_acc: 0.9958495229519225
	train_incorrect_acc: 0.010932738760614326
	train_positive_acc: 0.9935075477694729
	train_negative_acc: 0.5811729026681132
	train_correct_nonzero: 12370
	train_incorrect_nonzero: 1
	train_positive_nonzero: 3302
	train_negative_nonzero: 9069
val:
	val_positive_loss: 0.00041884242091327906
	val_negative_loss: 1.4699317944177892e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03609026223421097
	test_negative_loss: 0.02049640193581581
	test_positive_acc: 0.9920719975432046
	test_negative_acc: 0.997439381270903
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 91.97223567962646 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.45
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2338531017303467
	train_negative_loss: 2.280409812927246
	train_positive_acc: 0.7003691726893747
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.19437916576862335
	train_incorrect_loss: 2.013611316680908
	train_positive_loss: 0.7283430695533752
	train_negative_loss: 0.2766419053077698
	train_correct_acc: 0.9501895922332761
	train_incorrect_acc: 0.0950466880123867
	train_positive_acc: 0.9729834523712969
	train_negative_acc: 0.5436418490946003
	train_correct_nonzero: 16783
	train_incorrect_nonzero: 1154
	train_positive_nonzero: 6987
	train_negative_nonzero: 10950
val:
	val_positive_loss: 0.00701072346419096
	val_negative_loss: 0.032208152115345
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02237026020884514
	test_negative_loss: 0.05364461615681648
	test_positive_acc: 0.9952076501093159
	test_negative_acc: 0.9844642282535756
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.04614237695932388
	train_incorrect_loss: 3.382755994796753
	train_positive_loss: 1.0645151138305664
	train_negative_loss: 0.0784406065940857
	train_correct_acc: 0.9922330391353618
	train_incorrect_acc: 0.016485436102358197
	train_positive_acc: 0.9933186560517046
	train_negative_acc: 0.5536457293590361
	train_correct_nonzero: 18660
	train_incorrect_nonzero: 314
	train_positive_nonzero: 7985
	train_negative_nonzero: 10989
val:
	val_positive_loss: 0.0007852565031498671
	val_negative_loss: 0.01673763617873192
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.00618333462625742
	test_negative_loss: 0.04500003904104233
	test_positive_acc: 0.9977265211640212
	test_negative_acc: 0.9831413563914095
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.0227347481995821
	train_incorrect_loss: 4.599259376525879
	train_positive_loss: 1.4326958656311035
	train_negative_loss: 0.030598124489188194
	train_correct_acc: 0.9946743448711705
	train_incorrect_acc: 0.012258445166474594
	train_positive_acc: 0.9941578255147109
	train_negative_acc: 0.5545941282197164
	train_correct_nonzero: 18407
	train_incorrect_nonzero: 105
	train_positive_nonzero: 7449
	train_negative_nonzero: 11063
val:
	val_positive_loss: 0.0012658186024054885
	val_negative_loss: 0.04329362511634827
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.007498130667954683
	test_negative_loss: 0.08306276798248291
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9755889680057117
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.023006783798336983
	train_incorrect_loss: 5.670803546905518
	train_positive_loss: 1.7637856006622314
	train_negative_loss: 0.030982019379734993
	train_correct_acc: 0.9942774302618299
	train_incorrect_acc: 0.01551654451255751
	train_positive_acc: 0.9937121468881135
	train_negative_acc: 0.5562804241214322
	train_correct_nonzero: 19972
	train_incorrect_nonzero: 94
	train_positive_nonzero: 9021
	train_negative_nonzero: 11045
val:
	val_positive_loss: 0.014035292901098728
	val_negative_loss: 0.007229308597743511
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0141416285187006
	test_negative_loss: 0.024386875331401825
	test_positive_acc: 0.9933036994037381
	test_negative_acc: 0.9948066476157911
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.016158217564225197
	train_incorrect_loss: 7.073417663574219
	train_positive_loss: 2.2079570293426514
	train_negative_loss: 0.007612701039761305
	train_correct_acc: 0.9958244403219796
	train_incorrect_acc: 0.009525470474554999
	train_positive_acc: 0.9941267672131381
	train_negative_acc: 0.5548176776835896
	train_correct_nonzero: 15490
	train_incorrect_nonzero: 9
	train_positive_nonzero: 4443
	train_negative_nonzero: 11056
val:
	val_positive_loss: 0.00023542957205791026
	val_negative_loss: 0.004797275178134441
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.017481736838817596
	test_negative_loss: 0.03798931837081909
	test_positive_acc: 0.991055293549177
	test_negative_acc: 0.9875496582283396
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.018585817888379097
	train_incorrect_loss: 6.99149227142334
	train_positive_loss: 2.184623956680298
	train_negative_loss: 0.01469956710934639
	train_correct_acc: 0.9960269194719285
	train_incorrect_acc: 0.009722679590602907
	train_positive_acc: 0.994197205107556
	train_negative_acc: 0.5552185370988718
	train_correct_nonzero: 13782
	train_incorrect_nonzero: 49
	train_positive_nonzero: 2808
	train_negative_nonzero: 11023
val:
	val_positive_loss: 0.0016239662654697895
	val_negative_loss: 0.000786973221693188
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.036356113851070404
	test_negative_loss: 0.02420530468225479
	test_positive_acc: 0.9882976337075828
	test_negative_acc: 0.9937290614088945
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.023550348356366158
	train_incorrect_loss: 9.438633918762207
	train_positive_loss: 2.9486677646636963
	train_negative_loss: 0.0018785921856760979
	train_correct_acc: 0.9939723411923921
	train_incorrect_acc: 0.005948970615323397
	train_positive_acc: 0.9908862352047635
	train_negative_acc: 0.5531552984627698
	train_correct_nonzero: 13553
	train_incorrect_nonzero: 16
	train_positive_nonzero: 2550
	train_negative_nonzero: 11019
val:
	val_positive_loss: 0.03059348836541176
	val_negative_loss: 0.00017544117872603238
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04339834302663803
	test_negative_loss: 0.017874304205179214
	test_positive_acc: 0.9897626755093063
	test_negative_acc: 0.9964924115739333
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.02349277026951313
	train_incorrect_loss: 8.94288444519043
	train_positive_loss: 2.7857019901275635
	train_negative_loss: 0.01592760905623436
	train_correct_acc: 0.9953277119784221
	train_incorrect_acc: 0.00827535644653198
	train_positive_acc: 0.9933637222156668
	train_negative_acc: 0.5536960355550812
	train_correct_nonzero: 12835
	train_incorrect_nonzero: 70
	train_positive_nonzero: 1994
	train_negative_nonzero: 10911
val:
	val_positive_loss: 0.004247463308274746
	val_negative_loss: 0.00038354680873453617
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.024856097996234894
	test_negative_loss: 0.02515338361263275
	test_positive_acc: 0.9923424627433488
	test_negative_acc: 0.9938596779188213
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.024690622463822365
	train_incorrect_loss: 7.676493167877197
	train_positive_loss: 2.3936593532562256
	train_negative_loss: 0.009204564616084099
	train_correct_acc: 0.9928533308879578
	train_incorrect_acc: 0.008886890450279994
	train_positive_acc: 0.990058030155244
	train_negative_acc: 0.5539974323916954
	train_correct_nonzero: 15865
	train_incorrect_nonzero: 60
	train_positive_nonzero: 5021
	train_negative_nonzero: 10904
val:
	val_positive_loss: 0.004460022319108248
	val_negative_loss: 0.007585475221276283
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.007365277037024498
	test_negative_loss: 0.03735559433698654
	test_positive_acc: 0.9960059514439139
	test_negative_acc: 0.9880517100652697
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.01975702866911888
	train_incorrect_loss: 9.18094253540039
	train_positive_loss: 2.857156991958618
	train_negative_loss: 0.005958715453743935
	train_correct_acc: 0.9954577796942393
	train_incorrect_acc: 0.011218227845667058
	train_positive_acc: 0.9937905278444034
	train_negative_acc: 0.555839639805776
	train_correct_nonzero: 15944
	train_incorrect_nonzero: 37
	train_positive_nonzero: 5217
	train_negative_nonzero: 10764
val:
	val_positive_loss: 0.008098844438791275
	val_negative_loss: 0.001225839601829648
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.016857989132404327
	test_negative_loss: 0.014339767396450043
	test_positive_acc: 0.9947917946418333
	test_negative_acc: 0.9948066476157911
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.34920382499695 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.475
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2338171005249023
	train_negative_loss: 2.280332565307617
	train_positive_acc: 0.702860990901652
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.18963950872421265
	train_incorrect_loss: 2.0983753204345703
	train_positive_loss: 0.7770267128944397
	train_negative_loss: 0.2698814868927002
	train_correct_acc: 0.9497519661424004
	train_incorrect_acc: 0.09558696429606973
	train_positive_acc: 0.971319377551064
	train_negative_acc: 0.524132165168937
	train_correct_nonzero: 16011
	train_incorrect_nonzero: 1167
	train_positive_nonzero: 6622
	train_negative_nonzero: 10556
val:
	val_positive_loss: 0.015537978149950504
	val_negative_loss: 0.1635046899318695
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.019477933645248413
	test_negative_loss: 0.1782074123620987
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9668647344687407
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.04751041904091835
	train_incorrect_loss: 3.11991024017334
	train_positive_loss: 1.0199315547943115
	train_negative_loss: 0.08474183827638626
	train_correct_acc: 0.9923421822033253
	train_incorrect_acc: 0.020815841103905327
	train_positive_acc: 0.992971800296071
	train_negative_acc: 0.5318280051806473
	train_correct_nonzero: 17652
	train_incorrect_nonzero: 314
	train_positive_nonzero: 7400
	train_negative_nonzero: 10566
val:
	val_positive_loss: 0.0073466552421450615
	val_negative_loss: 0.014919798821210861
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.025364723056554794
	test_negative_loss: 0.03483209013938904
	test_positive_acc: 0.9895476337075828
	test_negative_acc: 0.9864468166544169
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02971028909087181
	train_incorrect_loss: 4.087432861328125
	train_positive_loss: 1.323280692100525
	train_negative_loss: 0.044471435248851776
	train_correct_acc: 0.9930101668617876
	train_incorrect_acc: 0.021737383335204575
	train_positive_acc: 0.9925360444449671
	train_negative_acc: 0.5336843445296334
	train_correct_nonzero: 18396
	train_incorrect_nonzero: 131
	train_positive_nonzero: 7979
	train_negative_nonzero: 10548
val:
	val_positive_loss: 0.011829955503344536
	val_negative_loss: 0.027272919192910194
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.02517130970954895
	test_negative_loss: 0.060501888394355774
	test_positive_acc: 0.9921322201737482
	test_negative_acc: 0.9821524191914148
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.02733555994927883
	train_incorrect_loss: 4.521063804626465
	train_positive_loss: 1.4587554931640625
	train_negative_loss: 0.046940192580223083
	train_correct_acc: 0.9942576416942736
	train_incorrect_acc: 0.02295971922640337
	train_positive_acc: 0.9947508925919295
	train_negative_acc: 0.5340632628285608
	train_correct_nonzero: 17861
	train_incorrect_nonzero: 192
	train_positive_nonzero: 7484
	train_negative_nonzero: 10569
val:
	val_positive_loss: 0.0015531274257227778
	val_negative_loss: 0.07589659839868546
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.007337633986026049
	test_negative_loss: 0.12379208207130432
	test_positive_acc: 0.9959492020492408
	test_negative_acc: 0.9692064282815724
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.01897493191063404
	train_incorrect_loss: 4.873568534851074
	train_positive_loss: 1.5730996131896973
	train_negative_loss: 0.027524026110768318
	train_correct_acc: 0.9962810388355668
	train_incorrect_acc: 0.02204717296063153
	train_positive_acc: 0.995881105037854
	train_negative_acc: 0.5349940273174946
	train_correct_nonzero: 19049
	train_incorrect_nonzero: 99
	train_positive_nonzero: 8567
	train_negative_nonzero: 10581
val:
	val_positive_loss: 0.00018792755145113915
	val_negative_loss: 0.02980205975472927
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.006164432503283024
	test_negative_loss: 0.06704965233802795
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9779879041900423
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.013351616449654102
	train_incorrect_loss: 6.705004692077637
	train_positive_loss: 2.17041277885437
	train_negative_loss: 0.008771562948822975
	train_correct_acc: 0.9969578208744098
	train_incorrect_acc: 0.017967865932418958
	train_positive_acc: 0.9956342728877345
	train_negative_acc: 0.5345939161612322
	train_correct_nonzero: 15359
	train_incorrect_nonzero: 38
	train_positive_nonzero: 4824
	train_negative_nonzero: 10573
val:
	val_positive_loss: 0.0002418416552245617
	val_negative_loss: 0.029781486839056015
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.012987368740141392
	test_negative_loss: 0.03959999606013298
	test_positive_acc: 0.996299342105263
	test_negative_acc: 0.9865967228734646
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.0157247856259346
	train_incorrect_loss: 7.068921089172363
	train_positive_loss: 2.2842485904693604
	train_negative_loss: 0.011592438444495201
	train_correct_acc: 0.9962075980575141
	train_incorrect_acc: 0.01735459869288624
	train_positive_acc: 0.9951079883995791
	train_negative_acc: 0.5329169138613837
	train_correct_nonzero: 16819
	train_incorrect_nonzero: 45
	train_positive_nonzero: 6303
	train_negative_nonzero: 10561
val:
	val_positive_loss: 0.0010180308017879725
	val_negative_loss: 0.0024411079939454794
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01916978880763054
	test_negative_loss: 0.028599480167031288
	test_positive_acc: 0.9936953034137632
	test_negative_acc: 0.9920510759103647
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.01412532851099968
	train_incorrect_loss: 8.161260604858398
	train_positive_loss: 2.6333820819854736
	train_negative_loss: 0.007547798100858927
	train_correct_acc: 0.9962689939191253
	train_incorrect_acc: 0.015942542854722127
	train_positive_acc: 0.9948130438672547
	train_negative_acc: 0.5326684668435733
	train_correct_nonzero: 14032
	train_incorrect_nonzero: 23
	train_positive_nonzero: 3519
	train_negative_nonzero: 10536
val:
	val_positive_loss: 0.0017269643722102046
	val_negative_loss: 0.0022804019972682
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.024148378521203995
	test_negative_loss: 0.020805414766073227
	test_positive_acc: 0.9908774209416253
	test_negative_acc: 0.9933531592436982
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.016697056591510773
	train_incorrect_loss: 7.839263916015625
	train_positive_loss: 2.5261051654815674
	train_negative_loss: 0.00737268291413784
	train_correct_acc: 0.9950603313176546
	train_incorrect_acc: 0.014697773081838107
	train_positive_acc: 0.9930953914812024
	train_negative_acc: 0.5324451820336685
	train_correct_nonzero: 16154
	train_incorrect_nonzero: 29
	train_positive_nonzero: 5630
	train_negative_nonzero: 10553
val:
	val_positive_loss: 0.002242466900497675
	val_negative_loss: 0.0005180377047508955
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.032385896891355515
	test_negative_loss: 0.02680320292711258
	test_positive_acc: 0.9907239121696956
	test_negative_acc: 0.9924061895467284
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.01621261052787304
	train_incorrect_loss: 9.178235054016113
	train_positive_loss: 2.9517741203308105
	train_negative_loss: 0.003521660575643182
	train_correct_acc: 0.9955197067292452
	train_incorrect_acc: 0.01195838245296589
	train_positive_acc: 0.9934135879233925
	train_negative_acc: 0.5321215449555701
	train_correct_nonzero: 14127
	train_incorrect_nonzero: 20
	train_positive_nonzero: 3606
	train_negative_nonzero: 10541
val:
	val_positive_loss: 0.001651514321565628
	val_negative_loss: 0.0012596572050824761
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.033283501863479614
	test_negative_loss: 0.043728627264499664
	test_positive_acc: 0.9895829052721097
	test_negative_acc: 0.9884197373305744
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.71716547012329 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.5
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233757734298706
	train_negative_loss: 2.2803099155426025
	train_positive_acc: 0.7051644685685265
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.2149524837732315
	train_incorrect_loss: 1.9059486389160156
	train_positive_loss: 0.7467643022537231
	train_negative_loss: 0.31045401096343994
	train_correct_acc: 0.9504129503075128
	train_incorrect_acc: 0.09847549462067368
	train_positive_acc: 0.9747229046558786
	train_negative_acc: 0.501020905687125
	train_correct_nonzero: 15401
	train_incorrect_nonzero: 1273
	train_positive_nonzero: 6496
	train_negative_nonzero: 10178
val:
	val_positive_loss: 0.020257890224456787
	val_negative_loss: 0.23896557092666626
	val_positive_acc: 1.0
	val_negative_acc: 0.959016393442623
test:
	test_positive_loss: 0.02612525038421154
	test_negative_loss: 0.253566175699234
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9623200466399917
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.0429338738322258
	train_incorrect_loss: 3.3804142475128174
	train_positive_loss: 1.1443166732788086
	train_negative_loss: 0.06809147447347641
	train_correct_acc: 0.9928010697511206
	train_incorrect_acc: 0.018064067100800815
	train_positive_acc: 0.993314603680077
	train_negative_acc: 0.50633269744576
	train_correct_nonzero: 17896
	train_incorrect_nonzero: 277
	train_positive_nonzero: 8102
	train_negative_nonzero: 10071
val:
	val_positive_loss: 0.015782177448272705
	val_negative_loss: 0.052298251539468765
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02308913879096508
	test_negative_loss: 0.07664694637060165
	test_positive_acc: 0.9966909461152882
	test_negative_acc: 0.9842189425983061
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.043177179992198944
	train_incorrect_loss: 4.1072916984558105
	train_positive_loss: 1.3878508806228638
	train_negative_loss: 0.06057386472821236
	train_correct_acc: 0.990074511528187
	train_incorrect_acc: 0.012235368149318884
	train_positive_acc: 0.9874696974862752
	train_negative_acc: 0.5056128996060305
	train_correct_nonzero: 18495
	train_incorrect_nonzero: 230
	train_positive_nonzero: 8669
	train_negative_nonzero: 10056
val:
	val_positive_loss: 0.0015885927714407444
	val_negative_loss: 0.04830330237746239
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.005800794810056686
	test_negative_loss: 0.13521477580070496
	test_positive_acc: 0.9966909461152882
	test_negative_acc: 0.9555691587895991
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.026007387787103653
	train_incorrect_loss: 5.507368564605713
	train_positive_loss: 1.8524531126022339
	train_negative_loss: 0.014472522772848606
	train_correct_acc: 0.9921449473224797
	train_incorrect_acc: 0.010489776007959504
	train_positive_acc: 0.9892928963966607
	train_negative_acc: 0.5060482117325457
	train_correct_nonzero: 16732
	train_incorrect_nonzero: 49
	train_positive_nonzero: 6701
	train_negative_nonzero: 10080
val:
	val_positive_loss: 0.01871352270245552
	val_negative_loss: 0.00304356194101274
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04981234669685364
	test_negative_loss: 0.009809382259845734
	test_positive_acc: 0.9806558034119597
	test_negative_acc: 0.997439381270903
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.036290042102336884
	train_incorrect_loss: 7.013603687286377
	train_positive_loss: 2.3675079345703125
	train_negative_loss: 0.007058677729219198
	train_correct_acc: 0.9894275310223652
	train_incorrect_acc: 0.00774592343115023
	train_positive_acc: 0.9846577532944928
	train_negative_acc: 0.5044638517986793
	train_correct_nonzero: 18174
	train_incorrect_nonzero: 79
	train_positive_nonzero: 8173
	train_negative_nonzero: 10080
val:
	val_positive_loss: 0.0026215803809463978
	val_negative_loss: 0.010206703096628189
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.017493661493062973
	test_negative_loss: 0.034384310245513916
	test_positive_acc: 0.9946194148151982
	test_negative_acc: 0.9924481570497534
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.028611328452825546
	train_incorrect_loss: 7.067391395568848
	train_positive_loss: 2.3792450428009033
	train_negative_loss: 0.007190528325736523
	train_correct_acc: 0.991111947383806
	train_incorrect_acc: 0.009239630580804634
	train_positive_acc: 0.9873642122914181
	train_negative_acc: 0.5051012196025993
	train_correct_nonzero: 17562
	train_incorrect_nonzero: 22
	train_positive_nonzero: 7518
	train_negative_nonzero: 10066
val:
	val_positive_loss: 0.018962226808071136
	val_negative_loss: 0.007403863128274679
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.020677033811807632
	test_negative_loss: 0.03983202949166298
	test_positive_acc: 0.9933694148151981
	test_negative_acc: 0.9868158524634102
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.02313438057899475
	train_incorrect_loss: 7.500774383544922
	train_positive_loss: 2.5135865211486816
	train_negative_loss: 0.006466199643909931
	train_correct_acc: 0.9936699201790906
	train_incorrect_acc: 0.011036279953747216
	train_positive_acc: 0.9913752110506892
	train_negative_acc: 0.5055133909620376
	train_correct_nonzero: 17131
	train_incorrect_nonzero: 41
	train_positive_nonzero: 7086
	train_negative_nonzero: 10086
val:
	val_positive_loss: 0.003038811031728983
	val_negative_loss: 0.008647043257951736
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.018656019121408463
	test_negative_loss: 0.04412122815847397
	test_positive_acc: 0.9933646155830753
	test_negative_acc: 0.9853623640913172
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.02023349702358246
	train_incorrect_loss: 7.2021918296813965
	train_positive_loss: 2.4070792198181152
	train_negative_loss: 0.012154419906437397
	train_correct_acc: 0.9953515970134287
	train_incorrect_acc: 0.013437970485519455
	train_positive_acc: 0.9935290285879351
	train_negative_acc: 0.506956726454296
	train_correct_nonzero: 17231
	train_incorrect_nonzero: 47
	train_positive_nonzero: 7291
	train_negative_nonzero: 9987
val:
	val_positive_loss: 0.0028290306217968464
	val_negative_loss: 0.019170930609107018
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.019513890147209167
	test_negative_loss: 0.07836318016052246
	test_positive_acc: 0.9946992020492407
	test_negative_acc: 0.9817760419636519
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.0222457405179739
	train_incorrect_loss: 10.899775505065918
	train_positive_loss: 3.6448965072631836
	train_negative_loss: 0.0011113607324659824
	train_correct_acc: 0.9952532468376659
	train_incorrect_acc: 0.0114356427427242
	train_positive_acc: 0.9929956518667369
	train_negative_acc: 0.5067220131124786
	train_correct_nonzero: 14982
	train_incorrect_nonzero: 34
	train_positive_nonzero: 5519
	train_negative_nonzero: 9497
val:
	val_positive_loss: 0.0014800392091274261
	val_negative_loss: 0.0009610209381207824
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03087523579597473
	test_negative_loss: 0.03500921651721001
	test_positive_acc: 0.9896274209416254
	test_negative_acc: 0.9925575945854881
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.024519195780158043
	train_incorrect_loss: 12.008194923400879
	train_positive_loss: 4.013330459594727
	train_negative_loss: 9.510407107882202e-05
	train_correct_acc: 0.9947646225829717
	train_incorrect_acc: 0.009599492534854972
	train_positive_acc: 0.9922421802666976
	train_negative_acc: 0.5065077046874089
	train_correct_nonzero: 16031
	train_incorrect_nonzero: 43
	train_positive_nonzero: 6585
	train_negative_nonzero: 9489
val:
	val_positive_loss: 0.001334220520220697
	val_negative_loss: 0.00026281503960490227
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.038808226585388184
	test_negative_loss: 0.03949086740612984
	test_positive_acc: 0.9896274209416254
	test_negative_acc: 0.9925575945854881
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.23170280456543 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.525
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233675956726074
	train_negative_loss: 2.2802953720092773
	train_positive_acc: 0.7078619092082715
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.21200557053089142
	train_incorrect_loss: 1.886206865310669
	train_positive_loss: 0.7548761367797852
	train_negative_loss: 0.3167194426059723
	train_correct_acc: 0.9490227994230404
	train_incorrect_acc: 0.10728755663336897
	train_positive_acc: 0.9729518331735193
	train_negative_acc: 0.4869862853777565
	train_correct_nonzero: 15405
	train_incorrect_nonzero: 1242
	train_positive_nonzero: 6855
	train_negative_nonzero: 9792
val:
	val_positive_loss: 0.03720707818865776
	val_negative_loss: 0.06137891486287117
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03750055283308029
	test_negative_loss: 0.08065901696681976
	test_positive_acc: 0.9965374373433584
	test_negative_acc: 0.9849444944230957
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.04172759875655174
	train_incorrect_loss: 3.2714412212371826
	train_positive_loss: 1.1380168199539185
	train_negative_loss: 0.07225745916366577
	train_correct_acc: 0.992865724851565
	train_incorrect_acc: 0.01750496031082076
	train_positive_acc: 0.9934766344761717
	train_negative_acc: 0.4820405823597743
	train_correct_nonzero: 17913
	train_incorrect_nonzero: 277
	train_positive_nonzero: 8636
	train_negative_nonzero: 9554
val:
	val_positive_loss: 0.0176021009683609
	val_negative_loss: 0.03284382447600365
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.014582597650587559
	test_negative_loss: 0.060750801116228104
	test_positive_acc: 0.9965374373433584
	test_negative_acc: 0.9815980637956404
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02505902759730816
	train_incorrect_loss: 4.3344950675964355
	train_positive_loss: 1.501700758934021
	train_negative_loss: 0.03099140152335167
	train_correct_acc: 0.9939185318363959
	train_incorrect_acc: 0.013687189113109966
	train_positive_acc: 0.9926500840203915
	train_negative_acc: 0.4824874044319847
	train_correct_nonzero: 17485
	train_incorrect_nonzero: 123
	train_positive_nonzero: 8005
	train_negative_nonzero: 9603
val:
	val_positive_loss: 0.0298274178057909
	val_negative_loss: 0.012014421634376049
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.021928373724222183
	test_negative_loss: 0.048190440982580185
	test_positive_acc: 0.9897857289456781
	test_negative_acc: 0.9856591885340162
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.029800105839967728
	train_incorrect_loss: 4.0008087158203125
	train_positive_loss: 1.3854308128356934
	train_negative_loss: 0.05123858153820038
	train_correct_acc: 0.9938946075152115
	train_incorrect_acc: 0.01884196024157298
	train_positive_acc: 0.9930427393442043
	train_negative_acc: 0.4846764085944406
	train_correct_nonzero: 14756
	train_incorrect_nonzero: 198
	train_positive_nonzero: 5345
	train_negative_nonzero: 9609
val:
	val_positive_loss: 0.00030801957473158836
	val_negative_loss: 0.03877587988972664
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.0052422164008021355
	test_negative_loss: 0.10961206257343292
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9685712869557157
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.02495984174311161
	train_incorrect_loss: 5.183422088623047
	train_positive_loss: 1.7891077995300293
	train_negative_loss: 0.03281692415475845
	train_correct_acc: 0.9939648598772515
	train_incorrect_acc: 0.01983948466617419
	train_positive_acc: 0.992692664708277
	train_negative_acc: 0.4852448712945299
	train_correct_nonzero: 13953
	train_incorrect_nonzero: 126
	train_positive_nonzero: 4514
	train_negative_nonzero: 9565
val:
	val_positive_loss: 0.0007356967544183135
	val_negative_loss: 0.01941315270960331
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01398548949509859
	test_negative_loss: 0.06805840134620667
	test_positive_acc: 0.9939528508771929
	test_negative_acc: 0.9777014272082738
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.01908203773200512
	train_incorrect_loss: 4.964447021484375
	train_positive_loss: 1.7178010940551758
	train_negative_loss: 0.027019452303647995
	train_correct_acc: 0.9954601911458141
	train_incorrect_acc: 0.022929518226650927
	train_positive_acc: 0.9948570538468673
	train_negative_acc: 0.48668729252453724
	train_correct_nonzero: 14221
	train_incorrect_nonzero: 102
	train_positive_nonzero: 4741
	train_negative_nonzero: 9582
val:
	val_positive_loss: 0.0013230498880147934
	val_negative_loss: 0.006866699084639549
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.019677944481372833
	test_negative_loss: 0.06580407172441483
	test_positive_acc: 0.9926230636431503
	test_negative_acc: 0.9802063343168281
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.01680704765021801
	train_incorrect_loss: 5.536977291107178
	train_positive_loss: 1.90933096408844
	train_negative_loss: 0.02154814451932907
	train_correct_acc: 0.9956719043054345
	train_incorrect_acc: 0.02401311549816354
	train_positive_acc: 0.9953336003416882
	train_negative_acc: 0.4867365483492776
	train_correct_nonzero: 15829
	train_incorrect_nonzero: 131
	train_positive_nonzero: 6353
	train_negative_nonzero: 9607
val:
	val_positive_loss: 0.00039679717156104743
	val_negative_loss: 0.015126226469874382
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.010155564174056053
	test_negative_loss: 0.08791229128837585
	test_positive_acc: 0.9948527108211707
	test_negative_acc: 0.9737316871281188
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.014965095557272434
	train_incorrect_loss: 6.690979957580566
	train_positive_loss: 2.3126606941223145
	train_negative_loss: 0.008858870714902878
	train_correct_acc: 0.9960418507837706
	train_incorrect_acc: 0.02370197280969136
	train_positive_acc: 0.9949003969121145
	train_negative_acc: 0.48741252074906566
	train_correct_nonzero: 14595
	train_incorrect_nonzero: 52
	train_positive_nonzero: 5058
	train_negative_nonzero: 9589
val:
	val_positive_loss: 0.0016475406009703875
	val_negative_loss: 0.012174032628536224
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.02002473920583725
	test_negative_loss: 0.05599357187747955
	test_positive_acc: 0.9921146155830753
	test_negative_acc: 0.9807493565182059
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.017171556130051613
	train_incorrect_loss: 5.984127998352051
	train_positive_loss: 2.0641043186187744
	train_negative_loss: 0.016154536977410316
	train_correct_acc: 0.9960703983539697
	train_incorrect_acc: 0.02346541868168122
	train_positive_acc: 0.9948120393009353
	train_negative_acc: 0.48795022378012337
	train_correct_nonzero: 13311
	train_incorrect_nonzero: 69
	train_positive_nonzero: 3788
	train_negative_nonzero: 9592
val:
	val_positive_loss: 0.0036822862457484007
	val_negative_loss: 0.021755747497081757
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.022052079439163208
	test_negative_loss: 0.04636940360069275
	test_positive_acc: 0.9921146155830753
	test_negative_acc: 0.9897454105612211
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.01726633496582508
	train_incorrect_loss: 7.3693437576293945
	train_positive_loss: 2.546414375305176
	train_negative_loss: 0.003243312006816268
	train_correct_acc: 0.9958194090983538
	train_incorrect_acc: 0.02016125005714976
	train_positive_acc: 0.9938793907215108
	train_negative_acc: 0.4873250240020228
	train_correct_nonzero: 11240
	train_incorrect_nonzero: 43
	train_positive_nonzero: 1690
	train_negative_nonzero: 9593
val:
	val_positive_loss: 0.0023815541062504053
	val_negative_loss: 0.003371803555637598
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03562316298484802
	test_negative_loss: 0.049112915992736816
	test_positive_acc: 0.9907848283490327
	test_negative_acc: 0.9886227775970429
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.18882012367249 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.55
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2335636615753174
	train_negative_loss: 2.2802512645721436
	train_positive_acc: 0.7108092040388617
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.20192696154117584
	train_incorrect_loss: 1.995843529701233
	train_positive_loss: 0.8107492923736572
	train_negative_loss: 0.2948952913284302
	train_correct_acc: 0.9544687494149132
	train_incorrect_acc: 0.09188163356092853
	train_positive_acc: 0.9749905174433886
	train_negative_acc: 0.4625688882732725
	train_correct_nonzero: 15148
	train_incorrect_nonzero: 1112
	train_positive_nonzero: 6920
	train_negative_nonzero: 9340
val:
	val_positive_loss: 0.032903075218200684
	val_negative_loss: 0.10187749564647675
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.031409092247486115
	test_negative_loss: 0.12646149098873138
	test_positive_acc: 0.9963839285714285
	test_negative_acc: 0.9780589403626474
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.04449906200170517
	train_incorrect_loss: 3.2485504150390625
	train_positive_loss: 1.1685078144073486
	train_negative_loss: 0.082005575299263
	train_correct_acc: 0.9919067445706392
	train_incorrect_acc: 0.02654385452473649
	train_positive_acc: 0.9936194542352085
	train_negative_acc: 0.4608135019824469
	train_correct_nonzero: 15192
	train_incorrect_nonzero: 304
	train_positive_nonzero: 6375
	train_negative_nonzero: 9121
val:
	val_positive_loss: 0.006653551012277603
	val_negative_loss: 0.11561686545610428
	val_positive_acc: 1.0
	val_negative_acc: 0.9625893232450609
test:
	test_positive_loss: 0.009963124059140682
	test_negative_loss: 0.13578659296035767
	test_positive_acc: 1.0
	test_negative_acc: 0.9488469766784031
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02772267907857895
	train_incorrect_loss: 4.386351585388184
	train_positive_loss: 1.566603660583496
	train_negative_loss: 0.036428552120923996
	train_correct_acc: 0.9937211039329028
	train_incorrect_acc: 0.018556907348989668
	train_positive_acc: 0.9932769602729723
	train_negative_acc: 0.45970234096926504
	train_correct_nonzero: 16736
	train_incorrect_nonzero: 130
	train_positive_nonzero: 7758
	train_negative_nonzero: 9108
val:
	val_positive_loss: 0.0023074958007782698
	val_negative_loss: 0.0428772047162056
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.008381577208638191
	test_negative_loss: 0.07608138024806976
	test_positive_acc: 0.9959492020492408
	test_negative_acc: 0.9748197058311139
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.018888114020228386
	train_incorrect_loss: 5.525914669036865
	train_positive_loss: 1.9686247110366821
	train_negative_loss: 0.024771487340331078
	train_correct_acc: 0.9954139210420103
	train_incorrect_acc: 0.020029926521026756
	train_positive_acc: 0.9955683333446332
	train_negative_acc: 0.4607630256080075
	train_correct_nonzero: 16952
	train_incorrect_nonzero: 64
	train_positive_nonzero: 7927
	train_negative_nonzero: 9089
val:
	val_positive_loss: 0.00018719598301686347
	val_negative_loss: 0.01564272865653038
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.002781989984214306
	test_negative_loss: 0.06660785526037216
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.975172930202406
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.02156156860291958
	train_incorrect_loss: 6.384305953979492
	train_positive_loss: 2.273719310760498
	train_negative_loss: 0.032919153571128845
	train_correct_acc: 0.9949907671573651
	train_incorrect_acc: 0.02314222702302901
	train_positive_acc: 0.995394496716909
	train_negative_acc: 0.46132144604858283
	train_correct_nonzero: 17874
	train_incorrect_nonzero: 143
	train_positive_nonzero: 8896
	train_negative_nonzero: 9121
val:
	val_positive_loss: 0.01219873782247305
	val_negative_loss: 0.007576195523142815
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.023168589919805527
	test_negative_loss: 0.023840520530939102
	test_positive_acc: 0.9908822201737483
	test_negative_acc: 0.9886958696847199
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.014635528437793255
	train_incorrect_loss: 7.050762176513672
	train_positive_loss: 2.509669542312622
	train_negative_loss: 0.010299690999090672
	train_correct_acc: 0.9958435812918133
	train_incorrect_acc: 0.020830617077854444
	train_positive_acc: 0.994852758810785
	train_negative_acc: 0.46139440466877063
	train_correct_nonzero: 16032
	train_incorrect_nonzero: 50
	train_positive_nonzero: 6987
	train_negative_nonzero: 9095
val:
	val_positive_loss: 0.017847172915935516
	val_negative_loss: 0.006302970927208662
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01897219941020012
	test_negative_loss: 0.028943775221705437
	test_positive_acc: 0.9925621474638131
	test_negative_acc: 0.9885942106085976
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.013939674012362957
	train_incorrect_loss: 9.281537055969238
	train_positive_loss: 3.2882065773010254
	train_negative_loss: 0.0038104383274912834
	train_correct_acc: 0.995891645196181
	train_incorrect_acc: 0.019395625091264496
	train_positive_acc: 0.9947078585544176
	train_negative_acc: 0.46085776750513013
	train_correct_nonzero: 14898
	train_incorrect_nonzero: 31
	train_positive_nonzero: 5879
	train_negative_nonzero: 9050
val:
	val_positive_loss: 0.01889956369996071
	val_negative_loss: 0.0011491251643747091
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04848967492580414
	test_negative_loss: 0.032533008605241776
	test_positive_acc: 0.9826664185327124
	test_negative_acc: 0.9873371740325461
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.018039820715785027
	train_incorrect_loss: 10.109206199645996
	train_positive_loss: 3.593865394592285
	train_negative_loss: 0.0008207468199543655
	train_correct_acc: 0.9953037508482763
	train_incorrect_acc: 0.013896504272616277
	train_positive_acc: 0.9932657608691057
	train_negative_acc: 0.45846231327987924
	train_correct_nonzero: 13609
	train_incorrect_nonzero: 14
	train_positive_nonzero: 4610
	train_negative_nonzero: 9013
val:
	val_positive_loss: 0.008496392518281937
	val_negative_loss: 0.0010783252073451877
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03306635469198227
	test_negative_loss: 0.0260984655469656
	test_positive_acc: 0.990644124935653
	test_negative_acc: 0.991899670871605
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.0191520806401968
	train_incorrect_loss: 12.125287055969238
	train_positive_loss: 4.306635856628418
	train_negative_loss: 0.00010606244904920459
	train_correct_acc: 0.9953574894329796
	train_incorrect_acc: 0.011866434348993756
	train_positive_acc: 0.9933187506638098
	train_negative_acc: 0.4574975939838181
	train_correct_nonzero: 10986
	train_incorrect_nonzero: 11
	train_positive_nonzero: 2360
	train_negative_nonzero: 8637
val:
	val_positive_loss: 0.007315037306398153
	val_negative_loss: 0.0005686504300683737
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03216846287250519
	test_negative_loss: 0.035044897347688675
	test_positive_acc: 0.9907239121696956
	test_negative_acc: 0.991899670871605
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.023366985842585564
	train_incorrect_loss: 13.321438789367676
	train_positive_loss: 4.731910228729248
	train_negative_loss: 4.372960756882094e-05
	train_correct_acc: 0.9947223631185323
	train_incorrect_acc: 0.011137890694807745
	train_positive_acc: 0.9923851655323801
	train_negative_acc: 0.4577880707414066
	train_correct_nonzero: 10903
	train_incorrect_nonzero: 14
	train_positive_nonzero: 2922
	train_negative_nonzero: 7995
val:
	val_positive_loss: 0.011585447937250137
	val_negative_loss: 0.00029222058947198093
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03759782016277313
	test_negative_loss: 0.0326952300965786
	test_positive_acc: 0.9895219890927724
	test_negative_acc: 0.991899670871605
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.496985912323 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.575
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233494281768799
	train_negative_loss: 2.280289888381958
	train_positive_acc: 0.7135953333063701
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.20159341394901276
	train_incorrect_loss: 1.9532191753387451
	train_positive_loss: 0.8133541941642761
	train_negative_loss: 0.30165114998817444
	train_correct_acc: 0.9544975349732552
	train_incorrect_acc: 0.1020348393976844
	train_positive_acc: 0.9786454822300319
	train_negative_acc: 0.4430423804478469
	train_correct_nonzero: 14028
	train_incorrect_nonzero: 1103
	train_positive_nonzero: 6208
	train_negative_nonzero: 8923
val:
	val_positive_loss: 0.011129159480333328
	val_negative_loss: 0.08323048055171967
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.017433123663067818
	test_negative_loss: 0.10941682755947113
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9735994901836471
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.051856644451618195
	train_incorrect_loss: 2.9099066257476807
	train_positive_loss: 1.0774542093276978
	train_negative_loss: 0.11159543693065643
	train_correct_acc: 0.992372944358567
	train_incorrect_acc: 0.019760509983525437
	train_positive_acc: 0.9942285484518847
	train_negative_acc: 0.43294948702396424
	train_correct_nonzero: 15728
	train_incorrect_nonzero: 392
	train_positive_nonzero: 7429
	train_negative_nonzero: 8691
val:
	val_positive_loss: 0.011533048003911972
	val_negative_loss: 0.026546701788902283
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.021636659279465675
	test_negative_loss: 0.046020589768886566
	test_positive_acc: 0.9925621474638131
	test_negative_acc: 0.985672430970399
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.026606429368257523
	train_incorrect_loss: 4.16241979598999
	train_positive_loss: 1.5290919542312622
	train_negative_loss: 0.04349837452173233
	train_correct_acc: 0.994364050748674
	train_incorrect_acc: 0.01878737893673585
	train_positive_acc: 0.9946354890545137
	train_negative_acc: 0.43521013078072024
	train_correct_nonzero: 17492
	train_incorrect_nonzero: 153
	train_positive_nonzero: 9030
	train_negative_nonzero: 8615
val:
	val_positive_loss: 0.000364032166544348
	val_negative_loss: 0.045252129435539246
	val_positive_acc: 1.0
	val_negative_acc: 0.9789827658680117
test:
	test_positive_loss: 0.002852406818419695
	test_negative_loss: 0.07695473730564117
	test_positive_acc: 0.9989035087719298
	test_negative_acc: 0.9756768713044075
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.018209317699074745
	train_incorrect_loss: 4.686062335968018
	train_positive_loss: 1.711818814277649
	train_negative_loss: 0.030794497579336166
	train_correct_acc: 0.9960447194512645
	train_incorrect_acc: 0.01884748605771065
	train_positive_acc: 0.9958863107356016
	train_negative_acc: 0.4362192660071617
	train_correct_nonzero: 16038
	train_incorrect_nonzero: 97
	train_positive_nonzero: 7539
	train_negative_nonzero: 8596
val:
	val_positive_loss: 0.015659866854548454
	val_negative_loss: 0.00893956609070301
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.018105152994394302
	test_negative_loss: 0.029657116159796715
	test_positive_acc: 0.9918739886987615
	test_negative_acc: 0.9904832927189845
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.019645843654870987
	train_incorrect_loss: 4.956274509429932
	train_positive_loss: 1.8094574213027954
	train_negative_loss: 0.036381129175424576
	train_correct_acc: 0.9956468583189302
	train_incorrect_acc: 0.021946462424341055
	train_positive_acc: 0.9961217073721538
	train_negative_acc: 0.43681314292386253
	train_correct_nonzero: 15456
	train_incorrect_nonzero: 177
	train_positive_nonzero: 7026
	train_negative_nonzero: 8607
val:
	val_positive_loss: 0.0008097753161564469
	val_negative_loss: 0.04368576779961586
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.0064189620316028595
	test_negative_loss: 0.08203482627868652
	test_positive_acc: 0.9975737215378873
	test_negative_acc: 0.9771357272129917
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.014823894947767258
	train_incorrect_loss: 5.4193572998046875
	train_positive_loss: 1.9816327095031738
	train_negative_loss: 0.024173112586140633
	train_correct_acc: 0.9969859645292365
	train_incorrect_acc: 0.024138434153911852
	train_positive_acc: 0.9970361739430823
	train_negative_acc: 0.4388336419139566
	train_correct_nonzero: 14852
	train_incorrect_nonzero: 106
	train_positive_nonzero: 6353
	train_negative_nonzero: 8605
val:
	val_positive_loss: 0.02198476530611515
	val_negative_loss: 0.07034219801425934
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03340606391429901
	test_negative_loss: 0.07578125596046448
	test_positive_acc: 0.9930704033977658
	test_negative_acc: 0.9945036794600748
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.015651438385248184
	train_incorrect_loss: 6.664621353149414
	train_positive_loss: 2.4344654083251953
	train_negative_loss: 0.009058916009962559
	train_correct_acc: 0.9960862228413758
	train_incorrect_acc: 0.014927585060008597
	train_positive_acc: 0.9947144480477472
	train_negative_acc: 0.43405586749955255
	train_correct_nonzero: 15352
	train_incorrect_nonzero: 32
	train_positive_nonzero: 6820
	train_negative_nonzero: 8564
val:
	val_positive_loss: 0.004380967002362013
	val_negative_loss: 0.0011642760364338756
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02085230126976967
	test_negative_loss: 0.03416258841753006
	test_positive_acc: 0.9907239121696956
	test_negative_acc: 0.9925078486228507
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.017819544300436974
	train_incorrect_loss: 9.979589462280273
	train_positive_loss: 3.6516313552856445
	train_negative_loss: 0.00026652784436009824
	train_correct_acc: 0.9958301821071265
	train_incorrect_acc: 0.011342356607016543
	train_positive_acc: 0.994044664418974
	train_negative_acc: 0.43221710926829543
	train_correct_nonzero: 11812
	train_incorrect_nonzero: 1
	train_positive_nonzero: 3272
	train_negative_nonzero: 8541
val:
	val_positive_loss: 0.002211612416431308
	val_negative_loss: 0.0002260638284496963
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01807982847094536
	test_negative_loss: 0.04294261336326599
	test_positive_acc: 0.9925621474638131
	test_negative_acc: 0.9925078486228507
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.020932257175445557
	train_incorrect_loss: 8.120400428771973
	train_positive_loss: 2.964694023132324
	train_negative_loss: 0.017991628497838974
	train_correct_acc: 0.9962556005058031
	train_incorrect_acc: 0.016439886352435127
	train_positive_acc: 0.9951714090035974
	train_negative_acc: 0.4352472374375818
	train_correct_nonzero: 14026
	train_incorrect_nonzero: 110
	train_positive_nonzero: 5564
	train_negative_nonzero: 8572
val:
	val_positive_loss: 8.999198325909674e-05
	val_negative_loss: 0.0064984653145074844
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.003089262405410409
	test_negative_loss: 0.06063266843557358
	test_positive_acc: 0.9981617647058824
	test_negative_acc: 0.9832760492941702
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.021499119699001312
	train_incorrect_loss: 5.406496047973633
	train_positive_loss: 1.9747627973556519
	train_negative_loss: 0.03948919102549553
	train_correct_acc: 0.9959078379691358
	train_incorrect_acc: 0.02271609494060346
	train_positive_acc: 0.9960084977885025
	train_negative_acc: 0.4379171665006656
	train_correct_nonzero: 14952
	train_incorrect_nonzero: 188
	train_positive_nonzero: 6508
	train_negative_nonzero: 8632
val:
	val_positive_loss: 0.0004977399366907775
	val_negative_loss: 0.00605372991412878
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.014073558151721954
	test_negative_loss: 0.033984024077653885
	test_positive_acc: 0.9923655161797206
	test_negative_acc: 0.9877819338143887
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.21809244155884 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.6
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233433723449707
	train_negative_loss: 2.2802317142486572
	train_positive_acc: 0.7163151086288699
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.2045782208442688
	train_incorrect_loss: 1.9175878763198853
	train_positive_loss: 0.8184019923210144
	train_negative_loss: 0.3125179708003998
	train_correct_acc: 0.9510455400680743
	train_incorrect_acc: 0.12060552784189382
	train_positive_acc: 0.9773214820809676
	train_negative_acc: 0.42872702118027256
	train_correct_nonzero: 13564
	train_incorrect_nonzero: 1116
	train_positive_nonzero: 6179
	train_negative_nonzero: 8501
val:
	val_positive_loss: 0.017758795991539955
	val_negative_loss: 0.13784709572792053
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.023499852046370506
	test_negative_loss: 0.15740139782428741
	test_positive_acc: 0.9976339285714286
	test_negative_acc: 0.980198718820628
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.038704052567481995
	train_incorrect_loss: 3.738088846206665
	train_positive_loss: 1.4168524742126465
	train_negative_loss: 0.07593376189470291
	train_correct_acc: 0.9924658338084255
	train_incorrect_acc: 0.024537587376668234
	train_positive_acc: 0.9937961552490728
	train_negative_acc: 0.41170134570772715
	train_correct_nonzero: 15747
	train_incorrect_nonzero: 254
	train_positive_nonzero: 7835
	train_negative_nonzero: 8166
val:
	val_positive_loss: 0.008071557618677616
	val_negative_loss: 0.05894462391734123
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.014155950397253036
	test_negative_loss: 0.08096236735582352
	test_positive_acc: 0.995754357298475
	test_negative_acc: 0.9866312555198151
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.0216973889619112
	train_incorrect_loss: 5.008923530578613
	train_positive_loss: 1.8838125467300415
	train_negative_loss: 0.02359747514128685
	train_correct_acc: 0.9946920052061077
	train_incorrect_acc: 0.013164443024987166
	train_positive_acc: 0.9932677544920963
	train_negative_acc: 0.4092753753217841
	train_correct_nonzero: 14986
	train_incorrect_nonzero: 76
	train_positive_nonzero: 6985
	train_negative_nonzero: 8077
val:
	val_positive_loss: 7.358362927334383e-05
	val_negative_loss: 0.02248120680451393
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0027423992287367582
	test_negative_loss: 0.09332053363323212
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9672730989577298
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.017742248252034187
	train_incorrect_loss: 7.2297444343566895
	train_positive_loss: 2.7227299213409424
	train_negative_loss: 0.005129375495016575
	train_correct_acc: 0.9946805152353333
	train_incorrect_acc: 0.008862101113410757
	train_positive_acc: 0.9928264906348904
	train_negative_acc: 0.4068189187921929
	train_correct_nonzero: 13962
	train_incorrect_nonzero: 1
	train_positive_nonzero: 5912
	train_negative_nonzero: 8051
val:
	val_positive_loss: 0.050151024013757706
	val_negative_loss: 0.00044221209827810526
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.026118706911802292
	test_negative_loss: 0.012377174571156502
	test_positive_acc: 0.9922917946418333
	test_negative_acc: 0.99598589289881
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.02056964486837387
	train_incorrect_loss: 9.463990211486816
	train_positive_loss: 3.559211015701294
	train_negative_loss: 0.000268684234470129
	train_correct_acc: 0.9944155689256321
	train_incorrect_acc: 0.00711887061758758
	train_positive_acc: 0.992265840538432
	train_negative_acc: 0.4055420095990581
	train_correct_nonzero: 12054
	train_incorrect_nonzero: 0
	train_positive_nonzero: 4004
	train_negative_nonzero: 8050
val:
	val_positive_loss: 0.038153693079948425
	val_negative_loss: 0.00017353927250951529
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0241556279361248
	test_negative_loss: 0.01796436309814453
	test_positive_acc: 0.9922917946418333
	test_negative_acc: 0.9948066476157911
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.026710590347647667
	train_incorrect_loss: 10.723121643066406
	train_positive_loss: 4.036938667297363
	train_negative_loss: 8.782347140368074e-05
	train_correct_acc: 0.9932062175868223
	train_incorrect_acc: 0.0054859166527822505
	train_positive_acc: 0.9904830000612779
	train_negative_acc: 0.4046285453135313
	train_correct_nonzero: 13959
	train_incorrect_nonzero: 6
	train_positive_nonzero: 5910
	train_negative_nonzero: 8055
val:
	val_positive_loss: 0.048577919602394104
	val_negative_loss: 7.315582479350269e-05
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.030406076461076736
	test_negative_loss: 0.014926166273653507
	test_positive_acc: 0.9871754978647023
	test_negative_acc: 0.99598589289881
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.02779844030737877
	train_incorrect_loss: 11.481690406799316
	train_positive_loss: 4.321633815765381
	train_negative_loss: 4.7606277803424746e-05
	train_correct_acc: 0.9934310938476463
	train_incorrect_acc: 0.0056671821696390534
	train_positive_acc: 0.990805276936496
	train_negative_acc: 0.40410097554007335
	train_correct_nonzero: 12591
	train_incorrect_nonzero: 2
	train_positive_nonzero: 4550
	train_negative_nonzero: 8043
val:
	val_positive_loss: 0.05277540534734726
	val_negative_loss: 4.206198354950175e-05
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.030604833737015724
	test_negative_loss: 0.016110140830278397
	test_positive_acc: 0.9871754978647023
	test_negative_acc: 0.99598589289881
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.02819451317191124
	train_incorrect_loss: 11.989883422851562
	train_positive_loss: 4.51265287399292
	train_negative_loss: 3.3644224458839744e-05
	train_correct_acc: 0.9932926325424528
	train_incorrect_acc: 0.006094064564227387
	train_positive_acc: 0.99057418796026
	train_negative_acc: 0.40438567520000795
	train_correct_nonzero: 11037
	train_incorrect_nonzero: 4
	train_positive_nonzero: 3027
	train_negative_nonzero: 8014
val:
	val_positive_loss: 0.052637018263339996
	val_negative_loss: 2.6582378268358298e-05
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03336404636502266
	test_negative_loss: 0.015301072970032692
	test_positive_acc: 0.9871754978647023
	test_negative_acc: 0.99598589289881
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.02900085598230362
	train_incorrect_loss: 8.770288467407227
	train_positive_loss: 3.2938780784606934
	train_negative_loss: 0.021614210680127144
	train_correct_acc: 0.9931750352835882
	train_incorrect_acc: 0.013089973700777581
	train_positive_acc: 0.9915564611784087
	train_negative_acc: 0.4081172604135827
	train_correct_nonzero: 12896
	train_incorrect_nonzero: 75
	train_positive_nonzero: 4931
	train_negative_nonzero: 8040
val:
	val_positive_loss: 0.016238681972026825
	val_negative_loss: 0.002193639986217022
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.012521965429186821
	test_negative_loss: 0.02080361358821392
	test_positive_acc: 0.996630029935951
	test_negative_acc: 0.9913286033398319
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.019811315461993217
	train_incorrect_loss: 7.739676475524902
	train_positive_loss: 2.912341833114624
	train_negative_loss: 0.016667062416672707
	train_correct_acc: 0.9948153211865121
	train_incorrect_acc: 0.017151859511506672
	train_positive_acc: 0.9940279119944365
	train_negative_acc: 0.4107322841988081
	train_correct_nonzero: 12132
	train_incorrect_nonzero: 31
	train_positive_nonzero: 4117
	train_negative_nonzero: 8046
val:
	val_positive_loss: 0.011183606460690498
	val_negative_loss: 0.005484560504555702
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01737491972744465
	test_negative_loss: 0.031406354159116745
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9895860689846521
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.33826494216919 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.625
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233368396759033
	train_negative_loss: 2.280108690261841
	train_positive_acc: 0.7194141765259525
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.20742838084697723
	train_incorrect_loss: 1.827830195426941
	train_positive_loss: 0.8054113388061523
	train_negative_loss: 0.3196184039115906
	train_correct_acc: 0.9516443842422077
	train_incorrect_acc: 0.12418458156316753
	train_positive_acc: 0.9793975022779069
	train_negative_acc: 0.40907881022709003
	train_correct_nonzero: 11826
	train_incorrect_nonzero: 1179
	train_positive_nonzero: 4889
	train_negative_nonzero: 8116
val:
	val_positive_loss: 0.008706476539373398
	val_negative_loss: 0.1480485051870346
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.012631433084607124
	test_negative_loss: 0.1669977605342865
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9705578557270724
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.04572245851159096
	train_incorrect_loss: 3.0211234092712402
	train_positive_loss: 1.174757480621338
	train_negative_loss: 0.10250088572502136
	train_correct_acc: 0.9925659604753595
	train_incorrect_acc: 0.027810664985494532
	train_positive_acc: 0.9946056626756984
	train_negative_acc: 0.38942640410587803
	train_correct_nonzero: 14873
	train_incorrect_nonzero: 372
	train_positive_nonzero: 7516
	train_negative_nonzero: 7729
val:
	val_positive_loss: 0.0982716828584671
	val_negative_loss: 0.30811405181884766
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.07304725795984268
	test_negative_loss: 0.3090147376060486
	test_positive_acc: 0.9915630480604585
	test_negative_acc: 0.9885428343666197
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02334722690284252
	train_incorrect_loss: 4.298271179199219
	train_positive_loss: 1.6596362590789795
	train_negative_loss: 0.03928525373339653
	train_correct_acc: 0.9951043931205509
	train_incorrect_acc: 0.020964745084743906
	train_positive_acc: 0.9950761706470163
	train_negative_acc: 0.38853228207845447
	train_correct_nonzero: 13762
	train_incorrect_nonzero: 106
	train_positive_nonzero: 6247
	train_negative_nonzero: 7621
val:
	val_positive_loss: 0.003944964148104191
	val_negative_loss: 0.026013925671577454
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.006861007306724787
	test_negative_loss: 0.08011061698198318
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9745636822695544
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.023316683247685432
	train_incorrect_loss: 4.5079450607299805
	train_positive_loss: 1.7442389726638794
	train_negative_loss: 0.038436610251665115
	train_correct_acc: 0.995037340282235
	train_incorrect_acc: 0.02453897186461221
	train_positive_acc: 0.995063461504294
	train_negative_acc: 0.39013858789462785
	train_correct_nonzero: 13126
	train_incorrect_nonzero: 97
	train_positive_nonzero: 5620
	train_negative_nonzero: 7603
val:
	val_positive_loss: 0.021296575665473938
	val_negative_loss: 0.01013382151722908
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.013241427019238472
	test_negative_loss: 0.041114442050457
	test_positive_acc: 0.9965374373433584
	test_negative_acc: 0.9846080173781744
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.019734535366296768
	train_incorrect_loss: 5.369426727294922
	train_positive_loss: 2.074354410171509
	train_negative_loss: 0.017056403681635857
	train_correct_acc: 0.9944680528413807
	train_incorrect_acc: 0.021645701162157766
	train_positive_acc: 0.9935014090712374
	train_negative_acc: 0.3886333808162935
	train_correct_nonzero: 12489
	train_incorrect_nonzero: 86
	train_positive_nonzero: 4974
	train_negative_nonzero: 7601
val:
	val_positive_loss: 0.055154602974653244
	val_negative_loss: 0.004043862223625183
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.08099867403507233
	test_negative_loss: 0.01582689955830574
	test_positive_acc: 0.9682653098895825
	test_negative_acc: 0.9929127082218516
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.021973568946123123
	train_incorrect_loss: 6.748873233795166
	train_positive_loss: 2.6092071533203125
	train_negative_loss: 0.007852710783481598
	train_correct_acc: 0.9930203724048976
	train_incorrect_acc: 0.017281146285620018
	train_positive_acc: 0.9909925368933619
	train_negative_acc: 0.38677204036686075
	train_correct_nonzero: 11202
	train_incorrect_nonzero: 27
	train_positive_nonzero: 3658
	train_negative_nonzero: 7571
val:
	val_positive_loss: 0.006272105034440756
	val_negative_loss: 0.003943049348890781
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.012964406982064247
	test_negative_loss: 0.055970095098018646
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9810359299402538
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.01973077282309532
	train_incorrect_loss: 5.988966941833496
	train_positive_loss: 2.316790819168091
	train_negative_loss: 0.022636670619249344
	train_correct_acc: 0.994138447874426
	train_incorrect_acc: 0.02492539138972995
	train_positive_acc: 0.9937955109639915
	train_negative_acc: 0.3895763269884845
	train_correct_nonzero: 14092
	train_incorrect_nonzero: 86
	train_positive_nonzero: 6552
	train_negative_nonzero: 7626
val:
	val_positive_loss: 0.012001977302134037
	val_negative_loss: 0.006163095124065876
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01132110133767128
	test_negative_loss: 0.04975393787026405
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9847113188752888
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.02272365614771843
	train_incorrect_loss: 6.181585788726807
	train_positive_loss: 2.383836030960083
	train_negative_loss: 0.03251564875245094
	train_correct_acc: 0.9957241740826724
	train_incorrect_acc: 0.025031946322843113
	train_positive_acc: 0.995111637626537
	train_negative_acc: 0.39045271235565715
	train_correct_nonzero: 16292
	train_incorrect_nonzero: 161
	train_positive_nonzero: 8829
	train_negative_nonzero: 7624
val:
	val_positive_loss: 0.027526922523975372
	val_negative_loss: 0.005002055782824755
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.020861582830548286
	test_negative_loss: 0.040434107184410095
	test_positive_acc: 0.9950493421052631
	test_negative_acc: 0.9859323614414843
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.013803362846374512
	train_incorrect_loss: 7.637657642364502
	train_positive_loss: 2.940427303314209
	train_negative_loss: 0.0031290375627577305
	train_correct_acc: 0.9965142603819603
	train_incorrect_acc: 0.018260700819242272
	train_positive_acc: 0.9954462579767507
	train_negative_acc: 0.3876102491695953
	train_correct_nonzero: 15369
	train_incorrect_nonzero: 58
	train_positive_nonzero: 7824
	train_negative_nonzero: 7603
val:
	val_positive_loss: 0.018043475225567818
	val_negative_loss: 0.0006198667688295245
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01726069673895836
	test_negative_loss: 0.046678654849529266
	test_positive_acc: 0.9965374373433584
	test_negative_acc: 0.9892590006786839
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.011715532280504704
	train_incorrect_loss: 7.527796745300293
	train_positive_loss: 2.8939857482910156
	train_negative_loss: 0.0032881952356547117
	train_correct_acc: 0.9965712856252846
	train_incorrect_acc: 0.018372617100845277
	train_positive_acc: 0.995580096429688
	train_negative_acc: 0.3879376697559231
	train_correct_nonzero: 13136
	train_incorrect_nonzero: 32
	train_positive_nonzero: 5587
	train_negative_nonzero: 7581
val:
	val_positive_loss: 0.03659000247716904
	val_negative_loss: 0.0003901784657500684
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03330080583691597
	test_negative_loss: 0.030070563778281212
	test_positive_acc: 0.99259741902834
	test_negative_acc: 0.992462801865569
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.30768203735352 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.65
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233320713043213
	train_negative_loss: 2.280116558074951
	train_positive_acc: 0.7213377320008312
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.21906335651874542
	train_incorrect_loss: 1.7866289615631104
	train_positive_loss: 0.8107100129127502
	train_negative_loss: 0.3378165662288666
	train_correct_acc: 0.9525664676116633
	train_incorrect_acc: 0.13051588922849386
	train_positive_acc: 0.9803547409369994
	train_negative_acc: 0.3921786921397197
	train_correct_nonzero: 11536
	train_incorrect_nonzero: 1207
	train_positive_nonzero: 5055
	train_negative_nonzero: 7688
val:
	val_positive_loss: 0.0065584564581513405
	val_negative_loss: 0.12444495409727097
	val_positive_acc: 1.0
	val_negative_acc: 0.9672131147540983
test:
	test_positive_loss: 0.013417198322713375
	test_negative_loss: 0.17253756523132324
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9538162813493078
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.05258919671177864
	train_incorrect_loss: 2.744349718093872
	train_positive_loss: 1.0942583084106445
	train_negative_loss: 0.12505672872066498
	train_correct_acc: 0.9920102641507013
	train_incorrect_acc: 0.02476505265466249
	train_positive_acc: 0.9938135439897732
	train_negative_acc: 0.36292507446322625
	train_correct_nonzero: 13240
	train_incorrect_nonzero: 473
	train_positive_nonzero: 6436
	train_negative_nonzero: 7277
val:
	val_positive_loss: 0.015868665650486946
	val_negative_loss: 0.05799521878361702
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.019253898411989212
	test_negative_loss: 0.08282582461833954
	test_positive_acc: 0.9938778628752734
	test_negative_acc: 0.9799375552045244
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02949478290975094
	train_incorrect_loss: 3.8571252822875977
	train_positive_loss: 1.524950623512268
	train_negative_loss: 0.06037908419966698
	train_correct_acc: 0.9932165391210197
	train_incorrect_acc: 0.025223513276515036
	train_positive_acc: 0.9948078260242582
	train_negative_acc: 0.3648093774345301
	train_correct_nonzero: 15464
	train_incorrect_nonzero: 187
	train_positive_nonzero: 8499
	train_negative_nonzero: 7152
val:
	val_positive_loss: 0.0021232259459793568
	val_negative_loss: 0.06116796284914017
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.008121883496642113
	test_negative_loss: 0.0980883538722992
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9687263587873057
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.01968744769692421
	train_incorrect_loss: 4.617921352386475
	train_positive_loss: 1.8240505456924438
	train_negative_loss: 0.03621599078178406
	train_correct_acc: 0.9952150363937515
	train_incorrect_acc: 0.02807858574086232
	train_positive_acc: 0.9963085568679373
	train_negative_acc: 0.36744257159662325
	train_correct_nonzero: 17273
	train_incorrect_nonzero: 161
	train_positive_nonzero: 10291
	train_negative_nonzero: 7143
val:
	val_positive_loss: 0.009298639371991158
	val_negative_loss: 0.04596535861492157
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.013104194775223732
	test_negative_loss: 0.1044817715883255
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9600625355087598
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.018397631123661995
	train_incorrect_loss: 5.066986560821533
	train_positive_loss: 2.005802869796753
	train_negative_loss: 0.02323906496167183
	train_correct_acc: 0.9952950829541343
	train_incorrect_acc: 0.029191627765815863
	train_positive_acc: 0.9951594051034544
	train_negative_acc: 0.3685717809354071
	train_correct_nonzero: 15098
	train_incorrect_nonzero: 90
	train_positive_nonzero: 8070
	train_negative_nonzero: 7118
val:
	val_positive_loss: 0.01600523106753826
	val_negative_loss: 0.011977044865489006
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03842119500041008
	test_negative_loss: 0.02885562554001808
	test_positive_acc: 0.98492031716819
	test_negative_acc: 0.9873937863513866
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.015612890012562275
	train_incorrect_loss: 6.206438064575195
	train_positive_loss: 2.451272487640381
	train_negative_loss: 0.009519188664853573
	train_correct_acc: 0.9954780763857509
	train_incorrect_acc: 0.022237065587117362
	train_positive_acc: 0.9944094791155139
	train_negative_acc: 0.36566501157073744
	train_correct_nonzero: 11691
	train_incorrect_nonzero: 31
	train_positive_nonzero: 4648
	train_negative_nonzero: 7074
val:
	val_positive_loss: 0.0012725491542369127
	val_negative_loss: 0.017434876412153244
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.008174289017915726
	test_negative_loss: 0.09133905172348022
	test_positive_acc: 0.9977015856950067
	test_negative_acc: 0.9720320974376262
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.012510253116488457
	train_incorrect_loss: 6.5792107582092285
	train_positive_loss: 2.5943214893341064
	train_negative_loss: 0.010074981488287449
	train_correct_acc: 0.9964837293417965
	train_incorrect_acc: 0.026570045655007337
	train_positive_acc: 0.9963497425894078
	train_negative_acc: 0.3670489410929795
	train_correct_nonzero: 12361
	train_incorrect_nonzero: 50
	train_positive_nonzero: 5317
	train_negative_nonzero: 7094
val:
	val_positive_loss: 7.232958159875125e-05
	val_negative_loss: 0.03894849866628647
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.008604316040873528
	test_negative_loss: 0.12795642018318176
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9621972669321401
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.013277146965265274
	train_incorrect_loss: 6.10933256149292
	train_positive_loss: 2.4091320037841797
	train_negative_loss: 0.02064964920282364
	train_correct_acc: 0.9960249701527784
	train_incorrect_acc: 0.0358214510230964
	train_positive_acc: 0.9967229038587545
	train_negative_acc: 0.372136001188472
	train_correct_nonzero: 13390
	train_incorrect_nonzero: 77
	train_positive_nonzero: 6345
	train_negative_nonzero: 7122
val:
	val_positive_loss: 0.01169557124376297
	val_negative_loss: 0.035165440291166306
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.010744872502982616
	test_negative_loss: 0.08197776228189468
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9745670673519633
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.014521517790853977
	train_incorrect_loss: 7.218015193939209
	train_positive_loss: 2.8482158184051514
	train_negative_loss: 0.0071092816069722176
	train_correct_acc: 0.9953737883822433
	train_incorrect_acc: 0.021363111649661766
	train_positive_acc: 0.9941457826009138
	train_negative_acc: 0.36517175182833883
	train_correct_nonzero: 13232
	train_incorrect_nonzero: 22
	train_positive_nonzero: 6185
	train_negative_nonzero: 7069
val:
	val_positive_loss: 0.014129281975328922
	val_negative_loss: 0.0006726604187861085
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.025709213688969612
	test_negative_loss: 0.045792106539011
	test_positive_acc: 0.9940009278002699
	test_negative_acc: 0.989650617841302
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.016862627118825912
	train_incorrect_loss: 11.738616943359375
	train_positive_loss: 4.623686790466309
	train_negative_loss: 0.00014560621639247984
	train_correct_acc: 0.9954683192410121
	train_incorrect_acc: 0.01799114749168175
	train_positive_acc: 0.9939170688022541
	train_negative_acc: 0.3633391163949521
	train_correct_nonzero: 11856
	train_incorrect_nonzero: 18
	train_positive_nonzero: 5114
	train_negative_nonzero: 6760
val:
	val_positive_loss: 0.019140569493174553
	val_negative_loss: 0.0002444390265736729
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.023416485637426376
	test_negative_loss: 0.06500959396362305
	test_positive_acc: 0.996299342105263
	test_negative_acc: 0.9876191955812326
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.23999047279358 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.675
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2332677841186523
	train_negative_loss: 2.2801103591918945
	train_positive_acc: 0.7237692101672392
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.22573159635066986
	train_incorrect_loss: 1.8184318542480469
	train_positive_loss: 0.8411728143692017
	train_negative_loss: 0.3640483319759369
	train_correct_acc: 0.943761210367118
	train_incorrect_acc: 0.161557855519726
	train_positive_acc: 0.9750044358827055
	train_negative_acc: 0.38695293730034097
	train_correct_nonzero: 12272
	train_incorrect_nonzero: 1199
	train_positive_nonzero: 6236
	train_negative_nonzero: 7235
val:
	val_positive_loss: 0.009203849360346794
	val_negative_loss: 0.06896568834781647
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02017660066485405
	test_negative_loss: 0.08157680928707123
	test_positive_acc: 0.9961458333333333
	test_negative_acc: 0.9821188836836414
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.0371989831328392
	train_incorrect_loss: 3.0890071392059326
	train_positive_loss: 1.2552850246429443
	train_negative_loss: 0.08418125659227371
	train_correct_acc: 0.9931969853603927
	train_incorrect_acc: 0.023722908274908267
	train_positive_acc: 0.9951310034055219
	train_negative_acc: 0.33862318019540816
	train_correct_nonzero: 14352
	train_incorrect_nonzero: 290
	train_positive_nonzero: 7947
	train_negative_nonzero: 6695
val:
	val_positive_loss: 0.01068506296724081
	val_negative_loss: 0.07868316769599915
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.008131679147481918
	test_negative_loss: 0.1060364693403244
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9750331173437736
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.021985864266753197
	train_incorrect_loss: 4.089955806732178
	train_positive_loss: 1.6540476083755493
	train_negative_loss: 0.039563920348882675
	train_correct_acc: 0.9953955613190987
	train_incorrect_acc: 0.025080077169772935
	train_positive_acc: 0.9952001789641497
	train_negative_acc: 0.34282386436654133
	train_correct_nonzero: 12661
	train_incorrect_nonzero: 112
	train_positive_nonzero: 6157
	train_negative_nonzero: 6616
val:
	val_positive_loss: 0.0032326513901352882
	val_negative_loss: 0.016305197030305862
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.011483833193778992
	test_negative_loss: 0.0538388229906559
	test_positive_acc: 0.9965374373433584
	test_negative_acc: 0.9842847778844206
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.020471900701522827
	train_incorrect_loss: 4.943763256072998
	train_positive_loss: 2.0008766651153564
	train_negative_loss: 0.034645918756723404
	train_correct_acc: 0.9943191283983184
	train_incorrect_acc: 0.03051638005434863
	train_positive_acc: 0.9946089493018963
	train_negative_acc: 0.3454162672573981
	train_correct_nonzero: 13299
	train_incorrect_nonzero: 101
	train_positive_nonzero: 6792
	train_negative_nonzero: 6608
val:
	val_positive_loss: 0.03007105365395546
	val_negative_loss: 0.00937618687748909
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.012020139023661613
	test_negative_loss: 0.04278770089149475
	test_positive_acc: 0.9950493421052631
	test_negative_acc: 0.9842994227002362
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.013533217832446098
	train_incorrect_loss: 6.262204647064209
	train_positive_loss: 2.5246503353118896
	train_negative_loss: 0.019301168620586395
	train_correct_acc: 0.9962885123419264
	train_incorrect_acc: 0.031115152019884445
	train_positive_acc: 0.9963858050995772
	train_negative_acc: 0.34577204360149544
	train_correct_nonzero: 15866
	train_incorrect_nonzero: 69
	train_positive_nonzero: 9322
	train_negative_nonzero: 6613
val:
	val_positive_loss: 0.05981059744954109
	val_negative_loss: 0.001750480616465211
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.007548273075371981
	test_negative_loss: 0.06014730781316757
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9843206016744284
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.012853411026299
	train_incorrect_loss: 7.650338649749756
	train_positive_loss: 3.0862231254577637
	train_negative_loss: 0.010201739147305489
	train_correct_acc: 0.9965439190261433
	train_incorrect_acc: 0.030325432836855324
	train_positive_acc: 0.9962348878044132
	train_negative_acc: 0.34637247739980354
	train_correct_nonzero: 12441
	train_incorrect_nonzero: 61
	train_positive_nonzero: 5895
	train_negative_nonzero: 6607
val:
	val_positive_loss: 0.0013777852291241288
	val_negative_loss: 0.11416357010602951
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.0008102909196168184
	test_negative_loss: 0.19499537348747253
	test_positive_acc: 1.0
	test_negative_acc: 0.9605597184879591
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.021348318085074425
	train_incorrect_loss: 11.185216903686523
	train_positive_loss: 4.510355472564697
	train_negative_loss: 0.0009631734574213624
	train_correct_acc: 0.9954199142954375
	train_incorrect_acc: 0.02328845501573001
	train_positive_acc: 0.9939581098483752
	train_negative_acc: 0.3416458170956838
	train_correct_nonzero: 10245
	train_incorrect_nonzero: 36
	train_positive_nonzero: 3942
	train_negative_nonzero: 6339
val:
	val_positive_loss: 0.08675719052553177
	val_negative_loss: 0.010076317936182022
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.014540580101311207
	test_negative_loss: 0.07198148965835571
	test_positive_acc: 0.996299342105263
	test_negative_acc: 0.9865982216931766
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.026592230424284935
	train_incorrect_loss: 12.75480842590332
	train_positive_loss: 5.150141716003418
	train_negative_loss: 7.194634235929698e-05
	train_correct_acc: 0.9951318708568472
	train_incorrect_acc: 0.021022710821223468
	train_positive_acc: 0.9935241135754301
	train_negative_acc: 0.34047469049757423
	train_correct_nonzero: 10269
	train_incorrect_nonzero: 45
	train_positive_nonzero: 4496
	train_negative_nonzero: 5818
val:
	val_positive_loss: 0.09419038146734238
	val_negative_loss: 0.009343847632408142
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.01581532321870327
	test_negative_loss: 0.07704851031303406
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9865982216931766
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.029607277363538742
	train_incorrect_loss: 13.579968452453613
	train_positive_loss: 5.479318141937256
	train_negative_loss: 4.0334227378480136e-05
	train_correct_acc: 0.9948286955633805
	train_incorrect_acc: 0.020397609820127706
	train_positive_acc: 0.9931698204065346
	train_negative_acc: 0.3402927018746487
	train_correct_nonzero: 9498
	train_incorrect_nonzero: 79
	train_positive_nonzero: 4233
	train_negative_nonzero: 5344
val:
	val_positive_loss: 0.09897657483816147
	val_negative_loss: 0.009331419132649899
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.01597488671541214
	test_negative_loss: 0.08284205198287964
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9861864957379725
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.030743597075343132
	train_incorrect_loss: 14.230076789855957
	train_positive_loss: 5.740208625793457
	train_negative_loss: 2.375078656768892e-05
	train_correct_acc: 0.9948593538821413
	train_incorrect_acc: 0.02006082607104589
	train_positive_acc: 0.99324761908491
	train_negative_acc: 0.3400136725921653
	train_correct_nonzero: 8099
	train_incorrect_nonzero: 62
	train_positive_nonzero: 3251
	train_negative_nonzero: 4910
val:
	val_positive_loss: 0.10268501937389374
	val_negative_loss: 0.008951039053499699
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.01648576743900776
	test_negative_loss: 0.08569487929344177
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9861864957379725
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 91.47967481613159 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.7
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233198642730713
	train_negative_loss: 2.2801876068115234
	train_positive_acc: 0.726779143718844
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.2154330015182495
	train_incorrect_loss: 1.7346159219741821
	train_positive_loss: 0.8181552886962891
	train_negative_loss: 0.3497985005378723
	train_correct_acc: 0.9596256665608551
	train_incorrect_acc: 0.12344292678318125
	train_positive_acc: 0.9831426994221577
	train_negative_acc: 0.3536112732513899
	train_correct_nonzero: 10752
	train_incorrect_nonzero: 1108
	train_positive_nonzero: 5145
	train_negative_nonzero: 6715
val:
	val_positive_loss: 0.011704115197062492
	val_negative_loss: 0.2045864462852478
	val_positive_acc: 1.0
	val_negative_acc: 0.959016393442623
test:
	test_positive_loss: 0.017574340105056763
	test_negative_loss: 0.21478617191314697
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9529774655083398
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.04180857911705971
	train_incorrect_loss: 2.9350385665893555
	train_positive_loss: 1.2193806171417236
	train_negative_loss: 0.10290653258562088
	train_correct_acc: 0.9921357164612598
	train_incorrect_acc: 0.03352822345578287
	train_positive_acc: 0.9949826299586173
	train_negative_acc: 0.3199608791989625
	train_correct_nonzero: 14147
	train_incorrect_nonzero: 351
	train_positive_nonzero: 8209
	train_negative_nonzero: 6289
val:
	val_positive_loss: 0.006378921680152416
	val_negative_loss: 0.03143811225891113
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.015324098989367485
	test_negative_loss: 0.046864937990903854
	test_positive_acc: 0.9975541413373861
	test_negative_acc: 0.9843694355336565
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.033990465104579926
	train_incorrect_loss: 4.145556926727295
	train_positive_loss: 1.7176822423934937
	train_negative_loss: 0.08742205798625946
	train_correct_acc: 0.9908554946068394
	train_incorrect_acc: 0.043692617069654764
	train_positive_acc: 0.9942213437520707
	train_negative_acc: 0.3268900743533585
	train_correct_nonzero: 12295
	train_incorrect_nonzero: 266
	train_positive_nonzero: 6326
	train_negative_nonzero: 6235
val:
	val_positive_loss: 0.04061643406748772
	val_negative_loss: 0.302706778049469
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04916572570800781
	test_negative_loss: 0.3191581666469574
	test_positive_acc: 0.9914515844131606
	test_negative_acc: 0.97752892823049
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.028956567868590355
	train_incorrect_loss: 4.284993648529053
	train_positive_loss: 1.7708488702774048
	train_negative_loss: 0.06217101961374283
	train_correct_acc: 0.9930182458566148
	train_incorrect_acc: 0.034103773582684564
	train_positive_acc: 0.9943035951383122
	train_negative_acc: 0.322072073928454
	train_correct_nonzero: 13001
	train_incorrect_nonzero: 135
	train_positive_nonzero: 6985
	train_negative_nonzero: 6151
val:
	val_positive_loss: 9.89243999356404e-05
	val_negative_loss: 0.06401115655899048
	val_positive_acc: 1.0
	val_negative_acc: 0.9672131147540983
test:
	test_positive_loss: 0.0012866980396211147
	test_negative_loss: 0.11634847521781921
	test_positive_acc: 1.0
	test_negative_acc: 0.9634045459792357
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.019335828721523285
	train_incorrect_loss: 5.384622573852539
	train_positive_loss: 2.225242853164673
	train_negative_loss: 0.028154127299785614
	train_correct_acc: 0.9948586788646531
	train_incorrect_acc: 0.027288422891595266
	train_positive_acc: 0.9952684453673523
	train_negative_acc: 0.31823277588721705
	train_correct_nonzero: 11384
	train_incorrect_nonzero: 98
	train_positive_nonzero: 5351
	train_negative_nonzero: 6131
val:
	val_positive_loss: 0.0008927958551794291
	val_negative_loss: 0.009639929980039597
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.008307784795761108
	test_negative_loss: 0.04391056299209595
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.984472006713188
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.02313021756708622
	train_incorrect_loss: 7.3293375968933105
	train_positive_loss: 3.029465436935425
	train_negative_loss: 0.006432788912206888
	train_correct_acc: 0.9934618737323319
	train_incorrect_acc: 0.01627697421821294
	train_positive_acc: 0.9919796256170478
	train_negative_acc: 0.312841849225624
	train_correct_nonzero: 13446
	train_incorrect_nonzero: 56
	train_positive_nonzero: 7403
	train_negative_nonzero: 6099
val:
	val_positive_loss: 0.00011329745757393539
	val_negative_loss: 0.0026468588039278984
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.006916285026818514
	test_negative_loss: 0.050217416137456894
	test_positive_acc: 0.996671365914787
	test_negative_acc: 0.9839654880380647
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.03494156524538994
	train_incorrect_loss: 13.624598503112793
	train_positive_loss: 5.620612144470215
	train_negative_loss: 9.08330111997202e-05
	train_correct_acc: 0.9935758131636605
	train_incorrect_acc: 0.012116301950069056
	train_positive_acc: 0.9917092289348338
	train_negative_acc: 0.30971563290494303
	train_correct_nonzero: 8147
	train_incorrect_nonzero: 31
	train_positive_nonzero: 3238
	train_negative_nonzero: 4940
val:
	val_positive_loss: 0.0005410524900071323
	val_negative_loss: 0.00012390370829962194
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01822243258357048
	test_negative_loss: 0.039108045399188995
	test_positive_acc: 0.9942450874526743
	test_negative_acc: 0.991899670871605
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.03933893144130707
	train_incorrect_loss: 15.718887329101562
	train_positive_loss: 6.491382598876953
	train_negative_loss: 1.0732145710790064e-05
	train_correct_acc: 0.993979144521891
	train_incorrect_acc: 0.012406372227413434
	train_positive_acc: 0.992222030685567
	train_negative_acc: 0.3101899739948791
	train_correct_nonzero: 4036
	train_incorrect_nonzero: 9
	train_positive_nonzero: 382
	train_negative_nonzero: 3663
val:
	val_positive_loss: 0.0031780696008354425
	val_negative_loss: 2.6180770873907022e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.029094774276018143
	test_negative_loss: 0.028761086985468864
	test_positive_acc: 0.9924068521585565
	test_negative_acc: 0.9933531592436982
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.046525854617357254
	train_incorrect_loss: 17.147602081298828
	train_positive_loss: 7.080275535583496
	train_negative_loss: 2.9184411687310785e-06
	train_correct_acc: 0.992851069867711
	train_incorrect_acc: 0.011406896430752909
	train_positive_acc: 0.9907533906974596
	train_negative_acc: 0.30948910458712964
	train_correct_nonzero: 4615
	train_incorrect_nonzero: 34
	train_positive_nonzero: 1953
	train_negative_nonzero: 2696
val:
	val_positive_loss: 0.002717018825933337
	val_negative_loss: 1.6720921848900616e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.030346892774105072
	test_negative_loss: 0.03012211248278618
	test_positive_acc: 0.9924068521585565
	test_negative_acc: 0.991899670871605
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.048926688730716705
	train_incorrect_loss: 18.004947662353516
	train_positive_loss: 7.433028697967529
	train_negative_loss: 1.7474585547461174e-06
	train_correct_acc: 0.9929963868272632
	train_incorrect_acc: 0.011585115884980974
	train_positive_acc: 0.9909842602777627
	train_negative_acc: 0.3099892378364815
	train_correct_nonzero: 3785
	train_incorrect_nonzero: 35
	train_positive_nonzero: 1652
	train_negative_nonzero: 2168
val:
	val_positive_loss: 0.0024960387963801622
	val_negative_loss: 1.3061009667580947e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.031113848090171814
	test_negative_loss: 0.031025568023324013
	test_positive_acc: 0.9924068521585565
	test_negative_acc: 0.991899670871605
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.51340079307556 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.725
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233133554458618
	train_negative_loss: 2.280287981033325
	train_positive_acc: 0.7292751257673277
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.21718138456344604
	train_incorrect_loss: 1.9090691804885864
	train_positive_loss: 0.9059159159660339
	train_negative_loss: 0.368667334318161
	train_correct_acc: 0.9474275024736456
	train_incorrect_acc: 0.17533359956274336
	train_positive_acc: 0.9813679805206462
	train_negative_acc: 0.35626246268991285
	train_correct_nonzero: 10121
	train_incorrect_nonzero: 1034
	train_positive_nonzero: 4896
	train_negative_nonzero: 6259
val:
	val_positive_loss: 0.0010997517965734005
	val_negative_loss: 0.08207398653030396
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.004214922897517681
	test_negative_loss: 0.12654784321784973
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9577187358446246
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.02838175743818283
	train_incorrect_loss: 3.799163579940796
	train_positive_loss: 1.60104238986969
	train_negative_loss: 0.06262338161468506
	train_correct_acc: 0.9933127641856973
	train_incorrect_acc: 0.02480391274058398
	train_positive_acc: 0.9944666048480378
	train_negative_acc: 0.29197530981797765
	train_correct_nonzero: 11586
	train_incorrect_nonzero: 185
	train_positive_nonzero: 6104
	train_negative_nonzero: 5667
val:
	val_positive_loss: 0.0016160337254405022
	val_negative_loss: 0.012717178091406822
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.013815702870488167
	test_negative_loss: 0.03722543269395828
	test_positive_acc: 0.9964576501093159
	test_negative_acc: 0.9864109928644091
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.028841974213719368
	train_incorrect_loss: 4.188370704650879
	train_positive_loss: 1.7702107429504395
	train_negative_loss: 0.08022749423980713
	train_correct_acc: 0.9942584348748715
	train_incorrect_acc: 0.026571131597104267
	train_positive_acc: 0.9953146292099552
	train_negative_acc: 0.29396649843567035
	train_correct_nonzero: 10390
	train_incorrect_nonzero: 278
	train_positive_nonzero: 4908
	train_negative_nonzero: 5760
val:
	val_positive_loss: 0.003674885490909219
	val_negative_loss: 0.08096379786729813
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.011953627690672874
	test_negative_loss: 0.11879552900791168
	test_positive_acc: 0.9965374373433584
	test_negative_acc: 0.9780031441248975
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.020406432449817657
	train_incorrect_loss: 4.570526123046875
	train_positive_loss: 1.928635597229004
	train_negative_loss: 0.04240178316831589
	train_correct_acc: 0.9940310539766993
	train_incorrect_acc: 0.028459573436066223
	train_positive_acc: 0.9943478495096107
	train_negative_acc: 0.29551504017500496
	train_correct_nonzero: 10960
	train_incorrect_nonzero: 112
	train_positive_nonzero: 5424
	train_negative_nonzero: 5648
val:
	val_positive_loss: 0.00047235877718776464
	val_negative_loss: 0.028629571199417114
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.0027559848967939615
	test_negative_loss: 0.09856340289115906
	test_positive_acc: 1.0
	test_negative_acc: 0.9616775188596922
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.025631925091147423
	train_incorrect_loss: 4.319241046905518
	train_positive_loss: 1.8185425996780396
	train_negative_loss: 0.0667652040719986
	train_correct_acc: 0.9943086841309579
	train_incorrect_acc: 0.03384508136940957
	train_positive_acc: 0.9948904674208309
	train_negative_acc: 0.29848124666657927
	train_correct_nonzero: 12031
	train_incorrect_nonzero: 180
	train_positive_nonzero: 6537
	train_negative_nonzero: 5674
val:
	val_positive_loss: 0.0019128748681396246
	val_negative_loss: 0.006149232853204012
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03512321412563324
	test_negative_loss: 0.03573554754257202
	test_positive_acc: 0.9837006486369588
	test_negative_acc: 0.9897376321016087
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.02007707953453064
	train_incorrect_loss: 4.944793224334717
	train_positive_loss: 2.0869133472442627
	train_negative_loss: 0.02501802146434784
	train_correct_acc: 0.9945102382492752
	train_incorrect_acc: 0.02531958954691129
	train_positive_acc: 0.993872303474621
	train_negative_acc: 0.2944292276820651
	train_correct_nonzero: 11246
	train_incorrect_nonzero: 115
	train_positive_nonzero: 5729
	train_negative_nonzero: 5632
val:
	val_positive_loss: 4.713728412752971e-05
	val_negative_loss: 0.05893361568450928
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.001108627300709486
	test_negative_loss: 0.17613667249679565
	test_positive_acc: 1.0
	test_negative_acc: 0.944574635822871
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.018276430666446686
	train_incorrect_loss: 5.757317066192627
	train_positive_loss: 2.4248719215393066
	train_negative_loss: 0.017880884930491447
	train_correct_acc: 0.994789999525213
	train_incorrect_acc: 0.033114887186549036
	train_positive_acc: 0.9948071898575446
	train_negative_acc: 0.29905355488821345
	train_correct_nonzero: 12146
	train_incorrect_nonzero: 64
	train_positive_nonzero: 6603
	train_negative_nonzero: 5607
val:
	val_positive_loss: 0.008934475481510162
	val_negative_loss: 0.001078569795936346
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.021076075732707977
	test_negative_loss: 0.042155634611845016
	test_positive_acc: 0.9903739642397957
	test_negative_acc: 0.9884355487682754
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.028374869376420975
	train_incorrect_loss: 7.714320182800293
	train_positive_loss: 3.2588047981262207
	train_negative_loss: 0.013190343044698238
	train_correct_acc: 0.992895486257469
	train_incorrect_acc: 0.027529643858997477
	train_positive_acc: 0.9921689183298525
	train_negative_acc: 0.29528255934763786
	train_correct_nonzero: 12540
	train_incorrect_nonzero: 81
	train_positive_nonzero: 6996
	train_negative_nonzero: 5625
val:
	val_positive_loss: 0.012752866372466087
	val_negative_loss: 0.03242627531290054
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.0067141298204660416
	test_negative_loss: 0.13481616973876953
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9607301508820998
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.019651055335998535
	train_incorrect_loss: 6.3896708488464355
	train_positive_loss: 2.6914446353912354
	train_negative_loss: 0.013741916976869106
	train_correct_acc: 0.994640862993142
	train_incorrect_acc: 0.035419627809886715
	train_positive_acc: 0.9942255876129402
	train_negative_acc: 0.30123532543798304
	train_correct_nonzero: 13550
	train_incorrect_nonzero: 93
	train_positive_nonzero: 8008
	train_negative_nonzero: 5635
val:
	val_positive_loss: 0.0011142764706164598
	val_negative_loss: 0.003725959686562419
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.017201324924826622
	test_negative_loss: 0.056478410959243774
	test_positive_acc: 0.9950493421052631
	test_negative_acc: 0.9833912714303239
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.0252717062830925
	train_incorrect_loss: 8.045010566711426
	train_positive_loss: 3.3890559673309326
	train_negative_loss: 0.00822001788765192
	train_correct_acc: 0.9937541504966857
	train_incorrect_acc: 0.029184331779148504
	train_positive_acc: 0.9925843184431001
	train_negative_acc: 0.29741084720822075
	train_correct_nonzero: 12139
	train_incorrect_nonzero: 58
	train_positive_nonzero: 6594
	train_negative_nonzero: 5603
val:
	val_positive_loss: 8.356617036042735e-05
	val_negative_loss: 0.06442257761955261
	val_positive_acc: 1.0
	val_negative_acc: 0.9789827658680117
test:
	test_positive_loss: 0.01021675206720829
	test_negative_loss: 0.24368157982826233
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9353097874343008
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.53744769096375 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.75
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233088493347168
	train_negative_loss: 2.2801828384399414
	train_positive_acc: 0.7311465810586171
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.22857962548732758
	train_incorrect_loss: 1.6823066473007202
	train_positive_loss: 0.829261839389801
	train_negative_loss: 0.3929453194141388
	train_correct_acc: 0.9541161793058903
	train_incorrect_acc: 0.15343318523120078
	train_positive_acc: 0.980804395821252
	train_negative_acc: 0.3288185416160552
	train_correct_nonzero: 9890
	train_incorrect_nonzero: 1070
	train_positive_nonzero: 5130
	train_negative_nonzero: 5830
val:
	val_positive_loss: 0.016277452930808067
	val_negative_loss: 0.10432839393615723
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.027758635580539703
	test_negative_loss: 0.11940380185842514
	test_positive_acc: 0.9976339285714286
	test_negative_acc: 0.9759708097614189
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03748847916722298
	train_incorrect_loss: 3.1636807918548584
	train_positive_loss: 1.3676493167877197
	train_negative_loss: 0.09278867393732071
	train_correct_acc: 0.9914025349001806
	train_incorrect_acc: 0.030682612453392124
	train_positive_acc: 0.9937730498339821
	train_negative_acc: 0.27022313464131
	train_correct_nonzero: 14320
	train_incorrect_nonzero: 310
	train_positive_nonzero: 9335
	train_negative_nonzero: 5295
val:
	val_positive_loss: 0.006897037848830223
	val_negative_loss: 0.013839833438396454
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.021102746948599815
	test_negative_loss: 0.03234247863292694
	test_positive_acc: 0.9954409461152882
	test_negative_acc: 0.9894183422552529
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.019717853516340256
	train_incorrect_loss: 4.543454170227051
	train_positive_loss: 1.9490960836410522
	train_negative_loss: 0.035188354551792145
	train_correct_acc: 0.9943936199496286
	train_incorrect_acc: 0.02555855961892704
	train_positive_acc: 0.9948776985184
	train_negative_acc: 0.26965490467690756
	train_correct_nonzero: 10914
	train_incorrect_nonzero: 74
	train_positive_nonzero: 5871
	train_negative_nonzero: 5117
val:
	val_positive_loss: 0.000490338250529021
	val_negative_loss: 0.0717402845621109
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.002036417368799448
	test_negative_loss: 0.17542687058448792
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9388302554728909
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.0284798014909029
	train_incorrect_loss: 6.171515941619873
	train_positive_loss: 2.6564905643463135
	train_negative_loss: 0.05013108253479004
	train_correct_acc: 0.9923594557032077
	train_incorrect_acc: 0.030198446854662955
	train_positive_acc: 0.9929373403318088
	train_negative_acc: 0.2721471030400134
	train_correct_nonzero: 9510
	train_incorrect_nonzero: 246
	train_positive_nonzero: 4514
	train_negative_nonzero: 5242
val:
	val_positive_loss: 0.008393628522753716
	val_negative_loss: 0.09933161735534668
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.016083693131804466
	test_negative_loss: 0.13937053084373474
	test_positive_acc: 0.9929618751740462
	test_negative_acc: 0.9636535452478082
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.022274542599916458
	train_incorrect_loss: 3.77598237991333
	train_positive_loss: 1.6239988803863525
	train_negative_loss: 0.05165613815188408
	train_correct_acc: 0.9943945695975182
	train_incorrect_acc: 0.030147597498512452
	train_positive_acc: 0.9946078554085245
	train_negative_acc: 0.272424707046122
	train_correct_nonzero: 8280
	train_incorrect_nonzero: 102
	train_positive_nonzero: 3254
	train_negative_nonzero: 5128
val:
	val_positive_loss: 0.00036358210491016507
	val_negative_loss: 0.06770747900009155
	val_positive_acc: 1.0
	val_negative_acc: 0.9789827658680117
test:
	test_positive_loss: 0.005199273582547903
	test_negative_loss: 0.11780120432376862
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9602768899974587
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.019655754789710045
	train_incorrect_loss: 5.0634846687316895
	train_positive_loss: 2.1731953620910645
	train_negative_loss: 0.03220219165086746
	train_correct_acc: 0.9937109595364727
	train_incorrect_acc: 0.031782599632504634
	train_positive_acc: 0.9940713958157725
	train_negative_acc: 0.27373318549751624
	train_correct_nonzero: 10934
	train_incorrect_nonzero: 73
	train_positive_nonzero: 5898
	train_negative_nonzero: 5109
val:
	val_positive_loss: 3.6323792301118374e-05
	val_negative_loss: 0.056429557502269745
	val_positive_acc: 1.0
	val_negative_acc: 0.9743589743589743
test:
	test_positive_loss: 0.0030501889996230602
	test_negative_loss: 0.13533736765384674
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9594174332395561
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.01747943088412285
	train_incorrect_loss: 6.140569686889648
	train_positive_loss: 2.6300201416015625
	train_negative_loss: 0.019784729927778244
	train_correct_acc: 0.9949956913772496
	train_incorrect_acc: 0.026454634181004195
	train_positive_acc: 0.9951162606650595
	train_negative_acc: 0.27017224460943495
	train_correct_nonzero: 11300
	train_incorrect_nonzero: 58
	train_positive_nonzero: 6257
	train_negative_nonzero: 5101
val:
	val_positive_loss: 0.0006711550522595644
	val_negative_loss: 0.0009214727906510234
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.014368576928973198
	test_negative_loss: 0.03448203206062317
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9891292962721662
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.018748164176940918
	train_incorrect_loss: 6.596868991851807
	train_positive_loss: 2.834200620651245
	train_negative_loss: 0.019059766083955765
	train_correct_acc: 0.994535839811231
	train_incorrect_acc: 0.03226329386657743
	train_positive_acc: 0.9946869699485351
	train_negative_acc: 0.2742425655962971
	train_correct_nonzero: 12046
	train_incorrect_nonzero: 86
	train_positive_nonzero: 7004
	train_negative_nonzero: 5128
val:
	val_positive_loss: 0.02183808572590351
	val_negative_loss: 0.01972290873527527
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.005512803792953491
	test_negative_loss: 0.09685574471950531
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9697989648149654
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.018198706209659576
	train_incorrect_loss: 6.776866436004639
	train_positive_loss: 2.9034085273742676
	train_negative_loss: 0.008563713170588017
	train_correct_acc: 0.9949041202268771
	train_incorrect_acc: 0.027188880473895696
	train_positive_acc: 0.9938961045214504
	train_negative_acc: 0.271804169491386
	train_correct_nonzero: 9713
	train_incorrect_nonzero: 62
	train_positive_nonzero: 4668
	train_negative_nonzero: 5107
val:
	val_positive_loss: 0.0041987039148807526
	val_negative_loss: 0.0021637713070958853
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.023389233276247978
	test_negative_loss: 0.056685496121644974
	test_positive_acc: 0.9915935203928625
	test_negative_acc: 0.9787894459112689
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.035176895558834076
	train_incorrect_loss: 9.617171287536621
	train_positive_loss: 4.135433673858643
	train_negative_loss: 0.0008564892923459411
	train_correct_acc: 0.9907150377605881
	train_incorrect_acc: 0.016113233955881167
	train_positive_acc: 0.9884558530547728
	train_negative_acc: 0.2638351500572247
	train_correct_nonzero: 12360
	train_incorrect_nonzero: 43
	train_positive_nonzero: 7315
	train_negative_nonzero: 5088
val:
	val_positive_loss: 0.0007824189378879964
	val_negative_loss: 0.0002684517530724406
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.023796342313289642
	test_negative_loss: 0.06297552585601807
	test_positive_acc: 0.9927954434697855
	test_negative_acc: 0.9828864030114561
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.39737915992737 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.775
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2330517768859863
	train_negative_loss: 2.279937982559204
	train_positive_acc: 0.7323999856677836
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.23655568063259125
	train_incorrect_loss: 1.7862833738327026
	train_positive_loss: 0.8908004760742188
	train_negative_loss: 0.4296129047870636
	train_correct_acc: 0.9448813375857019
	train_incorrect_acc: 0.20280335402110647
	train_positive_acc: 0.9771307821944959
	train_negative_acc: 0.33885786391348677
	train_correct_nonzero: 9719
	train_incorrect_nonzero: 1025
	train_positive_nonzero: 5387
	train_negative_nonzero: 5357
val:
	val_positive_loss: 0.009641140699386597
	val_negative_loss: 0.04878474026918411
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01891307719051838
	test_negative_loss: 0.07161867618560791
	test_positive_acc: 0.995380029935951
	test_negative_acc: 0.9773706568355269
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.030331110581755638
	train_incorrect_loss: 3.542328357696533
	train_positive_loss: 1.5556789636611938
	train_negative_loss: 0.078722283244133
	train_correct_acc: 0.9925472211557279
	train_incorrect_acc: 0.02844771298290142
	train_positive_acc: 0.994466217547884
	train_negative_acc: 0.245383072655547
	train_correct_nonzero: 11235
	train_incorrect_nonzero: 185
	train_positive_nonzero: 6738
	train_negative_nonzero: 4682
val:
	val_positive_loss: 0.0009789690375328064
	val_negative_loss: 0.10734912008047104
	val_positive_acc: 1.0
	val_negative_acc: 0.9543926019335855
test:
	test_positive_loss: 0.0017803222872316837
	test_negative_loss: 0.16245166957378387
	test_positive_acc: 1.0
	test_negative_acc: 0.9409440777954257
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.022118395194411278
	train_incorrect_loss: 4.752516746520996
	train_positive_loss: 2.0753955841064453
	train_negative_loss: 0.05281462147831917
	train_correct_acc: 0.9937339159315656
	train_incorrect_acc: 0.032755438303976356
	train_positive_acc: 0.9950578247015286
	train_negative_acc: 0.24958770685275045
	train_correct_nonzero: 10061
	train_incorrect_nonzero: 168
	train_positive_nonzero: 5555
	train_negative_nonzero: 4674
val:
	val_positive_loss: 0.00829196535050869
	val_negative_loss: 0.358043372631073
	val_positive_acc: 1.0
	val_negative_acc: 0.9625893232450609
test:
	test_positive_loss: 0.0077563319355249405
	test_negative_loss: 0.38566678762435913
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9611854469261875
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.02219933085143566
	train_incorrect_loss: 6.352905750274658
	train_positive_loss: 2.786975383758545
	train_negative_loss: 0.023319631814956665
	train_correct_acc: 0.9939594943112084
	train_incorrect_acc: 0.020410266385167294
	train_positive_acc: 0.9933653269065388
	train_negative_acc: 0.24169025714126816
	train_correct_nonzero: 11463
	train_incorrect_nonzero: 46
	train_positive_nonzero: 6916
	train_negative_nonzero: 4593
val:
	val_positive_loss: 0.05841019004583359
	val_negative_loss: 0.011832503601908684
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.019900258630514145
	test_negative_loss: 0.020684463903307915
	test_positive_acc: 0.9940502427019084
	test_negative_acc: 0.9878398638954549
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.030630534514784813
	train_incorrect_loss: 9.643348693847656
	train_positive_loss: 4.226369380950928
	train_negative_loss: 0.0004034696030430496
	train_correct_acc: 0.9924423478237134
	train_incorrect_acc: 0.013041379065585739
	train_positive_acc: 0.9908122766958539
	train_negative_acc: 0.23662789660130296
	train_correct_nonzero: 10220
	train_incorrect_nonzero: 15
	train_positive_nonzero: 5673
	train_negative_nonzero: 4562
val:
	val_positive_loss: 0.04711903631687164
	val_negative_loss: 0.003028004663065076
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02756926789879799
	test_negative_loss: 0.017041774466633797
	test_positive_acc: 0.9940502427019084
	test_negative_acc: 0.9932015961267415
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.03056403063237667
	train_incorrect_loss: 9.433584213256836
	train_positive_loss: 4.131506443023682
	train_negative_loss: 0.0038022692315280437
	train_correct_acc: 0.9922049186145407
	train_incorrect_acc: 0.015532797020402873
	train_positive_acc: 0.9906091726207642
	train_negative_acc: 0.23857022455095334
	train_correct_nonzero: 9572
	train_incorrect_nonzero: 38
	train_positive_nonzero: 5028
	train_negative_nonzero: 4582
val:
	val_positive_loss: 0.01020534336566925
	val_negative_loss: 0.002736986381933093
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02422209456562996
	test_negative_loss: 0.03289183974266052
	test_positive_acc: 0.9930139585073795
	test_negative_acc: 0.9875694496185952
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.03909033536911011
	train_incorrect_loss: 8.722993850708008
	train_positive_loss: 3.8226897716522217
	train_negative_loss: 0.018103377893567085
	train_correct_acc: 0.9895583268228905
	train_incorrect_acc: 0.016605906862395617
	train_positive_acc: 0.9878708716824912
	train_negative_acc: 0.23887949920579307
	train_correct_nonzero: 9990
	train_incorrect_nonzero: 52
	train_positive_nonzero: 5458
	train_negative_nonzero: 4584
val:
	val_positive_loss: 0.014971435070037842
	val_negative_loss: 0.026548665016889572
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.012293495237827301
	test_negative_loss: 0.03483819216489792
	test_positive_acc: 0.9940502427019084
	test_negative_acc: 0.9896638602776848
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.025641562417149544
	train_incorrect_loss: 9.625675201416016
	train_positive_loss: 4.197453022003174
	train_negative_loss: 0.03897650167346001
	train_correct_acc: 0.9937703724828633
	train_incorrect_acc: 0.01926162717228054
	train_positive_acc: 0.9940968658018834
	train_negative_acc: 0.2399680007743129
	train_correct_nonzero: 7747
	train_incorrect_nonzero: 164
	train_positive_nonzero: 3472
	train_negative_nonzero: 4439
val:
	val_positive_loss: 0.005382034461945295
	val_negative_loss: 0.05170005187392235
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.006185340695083141
	test_negative_loss: 0.06601310521364212
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9771228287975077
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.03391709178686142
	train_incorrect_loss: 5.5058674812316895
	train_positive_loss: 2.409107208251953
	train_negative_loss: 0.10214845091104507
	train_correct_acc: 0.9936166568851884
	train_incorrect_acc: 0.028409091044022648
	train_positive_acc: 0.995258545630767
	train_negative_acc: 0.24564440680208918
	train_correct_nonzero: 10566
	train_incorrect_nonzero: 165
	train_positive_nonzero: 6050
	train_negative_nonzero: 4681
val:
	val_positive_loss: 0.00045350834261626005
	val_negative_loss: 0.06094078719615936
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.005046254955232143
	test_negative_loss: 0.07307399809360504
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9723142272197138
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.01830746792256832
	train_incorrect_loss: 5.783357620239258
	train_positive_loss: 2.532139539718628
	train_negative_loss: 0.027595466002821922
	train_correct_acc: 0.9955603143058024
	train_incorrect_acc: 0.03329014523777221
	train_positive_acc: 0.9964648228274513
	train_negative_acc: 0.2508339376992103
	train_correct_nonzero: 13655
	train_incorrect_nonzero: 130
	train_positive_nonzero: 9111
	train_negative_nonzero: 4674
val:
	val_positive_loss: 0.00045819327351637185
	val_negative_loss: 0.034617334604263306
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.008517946116626263
	test_negative_loss: 0.06670262664556503
	test_positive_acc: 0.9964765211640212
	test_negative_acc: 0.9746267589250606
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.15358209609985 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.8
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2329845428466797
	train_negative_loss: 2.279938220977783
	train_positive_acc: 0.7351557951388837
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.2333812713623047
	train_incorrect_loss: 1.518052577972412
	train_positive_loss: 0.7803177833557129
	train_negative_loss: 0.45239531993865967
	train_correct_acc: 0.9525651501087994
	train_incorrect_acc: 0.21993952114743587
	train_positive_acc: 0.984950754190078
	train_negative_acc: 0.33730902257589457
	train_correct_nonzero: 7965
	train_incorrect_nonzero: 980
	train_positive_nonzero: 4135
	train_negative_nonzero: 4810
val:
	val_positive_loss: 0.004864503629505634
	val_negative_loss: 0.20876732468605042
	val_positive_acc: 1.0
	val_negative_acc: 0.9415720891130728
test:
	test_positive_loss: 0.008801048621535301
	test_negative_loss: 0.2585684657096863
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9321973397144271
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03188413381576538
	train_incorrect_loss: 3.029296636581421
	train_positive_loss: 1.3547494411468506
	train_negative_loss: 0.10138989984989166
	train_correct_acc: 0.9931216796633912
	train_incorrect_acc: 0.05148919023536977
	train_positive_acc: 0.995758434466844
	train_negative_acc: 0.23888272015888365
	train_correct_nonzero: 11826
	train_incorrect_nonzero: 279
	train_positive_nonzero: 7826
	train_negative_nonzero: 4279
val:
	val_positive_loss: 0.013096927665174007
	val_negative_loss: 0.04566546529531479
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.02224661037325859
	test_negative_loss: 0.06998570263385773
	test_positive_acc: 0.9924695548712206
	test_negative_acc: 0.97605864268723
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.021217942237854004
	train_incorrect_loss: 4.08752965927124
	train_positive_loss: 1.8183801174163818
	train_negative_loss: 0.04713835194706917
	train_correct_acc: 0.9942402901643462
	train_incorrect_acc: 0.04371418601757003
	train_positive_acc: 0.9949704489004157
	train_negative_acc: 0.23494537725410364
	train_correct_nonzero: 10870
	train_incorrect_nonzero: 159
	train_positive_nonzero: 6844
	train_negative_nonzero: 4185
val:
	val_positive_loss: 2.9501845347112976e-05
	val_negative_loss: 0.16657541692256927
	val_positive_acc: 1.0
	val_negative_acc: 0.9344262295081966
test:
	test_positive_loss: 0.001325936638750136
	test_negative_loss: 0.33758240938186646
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9175868796567046
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.021768731996417046
	train_incorrect_loss: 5.815730571746826
	train_positive_loss: 2.5922882556915283
	train_negative_loss: 0.02603738009929657
	train_correct_acc: 0.9930662216818824
	train_incorrect_acc: 0.0341239680950328
	train_positive_acc: 0.9932618093897178
	train_negative_acc: 0.22759464379687724
	train_correct_nonzero: 11483
	train_incorrect_nonzero: 65
	train_positive_nonzero: 7436
	train_negative_nonzero: 4112
val:
	val_positive_loss: 0.0014909072779119015
	val_negative_loss: 0.03664206340909004
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.013700969517230988
	test_negative_loss: 0.07738751918077469
	test_positive_acc: 0.996630029935951
	test_negative_acc: 0.9772921007710795
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.023601137101650238
	train_incorrect_loss: 7.125411510467529
	train_positive_loss: 3.172734260559082
	train_negative_loss: 0.012976829893887043
	train_correct_acc: 0.9928994009407258
	train_incorrect_acc: 0.031486212935859424
	train_positive_acc: 0.9923537684062759
	train_negative_acc: 0.22585091883982977
	train_correct_nonzero: 10915
	train_incorrect_nonzero: 31
	train_positive_nonzero: 6866
	train_negative_nonzero: 4080
val:
	val_positive_loss: 4.2136607589782216e-06
	val_negative_loss: 0.0774366557598114
	val_positive_acc: 1.0
	val_negative_acc: 0.9707860445565364
test:
	test_positive_loss: 0.003546142252162099
	test_negative_loss: 0.13370491564273834
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9587981462583396
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.022652221843600273
	train_incorrect_loss: 7.221632957458496
	train_positive_loss: 3.210268497467041
	train_negative_loss: 0.01630435697734356
	train_correct_acc: 0.9932648080647352
	train_incorrect_acc: 0.030952779812494606
	train_positive_acc: 0.9932402341191571
	train_negative_acc: 0.22535779686331167
	train_correct_nonzero: 9901
	train_incorrect_nonzero: 59
	train_positive_nonzero: 5853
	train_negative_nonzero: 4107
val:
	val_positive_loss: 0.001051548752002418
	val_negative_loss: 0.03746000677347183
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.014188388362526894
	test_negative_loss: 0.06449931114912033
	test_positive_acc: 0.9953002427019084
	test_negative_acc: 0.9806965313013118
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.020555667579174042
	train_incorrect_loss: 7.911309242248535
	train_positive_loss: 3.5229380130767822
	train_negative_loss: 0.005771388299763203
	train_correct_acc: 0.994605490079347
	train_incorrect_acc: 0.03455793190733133
	train_positive_acc: 0.9937504403553559
	train_negative_acc: 0.22892535302831593
	train_correct_nonzero: 9942
	train_incorrect_nonzero: 57
	train_positive_nonzero: 5892
	train_negative_nonzero: 4107
val:
	val_positive_loss: 4.0820967114996165e-05
	val_negative_loss: 0.06411567330360413
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.006268410012125969
	test_negative_loss: 0.1793609857559204
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9558415056757451
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.019590532407164574
	train_incorrect_loss: 9.193072319030762
	train_positive_loss: 4.089210510253906
	train_negative_loss: 0.0006751136388629675
	train_correct_acc: 0.9950845493775198
	train_incorrect_acc: 0.03318445909796686
	train_positive_acc: 0.9940943984298657
	train_negative_acc: 0.2284357705089519
	train_correct_nonzero: 9122
	train_incorrect_nonzero: 41
	train_positive_nonzero: 5073
	train_negative_nonzero: 4090
val:
	val_positive_loss: 0.00013324768224265426
	val_negative_loss: 0.030221465975046158
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.015619099140167236
	test_negative_loss: 0.12343032658100128
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9747430476035415
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.020344387739896774
	train_incorrect_loss: 10.708402633666992
	train_positive_loss: 4.759393215179443
	train_negative_loss: 0.00022150712902657688
	train_correct_acc: 0.9953552373708774
	train_incorrect_acc: 0.03567630106430221
	train_positive_acc: 0.9943960973364766
	train_negative_acc: 0.23057056850791094
	train_correct_nonzero: 5515
	train_incorrect_nonzero: 19
	train_positive_nonzero: 1532
	train_negative_nonzero: 4002
val:
	val_positive_loss: 2.497801324352622e-05
	val_negative_loss: 0.038492351770401
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.014130976051092148
	test_negative_loss: 0.17811283469200134
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9661514627141679
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.024358775466680527
	train_incorrect_loss: 9.147542953491211
	train_positive_loss: 4.077366828918457
	train_negative_loss: 0.02337213233113289
	train_correct_acc: 0.9944541378496421
	train_incorrect_acc: 0.040623955006241004
	train_positive_acc: 0.9942488353597239
	train_negative_acc: 0.2335988569214526
	train_correct_nonzero: 8547
	train_incorrect_nonzero: 95
	train_positive_nonzero: 4640
	train_negative_nonzero: 4002
val:
	val_positive_loss: 0.005761514417827129
	val_negative_loss: 0.008682666346430779
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.017898863181471825
	test_negative_loss: 0.1439608633518219
	test_positive_acc: 0.9950493421052631
	test_negative_acc: 0.9734371771682615
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.41308403015137 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.825
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2329533100128174
	train_negative_loss: 2.279864549636841
	train_positive_acc: 0.7370659224225704
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.2478407472372055
	train_incorrect_loss: 1.6016051769256592
	train_positive_loss: 0.836722731590271
	train_negative_loss: 0.5066846609115601
	train_correct_acc: 0.9414400143546549
	train_incorrect_acc: 0.2970140231492654
	train_positive_acc: 0.9824998335828775
	train_negative_acc: 0.36957663220144205
	train_correct_nonzero: 8902
	train_incorrect_nonzero: 1033
	train_positive_nonzero: 5533
	train_negative_nonzero: 4402
val:
	val_positive_loss: 0.00390806095674634
	val_negative_loss: 0.07776433974504471
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.012263674288988113
	test_negative_loss: 0.10691139101982117
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9695420284134565
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.029098933562636375
	train_incorrect_loss: 3.3353521823883057
	train_positive_loss: 1.5175296068191528
	train_negative_loss: 0.09426423162221909
	train_correct_acc: 0.9927753394959491
	train_incorrect_acc: 0.043774204612065826
	train_positive_acc: 0.9946606526180624
	train_negative_acc: 0.2098755822538102
	train_correct_nonzero: 9258
	train_incorrect_nonzero: 188
	train_positive_nonzero: 5731
	train_negative_nonzero: 3715
val:
	val_positive_loss: 0.004178810864686966
	val_negative_loss: 0.027693510055541992
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.013736434280872345
	test_negative_loss: 0.06287150084972382
	test_positive_acc: 0.9948331306206692
	test_negative_acc: 0.9789330034052455
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02264062874019146
	train_incorrect_loss: 4.145602703094482
	train_positive_loss: 1.8794269561767578
	train_negative_loss: 0.0657603070139885
	train_correct_acc: 0.9946053046804227
	train_incorrect_acc: 0.0436113895135288
	train_positive_acc: 0.9956775826096019
	train_negative_acc: 0.21108721915184386
	train_correct_nonzero: 8828
	train_incorrect_nonzero: 161
	train_positive_nonzero: 5309
	train_negative_nonzero: 3680
val:
	val_positive_loss: 0.00037097700987942517
	val_negative_loss: 0.07398899644613266
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.003876921720802784
	test_negative_loss: 0.17289382219314575
	test_positive_acc: 0.99875
	test_negative_acc: 0.9405272008899624
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.015197974629700184
	train_incorrect_loss: 5.352177619934082
	train_positive_loss: 2.422485589981079
	train_negative_loss: 0.03500671684741974
	train_correct_acc: 0.9953249610326506
	train_incorrect_acc: 0.04753035823625524
	train_positive_acc: 0.9964560487232194
	train_negative_acc: 0.2140655492760094
	train_correct_nonzero: 8592
	train_incorrect_nonzero: 79
	train_positive_nonzero: 5046
	train_negative_nonzero: 3625
val:
	val_positive_loss: 0.0009720646194182336
	val_negative_loss: 0.014834991656243801
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01602233201265335
	test_negative_loss: 0.07787157595157623
	test_positive_acc: 0.996299342105263
	test_negative_acc: 0.9725878751897483
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.0177767314016819
	train_incorrect_loss: 4.152684211730957
	train_positive_loss: 1.8782715797424316
	train_negative_loss: 0.06460542976856232
	train_correct_acc: 0.9951732655107327
	train_incorrect_acc: 0.06910633122415345
	train_positive_acc: 0.9974732281357477
	train_negative_acc: 0.2303513451250478
	train_correct_nonzero: 9022
	train_incorrect_nonzero: 177
	train_positive_nonzero: 5487
	train_negative_nonzero: 3712
val:
	val_positive_loss: 0.0007072155713103712
	val_negative_loss: 0.08999082446098328
	val_positive_acc: 1.0
	val_negative_acc: 0.9672131147540983
test:
	test_positive_loss: 0.0025389064103364944
	test_negative_loss: 0.21438565850257874
	test_positive_acc: 1.0
	test_negative_acc: 0.9154893788199896
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.012894951738417149
	train_incorrect_loss: 5.740514278411865
	train_positive_loss: 2.59256649017334
	train_negative_loss: 0.03127457574009895
	train_correct_acc: 0.9961774343160053
	train_incorrect_acc: 0.06323603516939637
	train_positive_acc: 0.9970200492496457
	train_negative_acc: 0.227574013760657
	train_correct_nonzero: 9109
	train_incorrect_nonzero: 86
	train_positive_nonzero: 5561
	train_negative_nonzero: 3634
val:
	val_positive_loss: 0.00020456186030060053
	val_negative_loss: 0.04454914107918739
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.0048862481489777565
	test_negative_loss: 0.13769285380840302
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.956004861497834
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.014796535484492779
	train_incorrect_loss: 7.060807228088379
	train_positive_loss: 3.1914124488830566
	train_negative_loss: 0.01772715151309967
	train_correct_acc: 0.9953132413252702
	train_incorrect_acc: 0.051961695230564375
	train_positive_acc: 0.995635284823718
	train_negative_acc: 0.21812351971496008
	train_correct_nonzero: 8935
	train_incorrect_nonzero: 90
	train_positive_nonzero: 5385
	train_negative_nonzero: 3640
val:
	val_positive_loss: 0.0003366349556017667
	val_negative_loss: 0.0481896735727787
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.015089836902916431
	test_negative_loss: 0.10921388864517212
	test_positive_acc: 0.9949695548712205
	test_negative_acc: 0.9711895269353521
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.015200980938971043
	train_incorrect_loss: 8.125055313110352
	train_positive_loss: 3.669445753097534
	train_negative_loss: 0.00923765730112791
	train_correct_acc: 0.9959363298823036
	train_incorrect_acc: 0.048980838733128564
	train_positive_acc: 0.9955469783468804
	train_negative_acc: 0.2171987692516076
	train_correct_nonzero: 7426
	train_incorrect_nonzero: 89
	train_positive_nonzero: 3877
	train_negative_nonzero: 3638
val:
	val_positive_loss: 4.888942203251645e-05
	val_negative_loss: 0.0350830964744091
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.01178872399032116
	test_negative_loss: 0.14660723507404327
	test_positive_acc: 0.9949695548712205
	test_negative_acc: 0.9659316256944934
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.015235147438943386
	train_incorrect_loss: 8.700711250305176
	train_positive_loss: 3.9246275424957275
	train_negative_loss: 0.012558403424918652
	train_correct_acc: 0.9952103706030039
	train_incorrect_acc: 0.05106790429545474
	train_positive_acc: 0.9951881594491718
	train_negative_acc: 0.21846582823368718
	train_correct_nonzero: 9091
	train_incorrect_nonzero: 85
	train_positive_nonzero: 5559
	train_negative_nonzero: 3617
val:
	val_positive_loss: 0.00010706509056035429
	val_negative_loss: 0.023898189887404442
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.026584800332784653
	test_negative_loss: 0.1337263435125351
	test_positive_acc: 0.9926034834426491
	test_negative_acc: 0.968993955659957
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.013290809467434883
	train_incorrect_loss: 8.3909912109375
	train_positive_loss: 3.78790020942688
	train_negative_loss: 0.010069843381643295
	train_correct_acc: 0.9960447651773038
	train_incorrect_acc: 0.054478385862725985
	train_positive_acc: 0.9959034057543505
	train_negative_acc: 0.22134774527848491
	train_correct_nonzero: 9028
	train_incorrect_nonzero: 107
	train_positive_nonzero: 5496
	train_negative_nonzero: 3639
val:
	val_positive_loss: 1.935178806888871e-05
	val_negative_loss: 0.04251420125365257
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.0160909965634346
	test_negative_loss: 0.1845989227294922
	test_positive_acc: 0.9939332706766917
	test_negative_acc: 0.9654902625692379
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.51290583610535 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.85
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2329137325286865
	train_negative_loss: 2.2799253463745117
	train_positive_acc: 0.7389251857273365
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.24893616139888763
	train_incorrect_loss: 1.490423321723938
	train_positive_loss: 0.7985647916793823
	train_negative_loss: 0.5285535454750061
	train_correct_acc: 0.9534033783442736
	train_incorrect_acc: 0.26978824090449555
	train_positive_acc: 0.9855299167363107
	train_negative_acc: 0.34232053142078744
	train_correct_nonzero: 6400
	train_incorrect_nonzero: 908
	train_positive_nonzero: 3474
	train_negative_nonzero: 3834
val:
	val_positive_loss: 0.03779914602637291
	val_negative_loss: 0.11239023506641388
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.04898662120103836
	test_negative_loss: 0.12185896933078766
	test_positive_acc: 0.9965374373433584
	test_negative_acc: 0.982338013273587
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03396068885922432
	train_incorrect_loss: 3.0244064331054688
	train_positive_loss: 1.3999903202056885
	train_negative_loss: 0.12125977873802185
	train_correct_acc: 0.991555010397164
	train_incorrect_acc: 0.0606836535033535
	train_positive_acc: 0.9949330999544671
	train_negative_acc: 0.19853676370514964
	train_correct_nonzero: 11070
	train_incorrect_nonzero: 293
	train_positive_nonzero: 8059
	train_negative_nonzero: 3304
val:
	val_positive_loss: 0.0002557814586907625
	val_negative_loss: 0.20507198572158813
	val_positive_acc: 1.0
	val_negative_acc: 0.9298024379991593
test:
	test_positive_loss: 0.0016886575613170862
	test_negative_loss: 0.359488844871521
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.8783639548063185
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.022029178217053413
	train_incorrect_loss: 4.445298671722412
	train_positive_loss: 2.0475995540618896
	train_negative_loss: 0.0567675344645977
	train_correct_acc: 0.9931339051509447
	train_incorrect_acc: 0.05370058119665218
	train_positive_acc: 0.9947305379678527
	train_negative_acc: 0.195530574616818
	train_correct_nonzero: 9655
	train_incorrect_nonzero: 119
	train_positive_nonzero: 6622
	train_negative_nonzero: 3152
val:
	val_positive_loss: 0.014805970713496208
	val_negative_loss: 0.10788141191005707
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.02072255313396454
	test_negative_loss: 0.13669969141483307
	test_positive_acc: 0.9954213659147869
	test_negative_acc: 0.9697962170219951
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.028222568333148956
	train_incorrect_loss: 4.520116329193115
	train_positive_loss: 2.080092430114746
	train_negative_loss: 0.1032712534070015
	train_correct_acc: 0.9919859666872115
	train_incorrect_acc: 0.0757944167938174
	train_positive_acc: 0.9953596215810295
	train_negative_acc: 0.2114712535602929
	train_correct_nonzero: 13233
	train_incorrect_nonzero: 247
	train_positive_nonzero: 10199
	train_negative_nonzero: 3281
val:
	val_positive_loss: 0.0014354800805449486
	val_negative_loss: 0.09000927209854126
	val_positive_acc: 1.0
	val_negative_acc: 0.9672131147540983
test:
	test_positive_loss: 0.003909081686288118
	test_negative_loss: 0.1674429327249527
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9422977198931035
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.015937721356749535
	train_incorrect_loss: 5.934593677520752
	train_positive_loss: 2.7239091396331787
	train_negative_loss: 0.03273380920290947
	train_correct_acc: 0.9952470515627629
	train_incorrect_acc: 0.07286915406141757
	train_positive_acc: 0.9963988225119652
	train_negative_acc: 0.2121239801516455
	train_correct_nonzero: 13795
	train_incorrect_nonzero: 237
	train_positive_nonzero: 10750
	train_negative_nonzero: 3282
val:
	val_positive_loss: 0.00015462006558664143
	val_negative_loss: 0.09943807870149612
	val_positive_acc: 1.0
	val_negative_acc: 0.9625893232450609
test:
	test_positive_loss: 0.011194802820682526
	test_negative_loss: 0.2611832618713379
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9317774891043128
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.028266647830605507
	train_incorrect_loss: 8.778321266174316
	train_positive_loss: 4.041606426239014
	train_negative_loss: 0.03189069405198097
	train_correct_acc: 0.9933303408277355
	train_incorrect_acc: 0.06107282797796732
	train_positive_acc: 0.9941291957501479
	train_negative_acc: 0.20183788082970278
	train_correct_nonzero: 10633
	train_incorrect_nonzero: 121
	train_positive_nonzero: 7588
	train_negative_nonzero: 3166
val:
	val_positive_loss: 0.01598208397626877
	val_negative_loss: 0.04889984428882599
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.016751566901803017
	test_negative_loss: 0.09297668933868408
	test_positive_acc: 0.9954213659147869
	test_negative_acc: 0.959913055074956
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.016645628958940506
	train_incorrect_loss: 5.7610039710998535
	train_positive_loss: 2.649045705795288
	train_negative_loss: 0.03440503776073456
	train_correct_acc: 0.9946658748629581
	train_incorrect_acc: 0.07763827273371904
	train_positive_acc: 0.9955913159120522
	train_negative_acc: 0.21571203751597037
	train_correct_nonzero: 14145
	train_incorrect_nonzero: 253
	train_positive_nonzero: 11100
	train_negative_nonzero: 3298
val:
	val_positive_loss: 0.0005000869277864695
	val_negative_loss: 0.1184162050485611
	val_positive_acc: 1.0
	val_negative_acc: 0.9625893232450609
test:
	test_positive_loss: 0.0035892524756491184
	test_negative_loss: 0.219136044383049
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9309839362606255
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.01593051105737686
	train_incorrect_loss: 6.337040901184082
	train_positive_loss: 2.905705213546753
	train_negative_loss: 0.04537954926490784
	train_correct_acc: 0.9949871414556817
	train_incorrect_acc: 0.08330002731634135
	train_positive_acc: 0.9962592171787185
	train_negative_acc: 0.22104048171161791
	train_correct_nonzero: 11830
	train_incorrect_nonzero: 273
	train_positive_nonzero: 8785
	train_negative_nonzero: 3318
val:
	val_positive_loss: 0.0007674235384911299
	val_negative_loss: 0.09936095029115677
	val_positive_acc: 1.0
	val_negative_acc: 0.9625893232450609
test:
	test_positive_loss: 0.008761041797697544
	test_negative_loss: 0.18043917417526245
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9439603298484742
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.014941020868718624
	train_incorrect_loss: 8.069557189941406
	train_positive_loss: 3.70532488822937
	train_negative_loss: 0.017147917300462723
	train_correct_acc: 0.995989865818206
	train_incorrect_acc: 0.06694862639524399
	train_positive_acc: 0.9962195854684861
	train_negative_acc: 0.2084424769621918
	train_correct_nonzero: 10874
	train_incorrect_nonzero: 156
	train_positive_nonzero: 7826
	train_negative_nonzero: 3204
val:
	val_positive_loss: 0.0026716331485658884
	val_negative_loss: 0.1180248111486435
	val_positive_acc: 1.0
	val_negative_acc: 0.9672131147540983
test:
	test_positive_loss: 0.004241426475346088
	test_negative_loss: 0.28762519359588623
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9235155941167533
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.01079582143574953
	train_incorrect_loss: 7.254197120666504
	train_positive_loss: 3.328904628753662
	train_negative_loss: 0.014767387881875038
	train_correct_acc: 0.9966933149943505
	train_incorrect_acc: 0.0771348630882291
	train_positive_acc: 0.9969913618321901
	train_negative_acc: 0.21673995961495215
	train_correct_nonzero: 9481
	train_incorrect_nonzero: 175
	train_positive_nonzero: 6434
	train_negative_nonzero: 3222
val:
	val_positive_loss: 0.01581197790801525
	val_negative_loss: 0.06211797147989273
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.00867697224020958
	test_negative_loss: 0.21306274831295013
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9481057871893092
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.40133452415466 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.875
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2328531742095947
	train_negative_loss: 2.2799809871606493
	train_positive_acc: 0.7410113677003686
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.2748951017856598
	train_incorrect_loss: 1.2469288110733032
	train_positive_loss: 0.7068507075309753
	train_negative_loss: 0.6409909725189209
	train_correct_acc: 0.9502803483789298
	train_incorrect_acc: 0.34392137525411787
	train_positive_acc: 0.9857554424094288
	train_negative_acc: 0.38686852028128993
	train_correct_nonzero: 5741
	train_incorrect_nonzero: 933
	train_positive_nonzero: 3305
	train_negative_nonzero: 3369
val:
	val_positive_loss: 0.01660323515534401
	val_negative_loss: 0.08146438002586365
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.03274253010749817
	test_negative_loss: 0.10123172402381897
	test_positive_acc: 0.9926034834426491
	test_negative_acc: 0.9811641621456277
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03111783228814602
	train_incorrect_loss: 2.976491689682007
	train_positive_loss: 1.3942116498947144
	train_negative_loss: 0.16109901318675837
	train_correct_acc: 0.9911869502068502
	train_incorrect_acc: 0.0786877640598431
	train_positive_acc: 0.9965060550145475
	train_negative_acc: 0.18972954771790607
	train_correct_nonzero: 8602
	train_incorrect_nonzero: 227
	train_positive_nonzero: 6076
	train_negative_nonzero: 2753
val:
	val_positive_loss: 0.002436030888929963
	val_negative_loss: 0.2591400146484375
	val_positive_acc: 1.0
	val_negative_acc: 0.8877679697351828
test:
	test_positive_loss: 0.002919293474406004
	test_negative_loss: 0.3680264353752136
	test_positive_acc: 1.0
	test_negative_acc: 0.8378754858658652
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.021581003442406654
	train_incorrect_loss: 3.739476442337036
	train_positive_loss: 1.7460122108459473
	train_negative_loss: 0.11197710037231445
	train_correct_acc: 0.9938837732441931
	train_incorrect_acc: 0.09309358156304402
	train_positive_acc: 0.9975319051311079
	train_negative_acc: 0.20434610711537274
	train_correct_nonzero: 12240
	train_incorrect_nonzero: 372
	train_positive_nonzero: 9715
	train_negative_nonzero: 2897
val:
	val_positive_loss: 0.001203616033308208
	val_negative_loss: 0.2671095132827759
	val_positive_acc: 1.0
	val_negative_acc: 0.8841950399327448
test:
	test_positive_loss: 0.0015750003512948751
	test_negative_loss: 0.5071277618408203
	test_positive_acc: 0.9989035087719298
	test_negative_acc: 0.831166521175088
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.015553174540400505
	train_incorrect_loss: 4.839408874511719
	train_positive_loss: 2.260557174682617
	train_negative_loss: 0.06994867324829102
	train_correct_acc: 0.9951212707712641
	train_incorrect_acc: 0.10224116735007803
	train_positive_acc: 0.9974713383614563
	train_negative_acc: 0.21337457164227822
	train_correct_nonzero: 11445
	train_incorrect_nonzero: 292
	train_positive_nonzero: 8905
	train_negative_nonzero: 2832
val:
	val_positive_loss: 0.004507705103605986
	val_negative_loss: 0.06898009032011032
	val_positive_acc: 1.0
	val_negative_acc: 0.959016393442623
test:
	test_positive_loss: 0.006802703253924847
	test_negative_loss: 0.18258333206176758
	test_positive_acc: 0.9964576501093159
	test_negative_acc: 0.9366268358885188
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.02117306739091873
	train_incorrect_loss: 4.498808860778809
	train_positive_loss: 2.1001298427581787
	train_negative_loss: 0.1258436143398285
	train_correct_acc: 0.9932709871999451
	train_incorrect_acc: 0.13825709963996635
	train_positive_acc: 0.9977193197824556
	train_negative_acc: 0.24253280611797629
	train_correct_nonzero: 11515
	train_incorrect_nonzero: 450
	train_positive_nonzero: 8978
	train_negative_nonzero: 2987
val:
	val_positive_loss: 0.0046812742948532104
	val_negative_loss: 0.13201849162578583
	val_positive_acc: 1.0
	val_negative_acc: 0.9415720891130728
test:
	test_positive_loss: 0.01313316635787487
	test_negative_loss: 0.27467384934425354
	test_positive_acc: 0.9965855142664353
	test_negative_acc: 0.8841793485795402
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.018805263563990593
	train_incorrect_loss: 4.443894386291504
	train_positive_loss: 2.0743703842163086
	train_negative_loss: 0.1009792909026146
	train_correct_acc: 0.9942267893377382
	train_incorrect_acc: 0.14053152788471926
	train_positive_acc: 0.9979242187504644
	train_negative_acc: 0.24508878533723577
	train_correct_nonzero: 12436
	train_incorrect_nonzero: 491
	train_positive_nonzero: 9911
	train_negative_nonzero: 3016
val:
	val_positive_loss: 0.0070131453685462475
	val_negative_loss: 0.08372429758310318
	val_positive_acc: 1.0
	val_negative_acc: 0.9543926019335855
test:
	test_positive_loss: 0.011128897778689861
	test_negative_loss: 0.24960564076900482
	test_positive_acc: 0.9964576501093159
	test_negative_acc: 0.9090779965533995
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.015505744144320488
	train_incorrect_loss: 4.8069071769714355
	train_positive_loss: 2.244560956954956
	train_negative_loss: 0.08854035583652917
	train_correct_acc: 0.9955756566001569
	train_incorrect_acc: 0.1417908364513633
	train_positive_acc: 0.9986588882279241
	train_negative_acc: 0.2467797393779593
	train_correct_nonzero: 11159
	train_incorrect_nonzero: 454
	train_positive_nonzero: 8632
	train_negative_nonzero: 2981
val:
	val_positive_loss: 0.00036859410465694964
	val_negative_loss: 0.29311221837997437
	val_positive_acc: 1.0
	val_negative_acc: 0.8923917612442203
test:
	test_positive_loss: 0.007130763493478298
	test_negative_loss: 0.5481534600257874
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.8418426327739607
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.014008103869855404
	train_incorrect_loss: 6.157561302185059
	train_positive_loss: 2.8745083808898926
	train_negative_loss: 0.05722207576036453
	train_correct_acc: 0.9967269894748609
	train_incorrect_acc: 0.12053813350396103
	train_positive_acc: 0.997864362633091
	train_negative_acc: 0.2310886038028128
	train_correct_nonzero: 9057
	train_incorrect_nonzero: 302
	train_positive_nonzero: 6519
	train_negative_nonzero: 2840
val:
	val_positive_loss: 6.822459545219317e-05
	val_negative_loss: 0.425682008266449
	val_positive_acc: 1.0
	val_negative_acc: 0.8467843631778058
test:
	test_positive_loss: 0.005163902882486582
	test_negative_loss: 0.6978452801704407
	test_positive_acc: 0.9989035087719298
	test_negative_acc: 0.8122203145936941
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.013344300910830498
	train_incorrect_loss: 5.745991230010986
	train_positive_loss: 2.6764869689941406
	train_negative_loss: 0.058064453303813934
	train_correct_acc: 0.9964971899145223
	train_incorrect_acc: 0.12420767457256725
	train_positive_acc: 0.9977488337528969
	train_negative_acc: 0.2341920248482393
	train_correct_nonzero: 7882
	train_incorrect_nonzero: 262
	train_positive_nonzero: 5339
	train_negative_nonzero: 2805
val:
	val_positive_loss: 0.003278000745922327
	val_negative_loss: 0.09064116328954697
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.00756220705807209
	test_negative_loss: 0.3777174949645996
	test_positive_acc: 0.996671365914787
	test_negative_acc: 0.9012800322207678
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.017156250774860382
	train_incorrect_loss: 5.693511009216309
	train_positive_loss: 2.658198356628418
	train_negative_loss: 0.06736614235057459
	train_correct_acc: 0.9955254994799912
	train_incorrect_acc: 0.12908048933612243
	train_positive_acc: 0.9968890211590729
	train_negative_acc: 0.23790763584416866
	train_correct_nonzero: 8897
	train_incorrect_nonzero: 339
	train_positive_nonzero: 6356
	train_negative_nonzero: 2880
val:
	val_positive_loss: 0.000161739531904459
	val_negative_loss: 0.1929415613412857
	val_positive_acc: 1.0
	val_negative_acc: 0.9123581336696092
test:
	test_positive_loss: 0.01020100712776184
	test_negative_loss: 0.5231353044509888
	test_positive_acc: 0.9964576501093159
	test_negative_acc: 0.8816834879419588
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.20301008224487 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.9
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.232800006866455
	train_negative_loss: 2.27990967200445
	train_positive_acc: 0.7427453789211751
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.2783658504486084
	train_incorrect_loss: 1.1894139051437378
	train_positive_loss: 0.6900232434272766
	train_negative_loss: 0.6948950945086141
	train_correct_acc: 0.9533506188812356
	train_incorrect_acc: 0.43346254096399706
	train_positive_acc: 0.9899613303473539
	train_negative_acc: 0.45061142757066314
	train_correct_nonzero: 5135
	train_incorrect_nonzero: 839
	train_positive_nonzero: 3145
	train_negative_nonzero: 2829
val:
	val_positive_loss: 0.0033484469167888165
	val_negative_loss: 0.21489369869232178
	val_positive_acc: 1.0
	val_negative_acc: 0.9113072719630096
test:
	test_positive_loss: 0.00717664510011673
	test_negative_loss: 0.2936376929283142
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.8946138648511388
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03869171813130379
	train_incorrect_loss: 2.987070322036743
	train_positive_loss: 1.4207158088684082
	train_negative_loss: 0.19327318128857782
	train_correct_acc: 0.989839577797767
	train_incorrect_acc: 0.0882795625861504
	train_positive_acc: 0.99624467523769
	train_negative_acc: 0.17407145518187048
	train_correct_nonzero: 7078
	train_incorrect_nonzero: 298
	train_positive_nonzero: 5048
	train_negative_nonzero: 2328
val:
	val_positive_loss: 0.0017599693965166807
	val_negative_loss: 0.14934265613555908
	val_positive_acc: 1.0
	val_negative_acc: 0.959016393442623
test:
	test_positive_loss: 0.0028379764407873154
	test_negative_loss: 0.22179463505744934
	test_positive_acc: 1.0
	test_negative_acc: 0.9259649714845222
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.021498145535588264
	train_incorrect_loss: 3.9896273612976074
	train_positive_loss: 1.8934661149978638
	train_negative_loss: 0.09941957145929337
	train_correct_acc: 0.9936373386127072
	train_incorrect_acc: 0.07543567289141181
	train_positive_acc: 0.9962342049208747
	train_negative_acc: 0.16711368882921024
	train_correct_nonzero: 7867
	train_incorrect_nonzero: 177
	train_positive_nonzero: 5826
	train_negative_nonzero: 2218
val:
	val_positive_loss: 0.0015628450782969594
	val_negative_loss: 0.15186670422554016
	val_positive_acc: 1.0
	val_negative_acc: 0.9379991593106347
test:
	test_positive_loss: 0.0071698748506605625
	test_negative_loss: 0.17631131410598755
	test_positive_acc: 0.9959492020492408
	test_negative_acc: 0.9394561222888105
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.016480211168527603
	train_incorrect_loss: 4.789510726928711
	train_positive_loss: 2.2731032371520996
	train_negative_loss: 0.05637504979604273
	train_correct_acc: 0.9947792138008084
	train_incorrect_acc: 0.07067473989198338
	train_positive_acc: 0.9963331880829834
	train_negative_acc: 0.16347508524403284
	train_correct_nonzero: 6808
	train_incorrect_nonzero: 78
	train_positive_nonzero: 4760
	train_negative_nonzero: 2126
val:
	val_positive_loss: 0.0005355932516977191
	val_negative_loss: 0.16871201992034912
	val_positive_acc: 1.0
	val_negative_acc: 0.9461958806221101
test:
	test_positive_loss: 0.005839862860739231
	test_negative_loss: 0.20258279144763947
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.939545534779413
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.01633826456964016
	train_incorrect_loss: 4.8421711921691895
	train_positive_loss: 2.2939352989196777
	train_negative_loss: 0.06943290764263879
	train_correct_acc: 0.9955495085380771
	train_incorrect_acc: 0.0836030620572844
	train_positive_acc: 0.9970077907875471
	train_negative_acc: 0.17545744523418458
	train_correct_nonzero: 7922
	train_incorrect_nonzero: 170
	train_positive_nonzero: 5873
	train_negative_nonzero: 2219
val:
	val_positive_loss: 0.00359009369276464
	val_negative_loss: 0.15067113935947418
	val_positive_acc: 1.0
	val_negative_acc: 0.9461958806221101
test:
	test_positive_loss: 0.012007281184196472
	test_negative_loss: 0.17586737871170044
	test_positive_acc: 0.9946992020492407
	test_negative_acc: 0.9473443302259319
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.02192622795701027
	train_incorrect_loss: 6.477165222167969
	train_positive_loss: 3.0666415691375732
	train_negative_loss: 0.06519553106011956
	train_correct_acc: 0.9934916633740567
	train_incorrect_acc: 0.08089981894201112
	train_positive_acc: 0.9952509102261083
	train_negative_acc: 0.17210630777627708
	train_correct_nonzero: 6279
	train_incorrect_nonzero: 150
	train_positive_nonzero: 4231
	train_negative_nonzero: 2198
val:
	val_positive_loss: 4.820326648768969e-05
	val_negative_loss: 0.19966931641101837
	val_positive_acc: 1.0
	val_negative_acc: 0.9461958806221101
test:
	test_positive_loss: 0.001820490462705493
	test_negative_loss: 0.2684727907180786
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9361833589825924
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.01300776842981577
	train_incorrect_loss: 7.538248062133789
	train_positive_loss: 3.5692007541656494
	train_negative_loss: 0.00534427442382159
	train_correct_acc: 0.9965036468215039
	train_incorrect_acc: 0.06232597399091156
	train_positive_acc: 0.9963437632087773
	train_negative_acc: 0.1576366713383414
	train_correct_nonzero: 5177
	train_incorrect_nonzero: 59
	train_positive_nonzero: 3127
	train_negative_nonzero: 2109
val:
	val_positive_loss: 0.000293243327178061
	val_negative_loss: 0.12326711416244507
	val_positive_acc: 1.0
	val_negative_acc: 0.9707860445565364
test:
	test_positive_loss: 0.010706205852329731
	test_negative_loss: 0.17030800879001617
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9565319018807958
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.01750144362449646
	train_incorrect_loss: 8.917990684509277
	train_positive_loss: 4.227977275848389
	train_negative_loss: 0.023137010379837102
	train_correct_acc: 0.9956167439639165
	train_incorrect_acc: 0.0642682265521175
	train_positive_acc: 0.9961288928273431
	train_negative_acc: 0.15936433033047154
	train_correct_nonzero: 7980
	train_incorrect_nonzero: 181
	train_positive_nonzero: 5958
	train_negative_nonzero: 2203
val:
	val_positive_loss: 0.000547271512914449
	val_negative_loss: 0.10125578194856644
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.020039696246385574
	test_negative_loss: 0.16704240441322327
	test_positive_acc: 0.9939528508771929
	test_negative_acc: 0.9582463909055803
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.030453501269221306
	train_incorrect_loss: 9.970911026000977
	train_positive_loss: 4.730430603027344
	train_negative_loss: 0.0003148775431327522
	train_correct_acc: 0.9944907518367953
	train_incorrect_acc: 0.04653880518382319
	train_positive_acc: 0.9939322484004017
	train_negative_acc: 0.1442721105275262
	train_correct_nonzero: 10299
	train_incorrect_nonzero: 170
	train_positive_nonzero: 8272
	train_negative_nonzero: 2197
val:
	val_positive_loss: 0.00018880577408708632
	val_negative_loss: 0.12127835303544998
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.028000198304653168
	test_negative_loss: 0.21216410398483276
	test_positive_acc: 0.9939528508771929
	test_negative_acc: 0.9580141153195312
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.034961115568876266
	train_incorrect_loss: 11.679930686950684
	train_positive_loss: 5.538836479187012
	train_negative_loss: 6.584321748704661e-05
	train_correct_acc: 0.9942827751032514
	train_incorrect_acc: 0.04871796765758281
	train_positive_acc: 0.9937380878372258
	train_negative_acc: 0.1459649940523398
	train_correct_nonzero: 7362
	train_incorrect_nonzero: 225
	train_positive_nonzero: 5459
	train_negative_nonzero: 2128
val:
	val_positive_loss: 0.00015985043137334287
	val_negative_loss: 0.13044621050357819
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.03211796283721924
	test_negative_loss: 0.22869287431240082
	test_positive_acc: 0.9939528508771929
	test_negative_acc: 0.9577729060570954
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 91.9145758152008 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.925
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2327868938446045
	train_negative_loss: 2.2799820700272693
	train_positive_acc: 0.7438402610282191
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.2813025116920471
	train_incorrect_loss: 0.9519392848014832
	train_positive_loss: 0.5852901339530945
	train_negative_loss: 0.8320207867401702
	train_correct_acc: 0.954151522823216
	train_incorrect_acc: 0.5385399339768938
	train_positive_acc: 0.9876245027285054
	train_negative_acc: 0.5388693495362616
	train_correct_nonzero: 4378
	train_incorrect_nonzero: 788
	train_positive_nonzero: 2879
	train_negative_nonzero: 2287
val:
	val_positive_loss: 0.01919238269329071
	val_negative_loss: 0.17575900256633759
	val_positive_acc: 1.0
	val_negative_acc: 0.959016393442623
test:
	test_positive_loss: 0.025586118921637535
	test_negative_loss: 0.18743300437927246
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.938522245950619
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.039411094039678574
	train_incorrect_loss: 2.7693862915039062
	train_positive_loss: 1.3404020071029663
	train_negative_loss: 0.23793272426551132
	train_correct_acc: 0.9884969500365082
	train_incorrect_acc: 0.119111798777193
	train_positive_acc: 0.9946734939545886
	train_negative_acc: 0.179976049513635
	train_correct_nonzero: 7162
	train_incorrect_nonzero: 224
	train_positive_nonzero: 5627
	train_negative_nonzero: 1759
val:
	val_positive_loss: 0.0010462601203471422
	val_negative_loss: 0.2679937481880188
	val_positive_acc: 1.0
	val_negative_acc: 0.9169819251786464
test:
	test_positive_loss: 0.004780961200594902
	test_negative_loss: 0.31112051010131836
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.8830896166092562
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.025174662470817566
	train_incorrect_loss: 4.150937080383301
	train_positive_loss: 2.003216505050659
	train_negative_loss: 0.10593089875457856
	train_correct_acc: 0.9916845711347363
	train_incorrect_acc: 0.08053751701043353
	train_positive_acc: 0.9932805094473235
	train_negative_acc: 0.149652280917697
	train_correct_nonzero: 8201
	train_incorrect_nonzero: 153
	train_positive_nonzero: 6656
	train_negative_nonzero: 1698
val:
	val_positive_loss: 0.000587400165386498
	val_negative_loss: 0.09233764559030533
	val_positive_acc: 1.0
	val_negative_acc: 0.9625893232450609
test:
	test_positive_loss: 0.012196001596748829
	test_negative_loss: 0.11641420423984528
	test_positive_acc: 0.9955139585073796
	test_negative_acc: 0.9598125705301193
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.02300523966550827
	train_incorrect_loss: 5.734146595001221
	train_positive_loss: 2.759183883666992
	train_negative_loss: 0.06412337480204144
	train_correct_acc: 0.9934242535184629
	train_incorrect_acc: 0.06323696993427617
	train_positive_acc: 0.9944369686410992
	train_negative_acc: 0.13411504438021143
	train_correct_nonzero: 4969
	train_incorrect_nonzero: 66
	train_positive_nonzero: 3426
	train_negative_nonzero: 1609
val:
	val_positive_loss: 0.0011531722266227007
	val_negative_loss: 0.013074235059320927
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02525412291288376
	test_negative_loss: 0.05289825052022934
	test_positive_acc: 0.9919655442023863
	test_negative_acc: 0.9772177103495864
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.03933790326118469
	train_incorrect_loss: 5.25862455368042
	train_positive_loss: 2.5307555198669434
	train_negative_loss: 0.2586412066436705
	train_correct_acc: 0.9871534739239014
	train_incorrect_acc: 0.13910172726750106
	train_positive_acc: 0.993340724925598
	train_negative_acc: 0.19897412659153949
	train_correct_nonzero: 5974
	train_incorrect_nonzero: 210
	train_positive_nonzero: 4434
	train_negative_nonzero: 1750
val:
	val_positive_loss: 0.0157141275703907
	val_negative_loss: 0.12161538004875183
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.01808912679553032
	test_negative_loss: 0.1403198093175888
	test_positive_acc: 0.9964576501093159
	test_negative_acc: 0.9734660802509065
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.02344997599720955
	train_incorrect_loss: 4.247364521026611
	train_positive_loss: 2.050995111465454
	train_negative_loss: 0.0584706376088951
	train_correct_acc: 0.9927271165687431
	train_incorrect_acc: 0.06417144331797854
	train_positive_acc: 0.9932146705712938
	train_negative_acc: 0.13522773366323143
	train_correct_nonzero: 3840
	train_incorrect_nonzero: 37
	train_positive_nonzero: 2291
	train_negative_nonzero: 1586
val:
	val_positive_loss: 0.0004060680221300572
	val_negative_loss: 0.14498445391654968
	val_positive_acc: 1.0
	val_negative_acc: 0.9543926019335855
test:
	test_positive_loss: 0.008277430199086666
	test_negative_loss: 0.16229423880577087
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9497485010653719
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.021821392700076103
	train_incorrect_loss: 6.390843391418457
	train_positive_loss: 3.0787720680236816
	train_negative_loss: 0.0030779360829873126
	train_correct_acc: 0.994247051200688
	train_incorrect_acc: 0.044344265891052066
	train_positive_acc: 0.9937701948119924
	train_negative_acc: 0.11785765604531666
	train_correct_nonzero: 6063
	train_incorrect_nonzero: 56
	train_positive_nonzero: 4513
	train_negative_nonzero: 1606
val:
	val_positive_loss: 9.22812832868658e-05
	val_negative_loss: 0.1939377784729004
	val_positive_acc: 1.0
	val_negative_acc: 0.9543926019335855
test:
	test_positive_loss: 0.01075073704123497
	test_negative_loss: 0.2160165011882782
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9444803103149119
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.02066442370414734
	train_incorrect_loss: 4.351170539855957
	train_positive_loss: 2.0984413623809814
	train_negative_loss: 0.10230211418256287
	train_correct_acc: 0.9936858517604685
	train_incorrect_acc: 0.08697015168612227
	train_positive_acc: 0.9950660991725596
	train_negative_acc: 0.15599342940962602
	train_correct_nonzero: 4129
	train_incorrect_nonzero: 53
	train_positive_nonzero: 2579
	train_negative_nonzero: 1603
val:
	val_positive_loss: 0.005228378809988499
	val_negative_loss: 0.026328066363930702
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.025242745876312256
	test_negative_loss: 0.05844781547784805
	test_positive_acc: 0.9928848563716985
	test_negative_acc: 0.9758378587882404
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.017054004594683647
	train_incorrect_loss: 5.760448932647705
	train_positive_loss: 2.77030086517334
	train_negative_loss: 0.024374797078533374
	train_correct_acc: 0.9951817540635158
	train_incorrect_acc: 0.05737211190097879
	train_positive_acc: 0.9956357091251193
	train_negative_acc: 0.12961275425955815
	train_correct_nonzero: 7223
	train_incorrect_nonzero: 67
	train_positive_nonzero: 5673
	train_negative_nonzero: 1617
val:
	val_positive_loss: 0.0021969168446958065
	val_negative_loss: 0.018154511228203773
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.01172521524131298
	test_negative_loss: 0.08477474004030228
	test_positive_acc: 0.996671365914787
	test_negative_acc: 0.9729582438135576
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.01939067430794239
	train_incorrect_loss: 7.962396144866943
	train_positive_loss: 3.831361770629883
	train_negative_loss: 0.0005438852500850134
	train_correct_acc: 0.996285777800008
	train_incorrect_acc: 0.04507960658611371
	train_positive_acc: 0.9960308709615726
	train_negative_acc: 0.11893443327254088
	train_correct_nonzero: 10797
	train_incorrect_nonzero: 133
	train_positive_nonzero: 9247
	train_negative_nonzero: 1683
val:
	val_positive_loss: 0.0003379302506800741
	val_negative_loss: 0.029232339933514595
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.010113408789038658
	test_negative_loss: 0.1280621737241745
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.96624903658121
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.2103967666626 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.95
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2327494621276855
	train_negative_loss: 2.279500835615656
	train_positive_acc: 0.7457138524967531
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.3053513765335083
	train_incorrect_loss: 0.7424362301826477
	train_positive_loss: 0.5014519691467285
	train_negative_loss: 1.0332283113864715
	train_correct_acc: 0.9576372006449987
	train_incorrect_acc: 0.6805094415269552
	train_positive_acc: 0.9899139175345989
	train_negative_acc: 0.6636947080613937
	train_correct_nonzero: 2785
	train_incorrect_nonzero: 728
	train_positive_nonzero: 1765
	train_negative_nonzero: 1748
val:
	val_positive_loss: 0.004692854359745979
	val_negative_loss: 0.7513715624809265
	val_positive_acc: 1.0
	val_negative_acc: 0.5838587641866331
test:
	test_positive_loss: 0.007169865537434816
	test_negative_loss: 0.7928221225738525
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.6258515497444135
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03814763203263283
	train_incorrect_loss: 2.8801498413085938
	train_positive_loss: 1.4126273393630981
	train_negative_loss: 0.30390968661875173
	train_correct_acc: 0.9883149554471611
	train_incorrect_acc: 0.15176918895471955
	train_positive_acc: 0.9938151508693855
	train_negative_acc: 0.19037856314650306
	train_correct_nonzero: 4052
	train_incorrect_nonzero: 67
	train_positive_nonzero: 3004
	train_negative_nonzero: 1115
val:
	val_positive_loss: 0.0023014331236481667
	val_negative_loss: 0.09290860593318939
	val_positive_acc: 1.0
	val_negative_acc: 0.959016393442623
test:
	test_positive_loss: 0.009203795343637466
	test_negative_loss: 0.11260556429624557
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9671182149851469
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.027096759527921677
	train_incorrect_loss: 3.960355758666992
	train_positive_loss: 1.9281312227249146
	train_negative_loss: 0.18187273718241118
	train_correct_acc: 0.9912499118734507
	train_incorrect_acc: 0.07851210786029121
	train_positive_acc: 0.9938379675283755
	train_negative_acc: 0.1235478873634216
	train_correct_nonzero: 3914
	train_incorrect_nonzero: 78
	train_positive_nonzero: 2866
	train_negative_nonzero: 1126
val:
	val_positive_loss: 4.053762495459523e-06
	val_negative_loss: 2.2174575328826904
	val_positive_acc: 1.0
	val_negative_acc: 0.4192938209331652
test:
	test_positive_loss: 9.397693247592542e-06
	test_negative_loss: 2.4575936794281006
	test_positive_acc: 1.0
	test_negative_acc: 0.40188955756161326
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.02720026671886444
	train_incorrect_loss: 5.088005065917969
	train_positive_loss: 2.4815104007720947
	train_negative_loss: 0.1813897355608929
	train_correct_acc: 0.991963325932929
	train_incorrect_acc: 0.09520531925646539
	train_positive_acc: 0.994303773624877
	train_negative_acc: 0.13995695885415835
	train_correct_nonzero: 5502
	train_incorrect_nonzero: 35
	train_positive_nonzero: 4452
	train_negative_nonzero: 1085
val:
	val_positive_loss: 0.0026575028896331787
	val_negative_loss: 0.09678936749696732
	val_positive_acc: 1.0
	val_negative_acc: 0.9672131147540983
test:
	test_positive_loss: 0.018646029755473137
	test_negative_loss: 0.10496459156274796
	test_positive_acc: 0.9952076501093158
	test_negative_acc: 0.9592524573055017
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.024511201307177544
	train_incorrect_loss: 3.921299695968628
	train_positive_loss: 1.9044595956802368
	train_negative_loss: 0.26124576923693993
	train_correct_acc: 0.9914787682611494
	train_incorrect_acc: 0.14957683742984768
	train_positive_acc: 0.9966464584903941
	train_negative_acc: 0.1885151037284611
	train_correct_nonzero: 4776
	train_incorrect_nonzero: 187
	train_positive_nonzero: 3731
	train_negative_nonzero: 1232
val:
	val_positive_loss: 0.0028126728720963
	val_negative_loss: 0.05551791191101074
	val_positive_acc: 1.0
	val_negative_acc: 0.9625893232450609
test:
	test_positive_loss: 0.01262115128338337
	test_negative_loss: 0.10576318204402924
	test_positive_acc: 0.9966909461152882
	test_negative_acc: 0.9606679240912532
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.017264358699321747
	train_incorrect_loss: 6.368006229400635
	train_positive_loss: 3.107448101043701
	train_negative_loss: 0.01293034209582392
	train_correct_acc: 0.9951075102002811
	train_incorrect_acc: 0.0548633711802677
	train_positive_acc: 0.9949755250150877
	train_negative_acc: 0.10401076591777696
	train_correct_nonzero: 4384
	train_incorrect_nonzero: 36
	train_positive_nonzero: 3334
	train_negative_nonzero: 1086
val:
	val_positive_loss: 0.008486563339829445
	val_negative_loss: 0.1327148973941803
	val_positive_acc: 1.0
	val_negative_acc: 0.9707860445565364
test:
	test_positive_loss: 0.008629433810710907
	test_negative_loss: 0.16004855930805206
	test_positive_acc: 0.9965374373433584
	test_negative_acc: 0.9587154831134018
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.021875515580177307
	train_incorrect_loss: 8.212808609008789
	train_positive_loss: 4.006760597229004
	train_negative_loss: 0.00041615588907812306
	train_correct_acc: 0.9940584831346682
	train_incorrect_acc: 0.04126500073661533
	train_positive_acc: 0.9937359879054977
	train_negative_acc: 0.0912465748737969
	train_correct_nonzero: 8349
	train_incorrect_nonzero: 70
	train_positive_nonzero: 7299
	train_negative_nonzero: 1120
val:
	val_positive_loss: 0.01848875917494297
	val_negative_loss: 0.09721097350120544
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9707860445565364
test:
	test_positive_loss: 0.0159054733812809
	test_negative_loss: 0.1257247030735016
	test_positive_acc: 0.9954409461152882
	test_negative_acc: 0.9706553762630469
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.02072335034608841
	train_incorrect_loss: 8.829221725463867
	train_positive_loss: 4.309588432312012
	train_negative_loss: 0.0039764706226712385
	train_correct_acc: 0.994871323390867
	train_incorrect_acc: 0.051288892416955285
	train_positive_acc: 0.9946950199473177
	train_negative_acc: 0.10115901815944502
	train_correct_nonzero: 4245
	train_incorrect_nonzero: 46
	train_positive_nonzero: 3195
	train_negative_nonzero: 1096
val:
	val_positive_loss: 0.0003314024652354419
	val_negative_loss: 0.2007513791322708
	val_positive_acc: 1.0
	val_negative_acc: 0.9625893232450609
test:
	test_positive_loss: 0.01550024002790451
	test_negative_loss: 0.19452297687530518
	test_positive_acc: 0.9966909461152882
	test_negative_acc: 0.9596870198693471
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.026746883988380432
	train_incorrect_loss: 9.411216735839844
	train_positive_loss: 4.591128826141357
	train_negative_loss: 0.0009192651643241726
	train_correct_acc: 0.9948229372502154
	train_incorrect_acc: 0.04548799071795875
	train_positive_acc: 0.9945492465264472
	train_negative_acc: 0.09572209176633496
	train_correct_nonzero: 3457
	train_incorrect_nonzero: 55
	train_positive_nonzero: 2407
	train_negative_nonzero: 1105
val:
	val_positive_loss: 0.0026420019567012787
	val_negative_loss: 0.15487417578697205
	val_positive_acc: 1.0
	val_negative_acc: 0.9625893232450609
test:
	test_positive_loss: 0.0229530930519104
	test_negative_loss: 0.17093458771705627
	test_positive_acc: 0.9955748746867168
	test_negative_acc: 0.9636784491766329
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.03216720372438431
	train_incorrect_loss: 10.268685340881348
	train_positive_loss: 5.013639450073242
	train_negative_loss: 7.255129729478454e-05
	train_correct_acc: 0.9938903003759829
	train_incorrect_acc: 0.039299335892286104
	train_positive_acc: 0.9935794111236518
	train_negative_acc: 0.0896641142893769
	train_correct_nonzero: 6637
	train_incorrect_nonzero: 195
	train_positive_nonzero: 5587
	train_negative_nonzero: 1245
val:
	val_positive_loss: 0.005894708912819624
	val_negative_loss: 0.13149386644363403
	val_positive_acc: 1.0
	val_negative_acc: 0.9707860445565364
test:
	test_positive_loss: 0.025600440800189972
	test_negative_loss: 0.15700089931488037
	test_positive_acc: 0.9955748746867168
	test_negative_acc: 0.9646254188736025
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.34439992904663 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.975
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.232708215713501
	train_negative_loss: 2.2788845256818178
	train_positive_acc: 0.7474361074028508
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.3327763080596924
	train_incorrect_loss: 0.4745611548423767
	train_positive_loss: 0.3885120451450348
	train_negative_loss: 1.4098563350915094
	train_correct_acc: 0.9708926779590494
	train_incorrect_acc: 0.8205952469437144
	train_positive_acc: 0.9918200106209264
	train_negative_acc: 0.8038310187968837
	train_correct_nonzero: 1316
	train_incorrect_nonzero: 480
	train_positive_nonzero: 771
	train_negative_nonzero: 1025
val:
	val_positive_loss: 0.07573439925909042
	val_negative_loss: 0.7211930751800537
	val_positive_acc: 1.0
	val_negative_acc: 0.5863808322824716
test:
	test_positive_loss: 0.08324890583753586
	test_negative_loss: 0.7419766783714294
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.5625656823354641
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.0777781531214714
	train_incorrect_loss: 1.2847988605499268
	train_positive_loss: 0.66590815782547
	train_negative_loss: 1.080982889209648
	train_correct_acc: 0.9802790076247774
	train_incorrect_acc: 0.4651519159438876
	train_positive_acc: 0.991384768899096
	train_negative_acc: 0.4679983979863246
	train_correct_nonzero: 1786
	train_incorrect_nonzero: 196
	train_positive_nonzero: 1240
	train_negative_nonzero: 742
val:
	val_positive_loss: 0.02972588688135147
	val_negative_loss: 1.5532245635986328
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.03278602659702301
	test_negative_loss: 1.5425078868865967
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.04888413846492767
	train_incorrect_loss: 2.1842517852783203
	train_positive_loss: 1.0983872413635254
	train_negative_loss: 0.5012159867511875
	train_correct_acc: 0.9871293638118279
	train_incorrect_acc: 0.2542485249601659
	train_positive_acc: 0.9926526474786563
	train_negative_acc: 0.2681401256902742
	train_correct_nonzero: 2553
	train_incorrect_nonzero: 93
	train_positive_nonzero: 2003
	train_negative_nonzero: 643
val:
	val_positive_loss: 0.0038602331187576056
	val_negative_loss: 0.24153658747673035
	val_positive_acc: 1.0
	val_negative_acc: 0.9123581336696092
test:
	test_positive_loss: 0.015115775167942047
	test_negative_loss: 0.23760375380516052
	test_positive_acc: 0.992571885509848
	test_negative_acc: 0.926596954683023
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.04219359531998634
	train_incorrect_loss: 1.7850770950317383
	train_positive_loss: 0.8877618908882141
	train_negative_loss: 0.7950911006125433
	train_correct_acc: 0.9875383611670335
	train_incorrect_acc: 0.3919958703107271
	train_positive_acc: 0.9967012921717978
	train_negative_acc: 0.3995359858529665
	train_correct_nonzero: 1544
	train_incorrect_nonzero: 202
	train_positive_nonzero: 997
	train_negative_nonzero: 749
val:
	val_positive_loss: 0.033310987055301666
	val_negative_loss: 0.3946971893310547
	val_positive_acc: 1.0
	val_negative_acc: 0.8877679697351828
test:
	test_positive_loss: 0.03455482795834541
	test_negative_loss: 0.39708784222602844
	test_positive_acc: 1.0
	test_negative_acc: 0.8798558116710916
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.024438103660941124
	train_incorrect_loss: 2.528252124786377
	train_positive_loss: 1.258175015449524
	train_negative_loss: 0.5901050989661203
	train_correct_acc: 0.9937946189404029
	train_incorrect_acc: 0.2663266649657769
	train_positive_acc: 0.9982151493399453
	train_negative_acc: 0.2820074084595391
	train_correct_nonzero: 1449
	train_incorrect_nonzero: 117
	train_positive_nonzero: 902
	train_negative_nonzero: 664
val:
	val_positive_loss: 1.9352667095517972e-06
	val_negative_loss: 3.3756139278411865
	val_positive_acc: 1.0
	val_negative_acc: 0.08764186633039092
test:
	test_positive_loss: 1.2144013453507796e-05
	test_negative_loss: 3.4257888793945312
	test_positive_acc: 1.0
	test_negative_acc: 0.11399147957670945
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.021235879510641098
	train_incorrect_loss: 3.779344320297241
	train_positive_loss: 1.8628721237182617
	train_negative_loss: 0.38450588417367965
	train_correct_acc: 0.9935033037500964
	train_incorrect_acc: 0.20327770206811074
	train_positive_acc: 0.9971822796793252
	train_negative_acc: 0.22100281936028146
	train_correct_nonzero: 2008
	train_incorrect_nonzero: 48
	train_positive_nonzero: 1458
	train_negative_nonzero: 598
val:
	val_positive_loss: 0.004231084603816271
	val_negative_loss: 0.1244293749332428
	val_positive_acc: 1.0
	val_negative_acc: 0.9625893232450609
test:
	test_positive_loss: 0.008615395054221153
	test_negative_loss: 0.1332951933145523
	test_positive_acc: 1.0
	test_negative_acc: 0.946127772799492
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.010293252766132355
	train_incorrect_loss: 4.619292259216309
	train_positive_loss: 2.282454252243042
	train_negative_loss: 0.02925983678950734
	train_correct_acc: 0.9962609764513395
	train_incorrect_acc: 0.11349845047790723
	train_positive_acc: 0.9964153810576176
	train_negative_acc: 0.13750634964284106
	train_correct_nonzero: 2267
	train_incorrect_nonzero: 48
	train_positive_nonzero: 1718
	train_negative_nonzero: 597
val:
	val_positive_loss: 0.00013526692055165768
	val_negative_loss: 0.4374697208404541
	val_positive_acc: 1.0
	val_negative_acc: 0.8831441782261454
test:
	test_positive_loss: 0.0021372779738157988
	test_negative_loss: 0.43656060099601746
	test_positive_acc: 1.0
	test_negative_acc: 0.8757464668811044
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.013594025745987892
	train_incorrect_loss: 6.566926002502441
	train_positive_loss: 3.2441534996032715
	train_negative_loss: 0.005414123907751767
	train_correct_acc: 0.9956334933944062
	train_incorrect_acc: 0.1038969895265411
	train_positive_acc: 0.9955527468642944
	train_negative_acc: 0.1284247024434026
	train_correct_nonzero: 1726
	train_incorrect_nonzero: 43
	train_positive_nonzero: 1176
	train_negative_nonzero: 593
val:
	val_positive_loss: 8.440220699412748e-05
	val_negative_loss: 0.355831503868103
	val_positive_acc: 1.0
	val_negative_acc: 0.9379991593106347
test:
	test_positive_loss: 0.0029938844963908195
	test_negative_loss: 0.356130987405777
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9068438370341785
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.015150515362620354
	train_incorrect_loss: 7.553409099578857
	train_positive_loss: 3.729112386703491
	train_negative_loss: 0.0014289938992442725
	train_correct_acc: 0.9951696373313612
	train_incorrect_acc: 0.0980515502188906
	train_positive_acc: 0.9950420126074248
	train_negative_acc: 0.12295633968747047
	train_correct_nonzero: 589
	train_incorrect_nonzero: 7
	train_positive_nonzero: 40
	train_negative_nonzero: 556
val:
	val_positive_loss: 0.00014671326789539307
	val_negative_loss: 0.2827455401420593
	val_positive_acc: 1.0
	val_negative_acc: 0.9543926019335855
test:
	test_positive_loss: 0.005651154555380344
	test_negative_loss: 0.25278204679489136
	test_positive_acc: 0.9964576501093159
	test_negative_acc: 0.9384627671782173
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.01818222738802433
	train_incorrect_loss: 8.233720779418945
	train_positive_loss: 4.06873083114624
	train_negative_loss: 0.0005697079623716102
	train_correct_acc: 0.9944930284261998
	train_incorrect_acc: 0.08435856316915194
	train_positive_acc: 0.9943634334677371
	train_negative_acc: 0.10948610285544354
	train_correct_nonzero: 2108
	train_incorrect_nonzero: 64
	train_positive_nonzero: 1559
	train_negative_nonzero: 613
val:
	val_positive_loss: 6.104615022195503e-05
	val_negative_loss: 0.315330445766449
	val_positive_acc: 1.0
	val_negative_acc: 0.9543926019335855
test:
	test_positive_loss: 0.0035402262583374977
	test_negative_loss: 0.30836182832717896
	test_positive_acc: 0.9964576501093159
	test_negative_acc: 0.9287614122114042
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 92.23822069168091 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 1.0
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2326619625091553
	train_negative_loss: 2.2734428723653157
	train_positive_acc: 0.7493136951181456
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.12013247609138489
	train_incorrect_loss: 0.12715460360050201
	train_positive_loss: 0.11810117959976196
	train_negative_loss: 4.62834417941619
	train_correct_acc: 0.9947862393654088
	train_incorrect_acc: 0.9968762812504521
	train_positive_acc: 0.9972701180154246
	train_negative_acc: 0.9944798280900101
	train_correct_nonzero: 333
	train_incorrect_nonzero: 257
	train_positive_nonzero: 283
	train_negative_nonzero: 307
val:
	val_positive_loss: 0.20257937908172607
	val_negative_loss: 1.5083792209625244
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.2028592973947525
	test_negative_loss: 1.550646424293518
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.11859863996505737
	train_incorrect_loss: 0.2337813526391983
	train_positive_loss: 0.17372779548168182
	train_negative_loss: 2.407339551448822
	train_correct_acc: 0.9966817303194845
	train_incorrect_acc: 0.9736149449413553
	train_positive_acc: 0.9990323552372758
	train_negative_acc: 0.9712691725972271
	train_correct_nonzero: 132
	train_incorrect_nonzero: 59
	train_positive_nonzero: 82
	train_negative_nonzero: 109
val:
	val_positive_loss: 0.025496158748865128
	val_negative_loss: 2.9790432453155518
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.025285903364419937
	test_negative_loss: 3.2060275077819824
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.06621722877025604
	train_incorrect_loss: 0.30239176750183105
	train_positive_loss: 0.18041828274726868
	train_negative_loss: 2.415789811021608
	train_correct_acc: 0.9880120373131738
	train_incorrect_acc: 0.874265774925224
	train_positive_acc: 0.9896900349288711
	train_negative_acc: 0.8728726997121304
	train_correct_nonzero: 178
	train_incorrect_nonzero: 61
	train_positive_nonzero: 128
	train_negative_nonzero: 111
val:
	val_positive_loss: 0.12316711992025375
	val_negative_loss: 1.5681178569793701
	val_positive_acc: 0.9661622530474989
	val_negative_acc: 0.4510298444724674
test:
	test_positive_loss: 0.1112515777349472
	test_negative_loss: 1.8056195974349976
	test_positive_acc: 0.9610525854042973
	test_negative_acc: 0.42298874514389306
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.02971554920077324
	train_incorrect_loss: 0.08855877816677094
	train_positive_loss: 0.050483521074056625
	train_negative_loss: 7.214932247348454
	train_correct_acc: 0.9954039849678065
	train_incorrect_acc: 0.9739800363250865
	train_positive_acc: 0.9977712484287137
	train_negative_acc: 0.9717310229179744
	train_correct_nonzero: 147
	train_incorrect_nonzero: 96
	train_positive_nonzero: 97
	train_negative_nonzero: 146
val:
	val_positive_loss: 0.18893614411354065
	val_negative_loss: 0.9566876888275146
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 0.5981504833963851
test:
	test_positive_loss: 0.18204225599765778
	test_negative_loss: 1.01912522315979
	test_positive_acc: 0.9711537483080288
	test_negative_acc: 0.5428298565106788
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.023532487452030182
	train_incorrect_loss: 0.36210739612579346
	train_positive_loss: 0.19014568626880646
	train_negative_loss: 2.7044475520758526
	train_correct_acc: 0.9951166125549687
	train_incorrect_acc: 0.8351317131416632
	train_positive_acc: 0.9966404253481457
	train_negative_acc: 0.8338607807724185
	train_correct_nonzero: 122
	train_incorrect_nonzero: 52
	train_positive_nonzero: 72
	train_negative_nonzero: 102
val:
	val_positive_loss: 0.0021139876917004585
	val_negative_loss: 3.3593873977661133
	val_positive_acc: 1.0
	val_negative_acc: 0.2173182009247583
test:
	test_positive_loss: 0.0023830081336200237
	test_negative_loss: 3.7883706092834473
	test_positive_acc: 1.0
	test_negative_acc: 0.20864827334283087
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.010045815259218216
	train_incorrect_loss: 1.269863486289978
	train_positive_loss: 0.6380491852760315
	train_negative_loss: 0.06610259059721565
	train_correct_acc: 0.9982085846983324
	train_incorrect_acc: 0.5276259011247993
	train_positive_acc: 0.9982019738125786
	train_negative_acc: 0.5288295244255754
	train_correct_nonzero: 94
	train_incorrect_nonzero: 0
	train_positive_nonzero: 44
	train_negative_nonzero: 50
val:
	val_positive_loss: 0.008452940732240677
	val_negative_loss: 1.3407559394836426
	val_positive_acc: 1.0
	val_negative_acc: 0.6437578814627996
test:
	test_positive_loss: 0.011879760771989822
	test_negative_loss: 1.619629979133606
	test_positive_acc: 0.9976535087719298
	test_negative_acc: 0.5863115968432923
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.016090864315629005
	train_incorrect_loss: 2.3564467430114746
	train_positive_loss: 1.182808518409729
	train_negative_loss: 0.005429976002487819
	train_correct_acc: 0.9958617733934356
	train_incorrect_acc: 0.3703446509317047
	train_positive_acc: 0.9958481977463941
	train_negative_acc: 0.37192310947309815
	train_correct_nonzero: 146
	train_incorrect_nonzero: 7
	train_positive_nonzero: 96
	train_negative_nonzero: 57
val:
	val_positive_loss: 0.006588707212358713
	val_negative_loss: 1.5436948537826538
	val_positive_acc: 1.0
	val_negative_acc: 0.6437578814627996
test:
	test_positive_loss: 0.011111374944448471
	test_negative_loss: 1.9016309976577759
	test_positive_acc: 0.9965570175438596
	test_negative_acc: 0.5840273276057466
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.016875358298420906
	train_incorrect_loss: 2.7282068729400635
	train_positive_loss: 1.369802474975586
	train_negative_loss: 0.0027065746724019846
	train_correct_acc: 0.9947485724062789
	train_incorrect_acc: 0.35721071015964023
	train_positive_acc: 0.9947327447927902
	train_negative_acc: 0.3587994083604037
	train_correct_nonzero: 206
	train_incorrect_nonzero: 3
	train_positive_nonzero: 156
	train_negative_nonzero: 53
val:
	val_positive_loss: 0.008160009980201721
	val_negative_loss: 1.3484394550323486
	val_positive_acc: 1.0
	val_negative_acc: 0.6519546027742749
test:
	test_positive_loss: 0.014417886734008789
	test_negative_loss: 1.6788599491119385
	test_positive_acc: 0.9941976870595292
	test_negative_acc: 0.6299334114439544
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.012242279015481472
	train_incorrect_loss: 2.825167417526245
	train_positive_loss: 1.4150646924972534
	train_negative_loss: 0.0016278338377257266
	train_correct_acc: 0.9958773814746524
	train_incorrect_acc: 0.3742695701222077
	train_positive_acc: 0.9958644937130204
	train_negative_acc: 0.37581992723897584
	train_correct_nonzero: 282
	train_incorrect_nonzero: 14
	train_positive_nonzero: 232
	train_negative_nonzero: 64
val:
	val_positive_loss: 0.0028143192175775766
	val_negative_loss: 1.7342009544372559
	val_positive_acc: 1.0
	val_negative_acc: 0.6519546027742749
test:
	test_positive_loss: 0.0076255202293396
	test_negative_loss: 2.1660032272338867
	test_positive_acc: 0.9953550944669365
	test_negative_acc: 0.6000226777430201
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.012298107147216797
	train_incorrect_loss: 3.1346335411071777
	train_positive_loss: 1.5695606470108032
	train_negative_loss: 0.0008289602578572711
	train_correct_acc: 0.9955710838545929
	train_incorrect_acc: 0.3556956292174326
	train_positive_acc: 0.9955619376247041
	train_negative_acc: 0.3573214590735748
	train_correct_nonzero: 50
	train_incorrect_nonzero: 0
	train_positive_nonzero: 0
	train_negative_nonzero: 50
val:
	val_positive_loss: 0.004022763576358557
	val_negative_loss: 1.5179431438446045
	val_positive_acc: 1.0
	val_negative_acc: 0.6647751155947877
test:
	test_positive_loss: 0.010748310945928097
	test_negative_loss: 1.916820764541626
	test_positive_acc: 0.9941976870595292
	test_negative_acc: 0.6337025338406711
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 91.79867386817932 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.0
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.235910654067993
	train_negative_loss: 2.2804512977600098
	train_positive_acc: 0.6210397876146286
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.09910419583320618
	train_incorrect_loss: 0.42243262158888506
	train_positive_loss: 0.08428303152322769
	train_negative_loss: 0.11631575226783752
	train_correct_acc: 0.9725750778467023
	train_incorrect_acc: 1.0
	train_positive_acc: 0.9802555392510401
	train_negative_acc: 0.9650658412112385
	train_correct_nonzero: 24827
	train_incorrect_nonzero: 171
	train_positive_nonzero: 12776
	train_negative_nonzero: 12222
val:
	val_positive_loss: 0.04717470705509186
	val_negative_loss: 0.006355863995850086
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0452251210808754
	test_negative_loss: 0.01352439634501934
	test_positive_acc: 0.9871633521572356
	test_negative_acc: 0.9962601359878842
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.014395076781511307
	train_incorrect_loss: 0.21898520956165157
	train_positive_loss: 0.012325086630880833
	train_negative_loss: 0.016829974949359894
	train_correct_acc: 0.9972558502733068
	train_incorrect_acc: 1.0
	train_positive_acc: 0.9974866725894455
	train_negative_acc: 0.9970843790442221
	train_correct_nonzero: 27493
	train_incorrect_nonzero: 51
	train_positive_nonzero: 12415
	train_negative_nonzero: 15129
val:
	val_positive_loss: 0.0016566287958994508
	val_negative_loss: 0.0032897768542170525
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.008146836422383785
	test_negative_loss: 0.03286523371934891
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9887151593938408
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.006999570410698652
	train_incorrect_loss: 0.26248004235967526
	train_positive_loss: 0.007047239225357771
	train_negative_loss: 0.007657360285520554
	train_correct_acc: 0.9984772916194362
	train_incorrect_acc: 1.0
	train_positive_acc: 0.9983795005365012
	train_negative_acc: 0.9985618345965197
	train_correct_nonzero: 27434
	train_incorrect_nonzero: 56
	train_positive_nonzero: 9504
	train_negative_nonzero: 17986
val:
	val_positive_loss: 0.0005958947585895658
	val_negative_loss: 0.0014858637005090714
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.005700360052287579
	test_negative_loss: 0.03793880343437195
	test_positive_acc: 0.9989035087719298
	test_negative_acc: 0.9900684875095235
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.007185885217040777
	train_incorrect_loss: 0.2627092348955236
	train_positive_loss: 0.008355897851288319
	train_negative_loss: 0.006600392051041126
	train_correct_acc: 0.9982538602987481
	train_incorrect_acc: 1.0
	train_positive_acc: 0.9977167111229848
	train_negative_acc: 0.9988532259369919
	train_correct_nonzero: 25614
	train_incorrect_nonzero: 53
	train_positive_nonzero: 9383
	train_negative_nonzero: 16284
val:
	val_positive_loss: 0.002501837210729718
	val_negative_loss: 0.00021233125880826265
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.021146077662706375
	test_negative_loss: 0.014355780556797981
	test_positive_acc: 0.992101776326815
	test_negative_acc: 0.99598589289881
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.0028489974793046713
	train_incorrect_loss: 0.09168677010790711
	train_positive_loss: 0.003531745634973049
	train_negative_loss: 0.002274616388604045
	train_correct_acc: 0.9991518678052344
	train_incorrect_acc: 1.0
	train_positive_acc: 0.9989958365812303
	train_negative_acc: 0.9993677041976777
	train_correct_nonzero: 22365
	train_incorrect_nonzero: 64
	train_positive_nonzero: 6358
	train_negative_nonzero: 16071
val:
	val_positive_loss: 0.00015105109196156263
	val_negative_loss: 4.110169902560301e-05
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.015043733641505241
	test_negative_loss: 0.024698156863451004
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9938596779188213
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.0037624009419232607
	train_incorrect_loss: 0.15486348016384
	train_positive_loss: 0.005781422834843397
	train_negative_loss: 0.0025192436296492815
	train_correct_acc: 0.9991012368069725
	train_incorrect_acc: 1.0
	train_positive_acc: 0.9985791626051916
	train_negative_acc: 0.999663800175874
	train_correct_nonzero: 18230
	train_incorrect_nonzero: 109
	train_positive_nonzero: 3868
	train_negative_nonzero: 14471
val:
	val_positive_loss: 0.0003021082666236907
	val_negative_loss: 0.0006884142057970166
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01423601247370243
	test_negative_loss: 0.030443932861089706
	test_positive_acc: 0.9944611068111455
	test_negative_acc: 0.9920510759103647
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.001640829024836421
	train_incorrect_loss: 0.1088063525520673
	train_positive_loss: 0.002345308428630233
	train_negative_loss: 0.0012026610784232616
	train_correct_acc: 0.9995259326431397
	train_incorrect_acc: 1.0
	train_positive_acc: 0.9993295066995228
	train_negative_acc: 0.9997792555647917
	train_correct_nonzero: 15141
	train_incorrect_nonzero: 73
	train_positive_nonzero: 2919
	train_negative_nonzero: 12295
val:
	val_positive_loss: 0.017411796376109123
	val_negative_loss: 2.023579781962326e-06
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04245767369866371
	test_negative_loss: 0.018407125025987625
	test_positive_acc: 0.9905839023051094
	test_negative_acc: 0.994532404526717
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.001006127567961812
	train_incorrect_loss: 0.05591785893766933
	train_positive_loss: 0.0017359746852889657
	train_negative_loss: 0.0004139369120821357
	train_correct_acc: 0.9998501221693242
	train_incorrect_acc: 1.0
	train_positive_acc: 0.9997293967864646
	train_negative_acc: 1.0
	train_correct_nonzero: 12603
	train_incorrect_nonzero: 100
	train_positive_nonzero: 2038
	train_negative_nonzero: 10665
val:
	val_positive_loss: 0.008742261677980423
	val_negative_loss: 3.730968046511407e-06
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04210684448480606
	test_negative_loss: 0.02809271216392517
	test_positive_acc: 0.9894976096601483
	test_negative_acc: 0.994532404526717
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.0032618697732686996
	train_incorrect_loss: 0.12726048636290785
	train_positive_loss: 0.005960576701909304
	train_negative_loss: 0.0013037740718573332
	train_correct_acc: 0.9992513665331619
	train_incorrect_acc: 1.0
	train_positive_acc: 0.998544696249576
	train_negative_acc: 0.999955468471678
	train_correct_nonzero: 14549
	train_incorrect_nonzero: 115
	train_positive_nonzero: 1725
	train_negative_nonzero: 12939
val:
	val_positive_loss: 0.073649562895298
	val_negative_loss: 0.00020007917191833258
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03765049949288368
	test_negative_loss: 0.004223945550620556
	test_positive_acc: 0.9879473656763937
	test_negative_acc: 0.9987980769230769
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.0040358263067901134
	train_incorrect_loss: 0.12813401878937852
	train_positive_loss: 0.007148211356252432
	train_negative_loss: 0.001866713399067521
	train_correct_acc: 0.9990266705941803
	train_incorrect_acc: 1.0
	train_positive_acc: 0.9980944343396085
	train_negative_acc: 0.999951102635568
	train_correct_nonzero: 16468
	train_incorrect_nonzero: 154
	train_positive_nonzero: 1526
	train_negative_nonzero: 15096
val:
	val_positive_loss: 0.10181167721748352
	val_negative_loss: 1.478419653722085e-05
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.11482074856758118
	test_negative_loss: 0.004639988299459219
	test_positive_acc: 0.9707034465737368
	test_negative_acc: 0.997344588550984
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 89.9240174293518 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.025
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2357494831085205
	train_negative_loss: 2.280472755432129
	train_positive_acc: 0.6270972681850142
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.1165403351187706
	train_incorrect_loss: 1.1257102166978168
	train_positive_loss: 0.10648595541715622
	train_negative_loss: 0.1442217230796814
	train_correct_acc: 0.9724535577482395
	train_incorrect_acc: 0.6968954248366013
	train_positive_acc: 0.9790537623911685
	train_negative_acc: 0.9601818706533871
	train_correct_nonzero: 27490
	train_incorrect_nonzero: 320
	train_positive_nonzero: 12015
	train_negative_nonzero: 15795
val:
	val_positive_loss: 0.06439416110515594
	val_negative_loss: 0.05899401009082794
	val_positive_acc: 0.9743589743589743
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05088617652654648
	test_negative_loss: 0.06127988547086716
	test_positive_acc: 0.9873052596514668
	test_negative_acc: 0.9964924115739333
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.026785092428326607
	train_incorrect_loss: 1.5764544896206798
	train_positive_loss: 0.02294743061065674
	train_negative_loss: 0.04074819013476372
	train_correct_acc: 0.9966476866338406
	train_incorrect_acc: 0.6843971631205673
	train_positive_acc: 0.9976205336374081
	train_negative_acc: 0.9935124788227945
	train_correct_nonzero: 27682
	train_incorrect_nonzero: 119
	train_positive_nonzero: 9761
	train_negative_nonzero: 18040
val:
	val_positive_loss: 0.0020284787751734257
	val_negative_loss: 0.013296033255755901
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.006283159367740154
	test_negative_loss: 0.03517085313796997
	test_positive_acc: 0.9989035087719298
	test_negative_acc: 0.9924061895467284
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.014575368724763393
	train_incorrect_loss: 1.1962686673721645
	train_positive_loss: 0.015832610428333282
	train_negative_loss: 0.020757626742124557
	train_correct_acc: 0.997573968444546
	train_incorrect_acc: 0.8461538461538461
	train_positive_acc: 0.9980632753847426
	train_negative_acc: 0.9961337391578671
	train_correct_nonzero: 29462
	train_incorrect_nonzero: 90
	train_positive_nonzero: 10341
	train_negative_nonzero: 19211
val:
	val_positive_loss: 0.02397194691002369
	val_negative_loss: 0.003444976406171918
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.020685812458395958
	test_negative_loss: 0.015330645255744457
	test_positive_acc: 0.9909145901357972
	test_negative_acc: 0.99598589289881
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.012080775573849678
	train_incorrect_loss: 1.8727480891744592
	train_positive_loss: 0.014300067909061909
	train_negative_loss: 0.019795935600996017
	train_correct_acc: 0.9986258943913776
	train_incorrect_acc: 0.6904761904761905
	train_positive_acc: 0.9989480987992602
	train_negative_acc: 0.9965463212099351
	train_correct_nonzero: 29817
	train_incorrect_nonzero: 78
	train_positive_nonzero: 10832
	train_negative_nonzero: 19063
val:
	val_positive_loss: 0.004016542807221413
	val_negative_loss: 0.02299756184220314
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.005170377437025309
	test_negative_loss: 0.04733011871576309
	test_positive_acc: 0.9970652734778122
	test_negative_acc: 0.9884068237016332
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.008303370326757431
	train_incorrect_loss: 1.753998288611436
	train_positive_loss: 0.014457428827881813
	train_negative_loss: 0.011197990737855434
	train_correct_acc: 0.9987953739645938
	train_incorrect_acc: 0.7971014492753623
	train_positive_acc: 0.998325222062143
	train_negative_acc: 0.9981393516929136
	train_correct_nonzero: 24042
	train_incorrect_nonzero: 85
	train_positive_nonzero: 5170
	train_negative_nonzero: 18957
val:
	val_positive_loss: 0.0004243841103743762
	val_negative_loss: 0.04292909801006317
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.004293431062251329
	test_negative_loss: 0.07979989051818848
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9864468166544169
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.01136582251638174
	train_incorrect_loss: 0.9316361914661845
	train_positive_loss: 0.01424582488834858
	train_negative_loss: 0.0185337346047163
	train_correct_acc: 0.9988971230447896
	train_incorrect_acc: 0.911504424778761
	train_positive_acc: 0.9991066162269043
	train_negative_acc: 0.9975618050907107
	train_correct_nonzero: 24504
	train_incorrect_nonzero: 142
	train_positive_nonzero: 5248
	train_negative_nonzero: 19398
val:
	val_positive_loss: 0.014454564079642296
	val_negative_loss: 0.002691950649023056
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02571343630552292
	test_negative_loss: 0.013091882690787315
	test_positive_acc: 0.9916432243390076
	test_negative_acc: 0.99598589289881
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.006118733901530504
	train_incorrect_loss: 0.23481485934462398
	train_positive_loss: 0.0061248354613780975
	train_negative_loss: 0.008312486112117767
	train_correct_acc: 0.9991241438765486
	train_incorrect_acc: 0.9891304347826086
	train_positive_acc: 0.9987975175733026
	train_negative_acc: 0.9993063699419007
	train_correct_nonzero: 26404
	train_incorrect_nonzero: 182
	train_positive_nonzero: 6613
	train_negative_nonzero: 19973
val:
	val_positive_loss: 0.015536553226411343
	val_negative_loss: 0.0015998984454199672
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.012339030392467976
	test_negative_loss: 0.022255435585975647
	test_positive_acc: 0.9951419346978557
	test_negative_acc: 0.99598589289881
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.005256124306470156
	train_incorrect_loss: 0.7930827634286862
	train_positive_loss: 0.011936347931623459
	train_negative_loss: 0.005415693391114473
	train_correct_acc: 0.999346541911558
	train_incorrect_acc: 0.941747572815534
	train_positive_acc: 0.9990399307712929
	train_negative_acc: 0.9991146819437542
	train_correct_nonzero: 22663
	train_incorrect_nonzero: 125
	train_positive_nonzero: 3220
	train_negative_nonzero: 19568
val:
	val_positive_loss: 0.0275054220110178
	val_negative_loss: 0.0022621771786361933
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01701832190155983
	test_negative_loss: 0.01693260855972767
	test_positive_acc: 0.9907191129375728
	test_negative_acc: 0.99598589289881
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.0019411627436056733
	train_incorrect_loss: 0.15405899940196832
	train_positive_loss: 0.0030554879922419786
	train_negative_loss: 0.0021140079479664564
	train_correct_acc: 0.999775561097257
	train_incorrect_acc: 0.9930555555555556
	train_positive_acc: 0.9996972367930748
	train_negative_acc: 0.9998160458888022
	train_correct_nonzero: 23894
	train_incorrect_nonzero: 174
	train_positive_nonzero: 4026
	train_negative_nonzero: 20042
val:
	val_positive_loss: 0.0552130751311779
	val_negative_loss: 0.0003099558234680444
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.031779639422893524
	test_negative_loss: 0.015825632959604263
	test_positive_acc: 0.9918765203449801
	test_negative_acc: 0.99598589289881
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.002556979889050126
	train_incorrect_loss: 0.32526645148582617
	train_positive_loss: 0.006092471070587635
	train_negative_loss: 0.003164161229506135
	train_correct_acc: 0.9996244135075629
	train_incorrect_acc: 0.976878612716763
	train_positive_acc: 0.9993854554227696
	train_negative_acc: 0.9995986918911749
	train_correct_nonzero: 20807
	train_incorrect_nonzero: 227
	train_positive_nonzero: 1215
	train_negative_nonzero: 19819
val:
	val_positive_loss: 0.046762578189373016
	val_negative_loss: 0.001199442078359425
	val_positive_acc: 0.9836065573770492
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05614755302667618
	test_negative_loss: 0.015436735935509205
	test_positive_acc: 0.9792583590543389
	test_negative_acc: 0.9963617950640065
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.25754451751709 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.05
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.235595464706421
	train_negative_loss: 2.2804431915283203
	train_positive_acc: 0.6345275283621715
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.12734365463256836
	train_incorrect_loss: 1.245859823297136
	train_positive_loss: 0.12112788110971451
	train_negative_loss: 0.1576039046049118
	train_correct_acc: 0.9748604924784805
	train_incorrect_acc: 0.6618189102564102
	train_positive_acc: 0.9821844975598676
	train_negative_acc: 0.9592213828110128
	train_correct_nonzero: 24583
	train_incorrect_nonzero: 373
	train_positive_nonzero: 8874
	train_negative_nonzero: 16082
val:
	val_positive_loss: 0.05094926059246063
	val_negative_loss: 0.07374408096075058
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.040425047278404236
	test_negative_loss: 0.08131054043769836
	test_positive_acc: 0.9894922103091621
	test_negative_acc: 0.9945984721799939
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.02667366713285446
	train_incorrect_loss: 1.3456989096158796
	train_positive_loss: 0.028315920382738113
	train_negative_loss: 0.04190288484096527
	train_correct_acc: 0.9974206407809831
	train_incorrect_acc: 0.69009009009009
	train_positive_acc: 0.9985474703449243
	train_negative_acc: 0.9924500991878238
	train_correct_nonzero: 28503
	train_incorrect_nonzero: 163
	train_positive_nonzero: 9869
	train_negative_nonzero: 18797
val:
	val_positive_loss: 0.0006168952095322311
	val_negative_loss: 0.03475196659564972
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.00267969723790884
	test_negative_loss: 0.07091951370239258
	test_positive_acc: 1.0
	test_negative_acc: 0.9806034154562167
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.018202345818281174
	train_incorrect_loss: 1.1898184463913952
	train_positive_loss: 0.01875438168644905
	train_negative_loss: 0.027507077902555466
	train_correct_acc: 0.9979213859766706
	train_incorrect_acc: 0.7797619047619048
	train_positive_acc: 0.9983616646790547
	train_negative_acc: 0.9954013101908084
	train_correct_nonzero: 32260
	train_incorrect_nonzero: 98
	train_positive_nonzero: 12986
	train_negative_nonzero: 19372
val:
	val_positive_loss: 0.006864435039460659
	val_negative_loss: 0.0073525370098650455
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.013965816237032413
	test_negative_loss: 0.024750376120209694
	test_positive_acc: 0.993131319577103
	test_negative_acc: 0.9894183422552528
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.012889742851257324
	train_incorrect_loss: 1.5215998090177498
	train_positive_loss: 0.01487597357481718
	train_negative_loss: 0.01972467638552189
	train_correct_acc: 0.9981983751711218
	train_incorrect_acc: 0.7162162162162162
	train_positive_acc: 0.9989593189486886
	train_negative_acc: 0.9957950445372743
	train_correct_nonzero: 30778
	train_incorrect_nonzero: 75
	train_positive_nonzero: 11397
	train_negative_nonzero: 19456
val:
	val_positive_loss: 0.005856353789567947
	val_negative_loss: 0.01677723415195942
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0330258309841156
	test_negative_loss: 0.024092089384794235
	test_positive_acc: 0.9858396293375022
	test_negative_acc: 0.9933531592436982
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.007408367469906807
	train_incorrect_loss: 0.9905969523289665
	train_positive_loss: 0.014471448957920074
	train_negative_loss: 0.00951439794152975
	train_correct_acc: 0.9988979160015854
	train_incorrect_acc: 0.8880208333333334
	train_positive_acc: 0.9987270899468825
	train_negative_acc: 0.9977794055178565
	train_correct_nonzero: 26620
	train_incorrect_nonzero: 102
	train_positive_nonzero: 7096
	train_negative_nonzero: 19626
val:
	val_positive_loss: 0.01946602389216423
	val_negative_loss: 0.0011375187896192074
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03148176148533821
	test_negative_loss: 0.015412334352731705
	test_positive_acc: 0.9920152481485316
	test_negative_acc: 0.9948066476157911
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.003665585070848465
	train_incorrect_loss: 0.36787621044219887
	train_positive_loss: 0.005611990578472614
	train_negative_loss: 0.00450242729857564
	train_correct_acc: 0.9994254211924323
	train_incorrect_acc: 0.9526315789473684
	train_positive_acc: 0.9993182520707489
	train_negative_acc: 0.9991549758989638
	train_correct_nonzero: 23439
	train_incorrect_nonzero: 100
	train_positive_nonzero: 3624
	train_negative_nonzero: 19915
val:
	val_positive_loss: 0.0002109457564074546
	val_negative_loss: 0.008842280134558678
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.006174861919134855
	test_negative_loss: 0.0581924133002758
	test_positive_acc: 0.9973958333333333
	test_negative_acc: 0.9874457225298916
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.005389668978750706
	train_incorrect_loss: 0.36015469309216874
	train_positive_loss: 0.013360806740820408
	train_negative_loss: 0.004868595395237207
	train_correct_acc: 0.998942921284793
	train_incorrect_acc: 0.9738475177304964
	train_positive_acc: 0.9982105346344373
	train_negative_acc: 0.9990430617687884
	train_correct_nonzero: 22622
	train_incorrect_nonzero: 303
	train_positive_nonzero: 3066
	train_negative_nonzero: 19859
val:
	val_positive_loss: 0.004753586836159229
	val_negative_loss: 0.010945269837975502
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.009578434750437737
	test_negative_loss: 0.047475963830947876
	test_positive_acc: 0.9959492020492408
	test_negative_acc: 0.9898395235448935
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.008078431710600853
	train_incorrect_loss: 0.3149962636796476
	train_positive_loss: 0.016620609909296036
	train_negative_loss: 0.007862800732254982
	train_correct_acc: 0.9985592901870831
	train_incorrect_acc: 0.9825581395348837
	train_positive_acc: 0.9973141249645148
	train_negative_acc: 0.9993216508304023
	train_correct_nonzero: 22607
	train_incorrect_nonzero: 471
	train_positive_nonzero: 3343
	train_negative_nonzero: 19735
val:
	val_positive_loss: 0.08769524097442627
	val_negative_loss: 0.00047259486746042967
	val_positive_acc: 0.9625893232450609
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.09254519641399384
	test_negative_loss: 0.020151041448116302
	test_positive_acc: 0.9653324809970396
	test_negative_acc: 0.99598589289881
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.005058748181909323
	train_incorrect_loss: 0.24962816416273198
	train_positive_loss: 0.010826797224581242
	train_negative_loss: 0.00631322106346488
	train_correct_acc: 0.9990429870956096
	train_incorrect_acc: 0.9875
	train_positive_acc: 0.9982889938796521
	train_negative_acc: 0.9995725362686706
	train_correct_nonzero: 22620
	train_incorrect_nonzero: 665
	train_positive_nonzero: 3355
	train_negative_nonzero: 19930
val:
	val_positive_loss: 0.09062528610229492
	val_negative_loss: 0.0007224319851957262
	val_positive_acc: 0.9625893232450609
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.09018570929765701
	test_negative_loss: 0.015878641977906227
	test_positive_acc: 0.9696876897162177
	test_negative_acc: 0.99598589289881
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.005783368833363056
	train_incorrect_loss: 0.22523768562825267
	train_positive_loss: 0.010649626143276691
	train_negative_loss: 0.007113538216799498
	train_correct_acc: 0.9989870967977021
	train_incorrect_acc: 0.9861111111111113
	train_positive_acc: 0.9982237671218976
	train_negative_acc: 0.9995468838211394
	train_correct_nonzero: 22472
	train_incorrect_nonzero: 733
	train_positive_nonzero: 3233
	train_negative_nonzero: 19972
val:
	val_positive_loss: 0.0852017030119896
	val_negative_loss: 0.0009708384168334305
	val_positive_acc: 0.9707860445565364
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.11271771788597107
	test_negative_loss: 0.021451756358146667
	test_positive_acc: 0.9572951443895668
	test_negative_acc: 0.9949083066919134
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.39012908935547 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.075
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2354838848114014
	train_negative_loss: 2.280458927154541
	train_positive_acc: 0.6395294747643672
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.13329043984413147
	train_incorrect_loss: 1.0936310428978326
	train_positive_loss: 0.13055405020713806
	train_negative_loss: 0.16620628535747528
	train_correct_acc: 0.9719104136429897
	train_incorrect_acc: 0.66784140969163
	train_positive_acc: 0.9791284147071246
	train_negative_acc: 0.9525491611990404
	train_correct_nonzero: 25910
	train_incorrect_nonzero: 485
	train_positive_nonzero: 9552
	train_negative_nonzero: 16843
val:
	val_positive_loss: 0.09330865740776062
	val_negative_loss: 0.032364971935749054
	val_positive_acc: 0.9743589743589743
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.06541807949542999
	test_negative_loss: 0.04180481284856796
	test_positive_acc: 0.9759389615924895
	test_negative_acc: 0.9937368398685069
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.030703319236636162
	train_incorrect_loss: 1.3335997783246316
	train_positive_loss: 0.033698104321956635
	train_negative_loss: 0.048076506704092026
	train_correct_acc: 0.9969381411979515
	train_incorrect_acc: 0.7262755102040817
	train_positive_acc: 0.9974276142388534
	train_negative_acc: 0.9922334490436578
	train_correct_nonzero: 28047
	train_incorrect_nonzero: 174
	train_positive_nonzero: 9357
	train_negative_nonzero: 18864
val:
	val_positive_loss: 0.0006913793040439487
	val_negative_loss: 0.0046776034869253635
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.011467857286334038
	test_negative_loss: 0.017347313463687897
	test_positive_acc: 0.9933036994037381
	test_negative_acc: 0.994532404526717
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02415464259684086
	train_incorrect_loss: 1.2733291659068189
	train_positive_loss: 0.02602379396557808
	train_negative_loss: 0.04127425327897072
	train_correct_acc: 0.997765988562831
	train_incorrect_acc: 0.7813725490196078
	train_positive_acc: 0.9983629325299751
	train_negative_acc: 0.9937777022851653
	train_correct_nonzero: 27914
	train_incorrect_nonzero: 145
	train_positive_nonzero: 8836
	train_negative_nonzero: 19223
val:
	val_positive_loss: 4.2180407035630196e-05
	val_negative_loss: 0.06219826638698578
	val_positive_acc: 1.0
	val_negative_acc: 0.9789827658680117
test:
	test_positive_loss: 0.0004948118003085256
	test_negative_loss: 0.15061718225479126
	test_positive_acc: 1.0
	test_negative_acc: 0.9581966801531092
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.009628649801015854
	train_incorrect_loss: 0.546149653585299
	train_positive_loss: 0.00940119381994009
	train_negative_loss: 0.01415481511503458
	train_correct_acc: 0.998825909869729
	train_incorrect_acc: 0.888235294117647
	train_positive_acc: 0.9989059440999014
	train_negative_acc: 0.9978479253833724
	train_correct_nonzero: 30423
	train_incorrect_nonzero: 97
	train_positive_nonzero: 10637
	train_negative_nonzero: 19883
val:
	val_positive_loss: 0.0006586845847778022
	val_negative_loss: 0.002294968580827117
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.010589508339762688
	test_negative_loss: 0.0353739932179451
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9920673976010044
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.011054551228880882
	train_incorrect_loss: 1.2237123519205737
	train_positive_loss: 0.01742946170270443
	train_negative_loss: 0.017636360600590706
	train_correct_acc: 0.9984461058754881
	train_incorrect_acc: 0.7925531914893617
	train_positive_acc: 0.9989854500374917
	train_negative_acc: 0.995710054956015
	train_correct_nonzero: 29975
	train_incorrect_nonzero: 120
	train_positive_nonzero: 10632
	train_negative_nonzero: 19463
val:
	val_positive_loss: 0.0017124967416748405
	val_negative_loss: 0.09137064218521118
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.007496866397559643
	test_negative_loss: 0.11476339399814606
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9907864932418631
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.009639056399464607
	train_incorrect_loss: 0.9318066565460155
	train_positive_loss: 0.009653289802372456
	train_negative_loss: 0.015924839302897453
	train_correct_acc: 0.9994493512662377
	train_incorrect_acc: 0.8674698795180723
	train_positive_acc: 0.9995033139185026
	train_negative_acc: 0.99833558034027
	train_correct_nonzero: 30846
	train_incorrect_nonzero: 88
	train_positive_nonzero: 11230
	train_negative_nonzero: 19704
val:
	val_positive_loss: 0.009583614766597748
	val_negative_loss: 0.0037702047266066074
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02620074152946472
	test_negative_loss: 0.018531478941440582
	test_positive_acc: 0.9892838938546772
	test_negative_acc: 0.99598589289881
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.009055349044501781
	train_incorrect_loss: 0.761163858758479
	train_positive_loss: 0.017416158691048622
	train_negative_loss: 0.012841533869504929
	train_correct_acc: 0.9989914093340471
	train_incorrect_acc: 0.9194915254237288
	train_positive_acc: 0.9987875333283209
	train_negative_acc: 0.9977659910734102
	train_correct_nonzero: 26178
	train_incorrect_nonzero: 148
	train_positive_nonzero: 6625
	train_negative_nonzero: 19701
val:
	val_positive_loss: 0.01620548777282238
	val_negative_loss: 0.00029249649378471076
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05430680140852928
	test_negative_loss: 0.008450721390545368
	test_positive_acc: 0.9820807952096521
	test_negative_acc: 0.99598589289881
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.004613271914422512
	train_incorrect_loss: 0.27126216564308075
	train_positive_loss: 0.008886615745723248
	train_negative_loss: 0.004073198419064283
	train_correct_acc: 0.9991943759813849
	train_incorrect_acc: 0.9833333333333333
	train_positive_acc: 0.9987225494482234
	train_negative_acc: 0.9995106833473684
	train_correct_nonzero: 24523
	train_incorrect_nonzero: 269
	train_positive_nonzero: 4805
	train_negative_nonzero: 19987
val:
	val_positive_loss: 0.11179490387439728
	val_negative_loss: 0.00014686935173813254
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.13166160881519318
	test_negative_loss: 0.02470872551202774
	test_positive_acc: 0.9641941389164556
	test_negative_acc: 0.99598589289881
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.008245262317359447
	train_incorrect_loss: 0.44431369189336944
	train_positive_loss: 0.02661430835723877
	train_negative_loss: 0.0068771373480558395
	train_correct_acc: 0.9982322064914894
	train_incorrect_acc: 0.9606986899563319
	train_positive_acc: 0.9972177681035712
	train_negative_acc: 0.9974473341430126
	train_correct_nonzero: 22638
	train_incorrect_nonzero: 424
	train_positive_nonzero: 3640
	train_negative_nonzero: 19422
val:
	val_positive_loss: 0.0008543587755411863
	val_negative_loss: 0.23123325407505035
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.008252649568021297
	test_negative_loss: 0.24588151276111603
	test_positive_acc: 0.9959492020492408
	test_negative_acc: 0.9880309215364368
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.011373567394912243
	train_incorrect_loss: 0.1340610281755641
	train_positive_loss: 0.009104622527956963
	train_negative_loss: 0.01756989397108555
	train_correct_acc: 0.9989814666856429
	train_incorrect_acc: 0.989453125
	train_positive_acc: 0.9982029470310044
	train_negative_acc: 0.9995567390558137
	train_correct_nonzero: 23624
	train_incorrect_nonzero: 586
	train_positive_nonzero: 4475
	train_negative_nonzero: 19735
val:
	val_positive_loss: 0.2518799304962158
	val_negative_loss: 0.00033992441603913903
	val_positive_acc: 0.9251786464901219
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.21819046139717102
	test_negative_loss: 0.020259298384189606
	test_positive_acc: 0.9452950256621244
	test_negative_acc: 0.9949083066919134
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.68733596801758 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.1
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.235337495803833
	train_negative_loss: 2.2804651260375977
	train_positive_acc: 0.6451661559634939
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.14371921122074127
	train_incorrect_loss: 1.1550888022526782
	train_positive_loss: 0.1444106251001358
	train_negative_loss: 0.1839277446269989
	train_correct_acc: 0.9715579696761282
	train_incorrect_acc: 0.6215452396303459
	train_positive_acc: 0.9789428106015612
	train_negative_acc: 0.9470671812023054
	train_correct_nonzero: 24454
	train_incorrect_nonzero: 593
	train_positive_nonzero: 8390
	train_negative_nonzero: 16657
val:
	val_positive_loss: 0.006506959907710552
	val_negative_loss: 0.04964762553572655
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.013255912810564041
	test_negative_loss: 0.06582584977149963
	test_positive_acc: 0.9973958333333333
	test_negative_acc: 0.9857740900465214
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.025737544521689415
	train_incorrect_loss: 1.2847192269914292
	train_positive_loss: 0.03549855574965477
	train_negative_loss: 0.03808029741048813
	train_correct_acc: 0.9967031925066228
	train_incorrect_acc: 0.7478991596638656
	train_positive_acc: 0.9973073713961886
	train_negative_acc: 0.9914058062307374
	train_correct_nonzero: 27868
	train_incorrect_nonzero: 193
	train_positive_nonzero: 8894
	train_negative_nonzero: 19167
val:
	val_positive_loss: 0.008179605938494205
	val_negative_loss: 0.007800384424626827
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03260760009288788
	test_negative_loss: 0.01758590340614319
	test_positive_acc: 0.9903932243390077
	test_negative_acc: 0.99598589289881
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.017115557566285133
	train_incorrect_loss: 1.2692699260398512
	train_positive_loss: 0.034218091517686844
	train_negative_loss: 0.025587383657693863
	train_correct_acc: 0.9983323217530057
	train_incorrect_acc: 0.79375
	train_positive_acc: 0.9983540098901829
	train_negative_acc: 0.9941780421949926
	train_correct_nonzero: 29429
	train_incorrect_nonzero: 198
	train_positive_nonzero: 10425
	train_negative_nonzero: 19202
val:
	val_positive_loss: 0.004597941879183054
	val_negative_loss: 0.02732047438621521
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.029786136001348495
	test_negative_loss: 0.031735651195049286
	test_positive_acc: 0.9858780805927088
	test_negative_acc: 0.9960085706927142
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.02367183193564415
	train_incorrect_loss: 0.7653684247649047
	train_positive_loss: 0.015492042526602745
	train_negative_loss: 0.040490102022886276
	train_correct_acc: 0.9981971529638078
	train_incorrect_acc: 0.8949579831932774
	train_positive_acc: 0.9987537287051249
	train_negative_acc: 0.9963274465062432
	train_correct_nonzero: 26544
	train_incorrect_nonzero: 137
	train_positive_nonzero: 6935
	train_negative_nonzero: 19746
val:
	val_positive_loss: 0.009753563441336155
	val_negative_loss: 0.003430950455367565
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.019343234598636627
	test_negative_loss: 0.01879638433456421
	test_positive_acc: 0.9946992020492407
	test_negative_acc: 0.99598589289881
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.004968666937202215
	train_incorrect_loss: 0.20476079998365163
	train_positive_loss: 0.007106719072908163
	train_negative_loss: 0.005637557711452246
	train_correct_acc: 0.9991722403385073
	train_incorrect_acc: 0.9884259259259259
	train_positive_acc: 0.9988233480296219
	train_negative_acc: 0.9994797682317063
	train_correct_nonzero: 24738
	train_incorrect_nonzero: 322
	train_positive_nonzero: 5018
	train_negative_nonzero: 20042
val:
	val_positive_loss: 0.07173082232475281
	val_negative_loss: 0.0004748360370285809
	val_positive_acc: 0.9707860445565364
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.10676253587007523
	test_negative_loss: 0.007604401558637619
	test_positive_acc: 0.9599430473692316
	test_negative_acc: 0.997187815975733
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.006368905305862427
	train_incorrect_loss: 0.20267616056629675
	train_positive_loss: 0.01226708386093378
	train_negative_loss: 0.006033940240740776
	train_correct_acc: 0.9986905592502793
	train_incorrect_acc: 0.9895833333333334
	train_positive_acc: 0.9976630291036578
	train_negative_acc: 0.9993702683052914
	train_correct_nonzero: 23981
	train_incorrect_nonzero: 523
	train_positive_nonzero: 4564
	train_negative_nonzero: 19940
val:
	val_positive_loss: 0.026173921301960945
	val_negative_loss: 0.036113034933805466
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.03081314079463482
	test_negative_loss: 0.056372709572315216
	test_positive_acc: 0.9915711717606664
	test_negative_acc: 0.9870969619086876
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.008417947217822075
	train_incorrect_loss: 0.14544664391406825
	train_positive_loss: 0.015289230272173882
	train_negative_loss: 0.00747961550951004
	train_correct_acc: 0.9981722112662164
	train_incorrect_acc: 0.9952736318407961
	train_positive_acc: 0.9967847958240595
	train_negative_acc: 0.9994164930768953
	train_correct_nonzero: 24550
	train_incorrect_nonzero: 783
	train_positive_nonzero: 5370
	train_negative_nonzero: 19963
val:
	val_positive_loss: 0.08475656807422638
	val_negative_loss: 0.005208262242376804
	val_positive_acc: 0.9625893232450609
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05217491462826729
	test_negative_loss: 0.03164159506559372
	test_positive_acc: 0.981859092225988
	test_negative_acc: 0.991602846428906
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.005385555326938629
	train_incorrect_loss: 0.12975893310420714
	train_positive_loss: 0.009363075718283653
	train_negative_loss: 0.005365760996937752
	train_correct_acc: 0.9989426962190929
	train_incorrect_acc: 0.9991935483870967
	train_positive_acc: 0.9980582504585405
	train_negative_acc: 0.9997678339704993
	train_correct_nonzero: 24072
	train_incorrect_nonzero: 614
	train_positive_nonzero: 4710
	train_negative_nonzero: 19976
val:
	val_positive_loss: 0.1381840705871582
	val_negative_loss: 0.0019688315223902464
	val_positive_acc: 0.9451450189155107
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.1185542568564415
	test_negative_loss: 0.009024255909025669
	test_positive_acc: 0.9540495062914273
	test_negative_acc: 0.997439381270903
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.004540205467492342
	train_incorrect_loss: 0.13524477602303733
	train_positive_loss: 0.009200307540595531
	train_negative_loss: 0.005711013916879892
	train_correct_acc: 0.999291261438751
	train_incorrect_acc: 0.9938416422287389
	train_positive_acc: 0.9986964514120854
	train_negative_acc: 0.9996588352840065
	train_correct_nonzero: 22112
	train_incorrect_nonzero: 832
	train_positive_nonzero: 2935
	train_negative_nonzero: 20009
val:
	val_positive_loss: 0.22790762782096863
	val_negative_loss: 0.0006439958233386278
	val_positive_acc: 0.9333753678015972
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.1851457804441452
	test_negative_loss: 0.014679277315735817
	test_positive_acc: 0.9489318394355708
	test_negative_acc: 0.997439381270903
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.0045966473408043385
	train_incorrect_loss: 0.09111044435552451
	train_positive_loss: 0.008015761151909828
	train_negative_loss: 0.004885271657258272
	train_correct_acc: 0.9989354762301446
	train_incorrect_acc: 1.0
	train_positive_acc: 0.9981657246131793
	train_negative_acc: 0.9998201060797797
	train_correct_nonzero: 21734
	train_incorrect_nonzero: 896
	train_positive_nonzero: 2633
	train_negative_nonzero: 19997
val:
	val_positive_loss: 0.24487167596817017
	val_negative_loss: 0.0005826824344694614
	val_positive_acc: 0.9123581336696092
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.17302238941192627
	test_negative_loss: 0.005533311981707811
	test_positive_acc: 0.9462641697527485
	test_negative_acc: 0.998641304347826
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.650390625 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.125
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2352235317230225
	train_negative_loss: 2.2804722785949707
	train_positive_acc: 0.6501459646011946
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.14611704647541046
	train_incorrect_loss: 1.0805505383106178
	train_positive_loss: 0.1530063897371292
	train_negative_loss: 0.1828746497631073
	train_correct_acc: 0.971788425796774
	train_incorrect_acc: 0.6403021442495126
	train_positive_acc: 0.9810873714988223
	train_negative_acc: 0.9415155644986319
	train_correct_nonzero: 24689
	train_incorrect_nonzero: 686
	train_positive_nonzero: 8593
	train_negative_nonzero: 16782
val:
	val_positive_loss: 0.010734828189015388
	val_negative_loss: 0.024059392511844635
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.018515707924962044
	test_negative_loss: 0.04167193919420242
	test_positive_acc: 0.9946992020492407
	test_negative_acc: 0.9876680294404607
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03361722081899643
	train_incorrect_loss: 1.3258715789547584
	train_positive_loss: 0.041240885853767395
	train_negative_loss: 0.052876148372888565
	train_correct_acc: 0.9963819373362182
	train_incorrect_acc: 0.6431405577390978
	train_positive_acc: 0.9980200331702476
	train_negative_acc: 0.9875697234287142
	train_correct_nonzero: 27468
	train_incorrect_nonzero: 235
	train_positive_nonzero: 8596
	train_negative_nonzero: 19107
val:
	val_positive_loss: 0.0016676709055900574
	val_negative_loss: 0.017652640119194984
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.009069070219993591
	test_negative_loss: 0.03526538610458374
	test_positive_acc: 0.9989035087719298
	test_negative_acc: 0.9912269442637095
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.025291070342063904
	train_incorrect_loss: 1.0812787666514014
	train_positive_loss: 0.03322439268231392
	train_negative_loss: 0.04220713675022125
	train_correct_acc: 0.9975770940376285
	train_incorrect_acc: 0.7447089947089947
	train_positive_acc: 0.9984825026728471
	train_negative_acc: 0.9911519354351239
	train_correct_nonzero: 29943
	train_incorrect_nonzero: 201
	train_positive_nonzero: 10884
	train_negative_nonzero: 19260
val:
	val_positive_loss: 0.005494511220604181
	val_negative_loss: 0.013532072305679321
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.013010615482926369
	test_negative_loss: 0.0346967950463295
	test_positive_acc: 0.9959492020492408
	test_negative_acc: 0.9935045642824578
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.01837295852601528
	train_incorrect_loss: 1.2142933251954025
	train_positive_loss: 0.029017183929681778
	train_negative_loss: 0.029020272195339203
	train_correct_acc: 0.9984401298505026
	train_incorrect_acc: 0.7871287128712872
	train_positive_acc: 0.9988835049275709
	train_negative_acc: 0.9938443913684447
	train_correct_nonzero: 29422
	train_incorrect_nonzero: 154
	train_positive_nonzero: 10104
	train_negative_nonzero: 19472
val:
	val_positive_loss: 0.0028324341401457787
	val_negative_loss: 0.008944673463702202
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01862802729010582
	test_negative_loss: 0.02821248210966587
	test_positive_acc: 0.9933646155830753
	test_negative_acc: 0.9938596779188213
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.006670055910944939
	train_incorrect_loss: 0.6537704419889273
	train_positive_loss: 0.008242969401180744
	train_negative_loss: 0.010004985146224499
	train_correct_acc: 0.9992981349057518
	train_incorrect_acc: 0.896551724137931
	train_positive_acc: 0.9994210314728325
	train_negative_acc: 0.998303972947125
	train_correct_nonzero: 29498
	train_incorrect_nonzero: 72
	train_positive_nonzero: 9678
	train_negative_nonzero: 19892
val:
	val_positive_loss: 0.002693634945899248
	val_negative_loss: 0.0015717297792434692
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.021228469908237457
	test_negative_loss: 0.0165596604347229
	test_positive_acc: 0.9921146155830753
	test_negative_acc: 0.99598589289881
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.005149486940354109
	train_incorrect_loss: 0.5570161454167054
	train_positive_loss: 0.012280035763978958
	train_negative_loss: 0.0071157850325107574
	train_correct_acc: 0.9993697000750656
	train_incorrect_acc: 0.9146825396825397
	train_positive_acc: 0.9993739910292548
	train_negative_acc: 0.998005625002099
	train_correct_nonzero: 26030
	train_incorrect_nonzero: 137
	train_positive_nonzero: 6354
	train_negative_nonzero: 19813
val:
	val_positive_loss: 0.00026001277728937566
	val_negative_loss: 0.017317011952400208
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.010439958423376083
	test_negative_loss: 0.05583781749010086
	test_positive_acc: 0.9959492020492408
	test_negative_acc: 0.9865982216931766
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.009481136687099934
	train_incorrect_loss: 0.7158019736143781
	train_positive_loss: 0.015020344406366348
	train_negative_loss: 0.015629159286618233
	train_correct_acc: 0.9992959787700477
	train_incorrect_acc: 0.8828090869375274
	train_positive_acc: 0.999589556849789
	train_negative_acc: 0.9970472502568056
	train_correct_nonzero: 27768
	train_incorrect_nonzero: 115
	train_positive_nonzero: 8096
	train_negative_nonzero: 19787
val:
	val_positive_loss: 0.01812657155096531
	val_negative_loss: 0.017045380547642708
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03996090590953827
	test_negative_loss: 0.027258675545454025
	test_positive_acc: 0.9816201513200818
	test_negative_acc: 0.99598589289881
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.004554123152047396
	train_incorrect_loss: 0.15819365217480066
	train_positive_loss: 0.0061451527290046215
	train_negative_loss: 0.004734749905765057
	train_correct_acc: 0.9995735150326214
	train_incorrect_acc: 0.9943181818181818
	train_positive_acc: 0.9993332711139353
	train_negative_acc: 0.9998066948388513
	train_correct_nonzero: 25050
	train_incorrect_nonzero: 206
	train_positive_nonzero: 5242
	train_negative_nonzero: 20014
val:
	val_positive_loss: 0.006281095091253519
	val_negative_loss: 0.000286090187728405
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.049652665853500366
	test_negative_loss: 0.005345044657588005
	test_positive_acc: 0.9831617567299504
	test_negative_acc: 0.997439381270903
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.004795745015144348
	train_incorrect_loss: 0.20384819555215844
	train_positive_loss: 0.005732853431254625
	train_negative_loss: 0.005420469678938389
	train_correct_acc: 0.9991989568441297
	train_incorrect_acc: 0.9795081967213115
	train_positive_acc: 0.9990270147164686
	train_negative_acc: 0.9992373249951514
	train_correct_nonzero: 24976
	train_incorrect_nonzero: 143
	train_positive_nonzero: 5116
	train_negative_nonzero: 20003
val:
	val_positive_loss: 0.0007332378881983459
	val_negative_loss: 0.0013661454431712627
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.027069352567195892
	test_negative_loss: 0.0200179573148489
	test_positive_acc: 0.9918569401444788
	test_negative_acc: 0.9938596779188213
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.003669458208605647
	train_incorrect_loss: 0.30646739596140543
	train_positive_loss: 0.012324882671236992
	train_negative_loss: 0.004061711020767689
	train_correct_acc: 0.9992184441914398
	train_incorrect_acc: 0.9812834224598931
	train_positive_acc: 0.9988670639206759
	train_negative_acc: 0.9988217492385074
	train_correct_nonzero: 24642
	train_incorrect_nonzero: 258
	train_positive_nonzero: 4996
	train_negative_nonzero: 19904
val:
	val_positive_loss: 0.024310613051056862
	val_negative_loss: 0.0007402209448628128
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.07065338641405106
	test_negative_loss: 0.015195890329778194
	test_positive_acc: 0.9773702918389093
	test_negative_acc: 0.9960085706927142
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.57705068588257 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.15
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.235092878341675
	train_negative_loss: 2.280439853668213
	train_positive_acc: 0.6557906113916965
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.15364450216293335
	train_incorrect_loss: 1.0270693280110736
	train_positive_loss: 0.16345103085041046
	train_negative_loss: 0.19377164542675018
	train_correct_acc: 0.9719093909268938
	train_incorrect_acc: 0.6698670057541025
	train_positive_acc: 0.980973338331068
	train_negative_acc: 0.9389789231140792
	train_correct_nonzero: 25428
	train_incorrect_nonzero: 816
	train_positive_nonzero: 9290
	train_negative_nonzero: 16954
val:
	val_positive_loss: 0.039090346544981
	val_negative_loss: 0.02900015376508236
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04779275506734848
	test_negative_loss: 0.03396810591220856
	test_positive_acc: 0.9867486222901504
	test_negative_acc: 0.9941905333267361
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03274347260594368
	train_incorrect_loss: 1.0996503405482836
	train_positive_loss: 0.04439953342080116
	train_negative_loss: 0.049984801560640335
	train_correct_acc: 0.9968914247911352
	train_incorrect_acc: 0.7359154929577465
	train_positive_acc: 0.9975922082068565
	train_negative_acc: 0.9886655190578576
	train_correct_nonzero: 29812
	train_incorrect_nonzero: 266
	train_positive_nonzero: 10997
	train_negative_nonzero: 19081
val:
	val_positive_loss: 0.005280031356960535
	val_negative_loss: 0.01615968719124794
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.026710741221904755
	test_negative_loss: 0.025972861796617508
	test_positive_acc: 0.9882976337075828
	test_negative_acc: 0.994532404526717
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.020309939980506897
	train_incorrect_loss: 0.8499275743293658
	train_positive_loss: 0.03007826954126358
	train_negative_loss: 0.0339590385556221
	train_correct_acc: 0.997576472130212
	train_incorrect_acc: 0.8498774509803921
	train_positive_acc: 0.9982857520135454
	train_negative_acc: 0.992136254369143
	train_correct_nonzero: 28128
	train_incorrect_nonzero: 216
	train_positive_nonzero: 8828
	train_negative_nonzero: 19516
val:
	val_positive_loss: 0.001052682870067656
	val_negative_loss: 0.033806122839450836
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.005024605896323919
	test_negative_loss: 0.041986122727394104
	test_positive_acc: 0.9981617647058824
	test_negative_acc: 0.986851676253418
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.01728689856827259
	train_incorrect_loss: 0.9834524115592811
	train_positive_loss: 0.027257852256298065
	train_negative_loss: 0.028247017413377762
	train_correct_acc: 0.9982681487823697
	train_incorrect_acc: 0.8201058201058202
	train_positive_acc: 0.9986069262819867
	train_negative_acc: 0.9940260733783974
	train_correct_nonzero: 29342
	train_incorrect_nonzero: 189
	train_positive_nonzero: 9995
	train_negative_nonzero: 19536
val:
	val_positive_loss: 0.002997889881953597
	val_negative_loss: 0.013024689629673958
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02023950032889843
	test_negative_loss: 0.029288403689861298
	test_positive_acc: 0.9886885042113382
	test_negative_acc: 0.9948066476157911
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.007790088653564453
	train_incorrect_loss: 0.5328152353259308
	train_positive_loss: 0.012465325184166431
	train_negative_loss: 0.01100135874003172
	train_correct_acc: 0.9989981908199619
	train_incorrect_acc: 0.9333333333333333
	train_positive_acc: 0.9988981850455068
	train_negative_acc: 0.9980749955044536
	train_correct_nonzero: 28432
	train_incorrect_nonzero: 147
	train_positive_nonzero: 8714
	train_negative_nonzero: 19865
val:
	val_positive_loss: 0.038141313940286636
	val_negative_loss: 0.008438825607299805
	val_positive_acc: 0.9743589743589743
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03486261144280434
	test_negative_loss: 0.015417864546179771
	test_positive_acc: 0.9856184790389965
	test_negative_acc: 0.997439381270903
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.008904310874640942
	train_incorrect_loss: 0.6677970936829324
	train_positive_loss: 0.02126501314342022
	train_negative_loss: 0.015044710598886013
	train_correct_acc: 0.9991380711062111
	train_incorrect_acc: 0.9253731343283582
	train_positive_acc: 0.9991076229052774
	train_negative_acc: 0.9967637678396238
	train_correct_nonzero: 26318
	train_incorrect_nonzero: 171
	train_positive_nonzero: 6746
	train_negative_nonzero: 19743
val:
	val_positive_loss: 0.0030862672720104456
	val_negative_loss: 0.008256712928414345
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.029218606650829315
	test_negative_loss: 0.017281770706176758
	test_positive_acc: 0.9856934670409161
	test_negative_acc: 0.9962601359878842
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.009484865702688694
	train_incorrect_loss: 0.4746026515653024
	train_positive_loss: 0.022000810131430626
	train_negative_loss: 0.014974177815020084
	train_correct_acc: 0.9993836749355787
	train_incorrect_acc: 0.95
	train_positive_acc: 0.9990784115411419
	train_negative_acc: 0.997596727785191
	train_correct_nonzero: 27326
	train_incorrect_nonzero: 195
	train_positive_nonzero: 7699
	train_negative_nonzero: 19822
val:
	val_positive_loss: 0.001303141936659813
	val_negative_loss: 0.010239215567708015
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.03455996513366699
	test_negative_loss: 0.020802490413188934
	test_positive_acc: 0.9867486222901504
	test_negative_acc: 0.9935854348297473
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.007677711080759764
	train_incorrect_loss: 0.3525376960943686
	train_positive_loss: 0.02271806262433529
	train_negative_loss: 0.008835319429636002
	train_correct_acc: 0.9987148809243944
	train_incorrect_acc: 0.97
	train_positive_acc: 0.9980330032194794
	train_negative_acc: 0.9975013030411479
	train_correct_nonzero: 24295
	train_incorrect_nonzero: 431
	train_positive_nonzero: 4872
	train_negative_nonzero: 19854
val:
	val_positive_loss: 0.005911878310143948
	val_negative_loss: 0.0033331047743558884
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.039694126695394516
	test_negative_loss: 0.013232306577265263
	test_positive_acc: 0.9847728728105692
	test_negative_acc: 0.997439381270903
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.00702306954190135
	train_incorrect_loss: 0.2502147622749343
	train_positive_loss: 0.013396473601460457
	train_negative_loss: 0.007485066074877977
	train_correct_acc: 0.9989023767131379
	train_incorrect_acc: 0.9831223628691983
	train_positive_acc: 0.9983225650889542
	train_negative_acc: 0.9987334387305624
	train_correct_nonzero: 24665
	train_incorrect_nonzero: 392
	train_positive_nonzero: 5068
	train_negative_nonzero: 19989
val:
	val_positive_loss: 0.0002911636547651142
	val_negative_loss: 0.0038959328085184097
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01710500568151474
	test_negative_loss: 0.03461161255836487
	test_positive_acc: 0.9919739121696955
	test_negative_acc: 0.9912269442637095
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.0022606642451137304
	train_incorrect_loss: 0.1665420924322387
	train_positive_loss: 0.003567673033103347
	train_negative_loss: 0.00287504680454731
	train_correct_acc: 0.9997745432337524
	train_incorrect_acc: 0.9853801169590644
	train_positive_acc: 0.9996011591181275
	train_negative_acc: 0.9997517779625013
	train_correct_nonzero: 24921
	train_incorrect_nonzero: 215
	train_positive_nonzero: 5108
	train_negative_nonzero: 20028
val:
	val_positive_loss: 0.05004293844103813
	val_negative_loss: 0.0009385145967826247
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04139144718647003
	test_negative_loss: 0.020693637430667877
	test_positive_acc: 0.9871773954943472
	test_negative_acc: 0.9948066476157911
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.16321730613708 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.175
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.234931230545044
	train_negative_loss: 2.2804722785949707
	train_positive_acc: 0.6614058608035442
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.15657226741313934
	train_incorrect_loss: 1.041904544137174
	train_positive_loss: 0.16247041523456573
	train_negative_loss: 0.19886527955532074
	train_correct_acc: 0.9694917152863806
	train_incorrect_acc: 0.634795248012461
	train_positive_acc: 0.9798704285541087
	train_negative_acc: 0.9344513150506188
	train_correct_nonzero: 25390
	train_incorrect_nonzero: 798
	train_positive_nonzero: 9030
	train_negative_nonzero: 17158
val:
	val_positive_loss: 0.019950024783611298
	val_negative_loss: 0.09652359783649445
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.023207414895296097
	test_negative_loss: 0.10483621805906296
	test_positive_acc: 0.9959492020492408
	test_negative_acc: 0.988305164625511
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03166312724351883
	train_incorrect_loss: 1.0315263918857893
	train_positive_loss: 0.034714628010988235
	train_negative_loss: 0.04780396819114685
	train_correct_acc: 0.9966785315558708
	train_incorrect_acc: 0.7180459770114942
	train_positive_acc: 0.9976204490032264
	train_negative_acc: 0.989689356806482
	train_correct_nonzero: 28796
	train_incorrect_nonzero: 228
	train_positive_nonzero: 9630
	train_negative_nonzero: 19394
val:
	val_positive_loss: 0.005213527008891106
	val_negative_loss: 0.030912872403860092
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01774686574935913
	test_negative_loss: 0.046821560710668564
	test_positive_acc: 0.9932111068111454
	test_negative_acc: 0.9912269442637095
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.021696913987398148
	train_incorrect_loss: 0.8908438394277893
	train_positive_loss: 0.032994594424963
	train_negative_loss: 0.03596819192171097
	train_correct_acc: 0.997627850963819
	train_incorrect_acc: 0.8333333333333333
	train_positive_acc: 0.9986009550176029
	train_negative_acc: 0.9913281582953064
	train_correct_nonzero: 27402
	train_incorrect_nonzero: 236
	train_positive_nonzero: 8116
	train_negative_nonzero: 19522
val:
	val_positive_loss: 0.0073606763035058975
	val_negative_loss: 0.002120567485690117
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04779108613729477
	test_negative_loss: 0.01202465035021305
	test_positive_acc: 0.9783050174240586
	test_negative_acc: 0.99598589289881
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.011210797354578972
	train_incorrect_loss: 0.621449717523658
	train_positive_loss: 0.021198788657784462
	train_negative_loss: 0.015209469012916088
	train_correct_acc: 0.998466126557893
	train_incorrect_acc: 0.9259259259259258
	train_positive_acc: 0.9983088712238871
	train_negative_acc: 0.9963752948920265
	train_correct_nonzero: 28429
	train_incorrect_nonzero: 205
	train_positive_nonzero: 8824
	train_negative_nonzero: 19810
val:
	val_positive_loss: 0.002514027990400791
	val_negative_loss: 0.022842129692435265
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.019385196268558502
	test_negative_loss: 0.039309196174144745
	test_positive_acc: 0.9940938822337446
	test_negative_acc: 0.9879003050265099
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.007091829087585211
	train_incorrect_loss: 0.3828125939129624
	train_positive_loss: 0.010803841054439545
	train_negative_loss: 0.00923133734613657
	train_correct_acc: 0.9990941875466739
	train_incorrect_acc: 0.9635036496350365
	train_positive_acc: 0.9987433354079918
	train_negative_acc: 0.9987790599389922
	train_correct_nonzero: 27774
	train_incorrect_nonzero: 171
	train_positive_nonzero: 7986
	train_negative_nonzero: 19959
val:
	val_positive_loss: 0.004190540406852961
	val_negative_loss: 0.0012494457187131047
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03616238012909889
	test_negative_loss: 0.01022808812558651
	test_positive_acc: 0.9860011014352322
	test_negative_acc: 0.9977204907161804
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.005753315053880215
	train_incorrect_loss: 0.19396152452987983
	train_positive_loss: 0.008626213297247887
	train_negative_loss: 0.0053203413262963295
	train_correct_acc: 0.9988470483709926
	train_incorrect_acc: 0.9774011299435028
	train_positive_acc: 0.9984420923201187
	train_negative_acc: 0.9989463275582164
	train_correct_nonzero: 28072
	train_incorrect_nonzero: 249
	train_positive_nonzero: 8330
	train_negative_nonzero: 19991
val:
	val_positive_loss: 0.015504769049584866
	val_negative_loss: 0.0006576741579920053
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04583238065242767
	test_negative_loss: 0.008617198094725609
	test_positive_acc: 0.9833611071676485
	test_negative_acc: 0.997439381270903
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.004662039689719677
	train_incorrect_loss: 0.15061692498826143
	train_positive_loss: 0.008248599246144295
	train_negative_loss: 0.004615031648427248
	train_correct_acc: 0.999114620213562
	train_incorrect_acc: 0.9959016393442623
	train_positive_acc: 0.9986180288832487
	train_negative_acc: 0.9995140596631809
	train_correct_nonzero: 23943
	train_incorrect_nonzero: 496
	train_positive_nonzero: 5089
	train_negative_nonzero: 19350
val:
	val_positive_loss: 0.030495980754494667
	val_negative_loss: 0.0004052630392834544
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05876365303993225
	test_negative_loss: 0.021063944324851036
	test_positive_acc: 0.9868576153925644
	test_negative_acc: 0.9964924115739333
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.00925971008837223
	train_incorrect_loss: 0.2932417678744868
	train_positive_loss: 0.03430600464344025
	train_negative_loss: 0.008316601626574993
	train_correct_acc: 0.998057130351332
	train_incorrect_acc: 0.982385201710355
	train_positive_acc: 0.9967126959057743
	train_negative_acc: 0.9976081662617886
	train_correct_nonzero: 23324
	train_incorrect_nonzero: 801
	train_positive_nonzero: 5062
	train_negative_nonzero: 19063
val:
	val_positive_loss: 0.37262162566185
	val_negative_loss: 4.815959619008936e-05
	val_positive_acc: 0.8995376208490963
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.28609853982925415
	test_negative_loss: 0.015276636928319931
	test_positive_acc: 0.9329338770327656
	test_negative_acc: 0.997439381270903
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.005801724269986153
	train_incorrect_loss: 0.13346039272888402
	train_positive_loss: 0.009842059575021267
	train_negative_loss: 0.005604663863778114
	train_correct_acc: 0.9987585488255075
	train_incorrect_acc: 0.9937694704049844
	train_positive_acc: 0.997915447487704
	train_negative_acc: 0.9995759790423477
	train_correct_nonzero: 22866
	train_incorrect_nonzero: 796
	train_positive_nonzero: 3944
	train_negative_nonzero: 19718
val:
	val_positive_loss: 0.0034424462355673313
	val_negative_loss: 0.0008860036032274365
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03988225385546684
	test_negative_loss: 0.008688042871654034
	test_positive_acc: 0.986860779486242
	test_negative_acc: 0.9987980769230769
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.004996823612600565
	train_incorrect_loss: 0.10284835182489362
	train_positive_loss: 0.009911122731864452
	train_negative_loss: 0.0033987127244472504
	train_correct_acc: 0.9988008712459059
	train_incorrect_acc: 0.9983922829581994
	train_positive_acc: 0.9977798438369078
	train_negative_acc: 0.9998428535506747
	train_correct_nonzero: 22011
	train_incorrect_nonzero: 686
	train_positive_nonzero: 3691
	train_negative_nonzero: 19006
val:
	val_positive_loss: 0.14667850732803345
	val_negative_loss: 1.838620300986804e-05
	val_positive_acc: 0.9707860445565364
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.1514190137386322
	test_negative_loss: 0.011269799433648586
	test_positive_acc: 0.967969485644455
	test_negative_acc: 0.9987980769230769
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.36353158950806 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.2
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.234855890274048
	train_negative_loss: 2.2804818153381348
	train_positive_acc: 0.665159741755368
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.15319034457206726
	train_incorrect_loss: 0.9827571325295139
	train_positive_loss: 0.17144589126110077
	train_negative_loss: 0.1894339621067047
	train_correct_acc: 0.972902027204235
	train_incorrect_acc: 0.6751391186938062
	train_positive_acc: 0.9818241782225636
	train_negative_acc: 0.9358929485225369
	train_correct_nonzero: 25531
	train_incorrect_nonzero: 936
	train_positive_nonzero: 8962
	train_negative_nonzero: 17505
val:
	val_positive_loss: 0.057900700718164444
	val_negative_loss: 0.06468504667282104
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05954128876328468
	test_negative_loss: 0.06592832505702972
	test_positive_acc: 0.9845408588656317
	test_negative_acc: 1.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03517509996891022
	train_incorrect_loss: 0.9797727403874021
	train_positive_loss: 0.048360105603933334
	train_negative_loss: 0.05301452800631523
	train_correct_acc: 0.9970714854046939
	train_incorrect_acc: 0.7613649626517274
	train_positive_acc: 0.997514131859783
	train_negative_acc: 0.9882800501745199
	train_correct_nonzero: 27427
	train_incorrect_nonzero: 309
	train_positive_nonzero: 8425
	train_negative_nonzero: 19311
val:
	val_positive_loss: 0.006485476158559322
	val_negative_loss: 0.018479373306035995
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.023407980799674988
	test_negative_loss: 0.028975673019886017
	test_positive_acc: 0.9904858169316003
	test_negative_acc: 0.9948066476157911
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.021041356027126312
	train_incorrect_loss: 0.7265578361969309
	train_positive_loss: 0.03685849905014038
	train_negative_loss: 0.03102928213775158
	train_correct_acc: 0.9977061400828698
	train_incorrect_acc: 0.8777120315581853
	train_positive_acc: 0.9976723066879725
	train_negative_acc: 0.992589474517691
	train_correct_nonzero: 28023
	train_incorrect_nonzero: 267
	train_positive_nonzero: 8696
	train_negative_nonzero: 19594
val:
	val_positive_loss: 0.008244624361395836
	val_negative_loss: 0.00817684456706047
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03367112576961517
	test_negative_loss: 0.018329329788684845
	test_positive_acc: 0.9884578678267513
	test_negative_acc: 0.994532404526717
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.0176339540630579
	train_incorrect_loss: 0.7189599019131482
	train_positive_loss: 0.032184235751628876
	train_negative_loss: 0.027923397719860077
	train_correct_acc: 0.9983308534845824
	train_incorrect_acc: 0.8801169590643275
	train_positive_acc: 0.9986873150985922
	train_negative_acc: 0.9938166857046419
	train_correct_nonzero: 29208
	train_incorrect_nonzero: 245
	train_positive_nonzero: 9759
	train_negative_nonzero: 19694
val:
	val_positive_loss: 0.0013335600960999727
	val_negative_loss: 0.010243229568004608
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.024576276540756226
	test_negative_loss: 0.02827361784875393
	test_positive_acc: 0.9905839023051094
	test_negative_acc: 0.9898751149677387
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.016923200339078903
	train_incorrect_loss: 0.8703459471651058
	train_positive_loss: 0.04209279268980026
	train_negative_loss: 0.023685911670327187
	train_correct_acc: 0.9978626484230285
	train_incorrect_acc: 0.8867521367521366
	train_positive_acc: 0.9978018338424092
	train_negative_acc: 0.9933535072475432
	train_correct_nonzero: 27150
	train_incorrect_nonzero: 226
	train_positive_nonzero: 7693
	train_negative_nonzero: 19683
val:
	val_positive_loss: 0.010732592083513737
	val_negative_loss: 0.004095139913260937
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04272998124361038
	test_negative_loss: 0.017548998817801476
	test_positive_acc: 0.9794800294221389
	test_negative_acc: 0.99598589289881
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.010590161196887493
	train_incorrect_loss: 0.5832140653750854
	train_positive_loss: 0.03227890282869339
	train_negative_loss: 0.01705333963036537
	train_correct_acc: 0.999145374543906
	train_incorrect_acc: 0.936046511627907
	train_positive_acc: 0.9987828599425999
	train_negative_acc: 0.9949246797846163
	train_correct_nonzero: 22301
	train_incorrect_nonzero: 287
	train_positive_nonzero: 2948
	train_negative_nonzero: 19640
val:
	val_positive_loss: 0.012235928326845169
	val_negative_loss: 0.002687930827960372
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.034551382064819336
	test_negative_loss: 0.010536622256040573
	test_positive_acc: 0.9846822219300948
	test_negative_acc: 0.99598589289881
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.005612237844616175
	train_incorrect_loss: 0.3031502631848626
	train_positive_loss: 0.010267880745232105
	train_negative_loss: 0.007568932604044676
	train_correct_acc: 0.9991675216165447
	train_incorrect_acc: 0.9645061728395061
	train_positive_acc: 0.998782315459405
	train_negative_acc: 0.9986709227563623
	train_correct_nonzero: 22063
	train_incorrect_nonzero: 297
	train_positive_nonzero: 2407
	train_negative_nonzero: 19953
val:
	val_positive_loss: 0.00369257596321404
	val_negative_loss: 0.009101349860429764
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03922540694475174
	test_negative_loss: 0.020097997039556503
	test_positive_acc: 0.9809152485050344
	test_negative_acc: 0.9950616009957445
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.006821806076914072
	train_incorrect_loss: 0.26258993703902433
	train_positive_loss: 0.014063388109207153
	train_negative_loss: 0.008237691596150398
	train_correct_acc: 0.9989893122652187
	train_incorrect_acc: 0.9820872274143302
	train_positive_acc: 0.9983492041017805
	train_negative_acc: 0.998697867069298
	train_correct_nonzero: 21252
	train_incorrect_nonzero: 358
	train_positive_nonzero: 1671
	train_negative_nonzero: 19939
val:
	val_positive_loss: 0.10464096814393997
	val_negative_loss: 0.0009189342381432652
	val_positive_acc: 0.9661622530474989
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.10411538928747177
	test_negative_loss: 0.010606353171169758
	test_positive_acc: 0.9667313133062438
	test_negative_acc: 0.99573432760364
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.004737844690680504
	train_incorrect_loss: 0.11909272913833875
	train_positive_loss: 0.007297345902770758
	train_negative_loss: 0.0047932639718055725
	train_correct_acc: 0.9989922775423035
	train_incorrect_acc: 1.0
	train_positive_acc: 0.9983492346185778
	train_negative_acc: 0.999696448424899
	train_correct_nonzero: 21445
	train_incorrect_nonzero: 443
	train_positive_nonzero: 1854
	train_negative_nonzero: 20034
val:
	val_positive_loss: 0.05629489943385124
	val_negative_loss: 0.0007318468997254968
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.08491344004869461
	test_negative_loss: 0.005160285159945488
	test_positive_acc: 0.9712637285044274
	test_negative_acc: 0.998641304347826
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.004785037599503994
	train_incorrect_loss: 0.17478139916231059
	train_positive_loss: 0.012270218692719936
	train_negative_loss: 0.004601533990353346
	train_correct_acc: 0.9992159551205835
	train_incorrect_acc: 0.9898648648648649
	train_positive_acc: 0.9985174822513162
	train_negative_acc: 0.9993027062962518
	train_correct_nonzero: 21392
	train_incorrect_nonzero: 620
	train_positive_nonzero: 2056
	train_negative_nonzero: 19956
val:
	val_positive_loss: 0.104344442486763
	val_negative_loss: 0.0002221945469500497
	val_positive_acc: 0.9707860445565364
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.19755743443965912
	test_negative_loss: 0.009169929660856724
	test_positive_acc: 0.9503159562193517
	test_negative_acc: 0.997187815975733
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.18717837333679 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.225
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.234710454940796
	train_negative_loss: 2.2804484367370605
	train_positive_acc: 0.6701711000477298
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.16904832422733307
	train_incorrect_loss: 0.9807021117923803
	train_positive_loss: 0.18916328251361847
	train_negative_loss: 0.21654275059700012
	train_correct_acc: 0.9624969584720142
	train_incorrect_acc: 0.6691444365814113
	train_positive_acc: 0.9765425642012475
	train_negative_acc: 0.9155200653042619
	train_correct_nonzero: 26034
	train_incorrect_nonzero: 1048
	train_positive_nonzero: 9875
	train_negative_nonzero: 17207
val:
	val_positive_loss: 0.018403435125947
	val_negative_loss: 0.03478752076625824
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.034265533089637756
	test_negative_loss: 0.04831305146217346
	test_positive_acc: 0.9888060817676578
	test_negative_acc: 0.9876680294404607
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03086281009018421
	train_incorrect_loss: 0.9034666364614883
	train_positive_loss: 0.05086881294846535
	train_negative_loss: 0.04710625484585762
	train_correct_acc: 0.997310907102195
	train_incorrect_acc: 0.8066905005107251
	train_positive_acc: 0.9977154244432185
	train_negative_acc: 0.9876172216671844
	train_correct_nonzero: 29777
	train_incorrect_nonzero: 331
	train_positive_nonzero: 10728
	train_negative_nonzero: 19380
val:
	val_positive_loss: 0.018233560025691986
	val_negative_loss: 0.052872881293296814
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03945726528763771
	test_negative_loss: 0.06001677364110947
	test_positive_acc: 0.9861003564916118
	test_negative_acc: 0.997618831640058
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.019624829292297363
	train_incorrect_loss: 0.681587485842984
	train_positive_loss: 0.025547895580530167
	train_negative_loss: 0.03003855235874653
	train_correct_acc: 0.9982826040437079
	train_incorrect_acc: 0.8450292397660819
	train_positive_acc: 0.9982803547717393
	train_negative_acc: 0.994258606109441
	train_correct_nonzero: 31390
	train_incorrect_nonzero: 238
	train_positive_nonzero: 11876
	train_negative_nonzero: 19752
val:
	val_positive_loss: 0.004703205078840256
	val_negative_loss: 0.0028707715682685375
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.023754963651299477
	test_negative_loss: 0.016928497701883316
	test_positive_acc: 0.9903134371049651
	test_negative_acc: 0.9939613369949437
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.007636968046426773
	train_incorrect_loss: 0.3803558240061801
	train_positive_loss: 0.010587718337774277
	train_negative_loss: 0.008617154322564602
	train_correct_acc: 0.9987213475279026
	train_incorrect_acc: 0.9372294372294373
	train_positive_acc: 0.9984179416919089
	train_negative_acc: 0.998298279311899
	train_correct_nonzero: 31034
	train_incorrect_nonzero: 178
	train_positive_nonzero: 11224
	train_negative_nonzero: 19988
val:
	val_positive_loss: 0.023985479027032852
	val_negative_loss: 0.0019709542393684387
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.06170634925365448
	test_negative_loss: 0.02086891420185566
	test_positive_acc: 0.9768704194692683
	test_negative_acc: 0.9922755730368016
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.006952687632292509
	train_incorrect_loss: 0.28820972651776416
	train_positive_loss: 0.010561838746070862
	train_negative_loss: 0.0069299922324717045
	train_correct_acc: 0.9988678882266204
	train_incorrect_acc: 0.970618556701031
	train_positive_acc: 0.9984114856595624
	train_negative_acc: 0.9989773558822473
	train_correct_nonzero: 28413
	train_incorrect_nonzero: 264
	train_positive_nonzero: 8674
	train_negative_nonzero: 20003
val:
	val_positive_loss: 0.006931237876415253
	val_negative_loss: 0.009881215170025826
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.020636949688196182
	test_negative_loss: 0.03610468655824661
	test_positive_acc: 0.9892771529104363
	test_negative_acc: 0.9867210597434911
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.009898869320750237
	train_incorrect_loss: 0.36899431078338457
	train_positive_loss: 0.025564726442098618
	train_negative_loss: 0.01426205225288868
	train_correct_acc: 0.9990464001206163
	train_incorrect_acc: 0.968479968578162
	train_positive_acc: 0.9986294212751539
	train_negative_acc: 0.997170197370569
	train_correct_nonzero: 26252
	train_incorrect_nonzero: 537
	train_positive_nonzero: 6933
	train_negative_nonzero: 19856
val:
	val_positive_loss: 0.1477987915277481
	val_negative_loss: 0.00094934506341815
	val_positive_acc: 0.9251786464901219
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.15322107076644897
	test_negative_loss: 0.011353204026818275
	test_positive_acc: 0.9478668663923436
	test_negative_acc: 0.9960085706927142
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.011778565123677254
	train_incorrect_loss: 0.5307411553350591
	train_positive_loss: 0.04587617143988609
	train_negative_loss: 0.013077100738883018
	train_correct_acc: 0.9981227875103758
	train_incorrect_acc: 0.9498407643312102
	train_positive_acc: 0.996796309346065
	train_negative_acc: 0.9951560395739902
	train_correct_nonzero: 21515
	train_incorrect_nonzero: 681
	train_positive_nonzero: 2468
	train_negative_nonzero: 19728
val:
	val_positive_loss: 0.015379359014332294
	val_negative_loss: 0.0034933423157781363
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05173993855714798
	test_negative_loss: 0.029514579102396965
	test_positive_acc: 0.9768630729939245
	test_negative_acc: 0.9921739139606792
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.006551417987793684
	train_incorrect_loss: 0.26823926640219664
	train_positive_loss: 0.020917687565088272
	train_negative_loss: 0.008900173008441925
	train_correct_acc: 0.9989998775227276
	train_incorrect_acc: 0.9839836223506743
	train_positive_acc: 0.9981306466443103
	train_negative_acc: 0.998266393820205
	train_correct_nonzero: 20907
	train_incorrect_nonzero: 849
	train_positive_nonzero: 1847
	train_negative_nonzero: 19909
val:
	val_positive_loss: 0.3374718427658081
	val_negative_loss: 0.00029861711664125323
	val_positive_acc: 0.9123581336696092
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.2991747260093689
	test_negative_loss: 0.002091379836201668
	test_positive_acc: 0.9192968932902355
	test_negative_acc: 1.0
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.01761317253112793
	train_incorrect_loss: 0.4825212607117907
	train_positive_loss: 0.04845885559916496
	train_negative_loss: 0.023129574954509735
	train_correct_acc: 0.9971967601139365
	train_incorrect_acc: 0.9585523462572642
	train_positive_acc: 0.9949476430100063
	train_negative_acc: 0.9952355236144077
	train_correct_nonzero: 20746
	train_incorrect_nonzero: 1043
	train_positive_nonzero: 2092
	train_negative_nonzero: 19697
val:
	val_positive_loss: 0.06221693009138107
	val_negative_loss: 0.0051942253485322
	val_positive_acc: 0.9707860445565364
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.09290322661399841
	test_negative_loss: 0.037965886294841766
	test_positive_acc: 0.9584275911937208
	test_negative_acc: 0.9933531592436982
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.008174803107976913
	train_incorrect_loss: 0.25509668675034824
	train_positive_loss: 0.020132416859269142
	train_negative_loss: 0.008765707723796368
	train_correct_acc: 0.9980861278336712
	train_incorrect_acc: 0.9799347158218126
	train_positive_acc: 0.996518437682179
	train_negative_acc: 0.998849327848295
	train_correct_nonzero: 21165
	train_incorrect_nonzero: 1131
	train_positive_nonzero: 2446
	train_negative_nonzero: 19850
val:
	val_positive_loss: 0.21717509627342224
	val_negative_loss: 0.0013212375342845917
	val_positive_acc: 0.8913408995376209
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.18031081557273865
	test_negative_loss: 0.003071728628128767
	test_positive_acc: 0.9356227177554384
	test_negative_acc: 1.0
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.5691659450531 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.25
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2346014976501465
	train_negative_loss: 2.2804691791534424
	train_positive_acc: 0.6736668358308302
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.16488730907440186
	train_incorrect_loss: 0.9954547501972987
	train_positive_loss: 0.18900848925113678
	train_negative_loss: 0.20851609110832214
	train_correct_acc: 0.9728754590639218
	train_incorrect_acc: 0.657646986888208
	train_positive_acc: 0.9812815805671481
	train_negative_acc: 0.9274652808545698
	train_correct_nonzero: 25121
	train_incorrect_nonzero: 1123
	train_positive_nonzero: 8869
	train_negative_nonzero: 17375
val:
	val_positive_loss: 0.09059520065784454
	val_negative_loss: 0.08164407312870026
	val_positive_acc: 0.9743589743589743
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.07302849739789963
	test_negative_loss: 0.0894448459148407
	test_positive_acc: 0.9824344045877748
	test_negative_acc: 0.9912269442637095
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03450285270810127
	train_incorrect_loss: 0.7797967131797728
	train_positive_loss: 0.04575720801949501
	train_negative_loss: 0.05044311657547951
	train_correct_acc: 0.9968278949245974
	train_incorrect_acc: 0.8159722222222222
	train_positive_acc: 0.9971343345028985
	train_negative_acc: 0.9893658258782155
	train_correct_nonzero: 28237
	train_incorrect_nonzero: 316
	train_positive_nonzero: 8946
	train_negative_nonzero: 19607
val:
	val_positive_loss: 0.008746870793402195
	val_negative_loss: 0.013822654262185097
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.016342798247933388
	test_negative_loss: 0.0376497358083725
	test_positive_acc: 0.9928935288432947
	test_negative_acc: 0.9896428393816896
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.017496373504400253
	train_incorrect_loss: 0.762958617689047
	train_positive_loss: 0.03204875439405441
	train_negative_loss: 0.026986317709088326
	train_correct_acc: 0.9979712061845282
	train_incorrect_acc: 0.8598901098901099
	train_positive_acc: 0.9982907620962509
	train_negative_acc: 0.9927186434145047
	train_correct_nonzero: 27919
	train_incorrect_nonzero: 267
	train_positive_nonzero: 8519
	train_negative_nonzero: 19667
val:
	val_positive_loss: 0.010188360698521137
	val_negative_loss: 0.06679822504520416
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.010266798548400402
	test_negative_loss: 0.0739162415266037
	test_positive_acc: 0.9974154135338346
	test_negative_acc: 0.9912269442637095
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.01608789898455143
	train_incorrect_loss: 0.5842741528483616
	train_positive_loss: 0.027878375723958015
	train_negative_loss: 0.02506590075790882
	train_correct_acc: 0.998600566743455
	train_incorrect_acc: 0.9010101010101009
	train_positive_acc: 0.9986796981686542
	train_negative_acc: 0.9944865375961163
	train_correct_nonzero: 30379
	train_incorrect_nonzero: 247
	train_positive_nonzero: 10854
	train_negative_nonzero: 19772
val:
	val_positive_loss: 0.013874709606170654
	val_negative_loss: 0.011326083913445473
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.029848217964172363
	test_negative_loss: 0.02434709295630455
	test_positive_acc: 0.9880595384694876
	test_negative_acc: 0.9933531592436982
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.0061280326917767525
	train_incorrect_loss: 0.36847300419579304
	train_positive_loss: 0.010316504165530205
	train_negative_loss: 0.007248546928167343
	train_correct_acc: 0.9990976688259989
	train_incorrect_acc: 0.9410569105691056
	train_positive_acc: 0.9991701093891808
	train_negative_acc: 0.9981774511182463
	train_correct_nonzero: 32009
	train_incorrect_nonzero: 188
	train_positive_nonzero: 12237
	train_negative_nonzero: 19960
val:
	val_positive_loss: 0.021936796605587006
	val_negative_loss: 0.0030196947045624256
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.017249632626771927
	test_negative_loss: 0.03029656410217285
	test_positive_acc: 0.993131319577103
	test_negative_acc: 0.9901571365164253
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.005459811072796583
	train_incorrect_loss: 0.3495452168690166
	train_positive_loss: 0.00854346714913845
	train_negative_loss: 0.00721941189840436
	train_correct_acc: 0.9992964248267815
	train_incorrect_acc: 0.9640522875816994
	train_positive_acc: 0.9993550662546474
	train_negative_acc: 0.9986997847268265
	train_correct_nonzero: 27885
	train_incorrect_nonzero: 159
	train_positive_nonzero: 8071
	train_negative_nonzero: 19973
val:
	val_positive_loss: 0.003073277650400996
	val_negative_loss: 0.0010352698154747486
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05415809154510498
	test_negative_loss: 0.008114305324852467
	test_positive_acc: 0.9807569405009817
	test_negative_acc: 0.99598589289881
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.004083049483597279
	train_incorrect_loss: 0.15681911518525643
	train_positive_loss: 0.006483572535216808
	train_negative_loss: 0.004947222303599119
	train_correct_acc: 0.9994725153720523
	train_incorrect_acc: 0.9876543209876542
	train_positive_acc: 0.9992521679185595
	train_negative_acc: 0.9994572660067476
	train_correct_nonzero: 26198
	train_incorrect_nonzero: 397
	train_positive_nonzero: 6571
	train_negative_nonzero: 20024
val:
	val_positive_loss: 0.03460540995001793
	val_negative_loss: 0.001656853361055255
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.07290594279766083
	test_negative_loss: 0.025536220520734787
	test_positive_acc: 0.9784450272886447
	test_negative_acc: 0.9933758370376022
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.004144163336604834
	train_incorrect_loss: 0.14782740845141626
	train_positive_loss: 0.006991239730268717
	train_negative_loss: 0.004316209349781275
	train_correct_acc: 0.9991177846410165
	train_incorrect_acc: 0.9871299871299871
	train_positive_acc: 0.998706446212632
	train_negative_acc: 0.9993356239131901
	train_correct_nonzero: 23704
	train_incorrect_nonzero: 406
	train_positive_nonzero: 4133
	train_negative_nonzero: 19977
val:
	val_positive_loss: 0.0006353681674227118
	val_negative_loss: 0.0022461770568042994
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04940563440322876
	test_negative_loss: 0.023615606129169464
	test_positive_acc: 0.9797363632674807
	test_negative_acc: 0.9922755730368016
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.0036792808678001165
	train_incorrect_loss: 0.1652812467008032
	train_positive_loss: 0.006025662645697594
	train_negative_loss: 0.004586829338222742
	train_correct_acc: 0.9994475516945851
	train_incorrect_acc: 0.9879032258064516
	train_positive_acc: 0.9992837563987335
	train_negative_acc: 0.9994169954444153
	train_correct_nonzero: 26273
	train_incorrect_nonzero: 378
	train_positive_nonzero: 6655
	train_negative_nonzero: 19996
val:
	val_positive_loss: 0.0407465323805809
	val_negative_loss: 0.000338424724759534
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.08030203729867935
	test_negative_loss: 0.028855323791503906
	test_positive_acc: 0.9784382863444039
	test_negative_acc: 0.9933531592436982
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.0036395920906215906
	train_incorrect_loss: 0.14539231530122254
	train_positive_loss: 0.00624230969697237
	train_negative_loss: 0.0037370040081441402
	train_correct_acc: 0.9992460458830248
	train_incorrect_acc: 0.9901960784313726
	train_positive_acc: 0.9988003032619212
	train_negative_acc: 0.9995616215769348
	train_correct_nonzero: 23363
	train_incorrect_nonzero: 429
	train_positive_nonzero: 3796
	train_negative_nonzero: 19996
val:
	val_positive_loss: 0.059066176414489746
	val_negative_loss: 0.0003264842089265585
	val_positive_acc: 0.9707860445565364
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.11038066446781158
	test_negative_loss: 0.01592479646205902
	test_positive_acc: 0.9668387707599083
	test_negative_acc: 0.9945550823206211
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.44034719467163 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.275
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2345149517059326
	train_negative_loss: 2.280454635620117
	train_positive_acc: 0.6773676136085398
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.16462379693984985
	train_incorrect_loss: 0.960907584663029
	train_positive_loss: 0.1827702671289444
	train_negative_loss: 0.21158753335475922
	train_correct_acc: 0.9714681728925753
	train_incorrect_acc: 0.6778857373843125
	train_positive_acc: 0.9840601595445106
	train_negative_acc: 0.9232007284727894
	train_correct_nonzero: 24325
	train_incorrect_nonzero: 1131
	train_positive_nonzero: 7920
	train_negative_nonzero: 17536
val:
	val_positive_loss: 0.045592185109853745
	val_negative_loss: 0.0539323166012764
	val_positive_acc: 0.9743589743589743
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03948277235031128
	test_negative_loss: 0.06316713988780975
	test_positive_acc: 0.9832719878109263
	test_negative_acc: 0.9908718306273459
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03600792586803436
	train_incorrect_loss: 0.759324603117279
	train_positive_loss: 0.04667683690786362
	train_negative_loss: 0.05636901035904884
	train_correct_acc: 0.9969383140949528
	train_incorrect_acc: 0.8164183797806691
	train_positive_acc: 0.9976653360729126
	train_negative_acc: 0.9870891250753505
	train_correct_nonzero: 29136
	train_incorrect_nonzero: 370
	train_positive_nonzero: 9972
	train_negative_nonzero: 19534
val:
	val_positive_loss: 0.009416946209967136
	val_negative_loss: 0.011743446812033653
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.021097619086503983
	test_negative_loss: 0.030571196228265762
	test_positive_acc: 0.9942390230383651
	test_negative_acc: 0.9897734558916165
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.01778656430542469
	train_incorrect_loss: 0.6403174708003644
	train_positive_loss: 0.026714181527495384
	train_negative_loss: 0.025237232446670532
	train_correct_acc: 0.998108537396847
	train_incorrect_acc: 0.8425
	train_positive_acc: 0.9984044669631452
	train_negative_acc: 0.993653881073737
	train_correct_nonzero: 32784
	train_incorrect_nonzero: 259
	train_positive_nonzero: 13277
	train_negative_nonzero: 19766
val:
	val_positive_loss: 0.0022916451562196016
	val_negative_loss: 0.05097360908985138
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.006428399123251438
	test_negative_loss: 0.07145360112190247
	test_positive_acc: 0.9964576501093159
	test_negative_acc: 0.9788606487338747
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.011837027035653591
	train_incorrect_loss: 0.5098048502872032
	train_positive_loss: 0.013560321182012558
	train_negative_loss: 0.01651584915816784
	train_correct_acc: 0.9979421354269671
	train_incorrect_acc: 0.8638095238095239
	train_positive_acc: 0.9985195879540751
	train_negative_acc: 0.9955938900316346
	train_correct_nonzero: 33422
	train_incorrect_nonzero: 183
	train_positive_nonzero: 13661
	train_negative_nonzero: 19944
val:
	val_positive_loss: 0.021091194823384285
	val_negative_loss: 0.023293141275644302
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.012103830464184284
	test_negative_loss: 0.040271975100040436
	test_positive_acc: 0.9968319774718398
	test_negative_acc: 0.9853904094217125
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.009087235666811466
	train_incorrect_loss: 0.3802239585450139
	train_positive_loss: 0.014904282987117767
	train_negative_loss: 0.01281438022851944
	train_correct_acc: 0.9994193549782118
	train_incorrect_acc: 0.9458100558659218
	train_positive_acc: 0.9992316714601287
	train_negative_acc: 0.9982681279403318
	train_correct_nonzero: 32227
	train_incorrect_nonzero: 214
	train_positive_nonzero: 12486
	train_negative_nonzero: 19955
val:
	val_positive_loss: 0.041365571320056915
	val_negative_loss: 0.005376823246479034
	val_positive_acc: 0.9743589743589743
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0735221654176712
	test_negative_loss: 0.01767857000231743
	test_positive_acc: 0.9759389615924894
	test_negative_acc: 0.993078916154624
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.005265937652438879
	train_incorrect_loss: 0.21799835891696032
	train_positive_loss: 0.009278231300413609
	train_negative_loss: 0.0053970045410096645
	train_correct_acc: 0.9989928390074931
	train_incorrect_acc: 0.9790697674418605
	train_positive_acc: 0.9985527551423392
	train_negative_acc: 0.9990265015920085
	train_correct_nonzero: 27029
	train_incorrect_nonzero: 287
	train_positive_nonzero: 7370
	train_negative_nonzero: 19946
val:
	val_positive_loss: 0.04684695228934288
	val_negative_loss: 0.00027053712983615696
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.08634907007217407
	test_negative_loss: 0.012436818331480026
	test_positive_acc: 0.9771152400546022
	test_negative_acc: 0.9950389232018403
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.0045241257175803185
	train_incorrect_loss: 0.2839853450741405
	train_positive_loss: 0.010270860977470875
	train_negative_loss: 0.003893765155225992
	train_correct_acc: 0.9990704433886245
	train_incorrect_acc: 0.9638297872340426
	train_positive_acc: 0.9985034676625917
	train_negative_acc: 0.9990515170551444
	train_correct_nonzero: 24493
	train_incorrect_nonzero: 346
	train_positive_nonzero: 5090
	train_negative_nonzero: 19749
val:
	val_positive_loss: 0.04754970967769623
	val_negative_loss: 0.00039044703589752316
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.12118522822856903
	test_negative_loss: 0.05196022987365723
	test_positive_acc: 0.9746309301367817
	test_negative_acc: 0.9925078486228507
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.010762399062514305
	train_incorrect_loss: 0.3461944326117436
	train_positive_loss: 0.02285427786409855
	train_negative_loss: 0.01728258654475212
	train_correct_acc: 0.9992969078704595
	train_incorrect_acc: 0.9794520547945206
	train_positive_acc: 0.9990377311634492
	train_negative_acc: 0.9975078916783792
	train_correct_nonzero: 23641
	train_incorrect_nonzero: 352
	train_positive_nonzero: 4115
	train_negative_nonzero: 19878
val:
	val_positive_loss: 0.08234168589115143
	val_negative_loss: 0.000737703696358949
	val_positive_acc: 0.9661622530474989
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.07379157096147537
	test_negative_loss: 0.002575466874986887
	test_positive_acc: 0.97454507848843
	test_negative_acc: 0.998641304347826
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.003627415979281068
	train_incorrect_loss: 0.20558427871498786
	train_positive_loss: 0.009092768654227257
	train_negative_loss: 0.003681435249745846
	train_correct_acc: 0.9993182605186196
	train_incorrect_acc: 0.9868913857677902
	train_positive_acc: 0.9988958490858817
	train_negative_acc: 0.9993176525128767
	train_correct_nonzero: 24068
	train_incorrect_nonzero: 436
	train_positive_nonzero: 4623
	train_negative_nonzero: 19881
val:
	val_positive_loss: 0.04368654638528824
	val_negative_loss: 0.007739958353340626
	val_positive_acc: 0.9707860445565364
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.033494431525468826
	test_negative_loss: 0.018206439912319183
	test_positive_acc: 0.9809382863444038
	test_negative_acc: 0.99598589289881
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.007487894501537085
	train_incorrect_loss: 0.3202508752845709
	train_positive_loss: 0.03998913988471031
	train_negative_loss: 0.00820159912109375
	train_correct_acc: 0.9989087058747884
	train_incorrect_acc: 0.9837133550488599
	train_positive_acc: 0.9983018039285615
	train_negative_acc: 0.9961344883363067
	train_correct_nonzero: 21947
	train_incorrect_nonzero: 642
	train_positive_nonzero: 2722
	train_negative_nonzero: 19867
val:
	val_positive_loss: 0.15274956822395325
	val_negative_loss: 0.000784702249802649
	val_positive_acc: 0.9415720891130728
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.09505139291286469
	test_negative_loss: 0.00810551643371582
	test_positive_acc: 0.9743524874356944
	test_negative_acc: 0.9949309844858176
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.70652675628662 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.3
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2344160079956055
	train_negative_loss: 2.2803797721862793
	train_positive_acc: 0.6797156146726531
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.1689549833536148
	train_incorrect_loss: 0.9235508316213434
	train_positive_loss: 0.18944767117500305
	train_negative_loss: 0.22170525789260864
	train_correct_acc: 0.9725516464591002
	train_incorrect_acc: 0.6787115339081283
	train_positive_acc: 0.9847500887750805
	train_negative_acc: 0.9195033227777065
	train_correct_nonzero: 24681
	train_incorrect_nonzero: 1267
	train_positive_nonzero: 8382
	train_negative_nonzero: 17566
val:
	val_positive_loss: 0.017621945589780807
	val_negative_loss: 0.04704812169075012
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02292512357234955
	test_negative_loss: 0.06655425578355789
	test_positive_acc: 0.995054141337386
	test_negative_acc: 0.9846965038396248
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.04597672447562218
	train_incorrect_loss: 1.0052409919922387
	train_positive_loss: 0.07272941619157791
	train_negative_loss: 0.07398822903633118
	train_correct_acc: 0.9961623466544366
	train_incorrect_acc: 0.733900967453599
	train_positive_acc: 0.9972840315186928
	train_negative_acc: 0.9775717635267678
	train_correct_nonzero: 28358
	train_incorrect_nonzero: 478
	train_positive_nonzero: 9714
	train_negative_nonzero: 19122
val:
	val_positive_loss: 0.0035780775360763073
	val_negative_loss: 0.028165437281131744
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.022476673126220703
	test_negative_loss: 0.04571867361664772
	test_positive_acc: 0.9896645901357972
	test_negative_acc: 0.9889778912334064
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.025166776031255722
	train_incorrect_loss: 0.8553399645600057
	train_positive_loss: 0.04498252645134926
	train_negative_loss: 0.03973359614610672
	train_correct_acc: 0.9977031219581924
	train_incorrect_acc: 0.7867063492063492
	train_positive_acc: 0.997948832177518
	train_negative_acc: 0.9886094539554531
	train_correct_nonzero: 28235
	train_incorrect_nonzero: 313
	train_positive_nonzero: 8942
	train_negative_nonzero: 19606
val:
	val_positive_loss: 0.011760039255023003
	val_negative_loss: 0.047445908188819885
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.021378496661782265
	test_negative_loss: 0.05918579548597336
	test_positive_acc: 0.990644124935653
	test_negative_acc: 0.993258366523779
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.019381551072001457
	train_incorrect_loss: 0.5876681223090567
	train_positive_loss: 0.038229022175073624
	train_negative_loss: 0.030975650995969772
	train_correct_acc: 0.9986027693479989
	train_incorrect_acc: 0.9171686746987951
	train_positive_acc: 0.9986861468424032
	train_negative_acc: 0.9920078053729087
	train_correct_nonzero: 27440
	train_incorrect_nonzero: 274
	train_positive_nonzero: 7983
	train_negative_nonzero: 19731
val:
	val_positive_loss: 0.02001388929784298
	val_negative_loss: 0.02077244594693184
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.014487018808722496
	test_negative_loss: 0.05860210210084915
	test_positive_acc: 0.9949695548712205
	test_negative_acc: 0.9837643370366678
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.014911690726876259
	train_incorrect_loss: 0.5398021593397349
	train_positive_loss: 0.03167472034692764
	train_negative_loss: 0.022185927256941795
	train_correct_acc: 0.9985465016306077
	train_incorrect_acc: 0.9315789473684211
	train_positive_acc: 0.9982961463374654
	train_negative_acc: 0.9946127123023702
	train_correct_nonzero: 26880
	train_incorrect_nonzero: 266
	train_positive_nonzero: 7323
	train_negative_nonzero: 19823
val:
	val_positive_loss: 0.013822742737829685
	val_negative_loss: 0.006335027050226927
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.016634002327919006
	test_negative_loss: 0.022965755313634872
	test_positive_acc: 0.9933604487984112
	test_negative_acc: 0.9948632599346316
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.011491583660244942
	train_incorrect_loss: 0.493881966472383
	train_positive_loss: 0.02262437716126442
	train_negative_loss: 0.018398812040686607
	train_correct_acc: 0.9992254280991473
	train_incorrect_acc: 0.9395973154362416
	train_positive_acc: 0.998909222451363
	train_negative_acc: 0.9961957242608904
	train_correct_nonzero: 24945
	train_incorrect_nonzero: 187
	train_positive_nonzero: 5276
	train_negative_nonzero: 19856
val:
	val_positive_loss: 0.013462180271744728
	val_negative_loss: 0.0034224134869873524
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.017799824476242065
	test_negative_loss: 0.02384224906563759
	test_positive_acc: 0.991443580356119
	test_negative_acc: 0.9950389232018403
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.005266254302114248
	train_incorrect_loss: 0.3207434074028465
	train_positive_loss: 0.020938830450177193
	train_negative_loss: 0.004397147800773382
	train_correct_acc: 0.9992750926269661
	train_incorrect_acc: 0.9764150943396226
	train_positive_acc: 0.9988995140337207
	train_negative_acc: 0.9977306925260705
	train_correct_nonzero: 23283
	train_incorrect_nonzero: 301
	train_positive_nonzero: 3671
	train_negative_nonzero: 19913
val:
	val_positive_loss: 0.021677887067198753
	val_negative_loss: 0.003242775797843933
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.029560696333646774
	test_negative_loss: 0.02967691421508789
	test_positive_acc: 0.9865714432313923
	test_negative_acc: 0.99598589289881
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.004031761549413204
	train_incorrect_loss: 0.1382580166416249
	train_positive_loss: 0.006182333454489708
	train_negative_loss: 0.004078006371855736
	train_correct_acc: 0.9992981827956615
	train_incorrect_acc: 0.9955357142857143
	train_positive_acc: 0.9988947915716619
	train_negative_acc: 0.9996624499397274
	train_correct_nonzero: 23784
	train_incorrect_nonzero: 306
	train_positive_nonzero: 4070
	train_negative_nonzero: 20020
val:
	val_positive_loss: 4.656921373680234e-05
	val_negative_loss: 0.02600884437561035
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.01566186174750328
	test_negative_loss: 0.07232870161533356
	test_positive_acc: 0.9915826126639574
	test_negative_acc: 0.9840781859712732
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.006978877354413271
	train_incorrect_loss: 0.2563264944561657
	train_positive_loss: 0.010069482959806919
	train_negative_loss: 0.009711086750030518
	train_correct_acc: 0.9991462251488479
	train_incorrect_acc: 0.9817708333333334
	train_positive_acc: 0.9988551203886985
	train_negative_acc: 0.9988969477424369
	train_correct_nonzero: 27724
	train_incorrect_nonzero: 238
	train_positive_nonzero: 7985
	train_negative_nonzero: 19977
val:
	val_positive_loss: 0.004030917771160603
	val_negative_loss: 0.008814855478703976
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03780534118413925
	test_negative_loss: 0.028514306992292404
	test_positive_acc: 0.9823728998961965
	test_negative_acc: 0.9934479519636172
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.0033348356373608112
	train_incorrect_loss: 0.1917355433205573
	train_positive_loss: 0.0036224189680069685
	train_negative_loss: 0.005282306112349033
	train_correct_acc: 0.9997748054107155
	train_incorrect_acc: 0.9691714836223506
	train_positive_acc: 0.9997898715276178
	train_negative_acc: 0.9993663196618873
	train_correct_nonzero: 28746
	train_incorrect_nonzero: 192
	train_positive_nonzero: 8923
	train_negative_nonzero: 20015
val:
	val_positive_loss: 0.00044652295764535666
	val_negative_loss: 0.000713964574970305
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.048270657658576965
	test_negative_loss: 0.02044188603758812
	test_positive_acc: 0.9854611351903141
	test_negative_acc: 0.9948066476157911
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.4460141658783 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.325
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2343177795410156
	train_negative_loss: 2.2804057598114014
	train_positive_acc: 0.6832916175188505
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.1700335144996643
	train_incorrect_loss: 0.9328538031683982
	train_positive_loss: 0.20453771948814392
	train_negative_loss: 0.21376588940620422
	train_correct_acc: 0.9629139207423021
	train_incorrect_acc: 0.6839753031581846
	train_positive_acc: 0.972665021171247
	train_negative_acc: 0.9137834144213991
	train_correct_nonzero: 26676
	train_incorrect_nonzero: 1302
	train_positive_nonzero: 10249
	train_negative_nonzero: 17729
val:
	val_positive_loss: 0.02847662940621376
	val_negative_loss: 0.14419500529766083
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03393324837088585
	test_negative_loss: 0.1537143439054489
	test_positive_acc: 0.9910599804031355
	test_negative_acc: 0.9867210597434911
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.038985781371593475
	train_incorrect_loss: 0.8412636198897652
	train_positive_loss: 0.05623270943760872
	train_negative_loss: 0.061481427401304245
	train_correct_acc: 0.9972682809367325
	train_incorrect_acc: 0.767005076142132
	train_positive_acc: 0.9978934698170123
	train_negative_acc: 0.9838336405607251
	train_correct_nonzero: 30308
	train_incorrect_nonzero: 400
	train_positive_nonzero: 11247
	train_negative_nonzero: 19461
val:
	val_positive_loss: 0.005405930802226067
	val_negative_loss: 0.02205576002597809
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.020427066832780838
	test_negative_loss: 0.027742888778448105
	test_positive_acc: 0.9907422103091621
	test_negative_acc: 0.9924061895467284
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02304188907146454
	train_incorrect_loss: 0.7655900750820444
	train_positive_loss: 0.040124669671058655
	train_negative_loss: 0.037725597620010376
	train_correct_acc: 0.998036143045389
	train_incorrect_acc: 0.82015422125548
	train_positive_acc: 0.9985096492354875
	train_negative_acc: 0.9888175463833787
	train_correct_nonzero: 31830
	train_incorrect_nonzero: 298
	train_positive_nonzero: 12512
	train_negative_nonzero: 19616
val:
	val_positive_loss: 0.0007398527814075351
	val_negative_loss: 0.023471612483263016
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.004546612035483122
	test_negative_loss: 0.06083688884973526
	test_positive_acc: 0.9989035087719298
	test_negative_acc: 0.98422301899114
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.011807631701231003
	train_incorrect_loss: 0.5781746069696038
	train_positive_loss: 0.013160048052668571
	train_negative_loss: 0.017841989174485207
	train_correct_acc: 0.9987716890221907
	train_incorrect_acc: 0.8717622080679406
	train_positive_acc: 0.9989278632899924
	train_negative_acc: 0.9967891618788793
	train_correct_nonzero: 32034
	train_incorrect_nonzero: 152
	train_positive_nonzero: 12293
	train_negative_nonzero: 19893
val:
	val_positive_loss: 0.005568007938563824
	val_negative_loss: 0.02461094968020916
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.010274441912770271
	test_negative_loss: 0.04232320189476013
	test_positive_acc: 0.996085626299792
	test_negative_acc: 0.9880309215364368
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.011336169205605984
	train_incorrect_loss: 0.4526075879138305
	train_positive_loss: 0.01978783868253231
	train_negative_loss: 0.018184293061494827
	train_correct_acc: 0.9993228894368903
	train_incorrect_acc: 0.9410430839002268
	train_positive_acc: 0.9994156608813748
	train_negative_acc: 0.9961620660142622
	train_correct_nonzero: 28495
	train_incorrect_nonzero: 159
	train_positive_nonzero: 8787
	train_negative_nonzero: 19867
val:
	val_positive_loss: 0.0028961284551769495
	val_negative_loss: 0.040481094270944595
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.012681268155574799
	test_negative_loss: 0.04543936252593994
	test_positive_acc: 0.9964576501093159
	test_negative_acc: 0.9892101668194557
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.025480298325419426
	train_incorrect_loss: 0.7536398273759015
	train_positive_loss: 0.06522177904844284
	train_negative_loss: 0.04405157268047333
	train_correct_acc: 0.9987523085196746
	train_incorrect_acc: 0.9029304029304029
	train_positive_acc: 0.998483143998344
	train_negative_acc: 0.98883179649484
	train_correct_nonzero: 27125
	train_incorrect_nonzero: 357
	train_positive_nonzero: 7872
	train_negative_nonzero: 19610
val:
	val_positive_loss: 0.03947795554995537
	val_negative_loss: 0.004831956699490547
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04736950248479843
	test_negative_loss: 0.021175704896450043
	test_positive_acc: 0.9842480493749115
	test_negative_acc: 0.9922833514964139
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.007049627136439085
	train_incorrect_loss: 0.4408225743966853
	train_positive_loss: 0.014148296788334846
	train_negative_loss: 0.010605378076434135
	train_correct_acc: 0.9993725024126562
	train_incorrect_acc: 0.9070765458048696
	train_positive_acc: 0.9994657361151794
	train_negative_acc: 0.9964610829223923
	train_correct_nonzero: 26135
	train_incorrect_nonzero: 200
	train_positive_nonzero: 6413
	train_negative_nonzero: 19922
val:
	val_positive_loss: 0.04091878607869148
	val_negative_loss: 0.006547712720930576
	val_positive_acc: 0.9743589743589743
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.07232819497585297
	test_negative_loss: 0.020012062042951584
	test_positive_acc: 0.9768101968387248
	test_negative_acc: 0.9940919535048706
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.005463659763336182
	train_incorrect_loss: 0.18848667296834667
	train_positive_loss: 0.00933163519948721
	train_negative_loss: 0.005909813102334738
	train_correct_acc: 0.9990660940174857
	train_incorrect_acc: 0.9864779874213835
	train_positive_acc: 0.9985152298281539
	train_negative_acc: 0.9993377192642332
	train_correct_nonzero: 24466
	train_incorrect_nonzero: 400
	train_positive_nonzero: 4868
	train_negative_nonzero: 19998
val:
	val_positive_loss: 0.034308064728975296
	val_negative_loss: 0.0036016381345689297
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.06362180411815643
	test_negative_loss: 0.010731633752584457
	test_positive_acc: 0.9815416305500717
	test_negative_acc: 0.9963976188540142
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.005621742457151413
	train_incorrect_loss: 0.2822270246087085
	train_positive_loss: 0.012708315625786781
	train_negative_loss: 0.006911758333444595
	train_correct_acc: 0.9990132735087175
	train_incorrect_acc: 0.9809322033898306
	train_positive_acc: 0.9984304388575624
	train_negative_acc: 0.9986607347471691
	train_correct_nonzero: 23870
	train_incorrect_nonzero: 328
	train_positive_nonzero: 4218
	train_negative_nonzero: 19980
val:
	val_positive_loss: 0.012413432821631432
	val_negative_loss: 0.014067327603697777
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.041816677898168564
	test_negative_loss: 0.02570956200361252
	test_positive_acc: 0.9833124814731833
	test_negative_acc: 0.9948066476157911
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.009063716977834702
	train_incorrect_loss: 0.14895087138132276
	train_positive_loss: 0.01555508654564619
	train_negative_loss: 0.01027761958539486
	train_correct_acc: 0.9985191204142232
	train_incorrect_acc: 0.9959407831900668
	train_positive_acc: 0.9973669515432608
	train_negative_acc: 0.9994743527438638
	train_correct_nonzero: 24457
	train_incorrect_nonzero: 1081
	train_positive_nonzero: 5522
	train_negative_nonzero: 20016
val:
	val_positive_loss: 0.011453462764620781
	val_negative_loss: 0.019878361374139786
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03072943724691868
	test_negative_loss: 0.050494808703660965
	test_positive_acc: 0.9857259701737482
	test_negative_acc: 0.9873937863513866
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.69711923599243 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.35
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.234222412109375
	train_negative_loss: 2.280397415161133
	train_positive_acc: 0.6870120012317508
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.17721369862556458
	train_incorrect_loss: 0.8477116565716982
	train_positive_loss: 0.20501111447811127
	train_negative_loss: 0.22253486514091492
	train_correct_acc: 0.9600836402820212
	train_incorrect_acc: 0.7281894232965791
	train_positive_acc: 0.9734750230912143
	train_negative_acc: 0.9105302351863352
	train_correct_nonzero: 27248
	train_incorrect_nonzero: 1292
	train_positive_nonzero: 10662
	train_negative_nonzero: 17878
val:
	val_positive_loss: 0.030039647594094276
	val_negative_loss: 0.009439806453883648
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.051994383335113525
	test_negative_loss: 0.01848096027970314
	test_positive_acc: 0.9812658100814142
	test_negative_acc: 0.997187815975733
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.04584912583231926
	train_incorrect_loss: 0.9137681389058178
	train_positive_loss: 0.07504746317863464
	train_negative_loss: 0.0734095573425293
	train_correct_acc: 0.9961264725629277
	train_incorrect_acc: 0.7873654123654124
	train_positive_acc: 0.9969642655130165
	train_negative_acc: 0.9788862107146707
	train_correct_nonzero: 29906
	train_incorrect_nonzero: 487
	train_positive_nonzero: 11007
	train_negative_nonzero: 19386
val:
	val_positive_loss: 0.008617879822850227
	val_negative_loss: 0.01738426461815834
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.036140259355306625
	test_negative_loss: 0.02980176731944084
	test_positive_acc: 0.982918262140869
	test_negative_acc: 0.9948066476157911
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.01367601566016674
	train_incorrect_loss: 0.6069205360367703
	train_positive_loss: 0.020237905904650688
	train_negative_loss: 0.019630171358585358
	train_correct_acc: 0.9984399703423436
	train_incorrect_acc: 0.8649572649572649
	train_positive_acc: 0.9985278393463926
	train_negative_acc: 0.995362958302548
	train_correct_nonzero: 29259
	train_incorrect_nonzero: 234
	train_positive_nonzero: 9608
	train_negative_nonzero: 19885
val:
	val_positive_loss: 0.006531174294650555
	val_negative_loss: 0.013214758597314358
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.01648447848856449
	test_negative_loss: 0.027010496705770493
	test_positive_acc: 0.993131319577103
	test_negative_acc: 0.9925575945854881
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.010981585830450058
	train_incorrect_loss: 0.4937920919095976
	train_positive_loss: 0.02445194125175476
	train_negative_loss: 0.016453061252832413
	train_correct_acc: 0.9990097242721497
	train_incorrect_acc: 0.920400112707805
	train_positive_acc: 0.9988761904134058
	train_negative_acc: 0.9954367579330649
	train_correct_nonzero: 29841
	train_incorrect_nonzero: 215
	train_positive_nonzero: 10212
	train_negative_nonzero: 19844
val:
	val_positive_loss: 0.010403292253613472
	val_negative_loss: 0.007763652130961418
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.023222152143716812
	test_negative_loss: 0.023626165464520454
	test_positive_acc: 0.992422137599227
	test_negative_acc: 0.9927820917119248
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.005978938192129135
	train_incorrect_loss: 0.26842820710901
	train_positive_loss: 0.010070211254060268
	train_negative_loss: 0.0067116389982402325
	train_correct_acc: 0.9988678989916691
	train_incorrect_acc: 0.971342383107089
	train_positive_acc: 0.9985284762350353
	train_negative_acc: 0.9986280141888227
	train_correct_nonzero: 26510
	train_incorrect_nonzero: 247
	train_positive_nonzero: 6795
	train_negative_nonzero: 19962
val:
	val_positive_loss: 0.05186954885721207
	val_negative_loss: 0.003658472327515483
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.041908834129571915
	test_negative_loss: 0.025330428034067154
	test_positive_acc: 0.9867541150710668
	test_negative_acc: 0.9939613369949437
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.004457523580640554
	train_incorrect_loss: 0.3903125852495631
	train_positive_loss: 0.024104082956910133
	train_negative_loss: 0.004439127631485462
	train_correct_acc: 0.998937180380406
	train_incorrect_acc: 0.9415849673202613
	train_positive_acc: 0.9985698139186471
	train_negative_acc: 0.9964744880148533
	train_correct_nonzero: 25116
	train_incorrect_nonzero: 279
	train_positive_nonzero: 5481
	train_negative_nonzero: 19914
val:
	val_positive_loss: 0.0018910623621195555
	val_negative_loss: 0.015531789511442184
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.016476936638355255
	test_negative_loss: 0.04645051062107086
	test_positive_acc: 0.992850910803424
	test_negative_acc: 0.9868227188196134
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.01063052099198103
	train_incorrect_loss: 0.3463729547889405
	train_positive_loss: 0.015490774065256119
	train_negative_loss: 0.014831784181296825
	train_correct_acc: 0.9989582386830159
	train_incorrect_acc: 0.9695585996955859
	train_positive_acc: 0.9983979032877706
	train_negative_acc: 0.998476423407882
	train_correct_nonzero: 24466
	train_incorrect_nonzero: 333
	train_positive_nonzero: 4865
	train_negative_nonzero: 19934
val:
	val_positive_loss: 0.0033496711403131485
	val_negative_loss: 0.0036106305196881294
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02465732768177986
	test_negative_loss: 0.03376232087612152
	test_positive_acc: 0.9893697455030288
	test_negative_acc: 0.9904024221716949
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.005601623095571995
	train_incorrect_loss: 0.17532665103729622
	train_positive_loss: 0.015248075127601624
	train_negative_loss: 0.005066501442342997
	train_correct_acc: 0.9989842150309362
	train_incorrect_acc: 0.9922149122807017
	train_positive_acc: 0.9981186237178554
	train_negative_acc: 0.999259972531001
	train_correct_nonzero: 23145
	train_incorrect_nonzero: 659
	train_positive_nonzero: 4907
	train_negative_nonzero: 18897
val:
	val_positive_loss: 0.09496937692165375
	val_negative_loss: 0.000607757072430104
	val_positive_acc: 0.9754098360655737
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.19332703948020935
	test_negative_loss: 0.006473083049058914
	test_positive_acc: 0.9441574792662959
	test_negative_acc: 0.998641304347826
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.008081230334937572
	train_incorrect_loss: 0.20137406086320905
	train_positive_loss: 0.026387490332126617
	train_negative_loss: 0.00681127468124032
	train_correct_acc: 0.9983045254167173
	train_incorrect_acc: 0.990116205633447
	train_positive_acc: 0.9969995354107609
	train_negative_acc: 0.998556867189094
	train_correct_nonzero: 19758
	train_incorrect_nonzero: 1128
	train_positive_nonzero: 3504
	train_negative_nonzero: 17382
val:
	val_positive_loss: 0.3238741159439087
	val_negative_loss: 0.0005006721476092935
	val_positive_acc: 0.9123581336696092
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.24788790941238403
	test_negative_loss: 0.010176809504628181
	test_positive_acc: 0.9214567658005945
	test_negative_acc: 0.997187815975733
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.008425826206803322
	train_incorrect_loss: 0.2114964400389755
	train_positive_loss: 0.032660339027643204
	train_negative_loss: 0.008858411572873592
	train_correct_acc: 0.9984100099584426
	train_incorrect_acc: 0.988095238095238
	train_positive_acc: 0.9973681485006946
	train_negative_acc: 0.9973449103813506
	train_correct_nonzero: 21953
	train_incorrect_nonzero: 1218
	train_positive_nonzero: 3769
	train_negative_nonzero: 19402
val:
	val_positive_loss: 0.3386882245540619
	val_negative_loss: 0.00032177878892980516
	val_positive_acc: 0.9241277847835225
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.3021857738494873
	test_negative_loss: 0.020305581390857697
	test_positive_acc: 0.9232116987649313
	test_negative_acc: 0.997187815975733
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.52835726737976 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.375
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2341129779815674
	train_negative_loss: 2.2804253101348877
	train_positive_acc: 0.6900495560435597
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.17529964447021484
	train_incorrect_loss: 0.8534097738997781
	train_positive_loss: 0.19326844811439514
	train_negative_loss: 0.22568704187870026
	train_correct_acc: 0.951416214092325
	train_incorrect_acc: 0.709924595731325
	train_positive_acc: 0.9692787449041249
	train_negative_acc: 0.9041536316121863
	train_correct_nonzero: 27317
	train_incorrect_nonzero: 1254
	train_positive_nonzero: 10590
	train_negative_nonzero: 17981
val:
	val_positive_loss: 0.01544671319425106
	val_negative_loss: 0.058022499084472656
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.017639171332120895
	test_negative_loss: 0.08053328841924667
	test_positive_acc: 0.9976339285714286
	test_negative_acc: 0.978635471871191
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.02824985422194004
	train_incorrect_loss: 0.7990071836404056
	train_positive_loss: 0.042332276701927185
	train_negative_loss: 0.04229756444692612
	train_correct_acc: 0.9978294206152787
	train_incorrect_acc: 0.765072964669739
	train_positive_acc: 0.998386051925709
	train_negative_acc: 0.9876549315835877
	train_correct_nonzero: 29561
	train_incorrect_nonzero: 359
	train_positive_nonzero: 10265
	train_negative_nonzero: 19655
val:
	val_positive_loss: 0.01381862536072731
	val_negative_loss: 0.014396414160728455
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.024063950404524803
	test_negative_loss: 0.031850140541791916
	test_positive_acc: 0.9921516723990829
	test_negative_acc: 0.9903816336428621
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.015683872625231743
	train_incorrect_loss: 0.662040244688536
	train_positive_loss: 0.0276802908629179
	train_negative_loss: 0.023214131593704224
	train_correct_acc: 0.9985081396646097
	train_incorrect_acc: 0.8449317738791424
	train_positive_acc: 0.9987534827799349
	train_negative_acc: 0.9936736942657021
	train_correct_nonzero: 29797
	train_incorrect_nonzero: 226
	train_positive_nonzero: 10185
	train_negative_nonzero: 19838
val:
	val_positive_loss: 0.016882488504052162
	val_negative_loss: 0.003994228783994913
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.021566368639469147
	test_negative_loss: 0.02080395631492138
	test_positive_acc: 0.9883300036696319
	test_negative_acc: 0.99598589289881
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.008944704197347164
	train_incorrect_loss: 0.5683009728021543
	train_positive_loss: 0.01478882972151041
	train_negative_loss: 0.012334582395851612
	train_correct_acc: 0.998945168880354
	train_incorrect_acc: 0.8968253968253967
	train_positive_acc: 0.999142433871493
	train_negative_acc: 0.9968608452492642
	train_correct_nonzero: 28802
	train_incorrect_nonzero: 172
	train_positive_nonzero: 9027
	train_negative_nonzero: 19947
val:
	val_positive_loss: 0.00964014045894146
	val_negative_loss: 0.006375248543918133
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.019575949758291245
	test_negative_loss: 0.03006899356842041
	test_positive_acc: 0.9910551811710127
	test_negative_acc: 0.9900265200064985
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.011505614034831524
	train_incorrect_loss: 0.5880307490866481
	train_positive_loss: 0.025518245995044708
	train_negative_loss: 0.01727157272398472
	train_correct_acc: 0.9991406884425841
	train_incorrect_acc: 0.9216757741347905
	train_positive_acc: 0.9990382896907463
	train_negative_acc: 0.996314849811553
	train_correct_nonzero: 29265
	train_incorrect_nonzero: 222
	train_positive_nonzero: 9615
	train_negative_nonzero: 19872
val:
	val_positive_loss: 0.0009526619105599821
	val_negative_loss: 0.00733456015586853
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.011032920330762863
	test_negative_loss: 0.04835684597492218
	test_positive_acc: 0.9964576501093159
	test_negative_acc: 0.9840105347953464
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.008266143500804901
	train_incorrect_loss: 0.4770565425870674
	train_positive_loss: 0.02096731960773468
	train_negative_loss: 0.012255973182618618
	train_correct_acc: 0.9993321234690219
	train_incorrect_acc: 0.9246666666666666
	train_positive_acc: 0.9992424985879588
	train_negative_acc: 0.9965246361041878
	train_correct_nonzero: 28287
	train_incorrect_nonzero: 219
	train_positive_nonzero: 8592
	train_negative_nonzero: 19914
val:
	val_positive_loss: 0.02073359116911888
	val_negative_loss: 0.0010931158903986216
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04901019483804703
	test_negative_loss: 0.01639450341463089
	test_positive_acc: 0.9805108547334616
	test_negative_acc: 0.99598589289881
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.013062668964266777
	train_incorrect_loss: 0.4967246623903823
	train_positive_loss: 0.032212868332862854
	train_negative_loss: 0.02186613902449608
	train_correct_acc: 0.9995863388067265
	train_incorrect_acc: 0.9512235449735449
	train_positive_acc: 0.999465033128379
	train_negative_acc: 0.9947567024546785
	train_correct_nonzero: 27665
	train_incorrect_nonzero: 260
	train_positive_nonzero: 8102
	train_negative_nonzero: 19823
val:
	val_positive_loss: 0.028727080672979355
	val_negative_loss: 0.003094687592238188
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.039874911308288574
	test_negative_loss: 0.012980419211089611
	test_positive_acc: 0.9832813199336059
	test_negative_acc: 0.997439381270903
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.004632784519344568
	train_incorrect_loss: 0.2825319506022039
	train_positive_loss: 0.006219788920134306
	train_negative_loss: 0.006149183958768845
	train_correct_acc: 0.9992447287379188
	train_incorrect_acc: 0.9414141414141413
	train_positive_acc: 0.999121656170143
	train_negative_acc: 0.9987789329555645
	train_correct_nonzero: 27540
	train_incorrect_nonzero: 188
	train_positive_nonzero: 7725
	train_negative_nonzero: 20003
val:
	val_positive_loss: 0.05569612234830856
	val_negative_loss: 0.0014200008008629084
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02136075124144554
	test_negative_loss: 0.020589685067534447
	test_positive_acc: 0.9919739121696955
	test_negative_acc: 0.9950389232018403
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.005648155231028795
	train_incorrect_loss: 0.3802301248680852
	train_positive_loss: 0.006432564929127693
	train_negative_loss: 0.008839876390993595
	train_correct_acc: 0.9995742863003284
	train_incorrect_acc: 0.9337474120082815
	train_positive_acc: 0.9993761025193516
	train_negative_acc: 0.9989886267834804
	train_correct_nonzero: 26147
	train_incorrect_nonzero: 159
	train_positive_nonzero: 6327
	train_negative_nonzero: 19979
val:
	val_positive_loss: 0.0006635899189859629
	val_negative_loss: 0.0008643579203635454
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.050054699182510376
	test_negative_loss: 0.024086298421025276
	test_positive_acc: 0.9859037252075191
	test_negative_acc: 0.9939613369949437
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.010872612707316875
	train_incorrect_loss: 0.6780566172821452
	train_positive_loss: 0.03705137223005295
	train_negative_loss: 0.016943639144301414
	train_correct_acc: 0.9992516986040185
	train_incorrect_acc: 0.9200634057971016
	train_positive_acc: 0.9990956372335905
	train_negative_acc: 0.9938111254399769
	train_correct_nonzero: 26018
	train_incorrect_nonzero: 231
	train_positive_nonzero: 6483
	train_negative_nonzero: 19766
val:
	val_positive_loss: 0.0033255182206630707
	val_negative_loss: 0.0012054166290909052
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03665604442358017
	test_negative_loss: 0.017729083076119423
	test_positive_acc: 0.9870002164355893
	test_negative_acc: 0.9950389232018403
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.51085352897644 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.4
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2340149879455566
	train_negative_loss: 2.280461311340332
	train_positive_acc: 0.6933570569302053
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.18325097858905792
	train_incorrect_loss: 0.8903578008223023
	train_positive_loss: 0.20827516913414001
	train_negative_loss: 0.23463475704193115
	train_correct_acc: 0.959605889845212
	train_incorrect_acc: 0.6850958192361813
	train_positive_acc: 0.976925712032193
	train_negative_acc: 0.9019577924195248
	train_correct_nonzero: 25996
	train_incorrect_nonzero: 1409
	train_positive_nonzero: 9507
	train_negative_nonzero: 17898
val:
	val_positive_loss: 0.032227493822574615
	val_negative_loss: 0.032298676669597626
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03962654247879982
	test_negative_loss: 0.04194309562444687
	test_positive_acc: 0.9908024329397057
	test_negative_acc: 0.9903365868855803
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.030595965683460236
	train_incorrect_loss: 0.7321774778533043
	train_positive_loss: 0.05459153279662132
	train_negative_loss: 0.04401279240846634
	train_correct_acc: 0.9976110517317777
	train_incorrect_acc: 0.8105886850152905
	train_positive_acc: 0.9981709634351582
	train_negative_acc: 0.9859822421261666
	train_correct_nonzero: 31942
	train_incorrect_nonzero: 390
	train_positive_nonzero: 12652
	train_negative_nonzero: 19680
val:
	val_positive_loss: 0.016504578292369843
	val_negative_loss: 0.009997517801821232
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.030048470944166183
	test_negative_loss: 0.04908575862646103
	test_positive_acc: 0.9876900103390864
	test_negative_acc: 0.9850960575400524
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02754337713122368
	train_incorrect_loss: 0.7059562720661593
	train_positive_loss: 0.06747876107692719
	train_negative_loss: 0.04204518347978592
	train_correct_acc: 0.9979166668156843
	train_incorrect_acc: 0.9027484143763214
	train_positive_acc: 0.9975072408903023
	train_negative_acc: 0.9864726791450775
	train_correct_nonzero: 30168
	train_incorrect_nonzero: 473
	train_positive_nonzero: 11028
	train_negative_nonzero: 19613
val:
	val_positive_loss: 0.023184891790151596
	val_negative_loss: 0.010983780026435852
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02785663865506649
	test_negative_loss: 0.026364073157310486
	test_positive_acc: 0.9908218851650403
	test_negative_acc: 0.99598589289881
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.017088746652007103
	train_incorrect_loss: 0.5349358029849828
	train_positive_loss: 0.040601957589387894
	train_negative_loss: 0.026570459827780724
	train_correct_acc: 0.9988190318260497
	train_incorrect_acc: 0.926234817813765
	train_positive_acc: 0.9988854912065104
	train_negative_acc: 0.9919282814940029
	train_correct_nonzero: 28651
	train_incorrect_nonzero: 313
	train_positive_nonzero: 9176
	train_negative_nonzero: 19788
val:
	val_positive_loss: 0.008706330321729183
	val_negative_loss: 0.009177790023386478
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.011494578793644905
	test_negative_loss: 0.037440478801727295
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9909946686776604
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.007589381188154221
	train_incorrect_loss: 0.3791771597037344
	train_positive_loss: 0.019928714260458946
	train_negative_loss: 0.011221292428672314
	train_correct_acc: 0.9993524281018497
	train_incorrect_acc: 0.9427083333333334
	train_positive_acc: 0.999249258391477
	train_negative_acc: 0.9961567570548384
	train_correct_nonzero: 27901
	train_incorrect_nonzero: 228
	train_positive_nonzero: 8241
	train_negative_nonzero: 19888
val:
	val_positive_loss: 0.016180792823433876
	val_negative_loss: 0.0059304917231202126
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0230259969830513
	test_negative_loss: 0.030210932716727257
	test_positive_acc: 0.99199336439503
	test_negative_acc: 0.9949083066919134
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.005069755483418703
	train_incorrect_loss: 0.2751192236166349
	train_positive_loss: 0.005822915583848953
	train_negative_loss: 0.007509587332606316
	train_correct_acc: 0.9994212909244644
	train_incorrect_acc: 0.9487895716945995
	train_positive_acc: 0.9993911341057756
	train_negative_acc: 0.9988982229398743
	train_correct_nonzero: 26442
	train_incorrect_nonzero: 182
	train_positive_nonzero: 6643
	train_negative_nonzero: 19981
val:
	val_positive_loss: 0.0003932722029276192
	val_negative_loss: 0.004358292557299137
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01980212703347206
	test_negative_loss: 0.06076238304376602
	test_positive_acc: 0.9927083097603993
	test_negative_acc: 0.9839088757192241
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.00573009205982089
	train_incorrect_loss: 0.21699360162229328
	train_positive_loss: 0.009572332724928856
	train_negative_loss: 0.007421948481351137
	train_correct_acc: 0.9993959131142681
	train_incorrect_acc: 0.9780303030303031
	train_positive_acc: 0.9991138942982443
	train_negative_acc: 0.9991336886944201
	train_correct_nonzero: 24872
	train_incorrect_nonzero: 271
	train_positive_nonzero: 5167
	train_negative_nonzero: 19976
val:
	val_positive_loss: 0.01075021643191576
	val_negative_loss: 0.003920478746294975
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02535075694322586
	test_negative_loss: 0.044959042221307755
	test_positive_acc: 0.992496432052353
	test_negative_acc: 0.9904313796054995
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.005605456884950399
	train_incorrect_loss: 0.2954618334368807
	train_positive_loss: 0.020110277459025383
	train_negative_loss: 0.008339464664459229
	train_correct_acc: 0.9995218661708549
	train_incorrect_acc: 0.9737099023709902
	train_positive_acc: 0.9992709749205443
	train_negative_acc: 0.9976878772736555
	train_correct_nonzero: 22267
	train_incorrect_nonzero: 377
	train_positive_nonzero: 2681
	train_negative_nonzero: 19963
val:
	val_positive_loss: 0.0616571269929409
	val_negative_loss: 0.00042338413186371326
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.11913212388753891
	test_negative_loss: 0.013916892930865288
	test_positive_acc: 0.9641799243858533
	test_negative_acc: 0.997439381270903
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.004885675385594368
	train_incorrect_loss: 0.21194180130740553
	train_positive_loss: 0.006348583847284317
	train_negative_loss: 0.006212024018168449
	train_correct_acc: 0.9991735256786913
	train_incorrect_acc: 0.9819182389937107
	train_positive_acc: 0.9986753279915902
	train_negative_acc: 0.9995142767010935
	train_correct_nonzero: 22663
	train_incorrect_nonzero: 286
	train_positive_nonzero: 2925
	train_negative_nonzero: 20024
val:
	val_positive_loss: 0.037544868886470795
	val_negative_loss: 0.0006738667143508792
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05428432673215866
	test_negative_loss: 0.03907262533903122
	test_positive_acc: 0.9842090610315488
	test_negative_acc: 0.9950597117306731
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.005076192785054445
	train_incorrect_loss: 0.3241813072395304
	train_positive_loss: 0.02396818995475769
	train_negative_loss: 0.0068094306625425816
	train_correct_acc: 0.9993068462963016
	train_incorrect_acc: 0.9718792866941016
	train_positive_acc: 0.9988738181674413
	train_negative_acc: 0.9973955865170558
	train_correct_nonzero: 22242
	train_incorrect_nonzero: 378
	train_positive_nonzero: 2680
	train_negative_nonzero: 19940
val:
	val_positive_loss: 0.039000123739242554
	val_negative_loss: 0.0023096699733287096
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05028311908245087
	test_negative_loss: 0.025904685258865356
	test_positive_acc: 0.9848755803102004
	test_negative_acc: 0.9961372979375697
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.44643115997314 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.425
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2339446544647217
	train_negative_loss: 2.2804436683654785
	train_positive_acc: 0.6968891955828773
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.1854269802570343
	train_incorrect_loss: 0.8665054718966896
	train_positive_loss: 0.21297761797904968
	train_negative_loss: 0.24380622804164886
	train_correct_acc: 0.9725513016673334
	train_incorrect_acc: 0.6915233433745119
	train_positive_acc: 0.9804131471794442
	train_negative_acc: 0.9064318465893798
	train_correct_nonzero: 23727
	train_incorrect_nonzero: 1667
	train_positive_nonzero: 7424
	train_negative_nonzero: 17970
val:
	val_positive_loss: 0.016843479126691818
	val_negative_loss: 0.07707595825195312
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.023013297468423843
	test_negative_loss: 0.09279897809028625
	test_positive_acc: 0.9976339285714286
	test_negative_acc: 0.9807739321489852
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.04155823588371277
	train_incorrect_loss: 0.7551243037049626
	train_positive_loss: 0.07338584959506989
	train_negative_loss: 0.06310994923114777
	train_correct_acc: 0.9975162078566435
	train_incorrect_acc: 0.8168031609195402
	train_positive_acc: 0.9976168061990291
	train_negative_acc: 0.9790810566320615
	train_correct_nonzero: 27823
	train_incorrect_nonzero: 558
	train_positive_nonzero: 8892
	train_negative_nonzero: 19489
val:
	val_positive_loss: 0.00991261936724186
	val_negative_loss: 0.020897097885608673
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.03516041487455368
	test_negative_loss: 0.03620772808790207
	test_positive_acc: 0.9835978764094913
	test_negative_acc: 0.9854668131308086
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.017277082428336143
	train_incorrect_loss: 0.5508416055294807
	train_positive_loss: 0.02380000613629818
	train_negative_loss: 0.023577354848384857
	train_correct_acc: 0.9982565497492218
	train_incorrect_acc: 0.8856902356902357
	train_positive_acc: 0.9980817720612847
	train_negative_acc: 0.9953138313614314
	train_correct_nonzero: 28957
	train_incorrect_nonzero: 273
	train_positive_nonzero: 9335
	train_negative_nonzero: 19895
val:
	val_positive_loss: 0.017013289034366608
	val_negative_loss: 0.004886713810265064
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.025420717895030975
	test_negative_loss: 0.0325818806886673
	test_positive_acc: 0.9907848283490327
	test_negative_acc: 0.9884713725582831
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.02022656239569187
	train_incorrect_loss: 0.5660226769069008
	train_positive_loss: 0.04342978447675705
	train_negative_loss: 0.02780010737478733
	train_correct_acc: 0.9984331358145419
	train_incorrect_acc: 0.9067109144542772
	train_positive_acc: 0.99818830665283
	train_negative_acc: 0.9910408277426171
	train_correct_nonzero: 28279
	train_incorrect_nonzero: 385
	train_positive_nonzero: 8863
	train_negative_nonzero: 19801
val:
	val_positive_loss: 0.03288466855883598
	val_negative_loss: 0.009887339547276497
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03422045707702637
	test_negative_loss: 0.026977725327014923
	test_positive_acc: 0.9879060296975577
	test_negative_acc: 0.9884068237016332
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.006161045283079147
	train_incorrect_loss: 0.19470468463950966
	train_positive_loss: 0.009645774960517883
	train_negative_loss: 0.006608688738197088
	train_correct_acc: 0.9988426933755301
	train_incorrect_acc: 0.9830188679245283
	train_positive_acc: 0.9982806368353273
	train_negative_acc: 0.9991413898181667
	train_correct_nonzero: 25885
	train_incorrect_nonzero: 388
	train_positive_nonzero: 6297
	train_negative_nonzero: 19976
val:
	val_positive_loss: 0.1242879331111908
	val_negative_loss: 0.0011378852650523186
	val_positive_acc: 0.9579655317360235
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.12076902389526367
	test_negative_loss: 0.015985947102308273
	test_positive_acc: 0.9557290988239597
	test_negative_acc: 0.9936274023327722
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.006592562887817621
	train_incorrect_loss: 0.1886781796071661
	train_positive_loss: 0.014279902912676334
	train_negative_loss: 0.0052408319897949696
	train_correct_acc: 0.9985743014346444
	train_incorrect_acc: 0.9819819819819819
	train_positive_acc: 0.9975361732287723
	train_negative_acc: 0.9990832411336871
	train_correct_nonzero: 26638
	train_incorrect_nonzero: 673
	train_positive_nonzero: 7386
	train_negative_nonzero: 19925
val:
	val_positive_loss: 0.11023429036140442
	val_negative_loss: 0.0009316215291619301
	val_positive_acc: 0.9707860445565364
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.07336169481277466
	test_negative_loss: 0.0074520111083984375
	test_positive_acc: 0.9721773875184154
	test_negative_acc: 0.998641304347826
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.006230367347598076
	train_incorrect_loss: 0.1292740701939968
	train_positive_loss: 0.01151516754180193
	train_negative_loss: 0.005691638682037592
	train_correct_acc: 0.9984744900080941
	train_incorrect_acc: 0.9961127308066082
	train_positive_acc: 0.9972760458063512
	train_negative_acc: 0.9995516304229594
	train_correct_nonzero: 24231
	train_incorrect_nonzero: 748
	train_positive_nonzero: 5333
	train_negative_nonzero: 19646
val:
	val_positive_loss: 0.16789470613002777
	val_negative_loss: 0.00040503148920834064
	val_positive_acc: 0.9323245060949978
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.1404641717672348
	test_negative_loss: 0.004965364933013916
	test_positive_acc: 0.9556633447225278
	test_negative_acc: 0.9973392210144927
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.005070740357041359
	train_incorrect_loss: 0.1487910737585758
	train_positive_loss: 0.013300464488565922
	train_negative_loss: 0.005033624358475208
	train_correct_acc: 0.9990002186929087
	train_incorrect_acc: 0.9930555555555556
	train_positive_acc: 0.9980721428591427
	train_negative_acc: 0.9994458157478472
	train_correct_nonzero: 21605
	train_incorrect_nonzero: 885
	train_positive_nonzero: 3127
	train_negative_nonzero: 19363
val:
	val_positive_loss: 0.05629902333021164
	val_negative_loss: 0.0006011854857206345
	val_positive_acc: 0.9754098360655737
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.14931270480155945
	test_negative_loss: 0.011822700500488281
	test_positive_acc: 0.9549176229483178
	test_negative_acc: 0.995118213314585
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.008121972903609276
	train_incorrect_loss: 0.1448203215585344
	train_positive_loss: 0.0172580536454916
	train_negative_loss: 0.007350110448896885
	train_correct_acc: 0.9975289426945554
	train_incorrect_acc: 0.9922279792746114
	train_positive_acc: 0.9953427433232124
	train_negative_acc: 0.9996625981973856
	train_correct_nonzero: 20702
	train_incorrect_nonzero: 1388
	train_positive_nonzero: 3236
	train_negative_nonzero: 18854
val:
	val_positive_loss: 0.3563247323036194
	val_negative_loss: 0.0005963276489637792
	val_positive_acc: 0.87494745691467
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.2978357970714569
	test_negative_loss: 0.00783559214323759
	test_positive_acc: 0.911074852473545
	test_negative_acc: 0.9965717016866781
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.020221924409270287
	train_incorrect_loss: 0.46396551800910907
	train_positive_loss: 0.10235797613859177
	train_negative_loss: 0.021224454045295715
	train_correct_acc: 0.9959133185884389
	train_incorrect_acc: 0.9626427072134337
	train_positive_acc: 0.9928260907365505
	train_negative_acc: 0.9890073082783383
	train_correct_nonzero: 20130
	train_incorrect_nonzero: 1662
	train_positive_nonzero: 2682
	train_negative_nonzero: 19110
val:
	val_positive_loss: 0.3364623188972473
	val_negative_loss: 0.004210763610899448
	val_positive_acc: 0.8493064312736444
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.23490497469902039
	test_negative_loss: 0.017973100766539574
	test_positive_acc: 0.8981322686698932
	test_negative_acc: 0.9965717016866781
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.71089625358582 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.45
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2338531017303467
	train_negative_loss: 2.280409812927246
	train_positive_acc: 0.7003691726893747
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.1828724592924118
	train_incorrect_loss: 0.8867151672867212
	train_positive_loss: 0.21271474659442902
	train_negative_loss: 0.23962867259979248
	train_correct_acc: 0.9618905013639165
	train_incorrect_acc: 0.6902174958024305
	train_positive_acc: 0.9763030499520317
	train_negative_acc: 0.9001772143625048
	train_correct_nonzero: 25320
	train_incorrect_nonzero: 1532
	train_positive_nonzero: 8920
	train_negative_nonzero: 17932
val:
	val_positive_loss: 0.045693185180425644
	val_negative_loss: 0.10943040996789932
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04973115026950836
	test_negative_loss: 0.11541831493377686
	test_positive_acc: 0.9832306518320902
	test_negative_acc: 0.9889778912334064
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.04512816295027733
	train_incorrect_loss: 0.901466420515223
	train_positive_loss: 0.08520549535751343
	train_negative_loss: 0.0700099840760231
	train_correct_acc: 0.9969391557073716
	train_incorrect_acc: 0.7630081410976379
	train_positive_acc: 0.9974828979018091
	train_negative_acc: 0.9742506298803473
	train_correct_nonzero: 30594
	train_incorrect_nonzero: 602
	train_positive_nonzero: 11855
	train_negative_nonzero: 19341
val:
	val_positive_loss: 0.005166239570826292
	val_negative_loss: 0.24151402711868286
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.013519549742341042
	test_negative_loss: 0.25488871335983276
	test_positive_acc: 0.9981617647058824
	test_negative_acc: 0.986288545259454
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02453908696770668
	train_incorrect_loss: 0.6802569277497241
	train_positive_loss: 0.023075664415955544
	train_negative_loss: 0.039623625576496124
	train_correct_acc: 0.9982083870431154
	train_incorrect_acc: 0.8310391865079364
	train_positive_acc: 0.9982999251695487
	train_negative_acc: 0.9941217411985748
	train_correct_nonzero: 29926
	train_incorrect_nonzero: 245
	train_positive_nonzero: 10281
	train_negative_nonzero: 19890
val:
	val_positive_loss: 0.007075787056237459
	val_negative_loss: 0.00924075860530138
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02370969019830227
	test_negative_loss: 0.02877030149102211
	test_positive_acc: 0.9910181243550051
	test_negative_acc: 0.9915011873527837
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.019743410870432854
	train_incorrect_loss: 0.542984490021609
	train_positive_loss: 0.03943584859371185
	train_negative_loss: 0.03123713657259941
	train_correct_acc: 0.9987807759465344
	train_incorrect_acc: 0.9060975609756098
	train_positive_acc: 0.9986967477003538
	train_negative_acc: 0.9924042462576822
	train_correct_nonzero: 31031
	train_incorrect_nonzero: 354
	train_positive_nonzero: 11571
	train_negative_nonzero: 19814
val:
	val_positive_loss: 0.01816456951200962
	val_negative_loss: 0.007597942370921373
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.029424982145428658
	test_negative_loss: 0.030857466161251068
	test_positive_acc: 0.9866057528361738
	test_negative_acc: 0.9915011873527837
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.00932674016803503
	train_incorrect_loss: 0.3913835878276866
	train_positive_loss: 0.01761697605252266
	train_negative_loss: 0.01393919438123703
	train_correct_acc: 0.999063689602466
	train_incorrect_acc: 0.9455128205128205
	train_positive_acc: 0.998673551497465
	train_negative_acc: 0.9968522470355082
	train_correct_nonzero: 27084
	train_incorrect_nonzero: 297
	train_positive_nonzero: 7438
	train_negative_nonzero: 19943
val:
	val_positive_loss: 0.005967911798506975
	val_negative_loss: 0.006586093921214342
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.031075522303581238
	test_negative_loss: 0.0214986614882946
	test_positive_acc: 0.9896505183132147
	test_negative_acc: 0.9913783493024692
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.010652306489646435
	train_incorrect_loss: 0.456317366577255
	train_positive_loss: 0.02907576970756054
	train_negative_loss: 0.015873929485678673
	train_correct_acc: 0.9989691002359374
	train_incorrect_acc: 0.9316239316239315
	train_positive_acc: 0.9984855102474666
	train_negative_acc: 0.994480226544007
	train_correct_nonzero: 26573
	train_incorrect_nonzero: 301
	train_positive_nonzero: 6973
	train_negative_nonzero: 19901
val:
	val_positive_loss: 0.0017611563671380281
	val_negative_loss: 0.0016218381933867931
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04559279978275299
	test_negative_loss: 0.01322767324745655
	test_positive_acc: 0.9845482933586662
	test_negative_acc: 0.9946838095654766
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.00591911980882287
	train_incorrect_loss: 0.29843257992902117
	train_positive_loss: 0.009838386438786983
	train_negative_loss: 0.008734798058867455
	train_correct_acc: 0.9994473206799533
	train_incorrect_acc: 0.9600301659125188
	train_positive_acc: 0.9992528937051605
	train_negative_acc: 0.998733563699887
	train_correct_nonzero: 25693
	train_incorrect_nonzero: 269
	train_positive_nonzero: 5991
	train_negative_nonzero: 19971
val:
	val_positive_loss: 0.004161447286605835
	val_negative_loss: 0.008220834657549858
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.027386832982301712
	test_negative_loss: 0.023220408707857132
	test_positive_acc: 0.9908219975432047
	test_negative_acc: 0.9916106248885184
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.004513883963227272
	train_incorrect_loss: 0.17601170284592627
	train_positive_loss: 0.006956829223781824
	train_negative_loss: 0.005620441399514675
	train_correct_acc: 0.9992925011478719
	train_incorrect_acc: 0.9762369791666667
	train_positive_acc: 0.9990250277158961
	train_negative_acc: 0.999093292845919
	train_correct_nonzero: 25227
	train_incorrect_nonzero: 384
	train_positive_nonzero: 5609
	train_negative_nonzero: 20002
val:
	val_positive_loss: 0.0001860578340711072
	val_negative_loss: 0.003895250614732504
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03775063902139664
	test_negative_loss: 0.025854919105768204
	test_positive_acc: 0.9883950255322983
	test_negative_acc: 0.9904313796054995
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.005016399547457695
	train_incorrect_loss: 0.22172474625052777
	train_positive_loss: 0.016951605677604675
	train_negative_loss: 0.00519099086523056
	train_correct_acc: 0.9990826229349709
	train_incorrect_acc: 0.9846296296296297
	train_positive_acc: 0.9984728258839646
	train_negative_acc: 0.9980709651660068
	train_correct_nonzero: 24530
	train_incorrect_nonzero: 532
	train_positive_nonzero: 5118
	train_negative_nonzero: 19944
val:
	val_positive_loss: 0.048709362745285034
	val_negative_loss: 0.005475706420838833
	val_positive_acc: 0.9836065573770492
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.09039542078971863
	test_negative_loss: 0.011288097128272057
	test_positive_acc: 0.9636651729799977
	test_negative_acc: 0.997618831640058
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.005118289031088352
	train_incorrect_loss: 0.10711070677380034
	train_positive_loss: 0.007671989966183901
	train_negative_loss: 0.005990436300635338
	train_correct_acc: 0.9992377869837252
	train_incorrect_acc: 0.9989350372736953
	train_positive_acc: 0.9985855648642972
	train_negative_acc: 0.9998502142080696
	train_correct_nonzero: 23190
	train_incorrect_nonzero: 626
	train_positive_nonzero: 3788
	train_negative_nonzero: 20028
val:
	val_positive_loss: 0.05910199135541916
	val_negative_loss: 0.0022395839914679527
	val_positive_acc: 0.9672131147540983
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.10482533276081085
	test_negative_loss: 0.008073239587247372
	test_positive_acc: 0.9570279556612643
	test_negative_acc: 0.9987980769230769
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.77310228347778 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.475
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2338171005249023
	train_negative_loss: 2.280332565307617
	train_positive_acc: 0.702860990901652
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.18813173472881317
	train_incorrect_loss: 0.8540066372497979
	train_positive_loss: 0.22567898035049438
	train_negative_loss: 0.24231500923633575
	train_correct_acc: 0.9613721741817693
	train_incorrect_acc: 0.7088151042889123
	train_positive_acc: 0.9760500011774381
	train_negative_acc: 0.8946692338718434
	train_correct_nonzero: 26092
	train_incorrect_nonzero: 1664
	train_positive_nonzero: 9700
	train_negative_nonzero: 18056
val:
	val_positive_loss: 0.02958805486559868
	val_negative_loss: 0.0990910679101944
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.037671566009521484
	test_negative_loss: 0.10688167065382004
	test_positive_acc: 0.9955575980392157
	test_negative_acc: 0.9833736319774586
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.04157496988773346
	train_incorrect_loss: 0.7719035740881299
	train_positive_loss: 0.06219223141670227
	train_negative_loss: 0.06454640626907349
	train_correct_acc: 0.9972535742263904
	train_incorrect_acc: 0.7651502567200242
	train_positive_acc: 0.9982393752420338
	train_negative_acc: 0.9792823944543141
	train_correct_nonzero: 28010
	train_incorrect_nonzero: 523
	train_positive_nonzero: 8950
	train_negative_nonzero: 19583
val:
	val_positive_loss: 0.023039447143673897
	val_negative_loss: 0.0594046488404274
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.034412726759910583
	test_negative_loss: 0.07272429019212723
	test_positive_acc: 0.9894550411149902
	test_negative_acc: 0.9937368398685069
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.021613338962197304
	train_incorrect_loss: 0.6985586888030114
	train_positive_loss: 0.030096476897597313
	train_negative_loss: 0.03328690305352211
	train_correct_acc: 0.9985350481043713
	train_incorrect_acc: 0.8132427307206068
	train_positive_acc: 0.9988335796420442
	train_negative_acc: 0.9918096893197444
	train_correct_nonzero: 28883
	train_incorrect_nonzero: 282
	train_positive_nonzero: 9361
	train_negative_nonzero: 19804
val:
	val_positive_loss: 0.0004594539641402662
	val_negative_loss: 0.053186215460300446
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.003624480217695236
	test_negative_loss: 0.11991431564092636
	test_positive_acc: 0.9977265211640212
	test_negative_acc: 0.9642369893098719
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.016844602301716805
	train_incorrect_loss: 0.597184868544506
	train_positive_loss: 0.035762716084718704
	train_negative_loss: 0.027854744344949722
	train_correct_acc: 0.9985901939602385
	train_incorrect_acc: 0.8728036424265743
	train_positive_acc: 0.9986994796386008
	train_negative_acc: 0.9906618486786821
	train_correct_nonzero: 27173
	train_incorrect_nonzero: 316
	train_positive_nonzero: 7743
	train_negative_nonzero: 19746
val:
	val_positive_loss: 0.001061698654666543
	val_negative_loss: 0.0309004969894886
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.012132246047258377
	test_negative_loss: 0.059395402669906616
	test_positive_acc: 0.9943861188092259
	test_negative_acc: 0.9807408983223467
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.008531363680958748
	train_incorrect_loss: 0.40693530220247603
	train_positive_loss: 0.012253599241375923
	train_negative_loss: 0.012657205574214458
	train_correct_acc: 0.9991956140878477
	train_incorrect_acc: 0.9343891402714932
	train_positive_acc: 0.998929341478513
	train_negative_acc: 0.9980119585888042
	train_correct_nonzero: 26881
	train_incorrect_nonzero: 246
	train_positive_nonzero: 7182
	train_negative_nonzero: 19945
val:
	val_positive_loss: 0.001462842570617795
	val_negative_loss: 0.013489000499248505
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01860957220196724
	test_negative_loss: 0.03896821290254593
	test_positive_acc: 0.9922729235871279
	test_negative_acc: 0.9867210597434911
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.010912724770605564
	train_incorrect_loss: 0.44398263358179735
	train_positive_loss: 0.030898381024599075
	train_negative_loss: 0.017711134627461433
	train_correct_acc: 0.9992310844305459
	train_incorrect_acc: 0.9530837004405286
	train_positive_acc: 0.9990041405251744
	train_negative_acc: 0.9947061896204388
	train_correct_nonzero: 25565
	train_incorrect_nonzero: 338
	train_positive_nonzero: 6014
	train_negative_nonzero: 19889
val:
	val_positive_loss: 0.006058139726519585
	val_negative_loss: 0.019551865756511688
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.012739047408103943
	test_negative_loss: 0.050628069788217545
	test_positive_acc: 0.9943075980392156
	test_negative_acc: 0.9874598540046635
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.005180055741220713
	train_incorrect_loss: 0.2980526307548467
	train_positive_loss: 0.012280701659619808
	train_negative_loss: 0.007610802538692951
	train_correct_acc: 0.9995180564102011
	train_incorrect_acc: 0.9622787610619469
	train_positive_acc: 0.9992201990470035
	train_negative_acc: 0.9985253977384827
	train_correct_nonzero: 22439
	train_incorrect_nonzero: 311
	train_positive_nonzero: 2828
	train_negative_nonzero: 19922
val:
	val_positive_loss: 0.05730274319648743
	val_negative_loss: 0.0009618462063372135
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.09993460029363632
	test_negative_loss: 0.02973582036793232
	test_positive_acc: 0.9706240592032838
	test_negative_acc: 0.9924061895467284
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.005840013734996319
	train_incorrect_loss: 0.22266169943225905
	train_positive_loss: 0.022492537274956703
	train_negative_loss: 0.006586403585970402
	train_correct_acc: 0.9990386830028406
	train_incorrect_acc: 0.985929744177167
	train_positive_acc: 0.9984731087034208
	train_negative_acc: 0.9977611624782304
	train_correct_nonzero: 21407
	train_incorrect_nonzero: 519
	train_positive_nonzero: 2012
	train_negative_nonzero: 19914
val:
	val_positive_loss: 0.019896727055311203
	val_negative_loss: 0.0005599907599389553
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.06878244876861572
	test_negative_loss: 0.013495227321982384
	test_positive_acc: 0.9761390453198339
	test_negative_acc: 0.9960085706927142
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.013751781545579433
	train_incorrect_loss: 0.31485168079963133
	train_positive_loss: 0.04891502484679222
	train_negative_loss: 0.01900606043636799
	train_correct_acc: 0.9983927569854918
	train_incorrect_acc: 0.9704383282364935
	train_positive_acc: 0.9970806892972784
	train_negative_acc: 0.9932363915941291
	train_correct_nonzero: 20643
	train_incorrect_nonzero: 748
	train_positive_nonzero: 1621
	train_negative_nonzero: 19770
val:
	val_positive_loss: 0.07854964584112167
	val_negative_loss: 0.0009983698837459087
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.18004760146141052
	test_negative_loss: 0.047872357070446014
	test_positive_acc: 0.9515506759742975
	test_negative_acc: 0.9931015939485281
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.005753923207521439
	train_incorrect_loss: 0.10553940467482616
	train_positive_loss: 0.009569223038852215
	train_negative_loss: 0.005928835831582546
	train_correct_acc: 0.9988559665675465
	train_incorrect_acc: 0.9976591760299626
	train_positive_acc: 0.9979058155834892
	train_negative_acc: 0.9997939237747326
	train_correct_nonzero: 22016
	train_incorrect_nonzero: 837
	train_positive_nonzero: 2883
	train_negative_nonzero: 19970
val:
	val_positive_loss: 0.012899021618068218
	val_negative_loss: 0.002034316537901759
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.13405315577983856
	test_negative_loss: 0.05863623321056366
	test_positive_acc: 0.9659038165046601
	test_negative_acc: 0.9873371740325461
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.63300848007202 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.5
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233757734298706
	train_negative_loss: 2.2803099155426025
	train_positive_acc: 0.7051644685685265
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.19286957383155823
	train_incorrect_loss: 0.8227400449664579
	train_positive_loss: 0.2186840921640396
	train_negative_loss: 0.2490440458059311
	train_correct_acc: 0.9649440739813345
	train_incorrect_acc: 0.7333632359571038
	train_positive_acc: 0.9778049288811621
	train_negative_acc: 0.9000348253127279
	train_correct_nonzero: 24592
	train_incorrect_nonzero: 1652
	train_positive_nonzero: 8153
	train_negative_nonzero: 18091
val:
	val_positive_loss: 0.026077859103679657
	val_negative_loss: 0.05924797058105469
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.03394660726189613
	test_negative_loss: 0.06847843527793884
	test_positive_acc: 0.9952076501093159
	test_negative_acc: 0.9859047065564482
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.04102306813001633
	train_incorrect_loss: 0.7282276790819002
	train_positive_loss: 0.060295600444078445
	train_negative_loss: 0.06371224671602249
	train_correct_acc: 0.9969322582711333
	train_incorrect_acc: 0.7984285625554068
	train_positive_acc: 0.9977304539408874
	train_negative_acc: 0.9806661462802607
	train_correct_nonzero: 28886
	train_incorrect_nonzero: 470
	train_positive_nonzero: 9736
	train_negative_nonzero: 19620
val:
	val_positive_loss: 0.020515400916337967
	val_negative_loss: 0.029472600668668747
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.025719299912452698
	test_negative_loss: 0.05689038336277008
	test_positive_acc: 0.9897248127663408
	test_negative_acc: 0.9870352030154069
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02721162885427475
	train_incorrect_loss: 0.7284775711598489
	train_positive_loss: 0.04597209766507149
	train_negative_loss: 0.04512932524085045
	train_correct_acc: 0.9983303132345588
	train_incorrect_acc: 0.7964762971257932
	train_positive_acc: 0.9984797429077289
	train_negative_acc: 0.9870647419624017
	train_correct_nonzero: 29554
	train_incorrect_nonzero: 383
	train_positive_nonzero: 10224
	train_negative_nonzero: 19713
val:
	val_positive_loss: 0.002125023864209652
	val_negative_loss: 0.012032926082611084
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.009731492027640343
	test_negative_loss: 0.052538637071847916
	test_positive_acc: 0.9959492020492408
	test_negative_acc: 0.9816192427698326
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.014937912113964558
	train_incorrect_loss: 0.5832360740316992
	train_positive_loss: 0.017481835559010506
	train_negative_loss: 0.02470587193965912
	train_correct_acc: 0.9986149645745501
	train_incorrect_acc: 0.8244224422442245
	train_positive_acc: 0.9991773175810045
	train_negative_acc: 0.9945011725900849
	train_correct_nonzero: 29799
	train_incorrect_nonzero: 192
	train_positive_nonzero: 10128
	train_negative_nonzero: 19863
val:
	val_positive_loss: 0.012834563851356506
	val_negative_loss: 0.02703351527452469
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.01004074327647686
	test_negative_loss: 0.045223332941532135
	test_positive_acc: 0.995754357298475
	test_negative_acc: 0.9855495929200846
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.02242659591138363
	train_incorrect_loss: 0.6826905725982408
	train_positive_loss: 0.046733077615499496
	train_negative_loss: 0.03894125670194626
	train_correct_acc: 0.9986293842816674
	train_incorrect_acc: 0.8485737290085116
	train_positive_acc: 0.9989149950311595
	train_negative_acc: 0.9875063377877606
	train_correct_nonzero: 30815
	train_incorrect_nonzero: 382
	train_positive_nonzero: 11460
	train_negative_nonzero: 19737
val:
	val_positive_loss: 0.005576846655458212
	val_negative_loss: 0.020170647650957108
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.014104783535003662
	test_negative_loss: 0.04462707042694092
	test_positive_acc: 0.9936507877442475
	test_negative_acc: 0.989692585344327
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.01718488521873951
	train_incorrect_loss: 0.6976105851975873
	train_positive_loss: 0.054350245743989944
	train_negative_loss: 0.0300087109208107
	train_correct_acc: 0.9989861126524627
	train_incorrect_acc: 0.8837359098228663
	train_positive_acc: 0.9990714613241126
	train_negative_acc: 0.9885357830713486
	train_correct_nonzero: 27093
	train_incorrect_nonzero: 339
	train_positive_nonzero: 7721
	train_negative_nonzero: 19711
val:
	val_positive_loss: 0.003309047780930996
	val_negative_loss: 0.004454924259334803
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01935567706823349
	test_negative_loss: 0.04213753342628479
	test_positive_acc: 0.9933646155830753
	test_negative_acc: 0.9862145410683678
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.006223010830581188
	train_incorrect_loss: 0.33336358649658676
	train_positive_loss: 0.009936710819602013
	train_negative_loss: 0.010021365247666836
	train_correct_acc: 0.9992423973508747
	train_incorrect_acc: 0.9291277258566978
	train_positive_acc: 0.9993271696973098
	train_negative_acc: 0.9974657092104017
	train_correct_nonzero: 26078
	train_incorrect_nonzero: 190
	train_positive_nonzero: 6361
	train_negative_nonzero: 19907
val:
	val_positive_loss: 3.945336356991902e-05
	val_negative_loss: 0.053078606724739075
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.01051283534616232
	test_negative_loss: 0.1237611323595047
	test_positive_acc: 0.9959492020492408
	test_negative_acc: 0.9653368514602021
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.004139868542551994
	train_incorrect_loss: 0.3083294290235934
	train_positive_loss: 0.0070425840094685555
	train_negative_loss: 0.006939650047570467
	train_correct_acc: 0.99964806533964
	train_incorrect_acc: 0.9251207729468599
	train_positive_acc: 0.999844634445632
	train_negative_acc: 0.9981729798574656
	train_correct_nonzero: 26810
	train_incorrect_nonzero: 188
	train_positive_nonzero: 7069
	train_negative_nonzero: 19929
val:
	val_positive_loss: 0.0004245711606927216
	val_negative_loss: 0.018627217039465904
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.019806813448667526
	test_negative_loss: 0.062479112297296524
	test_positive_acc: 0.9936027108211706
	test_negative_acc: 0.9796510668176446
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.00737277464941144
	train_incorrect_loss: 0.2692664882930396
	train_positive_loss: 0.008392262272536755
	train_negative_loss: 0.011973360553383827
	train_correct_acc: 0.9994727619678496
	train_incorrect_acc: 0.9480480480480479
	train_positive_acc: 0.9995558481109357
	train_negative_acc: 0.9981925833391125
	train_correct_nonzero: 27130
	train_incorrect_nonzero: 189
	train_positive_nonzero: 7424
	train_negative_nonzero: 19895
val:
	val_positive_loss: 0.0017315077129751444
	val_negative_loss: 0.0066992854699492455
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02074294164776802
	test_negative_loss: 0.03672930225729942
	test_positive_acc: 0.9936953034137632
	test_negative_acc: 0.9849247030328401
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.0035792209673672915
	train_incorrect_loss: 0.22183329311166025
	train_positive_loss: 0.008220895193517208
	train_negative_loss: 0.005352683365345001
	train_correct_acc: 0.9996464269850681
	train_incorrect_acc: 0.9611378205128205
	train_positive_acc: 0.9995715986283578
	train_negative_acc: 0.9987635060370579
	train_correct_nonzero: 23697
	train_incorrect_nonzero: 175
	train_positive_nonzero: 3958
	train_negative_nonzero: 19914
val:
	val_positive_loss: 0.04438400641083717
	val_negative_loss: 0.002246302319690585
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0272415392100811
	test_negative_loss: 0.02894926629960537
	test_positive_acc: 0.9896626925061522
	test_negative_acc: 0.9883485345079687
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.63641619682312 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.525
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233675956726074
	train_negative_loss: 2.2802953720092773
	train_positive_acc: 0.7078619092082715
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.19874180853366852
	train_incorrect_loss: 0.8514250152580002
	train_positive_loss: 0.2248433530330658
	train_negative_loss: 0.2559659779071808
	train_correct_acc: 0.9570467608713206
	train_incorrect_acc: 0.7079753533383475
	train_positive_acc: 0.9717666549971994
	train_negative_acc: 0.8974063872256738
	train_correct_nonzero: 24723
	train_incorrect_nonzero: 1625
	train_positive_nonzero: 8286
	train_negative_nonzero: 18062
val:
	val_positive_loss: 0.004987967666238546
	val_negative_loss: 0.07985667884349823
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.010101566091179848
	test_negative_loss: 0.09933850914239883
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9759746928856838
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03640957921743393
	train_incorrect_loss: 0.7221367864718049
	train_positive_loss: 0.059438057243824005
	train_negative_loss: 0.05816139653325081
	train_correct_acc: 0.9973863265036866
	train_incorrect_acc: 0.8231799163179917
	train_positive_acc: 0.9978220174771216
	train_negative_acc: 0.9810486098893114
	train_correct_nonzero: 28069
	train_incorrect_nonzero: 459
	train_positive_nonzero: 8931
	train_negative_nonzero: 19597
val:
	val_positive_loss: 0.0028765685856342316
	val_negative_loss: 0.006846445146948099
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.016404416412115097
	test_negative_loss: 0.03204061836004257
	test_positive_acc: 0.9923655161797206
	test_negative_acc: 0.9847295376662633
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02130460925400257
	train_incorrect_loss: 0.6511573101979101
	train_positive_loss: 0.036412231624126434
	train_negative_loss: 0.03373439982533455
	train_correct_acc: 0.9985833429490957
	train_incorrect_acc: 0.8379182754182753
	train_positive_acc: 0.9984811788305107
	train_negative_acc: 0.9901993947344535
	train_correct_nonzero: 28936
	train_incorrect_nonzero: 321
	train_positive_nonzero: 9487
	train_negative_nonzero: 19770
val:
	val_positive_loss: 0.0002949765184894204
	val_negative_loss: 0.03098672814667225
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.007672244682908058
	test_negative_loss: 0.04765287786722183
	test_positive_acc: 0.9966909461152882
	test_negative_acc: 0.9851300885052681
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.007759911008179188
	train_incorrect_loss: 0.4596695900044223
	train_positive_loss: 0.01231162715703249
	train_negative_loss: 0.01100254338234663
	train_correct_acc: 0.9991425895320717
	train_incorrect_acc: 0.9087962962962962
	train_positive_acc: 0.9990564388639109
	train_negative_acc: 0.9976438232968785
	train_correct_nonzero: 29926
	train_incorrect_nonzero: 178
	train_positive_nonzero: 10164
	train_negative_nonzero: 19940
val:
	val_positive_loss: 0.01161174662411213
	val_negative_loss: 0.0009079774608835578
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.045504502952098846
	test_negative_loss: 0.012481718324124813
	test_positive_acc: 0.9845159233966172
	test_negative_acc: 0.9954148253670367
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.006868781056255102
	train_incorrect_loss: 0.4789437406395664
	train_positive_loss: 0.017261557281017303
	train_negative_loss: 0.010249903425574303
	train_correct_acc: 0.9992462661326078
	train_incorrect_acc: 0.9153976311336717
	train_positive_acc: 0.9991534718994828
	train_negative_acc: 0.9966698714850969
	train_correct_nonzero: 29110
	train_incorrect_nonzero: 200
	train_positive_nonzero: 9385
	train_negative_nonzero: 19925
val:
	val_positive_loss: 0.01276661828160286
	val_negative_loss: 0.004029208328574896
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0329601988196373
	test_negative_loss: 0.01774282194674015
	test_positive_acc: 0.9886959630648465
	test_negative_acc: 0.9914800083785915
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.008504708297550678
	train_incorrect_loss: 0.4460799476593795
	train_positive_loss: 0.03105497546494007
	train_negative_loss: 0.01412613783031702
	train_correct_acc: 0.9993838021361411
	train_incorrect_acc: 0.9243119266055045
	train_positive_acc: 0.9993580583191596
	train_negative_acc: 0.9946425775173865
	train_correct_nonzero: 28529
	train_incorrect_nonzero: 300
	train_positive_nonzero: 8939
	train_negative_nonzero: 19890
val:
	val_positive_loss: 0.0014189650537446141
	val_negative_loss: 0.018488502129912376
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.019554398953914642
	test_negative_loss: 0.05323801189661026
	test_positive_acc: 0.995202850877193
	test_negative_acc: 0.9829001471289738
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.007127317599952221
	train_incorrect_loss: 0.24294627753605716
	train_positive_loss: 0.019590085372328758
	train_negative_loss: 0.008394003845751286
	train_correct_acc: 0.999234208023293
	train_incorrect_acc: 0.9653307888040713
	train_positive_acc: 0.998833774811328
	train_negative_acc: 0.9973671299935437
	train_correct_nonzero: 28189
	train_incorrect_nonzero: 409
	train_positive_nonzero: 8668
	train_negative_nonzero: 19930
val:
	val_positive_loss: 0.05166598781943321
	val_negative_loss: 0.007312321104109287
	val_positive_acc: 0.9707860445565364
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.09483291953802109
	test_negative_loss: 0.0460299476981163
	test_positive_acc: 0.9711230250910476
	test_negative_acc: 0.9920240077416316
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.005697697401046753
	train_incorrect_loss: 0.11281246873363067
	train_positive_loss: 0.009432028979063034
	train_negative_loss: 0.005716164596378803
	train_correct_acc: 0.9989103016037477
	train_incorrect_acc: 0.9980334316617504
	train_positive_acc: 0.9980270716292773
	train_negative_acc: 0.9997528939421739
	train_correct_nonzero: 22878
	train_incorrect_nonzero: 688
	train_positive_nonzero: 3569
	train_negative_nonzero: 19997
val:
	val_positive_loss: 0.10428537428379059
	val_negative_loss: 0.000578727456741035
	val_positive_acc: 0.9579655317360235
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.09346908330917358
	test_negative_loss: 0.011409185826778412
	test_positive_acc: 0.9735208068305847
	test_negative_acc: 0.9962601359878842
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.009623889811336994
	train_incorrect_loss: 0.23422554030318582
	train_positive_loss: 0.03290751948952675
	train_negative_loss: 0.010093238204717636
	train_correct_acc: 0.9983415397742474
	train_incorrect_acc: 0.9877589453860641
	train_positive_acc: 0.9968974876476647
	train_negative_acc: 0.9971663309962606
	train_correct_nonzero: 22038
	train_incorrect_nonzero: 957
	train_positive_nonzero: 3150
	train_negative_nonzero: 19845
val:
	val_positive_loss: 0.2092791497707367
	val_negative_loss: 0.0013861269690096378
	val_positive_acc: 0.92875157629256
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.14066192507743835
	test_negative_loss: 0.008478835225105286
	test_positive_acc: 0.9508066075626314
	test_negative_acc: 0.998641304347826
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.006262348964810371
	train_incorrect_loss: 0.1950556992018917
	train_positive_loss: 0.03477873653173447
	train_negative_loss: 0.006494665518403053
	train_correct_acc: 0.9985805487272869
	train_incorrect_acc: 0.9874659400544958
	train_positive_acc: 0.9973963164730936
	train_negative_acc: 0.9966473960899661
	train_correct_nonzero: 20949
	train_incorrect_nonzero: 1171
	train_positive_nonzero: 2240
	train_negative_nonzero: 19880
val:
	val_positive_loss: 0.03938228636980057
	val_negative_loss: 0.03337845206260681
	val_positive_acc: 0.9707860445565364
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04288599267601967
	test_negative_loss: 0.09933491796255112
	test_positive_acc: 0.9759716250997292
	test_negative_acc: 0.9858096814693666
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.67748713493347 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.55
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2335636615753174
	train_negative_loss: 2.2802512645721436
	train_positive_acc: 0.7108092040388617
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.194505974650383
	train_incorrect_loss: 0.7919475417698805
	train_positive_loss: 0.22245749831199646
	train_negative_loss: 0.2591097354888916
	train_correct_acc: 0.9525890335545583
	train_incorrect_acc: 0.7371681215366371
	train_positive_acc: 0.9724504484807047
	train_negative_acc: 0.8884373861473492
	train_correct_nonzero: 25026
	train_incorrect_nonzero: 1702
	train_positive_nonzero: 8642
	train_negative_nonzero: 18086
val:
	val_positive_loss: 0.017909640446305275
	val_negative_loss: 0.10798174142837524
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.026587259024381638
	test_negative_loss: 0.12141388654708862
	test_positive_acc: 0.9965374373433584
	test_negative_acc: 0.9869533353295402
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03067740611732006
	train_incorrect_loss: 0.7082526263729807
	train_positive_loss: 0.045956484973430634
	train_negative_loss: 0.048632342368364334
	train_correct_acc: 0.9978792667847489
	train_incorrect_acc: 0.8003687550969756
	train_positive_acc: 0.9986001754489657
	train_negative_acc: 0.9856050716975858
	train_correct_nonzero: 28607
	train_incorrect_nonzero: 380
	train_positive_nonzero: 9245
	train_negative_nonzero: 19742
val:
	val_positive_loss: 0.014357161708176136
	val_negative_loss: 0.03911197558045387
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.019600937142968178
	test_negative_loss: 0.04843762516975403
	test_positive_acc: 0.9913121474638131
	test_negative_acc: 0.987879516497677
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.01423935778439045
	train_incorrect_loss: 0.505585756237057
	train_positive_loss: 0.021726639941334724
	train_negative_loss: 0.0200823787599802
	train_correct_acc: 0.998685650478887
	train_incorrect_acc: 0.8918931807343824
	train_positive_acc: 0.9985314779397425
	train_negative_acc: 0.9954175469531614
	train_correct_nonzero: 29928
	train_incorrect_nonzero: 302
	train_positive_nonzero: 10331
	train_negative_nonzero: 19899
val:
	val_positive_loss: 0.0005037995288148522
	val_negative_loss: 0.016416484490036964
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.009024585597217083
	test_negative_loss: 0.0424380861222744
	test_positive_acc: 0.9959492020492408
	test_negative_acc: 0.9843206016744284
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.012047403492033482
	train_incorrect_loss: 0.45293530156610656
	train_positive_loss: 0.023337451741099358
	train_negative_loss: 0.01950289122760296
	train_correct_acc: 0.9990916675356989
	train_incorrect_acc: 0.9236394557823129
	train_positive_acc: 0.9991357374221792
	train_negative_acc: 0.9946101947347874
	train_correct_nonzero: 27978
	train_incorrect_nonzero: 239
	train_positive_nonzero: 8349
	train_negative_nonzero: 19868
val:
	val_positive_loss: 0.02800971083343029
	val_negative_loss: 0.008324767462909222
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.011295005679130554
	test_negative_loss: 0.02349388226866722
	test_positive_acc: 0.9960059514439139
	test_negative_acc: 0.9903816336428621
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.012709017843008041
	train_incorrect_loss: 0.4733704341911017
	train_positive_loss: 0.042482078075408936
	train_negative_loss: 0.021440034732222557
	train_correct_acc: 0.9991367471037245
	train_incorrect_acc: 0.9365706757011104
	train_positive_acc: 0.9988707327606557
	train_negative_acc: 0.9929578377816024
	train_correct_nonzero: 26041
	train_incorrect_nonzero: 423
	train_positive_nonzero: 6613
	train_negative_nonzero: 19851
val:
	val_positive_loss: 0.00031564090750180185
	val_negative_loss: 0.009719095192849636
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.019527608528733253
	test_negative_loss: 0.027010614052414894
	test_positive_acc: 0.9917230115730502
	test_negative_acc: 0.9943661965939448
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.005389635916799307
	train_incorrect_loss: 0.20618480155451596
	train_positive_loss: 0.008750912733376026
	train_negative_loss: 0.006796776317059994
	train_correct_acc: 0.9992202633861466
	train_incorrect_acc: 0.9763729246487867
	train_positive_acc: 0.9986725443016369
	train_negative_acc: 0.9992127161783821
	train_correct_nonzero: 23056
	train_incorrect_nonzero: 377
	train_positive_nonzero: 3553
	train_negative_nonzero: 19880
val:
	val_positive_loss: 0.0005309132975526154
	val_negative_loss: 0.0008533337386325002
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.06498295813798904
	test_negative_loss: 0.061073072254657745
	test_positive_acc: 0.9803172676832569
	test_negative_acc: 0.9860350906992127
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.005577252712100744
	train_incorrect_loss: 0.2853106939254819
	train_positive_loss: 0.015510845929384232
	train_negative_loss: 0.006915045902132988
	train_correct_acc: 0.9990563338747905
	train_incorrect_acc: 0.9658996683250414
	train_positive_acc: 0.9987563337808598
	train_negative_acc: 0.9978743994038161
	train_correct_nonzero: 23365
	train_incorrect_nonzero: 400
	train_positive_nonzero: 3937
	train_negative_nonzero: 19828
val:
	val_positive_loss: 0.005004677455872297
	val_negative_loss: 0.001097522908821702
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03405192866921425
	test_negative_loss: 0.04065721482038498
	test_positive_acc: 0.9853429135799134
	test_negative_acc: 0.988790662404639
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.004357955418527126
	train_incorrect_loss: 0.1609469606662194
	train_positive_loss: 0.00752123910933733
	train_negative_loss: 0.00540080014616251
	train_correct_acc: 0.9994954012361387
	train_incorrect_acc: 0.9807692307692307
	train_positive_acc: 0.9991401120383646
	train_negative_acc: 0.9994494543902604
	train_correct_nonzero: 23818
	train_incorrect_nonzero: 539
	train_positive_nonzero: 4645
	train_negative_nonzero: 19712
val:
	val_positive_loss: 0.0730949118733406
	val_negative_loss: 0.0003810254856944084
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.15177524089813232
	test_negative_loss: 0.036322932690382004
	test_positive_acc: 0.9565958336285088
	test_negative_acc: 0.9935496110397395
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.005611071363091469
	train_incorrect_loss: 0.19341053136278344
	train_positive_loss: 0.02046387270092964
	train_negative_loss: 0.00610334100201726
	train_correct_acc: 0.9987558342807689
	train_incorrect_acc: 0.9799833887043191
	train_positive_acc: 0.99782659843549
	train_negative_acc: 0.9978324850933491
	train_correct_nonzero: 22391
	train_incorrect_nonzero: 759
	train_positive_nonzero: 3261
	train_negative_nonzero: 19889
val:
	val_positive_loss: 0.06919171661138535
	val_negative_loss: 0.00041815079748630524
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.1688908487558365
	test_negative_loss: 0.041696563363075256
	test_positive_acc: 0.9527012958625123
	test_negative_acc: 0.9935496110397395
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.006893167272210121
	train_incorrect_loss: 0.14209226050295767
	train_positive_loss: 0.018680380657315254
	train_negative_loss: 0.006979613099247217
	train_correct_acc: 0.9982107105995214
	train_incorrect_acc: 0.9928122192273137
	train_positive_acc: 0.9966781469188838
	train_negative_acc: 0.9988979191745382
	train_correct_nonzero: 21728
	train_incorrect_nonzero: 1104
	train_positive_nonzero: 3097
	train_negative_nonzero: 19735
val:
	val_positive_loss: 0.1531171202659607
	val_negative_loss: 0.00017768963880371302
	val_positive_acc: 0.9451450189155107
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.1922963261604309
	test_negative_loss: 0.01828959956765175
	test_positive_acc: 0.9434140209332548
	test_negative_acc: 0.997187815975733
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.39498901367188 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.575
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233494281768799
	train_negative_loss: 2.280289888381958
	train_positive_acc: 0.7135953333063701
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.1826496422290802
	train_incorrect_loss: 0.7937499351423318
	train_positive_loss: 0.20899194478988647
	train_negative_loss: 0.24320034682750702
	train_correct_acc: 0.9687050402530393
	train_incorrect_acc: 0.7479592220168771
	train_positive_acc: 0.9839263844510364
	train_negative_acc: 0.9048406773078108
	train_correct_nonzero: 24448
	train_incorrect_nonzero: 1643
	train_positive_nonzero: 7795
	train_negative_nonzero: 18296
val:
	val_positive_loss: 0.009822576306760311
	val_negative_loss: 0.051302723586559296
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.014628630131483078
	test_negative_loss: 0.07599587738513947
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9799375552045244
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.04805763065814972
	train_incorrect_loss: 0.7955161530720762
	train_positive_loss: 0.08886952698230743
	train_negative_loss: 0.07473821192979813
	train_correct_acc: 0.9974533919123031
	train_incorrect_acc: 0.801611570247934
	train_positive_acc: 0.9975258489294014
	train_negative_acc: 0.9733964153625547
	train_correct_nonzero: 27095
	train_incorrect_nonzero: 653
	train_positive_nonzero: 8209
	train_negative_nonzero: 19539
val:
	val_positive_loss: 0.008512117899954319
	val_negative_loss: 0.014265370555222034
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02171146497130394
	test_negative_loss: 0.03912413865327835
	test_positive_acc: 0.9910100843308677
	test_negative_acc: 0.9897734558916165
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.026414521038532257
	train_incorrect_loss: 0.5921507583980321
	train_positive_loss: 0.04785298928618431
	train_negative_loss: 0.04417615383863449
	train_correct_acc: 0.9986485348496713
	train_incorrect_acc: 0.8734856828193832
	train_positive_acc: 0.9986951126795087
	train_negative_acc: 0.9890275621976499
	train_correct_nonzero: 26309
	train_incorrect_nonzero: 402
	train_positive_nonzero: 6919
	train_negative_nonzero: 19792
val:
	val_positive_loss: 0.0020058229565620422
	val_negative_loss: 0.012180621735751629
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.010615771636366844
	test_negative_loss: 0.06306935846805573
	test_positive_acc: 0.9966909461152882
	test_negative_acc: 0.979178494072569
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.013053803704679012
	train_incorrect_loss: 0.38945671907149515
	train_positive_loss: 0.017936475574970245
	train_negative_loss: 0.018812593072652817
	train_correct_acc: 0.9987117419105739
	train_incorrect_acc: 0.907986111111111
	train_positive_acc: 0.9987747816936791
	train_negative_acc: 0.9956980023050863
	train_correct_nonzero: 27662
	train_incorrect_nonzero: 271
	train_positive_nonzero: 8055
	train_negative_nonzero: 19878
val:
	val_positive_loss: 9.637682524044067e-05
	val_negative_loss: 0.0207919180393219
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.006988264620304108
	test_negative_loss: 0.08631956577301025
	test_positive_acc: 0.9976339285714286
	test_negative_acc: 0.9790035105416071
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.014498903416097164
	train_incorrect_loss: 0.4033853039206949
	train_positive_loss: 0.029403718188405037
	train_negative_loss: 0.02420363761484623
	train_correct_acc: 0.9990828186110909
	train_incorrect_acc: 0.941795865633075
	train_positive_acc: 0.9986986990397986
	train_negative_acc: 0.9943391726447262
	train_correct_nonzero: 23571
	train_incorrect_nonzero: 384
	train_positive_nonzero: 4075
	train_negative_nonzero: 19880
val:
	val_positive_loss: 0.0001271404034923762
	val_negative_loss: 0.020057015120983124
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.004274240229278803
	test_negative_loss: 0.06786257028579712
	test_positive_acc: 0.9988425925925926
	test_negative_acc: 0.9780391489723917
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.007150527089834213
	train_incorrect_loss: 0.3596298088618174
	train_positive_loss: 0.01841137744486332
	train_negative_loss: 0.011221691034734249
	train_correct_acc: 0.9995111818720668
	train_incorrect_acc: 0.9473214285714285
	train_positive_acc: 0.999401483428991
	train_negative_acc: 0.9967450919620193
	train_correct_nonzero: 25647
	train_incorrect_nonzero: 314
	train_positive_nonzero: 6016
	train_negative_nonzero: 19945
val:
	val_positive_loss: 0.04715992882847786
	val_negative_loss: 0.0033985383342951536
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04465298354625702
	test_negative_loss: 0.024338077753782272
	test_positive_acc: 0.983425496582856
	test_negative_acc: 0.9924061895467284
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.005464467220008373
	train_incorrect_loss: 0.21740639035917417
	train_positive_loss: 0.008648497983813286
	train_negative_loss: 0.00713304802775383
	train_correct_acc: 0.9992925681570143
	train_incorrect_acc: 0.9787644787644788
	train_positive_acc: 0.9989591741656786
	train_negative_acc: 0.9991590369679475
	train_correct_nonzero: 23957
	train_incorrect_nonzero: 368
	train_positive_nonzero: 4344
	train_negative_nonzero: 19981
val:
	val_positive_loss: 0.07647688686847687
	val_negative_loss: 0.00041203573346138
	val_positive_acc: 0.9707860445565364
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.09432971477508545
	test_negative_loss: 0.006812482140958309
	test_positive_acc: 0.9691660303742373
	test_negative_acc: 0.9960085706927142
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.00790758989751339
	train_incorrect_loss: 0.2628300592768002
	train_positive_loss: 0.020596524700522423
	train_negative_loss: 0.007437143940478563
	train_correct_acc: 0.9985443667178924
	train_incorrect_acc: 0.9727142857142856
	train_positive_acc: 0.9973192982088299
	train_negative_acc: 0.9983161143733023
	train_correct_nonzero: 21817
	train_incorrect_nonzero: 783
	train_positive_nonzero: 2638
	train_negative_nonzero: 19962
val:
	val_positive_loss: 0.09842018038034439
	val_negative_loss: 0.003570134285837412
	val_positive_acc: 0.9497688104245481
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.15226247906684875
	test_negative_loss: 0.006399701349437237
	test_positive_acc: 0.9355949931387202
	test_negative_acc: 0.9989224137931034
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.007489664014428854
	train_incorrect_loss: 0.14969689384317253
	train_positive_loss: 0.014898385852575302
	train_negative_loss: 0.008428276516497135
	train_correct_acc: 0.9983432020416245
	train_incorrect_acc: 0.9918256130790191
	train_positive_acc: 0.9968983729678565
	train_negative_acc: 0.9993534169280227
	train_correct_nonzero: 21332
	train_incorrect_nonzero: 1016
	train_positive_nonzero: 2356
	train_negative_nonzero: 19992
val:
	val_positive_loss: 0.04096903279423714
	val_negative_loss: 0.0010288730263710022
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.09680388867855072
	test_negative_loss: 0.03436509892344475
	test_positive_acc: 0.965263802381496
	test_negative_acc: 0.9937290614088945
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.010902064852416515
	train_incorrect_loss: 0.33687011905118547
	train_positive_loss: 0.04747103899717331
	train_negative_loss: 0.014849032275378704
	train_correct_acc: 0.998215378894779
	train_incorrect_acc: 0.9708333333333332
	train_positive_acc: 0.996705702168788
	train_negative_acc: 0.9944819484791257
	train_correct_nonzero: 20811
	train_incorrect_nonzero: 1177
	train_positive_nonzero: 2070
	train_negative_nonzero: 19918
val:
	val_positive_loss: 0.15156975388526917
	val_negative_loss: 0.001815566560253501
	val_positive_acc: 0.9451450189155107
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.1671399474143982
	test_negative_loss: 0.020085284486413002
	test_positive_acc: 0.9421638180454889
	test_negative_acc: 0.9949083066919134
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.10541033744812 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.6
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233433723449707
	train_negative_loss: 2.2802317142486572
	train_positive_acc: 0.7163151086288699
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.18644089996814728
	train_incorrect_loss: 0.7750248361053961
	train_positive_loss: 0.22103820741176605
	train_negative_loss: 0.24857527017593384
	train_correct_acc: 0.971494123838014
	train_incorrect_acc: 0.7726112573225891
	train_positive_acc: 0.982634569091872
	train_negative_acc: 0.9033644372229916
	train_correct_nonzero: 24020
	train_incorrect_nonzero: 1799
	train_positive_nonzero: 7475
	train_negative_nonzero: 18344
val:
	val_positive_loss: 0.014511384069919586
	val_negative_loss: 0.10479605197906494
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.016643142327666283
	test_negative_loss: 0.1244954764842987
	test_positive_acc: 0.9977265211640212
	test_negative_acc: 0.9809861839776164
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03762158006429672
	train_incorrect_loss: 0.724724269745796
	train_positive_loss: 0.07196691632270813
	train_negative_loss: 0.06185729429125786
	train_correct_acc: 0.9981564044624757
	train_incorrect_acc: 0.8498048850990028
	train_positive_acc: 0.998553687948494
	train_negative_acc: 0.9806013045767485
	train_correct_nonzero: 27631
	train_incorrect_nonzero: 479
	train_positive_nonzero: 8453
	train_negative_nonzero: 19657
val:
	val_positive_loss: 0.033897366374731064
	val_negative_loss: 0.028463661670684814
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03179631382226944
	test_negative_loss: 0.038502201437950134
	test_positive_acc: 0.987318098907727
	test_negative_acc: 0.9932303211933836
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02413415163755417
	train_incorrect_loss: 0.5999643937741975
	train_positive_loss: 0.06469816714525223
	train_negative_loss: 0.039334144443273544
	train_correct_acc: 0.9982538936384361
	train_incorrect_acc: 0.9066621499548329
	train_positive_acc: 0.997850356311233
	train_negative_acc: 0.9859928382953188
	train_correct_nonzero: 26282
	train_incorrect_nonzero: 517
	train_positive_nonzero: 7033
	train_negative_nonzero: 19766
val:
	val_positive_loss: 0.03462089225649834
	val_negative_loss: 0.06299281120300293
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04209504276514053
	test_negative_loss: 0.08166253566741943
	test_positive_acc: 0.9833396293375022
	test_negative_acc: 0.9904313796054995
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.01716471090912819
	train_incorrect_loss: 0.4796705565675043
	train_positive_loss: 0.03034636378288269
	train_negative_loss: 0.026996679604053497
	train_correct_acc: 0.9989432163112972
	train_incorrect_acc: 0.8994202898550725
	train_positive_acc: 0.9988097222267821
	train_negative_acc: 0.9934690441692547
	train_correct_nonzero: 26119
	train_incorrect_nonzero: 310
	train_positive_nonzero: 6599
	train_negative_nonzero: 19830
val:
	val_positive_loss: 0.02490345574915409
	val_negative_loss: 0.005348376464098692
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.016002561897039413
	test_negative_loss: 0.036901336163282394
	test_positive_acc: 0.9932111068111454
	test_negative_acc: 0.9881325806125592
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.005723047070205212
	train_incorrect_loss: 0.29376204787697263
	train_positive_loss: 0.01059372816234827
	train_negative_loss: 0.008512698113918304
	train_correct_acc: 0.9993439034138408
	train_incorrect_acc: 0.942156862745098
	train_positive_acc: 0.9992177770901075
	train_negative_acc: 0.9978697072646646
	train_correct_nonzero: 24592
	train_incorrect_nonzero: 298
	train_positive_nonzero: 4957
	train_negative_nonzero: 19933
val:
	val_positive_loss: 0.03095141611993313
	val_negative_loss: 0.038742076605558395
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.0119894128292799
	test_negative_loss: 0.06325803697109222
	test_positive_acc: 0.9954213659147869
	test_negative_acc: 0.9872709483010722
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.007223665714263916
	train_incorrect_loss: 0.29753263189342666
	train_positive_loss: 0.009249071590602398
	train_negative_loss: 0.011506978422403336
	train_correct_acc: 0.9993673496442806
	train_incorrect_acc: 0.9377016129032258
	train_positive_acc: 0.999155613901404
	train_negative_acc: 0.9983349002260312
	train_correct_nonzero: 23623
	train_incorrect_nonzero: 272
	train_positive_nonzero: 3981
	train_negative_nonzero: 19914
val:
	val_positive_loss: 0.007960451766848564
	val_negative_loss: 0.0038730876985937357
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.027684055268764496
	test_negative_loss: 0.0473213866353035
	test_positive_acc: 0.9873593225083986
	test_negative_acc: 0.9850141168111567
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.005772886797785759
	train_incorrect_loss: 0.2545611699728785
	train_positive_loss: 0.00917811132967472
	train_negative_loss: 0.008511107414960861
	train_correct_acc: 0.9992914808665293
	train_incorrect_acc: 0.944808743169399
	train_positive_acc: 0.9990277433879907
	train_negative_acc: 0.9982921577075624
	train_correct_nonzero: 23971
	train_incorrect_nonzero: 309
	train_positive_nonzero: 4335
	train_negative_nonzero: 19945
val:
	val_positive_loss: 0.03859500214457512
	val_negative_loss: 0.009615374729037285
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.021607646718621254
	test_negative_loss: 0.06340005993843079
	test_positive_acc: 0.9886141217405215
	test_negative_acc: 0.9860350906992127
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.007256506476551294
	train_incorrect_loss: 0.3024332137434631
	train_positive_loss: 0.043818291276693344
	train_negative_loss: 0.007816130295395851
	train_correct_acc: 0.9989045808866419
	train_incorrect_acc: 0.9782096584216725
	train_positive_acc: 0.9979788003880277
	train_negative_acc: 0.9951456293442232
	train_correct_nonzero: 21869
	train_incorrect_nonzero: 513
	train_positive_nonzero: 2490
	train_negative_nonzero: 19892
val:
	val_positive_loss: 0.03203842043876648
	val_negative_loss: 0.05169222503900528
	val_positive_acc: 0.9743589743589743
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.025820789858698845
	test_negative_loss: 0.09701795876026154
	test_positive_acc: 0.9830274222351667
	test_negative_acc: 0.9876182834778233
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.008282192051410675
	train_incorrect_loss: 0.13074063869393557
	train_positive_loss: 0.013958941213786602
	train_negative_loss: 0.00934523157775402
	train_correct_acc: 0.9988492922872818
	train_incorrect_acc: 0.9906336088154271
	train_positive_acc: 0.9977505161577946
	train_negative_acc: 0.999581085293871
	train_correct_nonzero: 22144
	train_incorrect_nonzero: 982
	train_positive_nonzero: 3130
	train_negative_nonzero: 19996
val:
	val_positive_loss: 0.27713391184806824
	val_negative_loss: 0.001749180257320404
	val_positive_acc: 0.9169819251786464
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.21590258181095123
	test_negative_loss: 0.053009405732154846
	test_positive_acc: 0.9291893093598733
	test_negative_acc: 0.9898751149677387
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.014233458787202835
	train_incorrect_loss: 0.11223697958386271
	train_positive_loss: 0.02645670436322689
	train_negative_loss: 0.013087134808301926
	train_correct_acc: 0.9964377249960576
	train_incorrect_acc: 0.9965910903724975
	train_positive_acc: 0.9936496735364295
	train_negative_acc: 0.9993970909349948
	train_correct_nonzero: 22149
	train_incorrect_nonzero: 2259
	train_positive_nonzero: 4401
	train_negative_nonzero: 20007
val:
	val_positive_loss: 0.23266027867794037
	val_negative_loss: 0.008033880963921547
	val_positive_acc: 0.9123581336696092
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.14222709834575653
	test_negative_loss: 0.05574151873588562
	test_positive_acc: 0.9371843708907691
	test_negative_acc: 0.9918351220149552
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.51873922348022 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.625
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233368396759033
	train_negative_loss: 2.280108690261841
	train_positive_acc: 0.7194141765259525
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.18896588683128357
	train_incorrect_loss: 0.7324171481208385
	train_positive_loss: 0.21208232641220093
	train_negative_loss: 0.2654658555984497
	train_correct_acc: 0.9552927941861392
	train_incorrect_acc: 0.7765646111515389
	train_positive_acc: 0.9781826358471646
	train_negative_acc: 0.8927385056868696
	train_correct_nonzero: 24475
	train_incorrect_nonzero: 1633
	train_positive_nonzero: 8127
	train_negative_nonzero: 17981
val:
	val_positive_loss: 0.010250907391309738
	val_negative_loss: 0.029557934030890465
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01742796041071415
	test_negative_loss: 0.05076458305120468
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9819621111083906
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.031741224229335785
	train_incorrect_loss: 0.7080857415146063
	train_positive_loss: 0.05178726837038994
	train_negative_loss: 0.04923752322793007
	train_correct_acc: 0.9979870519747167
	train_incorrect_acc: 0.7918930392321649
	train_positive_acc: 0.9984020082599263
	train_negative_acc: 0.9833423543263128
	train_correct_nonzero: 28598
	train_incorrect_nonzero: 439
	train_positive_nonzero: 9362
	train_negative_nonzero: 19675
val:
	val_positive_loss: 0.019342640414834023
	val_negative_loss: 0.013700569048523903
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.008476181887090206
	test_negative_loss: 0.04543840512633324
	test_positive_acc: 1.0
	test_negative_acc: 0.9820149363252847
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.01832457073032856
	train_incorrect_loss: 0.5766023030008655
	train_positive_loss: 0.03907163068652153
	train_negative_loss: 0.029680553823709488
	train_correct_acc: 0.9986458826862066
	train_incorrect_acc: 0.8644216496147531
	train_positive_acc: 0.9991140531582555
	train_negative_acc: 0.9886440968607828
	train_correct_nonzero: 26187
	train_incorrect_nonzero: 319
	train_positive_nonzero: 6757
	train_negative_nonzero: 19749
val:
	val_positive_loss: 0.01465839147567749
	val_negative_loss: 0.04001311585307121
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.02300907112658024
	test_negative_loss: 0.05507921427488327
	test_positive_acc: 0.9897490642237983
	test_negative_acc: 0.988226461229069
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.012718773446977139
	train_incorrect_loss: 0.39581385524638074
	train_positive_loss: 0.021775390952825546
	train_negative_loss: 0.02092573046684265
	train_correct_acc: 0.9995218661708549
	train_incorrect_acc: 0.9372197309417041
	train_positive_acc: 0.9993499722797509
	train_negative_acc: 0.9962815413807153
	train_correct_nonzero: 26733
	train_incorrect_nonzero: 235
	train_positive_nonzero: 7076
	train_negative_nonzero: 19892
val:
	val_positive_loss: 0.006669797468930483
	val_negative_loss: 0.012948166579008102
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0017340336926281452
	test_negative_loss: 0.09381385892629623
	test_positive_acc: 1.0
	test_negative_acc: 0.9751782161240645
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.009756874293088913
	train_incorrect_loss: 0.3891755832492539
	train_positive_loss: 0.019480489194393158
	train_negative_loss: 0.01669936813414097
	train_correct_acc: 0.9993924647551857
	train_incorrect_acc: 0.9293048973143759
	train_positive_acc: 0.9993606776115805
	train_negative_acc: 0.9959620054242397
	train_correct_nonzero: 24565
	train_incorrect_nonzero: 218
	train_positive_nonzero: 4898
	train_negative_nonzero: 19885
val:
	val_positive_loss: 0.008188909851014614
	val_negative_loss: 0.004451158922165632
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.023798037320375443
	test_negative_loss: 0.05383460223674774
	test_positive_acc: 0.9903932243390077
	test_negative_acc: 0.9847780541231611
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.00546838715672493
	train_incorrect_loss: 0.3697240430846884
	train_positive_loss: 0.019689181819558144
	train_negative_loss: 0.006787918973714113
	train_correct_acc: 0.9993039856902133
	train_incorrect_acc: 0.957413749365804
	train_positive_acc: 0.9988516501481587
	train_negative_acc: 0.9973345582013711
	train_correct_nonzero: 23232
	train_incorrect_nonzero: 244
	train_positive_nonzero: 3583
	train_negative_nonzero: 19893
val:
	val_positive_loss: 0.019204609096050262
	val_negative_loss: 0.030846398323774338
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.018114570528268814
	test_negative_loss: 0.03228191286325455
	test_positive_acc: 0.9913904761077008
	test_negative_acc: 0.987879516497677
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.00706198625266552
	train_incorrect_loss: 0.29212999567306003
	train_positive_loss: 0.014995728619396687
	train_negative_loss: 0.010330664925277233
	train_correct_acc: 0.9990865878140364
	train_incorrect_acc: 0.9737663906142168
	train_positive_acc: 0.9983066619260849
	train_negative_acc: 0.9983953334347812
	train_correct_nonzero: 21882
	train_incorrect_nonzero: 397
	train_positive_nonzero: 2347
	train_negative_nonzero: 19932
val:
	val_positive_loss: 0.011850151233375072
	val_negative_loss: 0.03720854967832565
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.021557308733463287
	test_negative_loss: 0.028974534943699837
	test_positive_acc: 0.990644124935653
	test_negative_acc: 0.9914592198497587
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.014596427790820599
	train_incorrect_loss: 0.3584722190691952
	train_positive_loss: 0.048840198665857315
	train_negative_loss: 0.025170907378196716
	train_correct_acc: 0.9991105093437718
	train_incorrect_acc: 0.9671704859418171
	train_positive_acc: 0.9984953146036277
	train_negative_acc: 0.9927833460304217
	train_correct_nonzero: 20783
	train_incorrect_nonzero: 602
	train_positive_nonzero: 1527
	train_negative_nonzero: 19858
val:
	val_positive_loss: 0.09482385963201523
	val_negative_loss: 0.006295229308307171
	val_positive_acc: 0.9579655317360235
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.11139613389968872
	test_negative_loss: 0.010691406205296516
	test_positive_acc: 0.9604779844300818
	test_negative_acc: 0.998641304347826
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.006873521022498608
	train_incorrect_loss: 0.11031047853532175
	train_positive_loss: 0.011431883089244366
	train_negative_loss: 0.007369250524789095
	train_correct_acc: 0.9987151730034316
	train_incorrect_acc: 0.997417840375587
	train_positive_acc: 0.9975729522258858
	train_negative_acc: 0.9998517246535499
	train_correct_nonzero: 20930
	train_incorrect_nonzero: 1016
	train_positive_nonzero: 1957
	train_negative_nonzero: 19989
val:
	val_positive_loss: 0.5883533954620361
	val_negative_loss: 0.0001884165103547275
	val_positive_acc: 0.8656998738965952
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.5370123386383057
	test_negative_loss: 0.013661228120326996
	test_positive_acc: 0.8815262046945613
	test_negative_acc: 0.998641304347826
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.02170850895345211
	train_incorrect_loss: 0.2662257598245039
	train_positive_loss: 0.0706782191991806
	train_negative_loss: 0.02439705841243267
	train_correct_acc: 0.996757974713188
	train_incorrect_acc: 0.9821887213847014
	train_positive_acc: 0.9943787060517925
	train_negative_acc: 0.9916545056734329
	train_correct_nonzero: 21500
	train_incorrect_nonzero: 2373
	train_positive_nonzero: 3944
	train_negative_nonzero: 19929
val:
	val_positive_loss: 0.6326841711997986
	val_negative_loss: 0.0011511703487485647
	val_positive_acc: 0.8062211013030685
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.3525881767272949
	test_negative_loss: 0.043969955295324326
	test_positive_acc: 0.8943575853631129
	test_negative_acc: 0.9960085706927142
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.43813443183899 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.65
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233320713043213
	train_negative_loss: 2.280116558074951
	train_positive_acc: 0.7213377320008312
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.19321627914905548
	train_incorrect_loss: 0.7463137439252543
	train_positive_loss: 0.22265100479125977
	train_negative_loss: 0.26882824301719666
	train_correct_acc: 0.9631684308174708
	train_incorrect_acc: 0.7799941383175926
	train_positive_acc: 0.9843281982981376
	train_negative_acc: 0.8914792181527073
	train_correct_nonzero: 25169
	train_incorrect_nonzero: 1818
	train_positive_nonzero: 8964
	train_negative_nonzero: 18023
val:
	val_positive_loss: 0.01547579001635313
	val_negative_loss: 0.07491262257099152
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.02911689132452011
	test_negative_loss: 0.0836205929517746
	test_positive_acc: 0.9918156041656429
	test_negative_acc: 0.9839763461698947
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.036964207887649536
	train_incorrect_loss: 0.6980551389163642
	train_positive_loss: 0.06840328872203827
	train_negative_loss: 0.06099606677889824
	train_correct_acc: 0.997833368573201
	train_incorrect_acc: 0.7955250669853071
	train_positive_acc: 0.9985273253076481
	train_negative_acc: 0.9758017753706806
	train_correct_nonzero: 27535
	train_incorrect_nonzero: 588
	train_positive_nonzero: 8575
	train_negative_nonzero: 19548
val:
	val_positive_loss: 0.008866064250469208
	val_negative_loss: 0.0232456773519516
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01839711144566536
	test_negative_loss: 0.04221722483634949
	test_positive_acc: 0.9933694148151981
	test_negative_acc: 0.9854998469574472
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.018041346222162247
	train_incorrect_loss: 0.4919125593836469
	train_positive_loss: 0.040445324033498764
	train_negative_loss: 0.0291602686047554
	train_correct_acc: 0.998854812338846
	train_incorrect_acc: 0.8965255465255466
	train_positive_acc: 0.9987492281828028
	train_negative_acc: 0.9900356926349051
	train_correct_nonzero: 27051
	train_incorrect_nonzero: 344
	train_positive_nonzero: 7598
	train_negative_nonzero: 19797
val:
	val_positive_loss: 0.0017069019377231598
	val_negative_loss: 0.02681468427181244
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.010566990822553635
	test_negative_loss: 0.0628834217786789
	test_positive_acc: 0.9966050944669366
	test_negative_acc: 0.9858969280968359
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.009086421690881252
	train_incorrect_loss: 0.2982190189753877
	train_positive_loss: 0.01873566210269928
	train_negative_loss: 0.014012202620506287
	train_correct_acc: 0.9992226350224213
	train_incorrect_acc: 0.958904109589041
	train_positive_acc: 0.9992467037511447
	train_negative_acc: 0.9961415977956485
	train_correct_nonzero: 26483
	train_incorrect_nonzero: 236
	train_positive_nonzero: 6833
	train_negative_nonzero: 19886
val:
	val_positive_loss: 0.013754311949014664
	val_negative_loss: 0.0084612425416708
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01216855738312006
	test_negative_loss: 0.035858556628227234
	test_positive_acc: 0.9957956932773109
	test_negative_acc: 0.9899977949398564
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.008967434987425804
	train_incorrect_loss: 0.43122993988589686
	train_positive_loss: 0.03708622604608536
	train_negative_loss: 0.01402027066797018
	train_correct_acc: 0.9992734966959163
	train_incorrect_acc: 0.9227207977207976
	train_positive_acc: 0.9991198089971947
	train_negative_acc: 0.9922253176236348
	train_correct_nonzero: 26916
	train_incorrect_nonzero: 324
	train_positive_nonzero: 7381
	train_negative_nonzero: 19859
val:
	val_positive_loss: 0.010273857973515987
	val_negative_loss: 0.23991967737674713
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.017784247174859047
	test_negative_loss: 0.27542978525161743
	test_positive_acc: 0.9947917946418333
	test_negative_acc: 0.9845870663038901
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.010716928169131279
	train_incorrect_loss: 0.41607819052082473
	train_positive_loss: 0.03652331233024597
	train_negative_loss: 0.017388589680194855
	train_correct_acc: 0.9994068384871106
	train_incorrect_acc: 0.9569267139479904
	train_positive_acc: 0.999243273786114
	train_negative_acc: 0.9947065088673404
	train_correct_nonzero: 23368
	train_incorrect_nonzero: 325
	train_positive_nonzero: 3824
	train_negative_nonzero: 19869
val:
	val_positive_loss: 0.002714823931455612
	val_negative_loss: 0.003436414757743478
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.012189122848212719
	test_negative_loss: 0.05783922225236893
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9867210597434911
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.009788879193365574
	train_incorrect_loss: 0.3589186264717939
	train_positive_loss: 0.051545627415180206
	train_negative_loss: 0.01115440670400858
	train_correct_acc: 0.998569600488703
	train_incorrect_acc: 0.9654558404558404
	train_positive_acc: 0.9975659782274429
	train_negative_acc: 0.9926149974509255
	train_correct_nonzero: 21496
	train_incorrect_nonzero: 762
	train_positive_nonzero: 2365
	train_negative_nonzero: 19893
val:
	val_positive_loss: 0.16116246581077576
	val_negative_loss: 0.0015936807030811906
	val_positive_acc: 0.9461958806221101
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.1319538801908493
	test_negative_loss: 0.024205295369029045
	test_positive_acc: 0.9478508057058108
	test_negative_acc: 0.991560878925881
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.0074729518964886665
	train_incorrect_loss: 0.12130751179206353
	train_positive_loss: 0.015560866333544254
	train_negative_loss: 0.007707299664616585
	train_correct_acc: 0.998602127150725
	train_incorrect_acc: 0.9959666926880042
	train_positive_acc: 0.9972964127099962
	train_negative_acc: 0.9994817453836817
	train_correct_nonzero: 21998
	train_incorrect_nonzero: 1225
	train_positive_nonzero: 3238
	train_negative_nonzero: 19985
val:
	val_positive_loss: 0.5218976736068726
	val_negative_loss: 0.0008094563381746411
	val_positive_acc: 0.8785203867171081
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.3977734446525574
	test_negative_loss: 0.002551028737798333
	test_positive_acc: 0.8773290469483304
	test_negative_acc: 1.0
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.007837416604161263
	train_incorrect_loss: 0.10187824916937022
	train_positive_loss: 0.01779361441731453
	train_negative_loss: 0.005853335373103619
	train_correct_acc: 0.9982611814945822
	train_incorrect_acc: 0.9922089254549987
	train_positive_acc: 0.9965836872975937
	train_negative_acc: 0.9995479507703625
	train_correct_nonzero: 21147
	train_incorrect_nonzero: 1452
	train_positive_nonzero: 2612
	train_negative_nonzero: 19987
val:
	val_positive_loss: 0.3957078158855438
	val_negative_loss: 0.00038435281021520495
	val_positive_acc: 0.9333753678015972
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.29772427678108215
	test_negative_loss: 0.012758923694491386
	test_positive_acc: 0.9302106318163882
	test_negative_acc: 0.9940328486480761
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.011952074244618416
	train_incorrect_loss: 0.16305638996846844
	train_positive_loss: 0.04622204974293709
	train_negative_loss: 0.010883142240345478
	train_correct_acc: 0.9980218564979128
	train_incorrect_acc: 0.9883400661035622
	train_positive_acc: 0.9965567161441617
	train_negative_acc: 0.9947205874108678
	train_correct_nonzero: 20440
	train_incorrect_nonzero: 1537
	train_positive_nonzero: 2180
	train_negative_nonzero: 19797
val:
	val_positive_loss: 0.2575341463088989
	val_negative_loss: 0.0034276945516467094
	val_positive_acc: 0.9461958806221101
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.13481959700584412
	test_negative_loss: 0.0475829616189003
	test_positive_acc: 0.9626138725295155
	test_negative_acc: 0.9911267840072993
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.71107125282288 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.675
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2332677841186523
	train_negative_loss: 2.2801103591918945
	train_positive_acc: 0.7237692101672392
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.20232637226581573
	train_incorrect_loss: 0.7366470367581185
	train_positive_loss: 0.22815048694610596
	train_negative_loss: 0.29614242911338806
	train_correct_acc: 0.9543350618382479
	train_incorrect_acc: 0.7820700615949543
	train_positive_acc: 0.9779021317450434
	train_negative_acc: 0.8843095666835545
	train_correct_nonzero: 24550
	train_incorrect_nonzero: 1828
	train_positive_nonzero: 8669
	train_negative_nonzero: 17709
val:
	val_positive_loss: 0.018751060590147972
	val_negative_loss: 0.092161625623703
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.019835790619254112
	test_negative_loss: 0.1065949872136116
	test_positive_acc: 0.9976339285714286
	test_negative_acc: 0.9818658461873279
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.036537256091833115
	train_incorrect_loss: 0.6546658289446459
	train_positive_loss: 0.06411687284708023
	train_negative_loss: 0.06022484228014946
	train_correct_acc: 0.9981566090631319
	train_incorrect_acc: 0.8324276899598078
	train_positive_acc: 0.9983112385989141
	train_negative_acc: 0.9798437854378359
	train_correct_nonzero: 28420
	train_incorrect_nonzero: 525
	train_positive_nonzero: 9274
	train_negative_nonzero: 19671
val:
	val_positive_loss: 0.012744847685098648
	val_negative_loss: 0.04335695505142212
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.026702383533120155
	test_negative_loss: 0.05131563916802406
	test_positive_acc: 0.9901730381958723
	test_negative_acc: 0.9954926166600695
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.010595100931823254
	train_incorrect_loss: 0.4152021895425275
	train_positive_loss: 0.030026989057660103
	train_negative_loss: 0.015154846012592316
	train_correct_acc: 0.999339630034515
	train_incorrect_acc: 0.9320437548053401
	train_positive_acc: 0.9989644658880502
	train_negative_acc: 0.995439443866415
	train_correct_nonzero: 28282
	train_incorrect_nonzero: 354
	train_positive_nonzero: 8753
	train_negative_nonzero: 19883
val:
	val_positive_loss: 0.020406687632203102
	val_negative_loss: 0.016040509566664696
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.06245282664895058
	test_negative_loss: 0.02993924543261528
	test_positive_acc: 0.9719903870978096
	test_negative_acc: 0.9936289011524844
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.016944149509072304
	train_incorrect_loss: 0.46982547753660014
	train_positive_loss: 0.03820030763745308
	train_negative_loss: 0.0294349268078804
	train_correct_acc: 0.9993158176070931
	train_incorrect_acc: 0.9168957959752938
	train_positive_acc: 0.9992168158127152
	train_negative_acc: 0.9905225440316957
	train_correct_nonzero: 24833
	train_incorrect_nonzero: 372
	train_positive_nonzero: 5415
	train_negative_nonzero: 19790
val:
	val_positive_loss: 0.002492107916623354
	val_negative_loss: 0.010059666819870472
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.021618304774165154
	test_negative_loss: 0.025301026180386543
	test_positive_acc: 0.9891178829466382
	test_negative_acc: 0.9901991040194503
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.00622633146122098
	train_incorrect_loss: 0.23287997466865176
	train_positive_loss: 0.010450802743434906
	train_negative_loss: 0.00918723363429308
	train_correct_acc: 0.9995659714363835
	train_incorrect_acc: 0.9636714636714636
	train_positive_acc: 0.9992598119087067
	train_negative_acc: 0.9982101675074919
	train_correct_nonzero: 24054
	train_incorrect_nonzero: 281
	train_positive_nonzero: 4419
	train_negative_nonzero: 19916
val:
	val_positive_loss: 0.016618480905890465
	val_negative_loss: 0.001532411901280284
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.029914850369095802
	test_negative_loss: 0.028680182993412018
	test_positive_acc: 0.9901251216472031
	test_negative_acc: 0.9925498161258757
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.004800471477210522
	train_incorrect_loss: 0.17286314690203244
	train_positive_loss: 0.009369086474180222
	train_negative_loss: 0.005594764370471239
	train_correct_acc: 0.9991122495535062
	train_incorrect_acc: 0.9807411019015115
	train_positive_acc: 0.9984993419264332
	train_negative_acc: 0.9990193742033258
	train_correct_nonzero: 22524
	train_incorrect_nonzero: 395
	train_positive_nonzero: 2999
	train_negative_nonzero: 19920
val:
	val_positive_loss: 0.03168260306119919
	val_negative_loss: 0.0008756564348004758
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.09117517620325089
	test_negative_loss: 0.011327365413308144
	test_positive_acc: 0.9722234103512098
	test_negative_acc: 0.9963617950640065
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.006506503093987703
	train_incorrect_loss: 0.18374047021027087
	train_positive_loss: 0.01592271775007248
	train_negative_loss: 0.006996138021349907
	train_correct_acc: 0.9989281662917623
	train_incorrect_acc: 0.9846521595779756
	train_positive_acc: 0.9979994634651881
	train_negative_acc: 0.9990146910633726
	train_correct_nonzero: 23392
	train_incorrect_nonzero: 774
	train_positive_nonzero: 4208
	train_negative_nonzero: 19958
val:
	val_positive_loss: 0.12365026772022247
	val_negative_loss: 0.0014680465683341026
	val_positive_acc: 0.9451450189155107
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.1078072115778923
	test_negative_loss: 0.005515004973858595
	test_positive_acc: 0.9498755310375071
	test_negative_acc: 0.9974689254210104
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.008060905151069164
	train_incorrect_loss: 0.21809011701305783
	train_positive_loss: 0.02540772035717964
	train_negative_loss: 0.008512638509273529
	train_correct_acc: 0.9982979483331632
	train_incorrect_acc: 0.9819152046783625
	train_positive_acc: 0.9967282201010917
	train_negative_acc: 0.9981076550693343
	train_correct_nonzero: 22184
	train_incorrect_nonzero: 1168
	train_positive_nonzero: 3371
	train_negative_nonzero: 19981
val:
	val_positive_loss: 0.1201566681265831
	val_negative_loss: 0.0037903697229921818
	val_positive_acc: 0.9369482976040353
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.17834919691085815
	test_negative_loss: 0.022141294553875923
	test_positive_acc: 0.9294978199684788
	test_negative_acc: 0.995437503160941
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.01076492853462696
	train_incorrect_loss: 0.2501971090338782
	train_positive_loss: 0.04973014071583748
	train_negative_loss: 0.015720443800091743
	train_correct_acc: 0.9985401917734105
	train_incorrect_acc: 0.9824263038548752
	train_positive_acc: 0.9974884831135813
	train_negative_acc: 0.9941832034321136
	train_correct_nonzero: 20687
	train_incorrect_nonzero: 1525
	train_positive_nonzero: 2269
	train_negative_nonzero: 19943
val:
	val_positive_loss: 0.16962966322898865
	val_negative_loss: 0.0015110863605514169
	val_positive_acc: 0.9369482976040353
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.164898082613945
	test_negative_loss: 0.01574796624481678
	test_positive_acc: 0.9455467058462523
	test_negative_acc: 0.9975637181409296
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.007522089406847954
	train_incorrect_loss: 0.17139235332430622
	train_positive_loss: 0.014667313545942307
	train_negative_loss: 0.010267993435263634
	train_correct_acc: 0.998533996906429
	train_incorrect_acc: 0.986319073083779
	train_positive_acc: 0.9972599894637539
	train_negative_acc: 0.9989881855674393
	train_correct_nonzero: 20676
	train_incorrect_nonzero: 1201
	train_positive_nonzero: 1884
	train_negative_nonzero: 19993
val:
	val_positive_loss: 0.2571603059768677
	val_negative_loss: 0.001207547727972269
	val_positive_acc: 0.9159310634720471
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.20874682068824768
	test_negative_loss: 0.014803829602897167
	test_positive_acc: 0.9265798664485159
	test_negative_acc: 0.9975637181409296
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.6709201335907 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.7
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233198642730713
	train_negative_loss: 2.2801876068115234
	train_positive_acc: 0.726779143718844
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.20944209396839142
	train_incorrect_loss: 0.6989918001834303
	train_positive_loss: 0.23005977272987366
	train_negative_loss: 0.298857718706131
	train_correct_acc: 0.9548735872432907
	train_incorrect_acc: 0.7938523093805842
	train_positive_acc: 0.9811582931404226
	train_negative_acc: 0.8834662443595742
	train_correct_nonzero: 24055
	train_incorrect_nonzero: 1844
	train_positive_nonzero: 8313
	train_negative_nonzero: 17586
val:
	val_positive_loss: 0.01726946420967579
	val_negative_loss: 0.038151681423187256
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.029842421412467957
	test_negative_loss: 0.050646986812353134
	test_positive_acc: 0.9921931363530855
	test_negative_acc: 0.9891766313116823
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.024156292900443077
	train_incorrect_loss: 0.5211082699634805
	train_positive_loss: 0.03589558228850365
	train_negative_loss: 0.03686899691820145
	train_correct_acc: 0.9985745241616558
	train_incorrect_acc: 0.8844357976653696
	train_positive_acc: 0.9985093397326333
	train_negative_acc: 0.9905765976100432
	train_correct_nonzero: 27897
	train_incorrect_nonzero: 373
	train_positive_nonzero: 8491
	train_negative_nonzero: 19779
val:
	val_positive_loss: 0.0015599267790094018
	val_negative_loss: 0.0142625467851758
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.012798672541975975
	test_negative_loss: 0.05036602169275284
	test_positive_acc: 0.9965374373433584
	test_negative_acc: 0.9823457917331995
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.010098844766616821
	train_incorrect_loss: 0.40482119758088314
	train_positive_loss: 0.019421078264713287
	train_negative_loss: 0.015567234717309475
	train_correct_acc: 0.9991245844351089
	train_incorrect_acc: 0.9206582633053222
	train_positive_acc: 0.9988242218473162
	train_negative_acc: 0.9953645190293603
	train_correct_nonzero: 26920
	train_incorrect_nonzero: 284
	train_positive_nonzero: 7311
	train_negative_nonzero: 19893
val:
	val_positive_loss: 0.0035792766138911247
	val_negative_loss: 0.009811731986701488
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.012945585884153843
	test_negative_loss: 0.04585031792521477
	test_positive_acc: 0.9933694148151981
	test_negative_acc: 0.9857740900465214
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.009692072868347168
	train_incorrect_loss: 0.37168120496194695
	train_positive_loss: 0.018203720450401306
	train_negative_loss: 0.016185740008950233
	train_correct_acc: 0.9993513364041555
	train_incorrect_acc: 0.94037558685446
	train_positive_acc: 0.9990086111900255
	train_negative_acc: 0.9961522805043667
	train_correct_nonzero: 23038
	train_incorrect_nonzero: 253
	train_positive_nonzero: 3384
	train_negative_nonzero: 19907
val:
	val_positive_loss: 0.0013091207947582006
	val_negative_loss: 0.005097178276628256
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.023501219227910042
	test_negative_loss: 0.018645409494638443
	test_positive_acc: 0.9908165047622881
	test_negative_acc: 0.996165343267965
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.016076048836112022
	train_incorrect_loss: 0.4256670280617101
	train_positive_loss: 0.03875444829463959
	train_negative_loss: 0.028609629720449448
	train_correct_acc: 0.9994151165002926
	train_incorrect_acc: 0.9370442036463708
	train_positive_acc: 0.9993004294407145
	train_negative_acc: 0.9908656256529359
	train_correct_nonzero: 22129
	train_incorrect_nonzero: 336
	train_positive_nonzero: 2633
	train_negative_nonzero: 19832
val:
	val_positive_loss: 0.0011581513099372387
	val_negative_loss: 0.005848536267876625
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.028064439073204994
	test_negative_loss: 0.04048978537321091
	test_positive_acc: 0.9858517750449688
	test_negative_acc: 0.9875663703643385
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.011751833371818066
	train_incorrect_loss: 0.4373657192342797
	train_positive_loss: 0.04071349278092384
	train_negative_loss: 0.02061561867594719
	train_correct_acc: 0.9994161542344518
	train_incorrect_acc: 0.9294426290762067
	train_positive_acc: 0.9992437992635829
	train_negative_acc: 0.991469496396403
	train_correct_nonzero: 22490
	train_incorrect_nonzero: 390
	train_positive_nonzero: 3022
	train_negative_nonzero: 19858
val:
	val_positive_loss: 0.0003402858565095812
	val_negative_loss: 0.007754241116344929
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03127018362283707
	test_negative_loss: 0.04485031217336655
	test_positive_acc: 0.9854738031130705
	test_negative_acc: 0.9899248609303761
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.0077461376786231995
	train_incorrect_loss: 0.2149134485107867
	train_positive_loss: 0.01763860695064068
	train_negative_loss: 0.010623791255056858
	train_correct_acc: 0.9990189609478713
	train_incorrect_acc: 0.9777889312721676
	train_positive_acc: 0.9982233874145774
	train_negative_acc: 0.9978272699801634
	train_correct_nonzero: 22166
	train_incorrect_nonzero: 530
	train_positive_nonzero: 2762
	train_negative_nonzero: 19934
val:
	val_positive_loss: 0.08597350120544434
	val_negative_loss: 0.0009612212888896465
	val_positive_acc: 0.9754098360655737
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.098949134349823
	test_negative_loss: 0.017177514731884003
	test_positive_acc: 0.9705948805385367
	test_negative_acc: 0.9966718619430883
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.009488649666309357
	train_incorrect_loss: 0.35743087389374884
	train_positive_loss: 0.028113622218370438
	train_negative_loss: 0.014586013741791248
	train_correct_acc: 0.9990802689361139
	train_incorrect_acc: 0.9291880098653007
	train_positive_acc: 0.9986263108094283
	train_negative_acc: 0.9941887902854057
	train_correct_nonzero: 22033
	train_incorrect_nonzero: 388
	train_positive_nonzero: 2525
	train_negative_nonzero: 19896
val:
	val_positive_loss: 2.6511666874284856e-05
	val_negative_loss: 0.003990639932453632
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.022390149533748627
	test_negative_loss: 0.05623028427362442
	test_positive_acc: 0.9893496092661374
	test_negative_acc: 0.9863659461071275
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.0047951047308743
	train_incorrect_loss: 0.1877178684783438
	train_positive_loss: 0.017203280702233315
	train_negative_loss: 0.005937227979302406
	train_correct_acc: 0.9992791188978586
	train_incorrect_acc: 0.9784675615212529
	train_positive_acc: 0.9987309874018058
	train_negative_acc: 0.9978497685117413
	train_correct_nonzero: 21171
	train_incorrect_nonzero: 464
	train_positive_nonzero: 1703
	train_negative_nonzero: 19932
val:
	val_positive_loss: 0.002772275358438492
	val_negative_loss: 0.001265156315639615
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05848034471273422
	test_negative_loss: 0.04259549081325531
	test_positive_acc: 0.9776979318678544
	test_negative_acc: 0.991104106213395
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.006635449361056089
	train_incorrect_loss: 0.2163621232768033
	train_positive_loss: 0.022474255412817
	train_negative_loss: 0.009431146085262299
	train_correct_acc: 0.9988576539497347
	train_incorrect_acc: 0.9865591397849462
	train_positive_acc: 0.9979098004568401
	train_negative_acc: 0.997444440382814
	train_correct_nonzero: 21582
	train_incorrect_nonzero: 770
	train_positive_nonzero: 2439
	train_negative_nonzero: 19913
val:
	val_positive_loss: 0.0340987965464592
	val_negative_loss: 0.0009883798193186522
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.10569626837968826
	test_negative_loss: 0.01405604463070631
	test_positive_acc: 0.9677069696710099
	test_negative_acc: 0.9948066476157911
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.8030617237091 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.725
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233133554458618
	train_negative_loss: 2.280287981033325
	train_positive_acc: 0.7292751257673277
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.20686191320419312
	train_incorrect_loss: 0.7394575328033542
	train_positive_loss: 0.23297050595283508
	train_negative_loss: 0.28491735458374023
	train_correct_acc: 0.968249842676748
	train_incorrect_acc: 0.7742383228901226
	train_positive_acc: 0.9843501884571132
	train_negative_acc: 0.8939192731277483
	train_correct_nonzero: 24708
	train_incorrect_nonzero: 1930
	train_positive_nonzero: 8505
	train_negative_nonzero: 18133
val:
	val_positive_loss: 0.003484397893771529
	val_negative_loss: 0.10286837816238403
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.007240179926156998
	test_negative_loss: 0.13958102464675903
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.9627931381356729
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.04478967934846878
	train_incorrect_loss: 0.6971308259869651
	train_positive_loss: 0.08310865610837936
	train_negative_loss: 0.07776913791894913
	train_correct_acc: 0.997482502684584
	train_incorrect_acc: 0.8294192745818061
	train_positive_acc: 0.9982543009380346
	train_negative_acc: 0.9709613547265239
	train_correct_nonzero: 26815
	train_incorrect_nonzero: 622
	train_positive_nonzero: 7949
	train_negative_nonzero: 19488
val:
	val_positive_loss: 0.032971955835819244
	val_negative_loss: 0.09616976976394653
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.041658852249383926
	test_negative_loss: 0.10663767158985138
	test_positive_acc: 0.9846242073532354
	test_negative_acc: 0.9934758392158156
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.016603460535407066
	train_incorrect_loss: 0.4438597864643743
	train_positive_loss: 0.020675450563430786
	train_negative_loss: 0.027772560715675354
	train_correct_acc: 0.9991071939520414
	train_incorrect_acc: 0.8978138174894601
	train_positive_acc: 0.999310857190827
	train_negative_acc: 0.9947242351419526
	train_correct_nonzero: 26766
	train_incorrect_nonzero: 238
	train_positive_nonzero: 7221
	train_negative_nonzero: 19783
val:
	val_positive_loss: 0.020594719797372818
	val_negative_loss: 0.030334465205669403
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.039511676877737045
	test_negative_loss: 0.03974760323762894
	test_positive_acc: 0.9834430855765267
	test_negative_acc: 0.9965490238927739
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.014232819899916649
	train_incorrect_loss: 0.3597652484822902
	train_positive_loss: 0.019454995170235634
	train_negative_loss: 0.02475895918905735
	train_correct_acc: 0.9993338287159463
	train_incorrect_acc: 0.930579143079143
	train_positive_acc: 0.9993437007166739
	train_negative_acc: 0.9950465854671762
	train_correct_nonzero: 27166
	train_incorrect_nonzero: 293
	train_positive_nonzero: 7646
	train_negative_nonzero: 19813
val:
	val_positive_loss: 0.018382033333182335
	val_negative_loss: 0.007439223118126392
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0343204028904438
	test_negative_loss: 0.019000794738531113
	test_positive_acc: 0.9828914039079706
	test_negative_acc: 0.9948405821407275
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.00765783479437232
	train_incorrect_loss: 0.29959202761820053
	train_positive_loss: 0.012660352513194084
	train_negative_loss: 0.012805063277482986
	train_correct_acc: 0.9994410900395733
	train_incorrect_acc: 0.9494812925170066
	train_positive_acc: 0.9992654729093392
	train_negative_acc: 0.9974156868271236
	train_correct_nonzero: 24325
	train_incorrect_nonzero: 303
	train_positive_nonzero: 4781
	train_negative_nonzero: 19847
val:
	val_positive_loss: 0.003729158313944936
	val_negative_loss: 0.00458872877061367
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.055249184370040894
	test_negative_loss: 0.0416935533285141
	test_positive_acc: 0.9769833694872263
	test_negative_acc: 0.9885715328146933
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.0066925338469445705
	train_incorrect_loss: 0.23333436550553707
	train_positive_loss: 0.011570353992283344
	train_negative_loss: 0.009691066108644009
	train_correct_acc: 0.9991160743915042
	train_incorrect_acc: 0.9704761904761905
	train_positive_acc: 0.9985257405328924
	train_negative_acc: 0.9985505251000668
	train_correct_nonzero: 23358
	train_incorrect_nonzero: 369
	train_positive_nonzero: 3821
	train_negative_nonzero: 19906
val:
	val_positive_loss: 0.0015674227615818381
	val_negative_loss: 0.0023072301410138607
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0374348945915699
	test_negative_loss: 0.02070438675582409
	test_positive_acc: 0.9863406429045427
	test_negative_acc: 0.993078916154624
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.005807450506836176
	train_incorrect_loss: 0.21882347685809553
	train_positive_loss: 0.017537353560328484
	train_negative_loss: 0.009481563232839108
	train_correct_acc: 0.9994712089853699
	train_incorrect_acc: 0.9734059343434344
	train_positive_acc: 0.9992077033383249
	train_negative_acc: 0.9971998021410661
	train_correct_nonzero: 25812
	train_incorrect_nonzero: 390
	train_positive_nonzero: 6263
	train_negative_nonzero: 19939
val:
	val_positive_loss: 0.0008271354017779231
	val_negative_loss: 0.00899902917444706
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.016747798770666122
	test_negative_loss: 0.031410954892635345
	test_positive_acc: 0.992095035382574
	test_negative_acc: 0.9901686477659337
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.006634977180510759
	train_incorrect_loss: 0.2970567793606973
	train_positive_loss: 0.018555352464318275
	train_negative_loss: 0.011537209153175354
	train_correct_acc: 0.9995927578578054
	train_incorrect_acc: 0.9330354926780838
	train_positive_acc: 0.9996002051955953
	train_negative_acc: 0.9961097783677078
	train_correct_nonzero: 24913
	train_incorrect_nonzero: 256
	train_positive_nonzero: 5304
	train_negative_nonzero: 19865
val:
	val_positive_loss: 0.00020368932746350765
	val_negative_loss: 0.0041201310232281685
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.023507004603743553
	test_negative_loss: 0.02230554074048996
	test_positive_acc: 0.9910357133486758
	test_negative_acc: 0.989692585344327
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.004869911354035139
	train_incorrect_loss: 0.24080831785129939
	train_positive_loss: 0.012010096572339535
	train_negative_loss: 0.008919430896639824
	train_correct_acc: 0.9997718709509109
	train_incorrect_acc: 0.9733595800524933
	train_positive_acc: 0.9996148675666985
	train_negative_acc: 0.9981883055195184
	train_correct_nonzero: 22392
	train_incorrect_nonzero: 265
	train_positive_nonzero: 2773
	train_negative_nonzero: 19884
val:
	val_positive_loss: 0.005816531367599964
	val_negative_loss: 0.004314960911870003
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0315205380320549
	test_negative_loss: 0.03708832710981369
	test_positive_acc: 0.9897059261146333
	test_negative_acc: 0.9901764262255461
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.019299009814858437
	train_incorrect_loss: 0.39076467008187565
	train_positive_loss: 0.06407830864191055
	train_negative_loss: 0.03290834277868271
	train_correct_acc: 0.9992004828512293
	train_incorrect_acc: 0.9537129386163751
	train_positive_acc: 0.9987254151015731
	train_negative_acc: 0.9890024038635414
	train_correct_nonzero: 21113
	train_incorrect_nonzero: 507
	train_positive_nonzero: 1818
	train_negative_nonzero: 19802
val:
	val_positive_loss: 0.001633846783079207
	val_negative_loss: 0.0033321459777653217
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04091519117355347
	test_negative_loss: 0.027373261749744415
	test_positive_acc: 0.9867758864464039
	test_negative_acc: 0.994711854895872
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.76729941368103 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.75
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.233088493347168
	train_negative_loss: 2.2801828384399414
	train_positive_acc: 0.7311465810586171
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.2121349275112152
	train_incorrect_loss: 0.7047869722598366
	train_positive_loss: 0.23432256281375885
	train_negative_loss: 0.30659785866737366
	train_correct_acc: 0.9596559272667277
	train_incorrect_acc: 0.790668098843837
	train_positive_acc: 0.9797385405104183
	train_negative_acc: 0.8920557713051248
	train_correct_nonzero: 23677
	train_incorrect_nonzero: 1863
	train_positive_nonzero: 7843
	train_negative_nonzero: 17697
val:
	val_positive_loss: 0.030983608216047287
	val_negative_loss: 0.07392901182174683
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03573939949274063
	test_negative_loss: 0.0917678028345108
	test_positive_acc: 0.9870003496063724
	test_negative_acc: 0.9853171123219816
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.021344110369682312
	train_incorrect_loss: 0.4873409448676945
	train_positive_loss: 0.03522036597132683
	train_negative_loss: 0.0335281603038311
	train_correct_acc: 0.9990859435793248
	train_incorrect_acc: 0.8830390089615182
	train_positive_acc: 0.9991745049348074
	train_negative_acc: 0.9896489047415739
	train_correct_nonzero: 29300
	train_incorrect_nonzero: 388
	train_positive_nonzero: 9895
	train_negative_nonzero: 19793
val:
	val_positive_loss: 0.0017070925096049905
	val_negative_loss: 0.010220082476735115
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01855022832751274
	test_negative_loss: 0.036780498921871185
	test_positive_acc: 0.9922120074077908
	test_negative_acc: 0.9860483331355956
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.013364528305828571
	train_incorrect_loss: 0.41340183501721917
	train_positive_loss: 0.017547208815813065
	train_negative_loss: 0.021286552771925926
	train_correct_acc: 0.9992147993515493
	train_incorrect_acc: 0.9123015873015873
	train_positive_acc: 0.9991847163722515
	train_negative_acc: 0.9963865373315758
	train_correct_nonzero: 27249
	train_incorrect_nonzero: 227
	train_positive_nonzero: 7650
	train_negative_nonzero: 19826
val:
	val_positive_loss: 0.00011168530909344554
	val_negative_loss: 0.022627174854278564
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.00894050020724535
	test_negative_loss: 0.0682140439748764
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9793026923319172
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.020956972613930702
	train_incorrect_loss: 0.5650799782706204
	train_positive_loss: 0.05620064586400986
	train_negative_loss: 0.03589614853262901
	train_correct_acc: 0.9988613034878374
	train_incorrect_acc: 0.8918458198918259
	train_positive_acc: 0.9987770347082517
	train_negative_acc: 0.9865488021814205
	train_correct_nonzero: 25768
	train_incorrect_nonzero: 456
	train_positive_nonzero: 6489
	train_negative_nonzero: 19735
val:
	val_positive_loss: 0.002258177613839507
	val_negative_loss: 0.036481209099292755
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.009897924959659576
	test_negative_loss: 0.07730311155319214
	test_positive_acc: 0.996630029935951
	test_negative_acc: 0.981235051872291
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.013942601159214973
	train_incorrect_loss: 0.4265989350979529
	train_positive_loss: 0.03554433211684227
	train_negative_loss: 0.02449870854616165
	train_correct_acc: 0.9994667744676651
	train_incorrect_acc: 0.9280155642023347
	train_positive_acc: 0.9992573190100916
	train_negative_acc: 0.9922440769054458
	train_correct_nonzero: 23829
	train_incorrect_nonzero: 328
	train_positive_nonzero: 4344
	train_negative_nonzero: 19813
val:
	val_positive_loss: 0.00016883529315236956
	val_negative_loss: 0.015533051453530788
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.008199580013751984
	test_negative_loss: 0.06846126914024353
	test_positive_acc: 0.9958882858699035
	test_negative_acc: 0.9810372901492875
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.019551116973161697
	train_incorrect_loss: 0.4903642736312961
	train_positive_loss: 0.050594232976436615
	train_negative_loss: 0.035165295004844666
	train_correct_acc: 0.9992328642373844
	train_incorrect_acc: 0.9046314445236399
	train_positive_acc: 0.9991200767703482
	train_negative_acc: 0.9861674524744926
	train_correct_nonzero: 24315
	train_incorrect_nonzero: 441
	train_positive_nonzero: 4955
	train_negative_nonzero: 19801
val:
	val_positive_loss: 0.00024943117750808597
	val_negative_loss: 0.0035549539607018232
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05731883645057678
	test_negative_loss: 0.012253405526280403
	test_positive_acc: 0.9777629329379021
	test_negative_acc: 0.9961599757314739
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.00690182950347662
	train_incorrect_loss: 0.27961287925351974
	train_positive_loss: 0.02018558233976364
	train_negative_loss: 0.01045443955808878
	train_correct_acc: 0.9994367126353985
	train_incorrect_acc: 0.9646256296158957
	train_positive_acc: 0.9989174941592118
	train_negative_acc: 0.9966448439882337
	train_correct_nonzero: 21614
	train_incorrect_nonzero: 344
	train_positive_nonzero: 2054
	train_negative_nonzero: 19904
val:
	val_positive_loss: 9.177836545859464e-06
	val_negative_loss: 0.005944699980318546
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04052428901195526
	test_negative_loss: 0.04412782937288284
	test_positive_acc: 0.9819902774999606
	test_negative_acc: 0.9885810646124942
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.011836345307528973
	train_incorrect_loss: 0.36230921056478643
	train_positive_loss: 0.047512486577034
	train_negative_loss: 0.02029493637382984
	train_correct_acc: 0.9992973468140877
	train_incorrect_acc: 0.9487871069326687
	train_positive_acc: 0.9991639595362952
	train_negative_acc: 0.9901181800826123
	train_correct_nonzero: 20875
	train_incorrect_nonzero: 481
	train_positive_nonzero: 1534
	train_negative_nonzero: 19822
val:
	val_positive_loss: 0.00039696641033515334
	val_negative_loss: 0.0014147565234452486
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.09267152100801468
	test_negative_loss: 0.012480617500841618
	test_positive_acc: 0.9723520960322897
	test_negative_acc: 0.9950808907048653
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.00833679549396038
	train_incorrect_loss: 0.25988780595950933
	train_positive_loss: 0.01954137347638607
	train_negative_loss: 0.01174221932888031
	train_correct_acc: 0.9989785597346217
	train_incorrect_acc: 0.9646757679180886
	train_positive_acc: 0.9982573427407502
	train_negative_acc: 0.9962520264994296
	train_correct_nonzero: 21036
	train_incorrect_nonzero: 478
	train_positive_nonzero: 1608
	train_negative_nonzero: 19906
val:
	val_positive_loss: 0.005786108784377575
	val_negative_loss: 0.0020277800504118204
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.12253082543611526
	test_negative_loss: 0.019797176122665405
	test_positive_acc: 0.958759494788492
	test_negative_acc: 0.9949860979849461
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.010058891959488392
	train_incorrect_loss: 0.27962512094476233
	train_positive_loss: 0.05225035175681114
	train_negative_loss: 0.012112494558095932
	train_correct_acc: 0.9986568929171137
	train_incorrect_acc: 0.9733115863235472
	train_positive_acc: 0.9976288612476069
	train_negative_acc: 0.9930589524456005
	train_correct_nonzero: 21707
	train_incorrect_nonzero: 971
	train_positive_nonzero: 2767
	train_negative_nonzero: 19911
val:
	val_positive_loss: 0.062761589884758
	val_negative_loss: 0.009145700372755527
	val_positive_acc: 0.9836065573770492
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.11590807139873505
	test_negative_loss: 0.027370786294341087
	test_positive_acc: 0.9534959257113801
	test_negative_acc: 0.9939085117780496
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.32870388031006 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.775
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2330517768859863
	train_negative_loss: 2.279937982559204
	train_positive_acc: 0.7323999856677836
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.2239312082529068
	train_incorrect_loss: 0.6625626423345468
	train_positive_loss: 0.23361478745937347
	train_negative_loss: 0.3403612971305847
	train_correct_acc: 0.9521959156608729
	train_incorrect_acc: 0.8138922012547997
	train_positive_acc: 0.9769679344125327
	train_negative_acc: 0.8929553819468629
	train_correct_nonzero: 23186
	train_incorrect_nonzero: 1735
	train_positive_nonzero: 7825
	train_negative_nonzero: 17096
val:
	val_positive_loss: 0.012117791920900345
	val_negative_loss: 0.030580466613173485
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.024692507460713387
	test_negative_loss: 0.0493045412003994
	test_positive_acc: 0.9928002427019085
	test_negative_acc: 0.9909369861772137
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.024221297353506088
	train_incorrect_loss: 0.5276220769177903
	train_positive_loss: 0.054654669016599655
	train_negative_loss: 0.038576941937208176
	train_correct_acc: 0.9985937165148808
	train_incorrect_acc: 0.9023180575011673
	train_positive_acc: 0.9987389472747225
	train_negative_acc: 0.9852679977915463
	train_correct_nonzero: 28843
	train_incorrect_nonzero: 454
	train_positive_nonzero: 9565
	train_negative_nonzero: 19732
val:
	val_positive_loss: 0.0038009588606655598
	val_negative_loss: 0.008589205332100391
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.018270250409841537
	test_negative_loss: 0.03424724563956261
	test_positive_acc: 0.9925621474638131
	test_negative_acc: 0.9854920684978349
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.011146948672831059
	train_incorrect_loss: 0.41902563152740724
	train_positive_loss: 0.04344276338815689
	train_negative_loss: 0.016179818660020828
	train_correct_acc: 0.9992045668557352
	train_incorrect_acc: 0.9392594859241126
	train_positive_acc: 0.9989455920947427
	train_negative_acc: 0.9907362142913193
	train_correct_nonzero: 26737
	train_incorrect_nonzero: 425
	train_positive_nonzero: 7318
	train_negative_nonzero: 19844
val:
	val_positive_loss: 0.02589600719511509
	val_negative_loss: 0.0021921820007264614
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.07713311910629272
	test_negative_loss: 0.0077134836465120316
	test_positive_acc: 0.9663474036533569
	test_negative_acc: 0.997344588550984
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.012127963826060295
	train_incorrect_loss: 0.3701186487930609
	train_positive_loss: 0.046390943229198456
	train_negative_loss: 0.020450308918952942
	train_correct_acc: 0.9994443664823952
	train_incorrect_acc: 0.9625162127107653
	train_positive_acc: 0.9991367263049481
	train_negative_acc: 0.9905515081709385
	train_correct_nonzero: 21476
	train_incorrect_nonzero: 495
	train_positive_nonzero: 2067
	train_negative_nonzero: 19904
val:
	val_positive_loss: 0.008648446761071682
	val_negative_loss: 0.0033774985931813717
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05056193098425865
	test_negative_loss: 0.02874254435300827
	test_positive_acc: 0.9770322731298801
	test_negative_acc: 0.9927370449546431
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.010090244933962822
	train_incorrect_loss: 0.3248288402334432
	train_positive_loss: 0.04864858090877533
	train_negative_loss: 0.0105421869084239
	train_correct_acc: 0.9980916218283563
	train_incorrect_acc: 0.9554773929773931
	train_positive_acc: 0.9968088687074458
	train_negative_acc: 0.9914240023928269
	train_correct_nonzero: 20881
	train_incorrect_nonzero: 739
	train_positive_nonzero: 1712
	train_negative_nonzero: 19908
val:
	val_positive_loss: 0.09610958397388458
	val_negative_loss: 0.009462377987802029
	val_positive_acc: 0.9415720891130728
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.09814102947711945
	test_negative_loss: 0.01673516444861889
	test_positive_acc: 0.9468156227512056
	test_negative_acc: 0.997344588550984
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.007995488122105598
	train_incorrect_loss: 0.15158365888314584
	train_positive_loss: 0.013757482171058655
	train_negative_loss: 0.010436994954943657
	train_correct_acc: 0.9983496674260293
	train_incorrect_acc: 0.9919085312225155
	train_positive_acc: 0.996945906088048
	train_negative_acc: 0.9995126871373755
	train_correct_nonzero: 21356
	train_incorrect_nonzero: 1145
	train_positive_nonzero: 2498
	train_negative_nonzero: 20003
val:
	val_positive_loss: 0.1223481297492981
	val_negative_loss: 0.001837208867073059
	val_positive_acc: 0.9497688104245481
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.13005411624908447
	test_negative_loss: 0.01283756922930479
	test_positive_acc: 0.9565626980482178
	test_negative_acc: 0.9974959935897436
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.007387325167655945
	train_incorrect_loss: 0.23460612711552678
	train_positive_loss: 0.029754115268588066
	train_negative_loss: 0.01021452248096466
	train_correct_acc: 0.9988552201466459
	train_incorrect_acc: 0.9762673540451319
	train_positive_acc: 0.9978241076526793
	train_negative_acc: 0.9957342600671788
	train_correct_nonzero: 20442
	train_incorrect_nonzero: 885
	train_positive_nonzero: 1348
	train_negative_nonzero: 19979
val:
	val_positive_loss: 0.014067105017602444
	val_negative_loss: 0.012679021805524826
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.06019128859043121
	test_negative_loss: 0.07466433197259903
	test_positive_acc: 0.974809374377726
	test_negative_acc: 0.9878055123065907
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.006613631267100573
	train_incorrect_loss: 0.271809755970601
	train_positive_loss: 0.02761513739824295
	train_negative_loss: 0.009029155597090721
	train_correct_acc: 0.9989647139532193
	train_incorrect_acc: 0.9674543946932005
	train_positive_acc: 0.9980998633766155
	train_negative_acc: 0.9964127385929261
	train_correct_nonzero: 20253
	train_incorrect_nonzero: 711
	train_positive_nonzero: 1004
	train_negative_nonzero: 19960
val:
	val_positive_loss: 0.16680720448493958
	val_negative_loss: 0.010106204077601433
	val_positive_acc: 0.9216057166876839
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.17182280123233795
	test_negative_loss: 0.05401121824979782
	test_positive_acc: 0.9163766608081431
	test_negative_acc: 0.992462801865569
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.008390136063098907
	train_incorrect_loss: 0.14689438573198763
	train_positive_loss: 0.01584775373339653
	train_negative_loss: 0.01080313976854086
	train_correct_acc: 0.9980142721218273
	train_incorrect_acc: 0.9921875
	train_positive_acc: 0.9961243686181905
	train_negative_acc: 0.9994352692610315
	train_correct_nonzero: 20542
	train_incorrect_nonzero: 1319
	train_positive_nonzero: 1874
	train_negative_nonzero: 19987
val:
	val_positive_loss: 0.0802968293428421
	val_negative_loss: 0.0013947812840342522
	val_positive_acc: 0.9707860445565364
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0977582335472107
	test_negative_loss: 0.024056509137153625
	test_positive_acc: 0.9673967381785027
	test_negative_acc: 0.997618831640058
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.011520549654960632
	train_incorrect_loss: 0.3064218810215446
	train_positive_loss: 0.04695870354771614
	train_negative_loss: 0.014928322285413742
	train_correct_acc: 0.9979788429287567
	train_incorrect_acc: 0.9625239520681881
	train_positive_acc: 0.9963940182755504
	train_negative_acc: 0.9917337516697164
	train_correct_nonzero: 20276
	train_incorrect_nonzero: 1163
	train_positive_nonzero: 1514
	train_negative_nonzero: 19925
val:
	val_positive_loss: 0.05740961804986
	val_negative_loss: 0.0026871890295296907
	val_positive_acc: 0.9707860445565364
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.10697590559720993
	test_negative_loss: 0.04498479887843132
	test_positive_acc: 0.9649317201116091
	test_negative_acc: 0.9932435636297664
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.26968240737915 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.8
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2329845428466797
	train_negative_loss: 2.279938220977783
	train_positive_acc: 0.7351557951388837
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.21288682520389557
	train_incorrect_loss: 0.6793410161820551
	train_positive_loss: 0.23404493927955627
	train_negative_loss: 0.33209970593452454
	train_correct_acc: 0.9657193085223628
	train_incorrect_acc: 0.8068917185942335
	train_positive_acc: 0.9878143940575432
	train_negative_acc: 0.8935635532309858
	train_correct_nonzero: 23239
	train_incorrect_nonzero: 1842
	train_positive_nonzero: 7945
	train_negative_nonzero: 17136
val:
	val_positive_loss: 0.020741229876875877
	val_negative_loss: 0.07476144284009933
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.030244862660765648
	test_negative_loss: 0.09508025646209717
	test_positive_acc: 0.9924695548712206
	test_negative_acc: 0.9863372210404853
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.051176127046346664
	train_incorrect_loss: 0.6297959412848882
	train_positive_loss: 0.08578620851039886
	train_negative_loss: 0.09277565032243729
	train_correct_acc: 0.998107687287687
	train_incorrect_acc: 0.8384715805405287
	train_positive_acc: 0.9988020068609111
	train_negative_acc: 0.9684876213437837
	train_correct_nonzero: 29239
	train_incorrect_nonzero: 792
	train_positive_nonzero: 10591
	train_negative_nonzero: 19440
val:
	val_positive_loss: 0.0036049133632332087
	val_negative_loss: 0.016359427943825722
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.018875308334827423
	test_negative_loss: 0.050045497715473175
	test_positive_acc: 0.992389767637178
	test_negative_acc: 0.9815858184978348
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02224726602435112
	train_incorrect_loss: 0.4485929886910649
	train_positive_loss: 0.036161888390779495
	train_negative_loss: 0.03990824893116951
	train_correct_acc: 0.9989190830837343
	train_incorrect_acc: 0.8854997252409179
	train_positive_acc: 0.9992991285378791
	train_negative_acc: 0.987265124000651
	train_correct_nonzero: 29513
	train_incorrect_nonzero: 476
	train_positive_nonzero: 10463
	train_negative_nonzero: 19526
val:
	val_positive_loss: 0.00025677657686173916
	val_negative_loss: 0.06757275015115738
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.005022263154387474
	test_negative_loss: 0.16780000925064087
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9478881601056639
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.011411094106733799
	train_incorrect_loss: 0.3059054354741407
	train_positive_loss: 0.01664779521524906
	train_negative_loss: 0.0196123868227005
	train_correct_acc: 0.9994376164439259
	train_incorrect_acc: 0.9305734190782423
	train_positive_acc: 0.9992665053289054
	train_negative_acc: 0.9957338661068572
	train_correct_nonzero: 25886
	train_incorrect_nonzero: 258
	train_positive_nonzero: 6522
	train_negative_nonzero: 19622
val:
	val_positive_loss: 0.0013128502760082483
	val_negative_loss: 0.018841827288269997
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.012976091355085373
	test_negative_loss: 0.04744119942188263
	test_positive_acc: 0.9940502427019084
	test_negative_acc: 0.9874963575309181
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.009021339006721973
	train_incorrect_loss: 0.2897528192356645
	train_positive_loss: 0.02423718012869358
	train_negative_loss: 0.015338237397372723
	train_correct_acc: 0.9995768559197478
	train_incorrect_acc: 0.9378295533955912
	train_positive_acc: 0.9994215557627867
	train_negative_acc: 0.9939983709530394
	train_correct_nonzero: 25196
	train_incorrect_nonzero: 276
	train_positive_nonzero: 5876
	train_negative_nonzero: 19596
val:
	val_positive_loss: 0.010023447684943676
	val_negative_loss: 0.020408060401678085
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.022993668913841248
	test_negative_loss: 0.0763523057103157
	test_positive_acc: 0.988912290841375
	test_negative_acc: 0.9786882970880851
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.007461788132786751
	train_incorrect_loss: 0.28885937957706076
	train_positive_loss: 0.015988357365131378
	train_negative_loss: 0.011089354753494263
	train_correct_acc: 0.9992359533686667
	train_incorrect_acc: 0.9683738065587381
	train_positive_acc: 0.9985345644451579
	train_negative_acc: 0.997988735262785
	train_correct_nonzero: 24328
	train_incorrect_nonzero: 414
	train_positive_nonzero: 4873
	train_negative_nonzero: 19869
val:
	val_positive_loss: 0.00030434434302151203
	val_negative_loss: 0.0050528282299637794
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.022333398461341858
	test_negative_loss: 0.04456886649131775
	test_positive_acc: 0.9910869699624324
	test_negative_acc: 0.9927292664950308
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.006689914967864752
	train_incorrect_loss: 0.23125334764994848
	train_positive_loss: 0.018778808414936066
	train_negative_loss: 0.01010913122445345
	train_correct_acc: 0.9992608086135853
	train_incorrect_acc: 0.9691237666237665
	train_positive_acc: 0.9986442608578587
	train_negative_acc: 0.9968151855995319
	train_correct_nonzero: 22216
	train_incorrect_nonzero: 408
	train_positive_nonzero: 2750
	train_negative_nonzero: 19874
val:
	val_positive_loss: 0.0001216259624925442
	val_negative_loss: 0.008494957350194454
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.013315023854374886
	test_negative_loss: 0.07027433812618256
	test_positive_acc: 0.9965374373433584
	test_negative_acc: 0.9817614817650434
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.006003775633871555
	train_incorrect_loss: 0.34433493302956825
	train_positive_loss: 0.027045128867030144
	train_negative_loss: 0.008215788751840591
	train_correct_acc: 0.999106544689253
	train_incorrect_acc: 0.9601977567886659
	train_positive_acc: 0.9982320798990874
	train_negative_acc: 0.9969616671264337
	train_correct_nonzero: 20823
	train_incorrect_nonzero: 497
	train_positive_nonzero: 1603
	train_negative_nonzero: 19717
val:
	val_positive_loss: 3.40305341524072e-05
	val_negative_loss: 0.0031938825268298388
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04763605073094368
	test_negative_loss: 0.05856725573539734
	test_positive_acc: 0.9860295352743561
	test_negative_acc: 0.991197986829905
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.010716153308749199
	train_incorrect_loss: 0.2611754074071539
	train_positive_loss: 0.032103218138217926
	train_negative_loss: 0.02002567984163761
	train_correct_acc: 0.9995460219529511
	train_incorrect_acc: 0.9722222222222222
	train_positive_acc: 0.9992895165446156
	train_negative_acc: 0.99367853656695
	train_correct_nonzero: 20436
	train_incorrect_nonzero: 476
	train_positive_nonzero: 1050
	train_negative_nonzero: 19862
val:
	val_positive_loss: 8.95499179023318e-05
	val_negative_loss: 0.015553522855043411
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.030016133561730385
	test_negative_loss: 0.058312878012657166
	test_positive_acc: 0.9888856768755778
	test_negative_acc: 0.9926872989920057
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.009187581017613411
	train_incorrect_loss: 0.2801781868590083
	train_positive_loss: 0.019486377015709877
	train_negative_loss: 0.016752073541283607
	train_correct_acc: 0.9994872353585715
	train_incorrect_acc: 0.9722692966615734
	train_positive_acc: 0.9991066633597488
	train_negative_acc: 0.9969434342298089
	train_correct_nonzero: 20284
	train_incorrect_nonzero: 541
	train_positive_nonzero: 917
	train_negative_nonzero: 19908
val:
	val_positive_loss: 0.04526486247777939
	val_negative_loss: 0.01671246439218521
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.06415745615959167
	test_negative_loss: 0.015593022108078003
	test_positive_acc: 0.969884456457102
	test_negative_acc: 0.9962670023440874
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.18986892700195 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.825
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2329533100128174
	train_negative_loss: 2.279864549636841
	train_positive_acc: 0.7370659224225704
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.21567384898662567
	train_incorrect_loss: 0.6414745226425661
	train_positive_loss: 0.2296992689371109
	train_negative_loss: 0.35272857546806335
	train_correct_acc: 0.962797407591032
	train_incorrect_acc: 0.8079612977737397
	train_positive_acc: 0.9815419140641894
	train_negative_acc: 0.8966349159626974
	train_correct_nonzero: 23551
	train_incorrect_nonzero: 1900
	train_positive_nonzero: 8280
	train_negative_nonzero: 17171
val:
	val_positive_loss: 0.007297643460333347
	val_negative_loss: 0.040548160672187805
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.020927108824253082
	test_negative_loss: 0.05735410749912262
	test_positive_acc: 0.9926034834426491
	test_negative_acc: 0.9818843198153578
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.03571963682770729
	train_incorrect_loss: 0.6013297454866577
	train_positive_loss: 0.05456443503499031
	train_negative_loss: 0.06269168108701706
	train_correct_acc: 0.9987822136885526
	train_incorrect_acc: 0.841164562907234
	train_positive_acc: 0.9988641392122625
	train_negative_acc: 0.9814924653649866
	train_correct_nonzero: 27936
	train_incorrect_nonzero: 495
	train_positive_nonzero: 8869
	train_negative_nonzero: 19562
val:
	val_positive_loss: 0.0009600862395018339
	val_negative_loss: 0.03275906294584274
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.00995359942317009
	test_negative_loss: 0.05128613859415054
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9852753498310105
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02322204038500786
	train_incorrect_loss: 0.4427664131895967
	train_positive_loss: 0.041405823081731796
	train_negative_loss: 0.04268741235136986
	train_correct_acc: 0.9987855292147153
	train_incorrect_acc: 0.8876035665080719
	train_positive_acc: 0.998966022221393
	train_negative_acc: 0.9857185714873132
	train_correct_nonzero: 28566
	train_incorrect_nonzero: 526
	train_positive_nonzero: 9552
	train_negative_nonzero: 19540
val:
	val_positive_loss: 0.0004200814291834831
	val_negative_loss: 0.05146974325180054
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.006956069730222225
	test_negative_loss: 0.09743492305278778
	test_positive_acc: 0.9989035087719298
	test_negative_acc: 0.9685954687208003
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.012187683023512363
	train_incorrect_loss: 0.3775951235852517
	train_positive_loss: 0.019127387553453445
	train_negative_loss: 0.020693158730864525
	train_correct_acc: 0.9994860524766382
	train_incorrect_acc: 0.9062777777777777
	train_positive_acc: 0.9992989407545965
	train_negative_acc: 0.9949982327599056
	train_correct_nonzero: 27150
	train_incorrect_nonzero: 267
	train_positive_nonzero: 7735
	train_negative_nonzero: 19682
val:
	val_positive_loss: 0.0013123005628585815
	val_negative_loss: 0.016315478831529617
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.011443017981946468
	test_negative_loss: 0.04724114388227463
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9860115129435507
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.013137145899236202
	train_incorrect_loss: 0.3379435942743864
	train_positive_loss: 0.027614641934633255
	train_negative_loss: 0.025201397016644478
	train_correct_acc: 0.9997210404642952
	train_incorrect_acc: 0.9425249210579854
	train_positive_acc: 0.9996948094022019
	train_negative_acc: 0.9924110612354728
	train_correct_nonzero: 24111
	train_incorrect_nonzero: 327
	train_positive_nonzero: 4779
	train_negative_nonzero: 19659
val:
	val_positive_loss: 4.9144349759444594e-05
	val_negative_loss: 0.02872968278825283
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.006534045096486807
	test_negative_loss: 0.07863318175077438
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9784743148091197
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.006744785699993372
	train_incorrect_loss: 0.22348896391706882
	train_positive_loss: 0.010103441774845123
	train_negative_loss: 0.011682329699397087
	train_correct_acc: 0.9996950909074597
	train_incorrect_acc: 0.9606449771689497
	train_positive_acc: 0.9994753330579735
	train_negative_acc: 0.998094370317029
	train_correct_nonzero: 23246
	train_incorrect_nonzero: 265
	train_positive_nonzero: 3779
	train_negative_nonzero: 19732
val:
	val_positive_loss: 0.0023893914185464382
	val_negative_loss: 0.0021943836472928524
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04446164518594742
	test_negative_loss: 0.04422321170568466
	test_positive_acc: 0.9870401748540747
	test_negative_acc: 0.9910963277537826
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.01012700330466032
	train_incorrect_loss: 0.3619350857678242
	train_positive_loss: 0.03069240227341652
	train_negative_loss: 0.018092824146151543
	train_correct_acc: 0.9992400600027403
	train_incorrect_acc: 0.9328621908127208
	train_positive_acc: 0.9988878636083528
	train_negative_acc: 0.9908475141366072
	train_correct_nonzero: 21630
	train_incorrect_nonzero: 374
	train_positive_nonzero: 2230
	train_negative_nonzero: 19774
val:
	val_positive_loss: 0.006441500503569841
	val_negative_loss: 0.31088313460350037
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.005934549495577812
	test_negative_loss: 0.34849557280540466
	test_positive_acc: 0.9977874373433584
	test_negative_acc: 0.9870549944056626
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.010574482381343842
	train_incorrect_loss: 0.34167418245288766
	train_positive_loss: 0.023991957306861877
	train_negative_loss: 0.017585115507245064
	train_correct_acc: 0.9994681073661781
	train_incorrect_acc: 0.9488703051643191
	train_positive_acc: 0.9989568951167147
	train_negative_acc: 0.9964484897900554
	train_correct_nonzero: 21433
	train_incorrect_nonzero: 342
	train_positive_nonzero: 1982
	train_negative_nonzero: 19793
val:
	val_positive_loss: 0.020360412076115608
	val_negative_loss: 0.009981002658605576
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.025878723710775375
	test_negative_loss: 0.02987303026020527
	test_positive_acc: 0.9864880872621634
	test_negative_acc: 0.9948066476157911
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.005969105288386345
	train_incorrect_loss: 0.2964792161020623
	train_positive_loss: 0.02205336093902588
	train_negative_loss: 0.010263640433549881
	train_correct_acc: 0.9995411717291524
	train_incorrect_acc: 0.9405839214058392
	train_positive_acc: 0.9992334422949194
	train_negative_acc: 0.9956176988381279
	train_correct_nonzero: 20698
	train_incorrect_nonzero: 435
	train_positive_nonzero: 1294
	train_negative_nonzero: 19839
val:
	val_positive_loss: 0.028705425560474396
	val_negative_loss: 0.002743291202932596
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.1005590409040451
	test_negative_loss: 0.05174703896045685
	test_positive_acc: 0.9686555282238798
	test_negative_acc: 0.9899699076876579
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.0129822613671422
	train_incorrect_loss: 0.33493195381861307
	train_positive_loss: 0.04987664893269539
	train_negative_loss: 0.017658226191997528
	train_correct_acc: 0.9982691578032555
	train_incorrect_acc: 0.9551020122165654
	train_positive_acc: 0.9971815610963648
	train_negative_acc: 0.9908415169230061
	train_correct_nonzero: 20565
	train_incorrect_nonzero: 833
	train_positive_nonzero: 1546
	train_negative_nonzero: 19852
val:
	val_positive_loss: 2.2383410396287218e-06
	val_negative_loss: 0.004253726452589035
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.025146815925836563
	test_negative_loss: 0.11722061038017273
	test_positive_acc: 0.9912323602297706
	test_negative_acc: 0.9857451326127169
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.30737137794495 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.85
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2329137325286865
	train_negative_loss: 2.2799253463745117
	train_positive_acc: 0.7389251857273365
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.20637767016887665
	train_incorrect_loss: 0.6251579211341316
	train_positive_loss: 0.2181587815284729
	train_negative_loss: 0.384913831949234
	train_correct_acc: 0.9668530401994069
	train_incorrect_acc: 0.8352946367450471
	train_positive_acc: 0.9891130247035563
	train_negative_acc: 0.912723585250658
	train_correct_nonzero: 22457
	train_incorrect_nonzero: 1601
	train_positive_nonzero: 7628
	train_negative_nonzero: 16430
val:
	val_positive_loss: 0.010874146595597267
	val_negative_loss: 0.052501268684864044
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.018580835312604904
	test_negative_loss: 0.08978374302387238
	test_positive_acc: 0.9954781153094601
	test_negative_acc: 0.976108292627549
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.02285468392074108
	train_incorrect_loss: 0.4830531345579824
	train_positive_loss: 0.04890185967087746
	train_negative_loss: 0.037580642849206924
	train_correct_acc: 0.9992887635976455
	train_incorrect_acc: 0.9010940400433559
	train_positive_acc: 0.9992302432573368
	train_negative_acc: 0.9870315522277341
	train_correct_nonzero: 27733
	train_incorrect_nonzero: 569
	train_positive_nonzero: 8593
	train_negative_nonzero: 19709
val:
	val_positive_loss: 0.002169114537537098
	val_negative_loss: 0.079294852912426
	val_positive_acc: 1.0
	val_negative_acc: 0.9672131147540983
test:
	test_positive_loss: 0.02283436432480812
	test_negative_loss: 0.141220822930336
	test_positive_acc: 0.9888522169786168
	test_negative_acc: 0.9645744787068274
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.012301085516810417
	train_incorrect_loss: 0.3233567761015748
	train_positive_loss: 0.020854130387306213
	train_negative_loss: 0.020387547090649605
	train_correct_acc: 0.9992796678856878
	train_incorrect_acc: 0.9473410087719298
	train_positive_acc: 0.9990606175972278
	train_negative_acc: 0.9959033230404364
	train_correct_nonzero: 27157
	train_incorrect_nonzero: 326
	train_positive_nonzero: 7716
	train_negative_nonzero: 19767
val:
	val_positive_loss: 0.006166345439851284
	val_negative_loss: 0.016801567748188972
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.014300346374511719
	test_negative_loss: 0.07840332388877869
	test_positive_acc: 0.9937195548712205
	test_negative_acc: 0.9751905430367028
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.006578033324331045
	train_incorrect_loss: 0.2639365266478464
	train_positive_loss: 0.014232481829822063
	train_negative_loss: 0.009944775141775608
	train_correct_acc: 0.9994100758964402
	train_incorrect_acc: 0.9529985119047619
	train_positive_acc: 0.9991511976689327
	train_negative_acc: 0.9975380161574945
	train_correct_nonzero: 25078
	train_incorrect_nonzero: 403
	train_positive_nonzero: 5632
	train_negative_nonzero: 19849
val:
	val_positive_loss: 0.02509636990725994
	val_negative_loss: 0.0042638592422008514
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05427328497171402
	test_negative_loss: 0.07034125924110413
	test_positive_acc: 0.9799032313649653
	test_negative_acc: 0.9828879018311683
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.005246416199952364
	train_incorrect_loss: 0.21043647573811738
	train_positive_loss: 0.012316756881773472
	train_negative_loss: 0.008523345924913883
	train_correct_acc: 0.999515457264189
	train_incorrect_acc: 0.9718291404612158
	train_positive_acc: 0.9991134817951256
	train_negative_acc: 0.998177546714234
	train_correct_nonzero: 21305
	train_incorrect_nonzero: 481
	train_positive_nonzero: 1906
	train_negative_nonzero: 19880
val:
	val_positive_loss: 0.00034116493770852685
	val_negative_loss: 0.05247822403907776
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.04225834459066391
	test_negative_loss: 0.07557982206344604
	test_positive_acc: 0.9775054509072745
	test_negative_acc: 0.9868149403600011
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.007792845834046602
	train_incorrect_loss: 0.22337841071165704
	train_positive_loss: 0.02225247025489807
	train_negative_loss: 0.012206196784973145
	train_correct_acc: 0.9989923323109435
	train_incorrect_acc: 0.9766473887136347
	train_positive_acc: 0.9982059112106686
	train_negative_acc: 0.996867919865858
	train_correct_nonzero: 21814
	train_incorrect_nonzero: 609
	train_positive_nonzero: 2507
	train_negative_nonzero: 19916
val:
	val_positive_loss: 0.0020821732468903065
	val_negative_loss: 0.012669622898101807
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.040261559188365936
	test_negative_loss: 0.03785425052046776
	test_positive_acc: 0.9896516723990828
	test_negative_acc: 0.989650617841302
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.008386516012251377
	train_incorrect_loss: 0.29819999889149323
	train_positive_loss: 0.017836855724453926
	train_negative_loss: 0.015318749472498894
	train_correct_acc: 0.9997184936091871
	train_incorrect_acc: 0.9557601047291768
	train_positive_acc: 0.9995452808433654
	train_negative_acc: 0.9967480756882078
	train_correct_nonzero: 21191
	train_incorrect_nonzero: 411
	train_positive_nonzero: 1688
	train_negative_nonzero: 19914
val:
	val_positive_loss: 0.012684653513133526
	val_negative_loss: 0.005277588032186031
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05151499807834625
	test_negative_loss: 0.016339078545570374
	test_positive_acc: 0.9824622172987935
	test_negative_acc: 0.9952183735709954
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.004129501990973949
	train_incorrect_loss: 0.12892750336639772
	train_positive_loss: 0.00735586229711771
	train_negative_loss: 0.005920361261814833
	train_correct_acc: 0.999517731265984
	train_incorrect_acc: 0.9825184016824396
	train_positive_acc: 0.9991303759962614
	train_negative_acc: 0.9990739872109231
	train_correct_nonzero: 20868
	train_incorrect_nonzero: 478
	train_positive_nonzero: 1414
	train_negative_nonzero: 19932
val:
	val_positive_loss: 8.825790018818225e-07
	val_negative_loss: 0.013345474377274513
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.01827305555343628
	test_negative_loss: 0.05182680860161781
	test_positive_acc: 0.9937195548712205
	test_negative_acc: 0.9884348690320286
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.012336388230323792
	train_incorrect_loss: 0.3973048394546203
	train_positive_loss: 0.05084891617298126
	train_negative_loss: 0.02048739232122898
	train_correct_acc: 0.9989473035872976
	train_incorrect_acc: 0.9541916074323481
	train_positive_acc: 0.9982212554055404
	train_negative_acc: 0.9917130041004475
	train_correct_nonzero: 20404
	train_incorrect_nonzero: 657
	train_positive_nonzero: 1296
	train_negative_nonzero: 19765
val:
	val_positive_loss: 6.69688088237308e-05
	val_negative_loss: 0.012253249064087868
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03090648725628853
	test_negative_loss: 0.023192211985588074
	test_positive_acc: 0.9876041430937326
	test_negative_acc: 0.994010170854172
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.003938940819352865
	train_incorrect_loss: 0.21342316499853092
	train_positive_loss: 0.009525802917778492
	train_negative_loss: 0.006478741765022278
	train_correct_acc: 0.9995911550909586
	train_incorrect_acc: 0.9667503423094478
	train_positive_acc: 0.9992310670183501
	train_negative_acc: 0.9983732136793518
	train_correct_nonzero: 20526
	train_incorrect_nonzero: 506
	train_positive_nonzero: 1097
	train_negative_nonzero: 19935
val:
	val_positive_loss: 0.012071567587554455
	val_negative_loss: 0.002511488040909171
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.11101462692022324
	test_negative_loss: 0.011455103754997253
	test_positive_acc: 0.9616662577624902
	test_negative_acc: 0.9987980769230769
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.53735494613647 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.875
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2328531742095947
	train_negative_loss: 2.2799809871606493
	train_positive_acc: 0.7410113677003686
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.2277776598930359
	train_incorrect_loss: 0.6218725155163751
	train_positive_loss: 0.2438337504863739
	train_negative_loss: 0.44157350063323975
	train_correct_acc: 0.967281068464203
	train_incorrect_acc: 0.8369682848994517
	train_positive_acc: 0.987095791423244
	train_negative_acc: 0.9002731100077096
	train_correct_nonzero: 22112
	train_incorrect_nonzero: 1834
	train_positive_nonzero: 7961
	train_negative_nonzero: 15985
val:
	val_positive_loss: 0.021279145032167435
	val_negative_loss: 0.08410947769880295
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.02307867258787155
	test_negative_loss: 0.0952112153172493
	test_positive_acc: 0.9963041413373861
	test_negative_acc: 0.9764706396783809
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.0269697904586792
	train_incorrect_loss: 0.512326074715892
	train_positive_loss: 0.05008368194103241
	train_negative_loss: 0.046456631273031235
	train_correct_acc: 0.9991324525506162
	train_incorrect_acc: 0.8878899404135997
	train_positive_acc: 0.9989921043883092
	train_negative_acc: 0.9849868859410098
	train_correct_nonzero: 28574
	train_incorrect_nonzero: 443
	train_positive_nonzero: 9433
	train_negative_nonzero: 19584
val:
	val_positive_loss: 0.0005867202999070287
	val_negative_loss: 0.09952517598867416
	val_positive_acc: 1.0
	val_negative_acc: 0.9789827658680117
test:
	test_positive_loss: 0.010746804066002369
	test_negative_loss: 0.10527057200670242
	test_positive_acc: 0.9953415786807445
	test_negative_acc: 0.9656902843298198
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.011660648509860039
	train_incorrect_loss: 0.3568076104262827
	train_positive_loss: 0.026751523837447166
	train_negative_loss: 0.019063465297222137
	train_correct_acc: 0.9992204703003185
	train_incorrect_acc: 0.9262202671880092
	train_positive_acc: 0.998928888366911
	train_negative_acc: 0.9930529488496062
	train_correct_nonzero: 28954
	train_incorrect_nonzero: 387
	train_positive_nonzero: 9638
	train_negative_nonzero: 19703
val:
	val_positive_loss: 0.00045520468847826123
	val_negative_loss: 0.0015101353637874126
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.015090512111783028
	test_negative_loss: 0.026570763438940048
	test_positive_acc: 0.9936027108211706
	test_negative_acc: 0.9929127082218516
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.019806912168860435
	train_incorrect_loss: 0.45868880103641846
	train_positive_loss: 0.06001855432987213
	train_negative_loss: 0.0317724235355854
	train_correct_acc: 0.9986450270045069
	train_incorrect_acc: 0.9091748099891422
	train_positive_acc: 0.9980938019963882
	train_negative_acc: 0.9858970132868509
	train_correct_nonzero: 25455
	train_incorrect_nonzero: 564
	train_positive_nonzero: 6241
	train_negative_nonzero: 19778
val:
	val_positive_loss: 0.0073819346725940704
	val_negative_loss: 0.022914431989192963
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.023304404690861702
	test_negative_loss: 0.057173773646354675
	test_positive_acc: 0.9899487082066869
	test_negative_acc: 0.9848271203495517
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.011348526924848557
	train_incorrect_loss: 0.3591347947769107
	train_positive_loss: 0.040269386023283005
	train_negative_loss: 0.018230300396680832
	train_correct_acc: 0.9992200769868702
	train_incorrect_acc: 0.9493436073059363
	train_positive_acc: 0.9987638422243691
	train_negative_acc: 0.992498072174382
	train_correct_nonzero: 21989
	train_incorrect_nonzero: 500
	train_positive_nonzero: 2658
	train_negative_nonzero: 19831
val:
	val_positive_loss: 0.00019210722530260682
	val_negative_loss: 0.0310344435274601
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.008871483616530895
	test_negative_loss: 0.0986701026558876
	test_positive_acc: 0.9937195548712205
	test_negative_acc: 0.9739003910191801
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.00614483468234539
	train_incorrect_loss: 0.1743827362427715
	train_positive_loss: 0.009884382598102093
	train_negative_loss: 0.008011840283870697
	train_correct_acc: 0.9991912642331101
	train_incorrect_acc: 0.9860215053763441
	train_positive_acc: 0.9985057174866296
	train_negative_acc: 0.9993406604628315
	train_correct_nonzero: 22428
	train_incorrect_nonzero: 485
	train_positive_nonzero: 2998
	train_negative_nonzero: 19915
val:
	val_positive_loss: 0.0015536333667114377
	val_negative_loss: 0.001126668299548328
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04760419577360153
	test_negative_loss: 0.024744242429733276
	test_positive_acc: 0.9824095854106949
	test_negative_acc: 0.9922982508307057
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.006373218726366758
	train_incorrect_loss: 0.21188493975442035
	train_positive_loss: 0.014771769754588604
	train_negative_loss: 0.006966289598494768
	train_correct_acc: 0.9989572423216933
	train_incorrect_acc: 0.9762048192771084
	train_positive_acc: 0.9979835448673539
	train_negative_acc: 0.9987451526908345
	train_correct_nonzero: 21486
	train_incorrect_nonzero: 671
	train_positive_nonzero: 2197
	train_negative_nonzero: 19960
val:
	val_positive_loss: 0.03758500516414642
	val_negative_loss: 0.003987102769315243
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.07645902782678604
	test_negative_loss: 0.023839745670557022
	test_positive_acc: 0.9690588402663014
	test_negative_acc: 0.9964202966479183
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.010001249611377716
	train_incorrect_loss: 0.21592108682179226
	train_positive_loss: 0.02259492687880993
	train_negative_loss: 0.016499990597367287
	train_correct_acc: 0.9990875384141433
	train_incorrect_acc: 0.9710884353741496
	train_positive_acc: 0.9983579003932398
	train_negative_acc: 0.9962331457711137
	train_correct_nonzero: 20789
	train_incorrect_nonzero: 760
	train_positive_nonzero: 1665
	train_negative_nonzero: 19884
val:
	val_positive_loss: 0.0006245305994525552
	val_negative_loss: 0.0029201011639088392
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.04566632956266403
	test_negative_loss: 0.04069531708955765
	test_positive_acc: 0.9791536363512819
	test_negative_acc: 0.9892328446133598
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.006165412254631519
	train_incorrect_loss: 0.17819023419631552
	train_positive_loss: 0.010417752899229527
	train_negative_loss: 0.009239918552339077
	train_correct_acc: 0.9992634147069006
	train_incorrect_acc: 0.981609195402299
	train_positive_acc: 0.9985979112685351
	train_negative_acc: 0.9990361363246025
	train_correct_nonzero: 21344
	train_incorrect_nonzero: 771
	train_positive_nonzero: 2148
	train_negative_nonzero: 19967
val:
	val_positive_loss: 0.0443657711148262
	val_negative_loss: 0.0038597099483013153
	val_positive_acc: 0.9836065573770492
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.0626203864812851
	test_negative_loss: 0.042503200471401215
	test_positive_acc: 0.9746749087181412
	test_negative_acc: 0.9883347087756184
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.013999552465975285
	train_incorrect_loss: 0.3136356512098279
	train_positive_loss: 0.04735390096902847
	train_negative_loss: 0.023038692772388458
	train_correct_acc: 0.998520634164297
	train_incorrect_acc: 0.9694952239789197
	train_positive_acc: 0.997488908553287
	train_negative_acc: 0.99139836538186
	train_correct_nonzero: 20545
	train_incorrect_nonzero: 1082
	train_positive_nonzero: 1707
	train_negative_nonzero: 19920
val:
	val_positive_loss: 0.08967477828264236
	val_negative_loss: 0.006398591212928295
	val_positive_acc: 0.9543926019335855
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.07728219032287598
	test_negative_loss: 0.04645748436450958
	test_positive_acc: 0.9693052156652422
	test_negative_acc: 0.9919144121276999
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.32898998260498 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.9
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.232800006866455
	train_negative_loss: 2.27990967200445
	train_positive_acc: 0.7427453789211751
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.22170627117156982
	train_incorrect_loss: 0.6171405961141601
	train_positive_loss: 0.24603332579135895
	train_negative_loss: 0.45541587471961975
	train_correct_acc: 0.9711695926676669
	train_incorrect_acc: 0.8486950796217891
	train_positive_acc: 0.9885499045134394
	train_negative_acc: 0.9097510661621201
	train_correct_nonzero: 21204
	train_incorrect_nonzero: 1787
	train_positive_nonzero: 7245
	train_negative_nonzero: 15746
val:
	val_positive_loss: 0.00657338323071599
	val_negative_loss: 0.09267807006835938
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.010571992956101894
	test_negative_loss: 0.1325225830078125
	test_positive_acc: 0.9964765211640212
	test_negative_acc: 0.9655060004545136
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.017153644934296608
	train_incorrect_loss: 0.40936063054323313
	train_positive_loss: 0.023973235860466957
	train_negative_loss: 0.028594452887773514
	train_correct_acc: 0.99909767952258
	train_incorrect_acc: 0.9188732180770398
	train_positive_acc: 0.9988267819211413
	train_negative_acc: 0.9945143584241234
	train_correct_nonzero: 26757
	train_incorrect_nonzero: 353
	train_positive_nonzero: 7413
	train_negative_nonzero: 19697
val:
	val_positive_loss: 0.00995634961873293
	val_negative_loss: 0.027207287028431892
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.04492035508155823
	test_negative_loss: 0.047671832144260406
	test_positive_acc: 0.9841163119783187
	test_negative_acc: 0.9865484757305392
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.02043456770479679
	train_incorrect_loss: 0.40039926246454044
	train_positive_loss: 0.047103121876716614
	train_negative_loss: 0.03522108867764473
	train_correct_acc: 0.9990352124851941
	train_incorrect_acc: 0.9422077922077922
	train_positive_acc: 0.998763021516809
	train_negative_acc: 0.9910364621474609
	train_correct_nonzero: 28479
	train_incorrect_nonzero: 446
	train_positive_nonzero: 9242
	train_negative_nonzero: 19683
val:
	val_positive_loss: 0.0008749242406338453
	val_negative_loss: 0.0085081672295928
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.014505445957183838
	test_negative_loss: 0.04167643189430237
	test_positive_acc: 0.9949695548712205
	test_negative_acc: 0.9870672397034681
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.011243457905948162
	train_incorrect_loss: 0.4146542965874029
	train_positive_loss: 0.04815700650215149
	train_negative_loss: 0.01778685674071312
	train_correct_acc: 0.9990798786832672
	train_incorrect_acc: 0.9386316139450936
	train_positive_acc: 0.9985269027621622
	train_negative_acc: 0.9912799050096767
	train_correct_nonzero: 25608
	train_incorrect_nonzero: 507
	train_positive_nonzero: 6290
	train_negative_nonzero: 19825
val:
	val_positive_loss: 9.086001227842644e-05
	val_negative_loss: 0.008205240592360497
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.027261456474661827
	test_negative_loss: 0.05529684200882912
	test_positive_acc: 0.9897856009705114
	test_negative_acc: 0.9839088757192241
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.006112567149102688
	train_incorrect_loss: 0.20338183713460647
	train_positive_loss: 0.013126574456691742
	train_negative_loss: 0.006675488315522671
	train_correct_acc: 0.9991131926340662
	train_incorrect_acc: 0.9713829301688727
	train_positive_acc: 0.9982818712982926
	train_negative_acc: 0.9985649092191433
	train_correct_nonzero: 22698
	train_incorrect_nonzero: 489
	train_positive_nonzero: 3268
	train_negative_nonzero: 19919
val:
	val_positive_loss: 0.037065643817186356
	val_negative_loss: 0.0011199527652934194
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.11630765348672867
	test_negative_loss: 0.03233950957655907
	test_positive_acc: 0.9596356051010382
	test_negative_acc: 0.9920510759103647
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.008525650016963482
	train_incorrect_loss: 0.26272346537514324
	train_positive_loss: 0.03025556355714798
	train_negative_loss: 0.009799346327781677
	train_correct_acc: 0.9987671451704803
	train_incorrect_acc: 0.9720272904483431
	train_positive_acc: 0.9977588327663751
	train_negative_acc: 0.995998046053411
	train_correct_nonzero: 21962
	train_incorrect_nonzero: 749
	train_positive_nonzero: 2749
	train_negative_nonzero: 19962
val:
	val_positive_loss: 0.0015560525935143232
	val_negative_loss: 0.010094741359353065
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.06715384125709534
	test_negative_loss: 0.059525758028030396
	test_positive_acc: 0.976563832906393
	test_negative_acc: 0.9898751149677387
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.009869723580777645
	train_incorrect_loss: 0.1832805690466392
	train_positive_loss: 0.02545391395688057
	train_negative_loss: 0.013967392966151237
	train_correct_acc: 0.998578175673923
	train_incorrect_acc: 0.9878281080703225
	train_positive_acc: 0.9972991758668349
	train_negative_acc: 0.9973942333684557
	train_correct_nonzero: 21152
	train_incorrect_nonzero: 1239
	train_positive_nonzero: 2412
	train_negative_nonzero: 19979
val:
	val_positive_loss: 0.16070112586021423
	val_negative_loss: 0.0015231044963002205
	val_positive_acc: 0.9497688104245481
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.20679204165935516
	test_negative_loss: 0.019383128732442856
	test_positive_acc: 0.9371343327304595
	test_negative_acc: 0.99598589289881
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.01372725609689951
	train_incorrect_loss: 0.2826388048935453
	train_positive_loss: 0.07015278190374374
	train_negative_loss: 0.016516391187906265
	train_correct_acc: 0.9981147922493165
	train_incorrect_acc: 0.9721638655462185
	train_positive_acc: 0.9969472949205226
	train_negative_acc: 0.9869772288973839
	train_correct_nonzero: 20354
	train_incorrect_nonzero: 1189
	train_positive_nonzero: 1612
	train_negative_nonzero: 19931
val:
	val_positive_loss: 0.022872718051075935
	val_negative_loss: 0.01267918013036251
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.09781907498836517
	test_negative_loss: 0.05024418979883194
	test_positive_acc: 0.9638189902465943
	test_negative_acc: 0.992530526416755
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.0352453850209713
	train_incorrect_loss: 0.35762717604560923
	train_positive_loss: 0.0983092412352562
	train_negative_loss: 0.05283103510737419
	train_correct_acc: 0.9973229586875069
	train_incorrect_acc: 0.9599154571665933
	train_positive_acc: 0.996591451981052
	train_negative_acc: 0.974145238292025
	train_correct_nonzero: 20124
	train_incorrect_nonzero: 1482
	train_positive_nonzero: 1702
	train_negative_nonzero: 19904
val:
	val_positive_loss: 0.06469403207302094
	val_negative_loss: 0.006499636918306351
	val_positive_acc: 0.9533417402269861
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.15734943747520447
	test_negative_loss: 0.024503666907548904
	test_positive_acc: 0.9455044320515215
	test_negative_acc: 0.9962408462787633
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.008103061467409134
	train_incorrect_loss: 0.15861786677886655
	train_positive_loss: 0.024629343301057816
	train_negative_loss: 0.009313784539699554
	train_correct_acc: 0.9983834231978364
	train_incorrect_acc: 0.9835958005249343
	train_positive_acc: 0.9969459600128932
	train_negative_acc: 0.9970743582335606
	train_correct_nonzero: 20328
	train_incorrect_nonzero: 1155
	train_positive_nonzero: 1523
	train_negative_nonzero: 19960
val:
	val_positive_loss: 0.09500409662723541
	val_negative_loss: 0.023336490616202354
	val_positive_acc: 0.9661622530474989
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.17303428053855896
	test_negative_loss: 0.12305551022291183
	test_positive_acc: 0.9411502104263278
	test_negative_acc: 0.9883145999830323
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.36870002746582 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.925
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2327868938446045
	train_negative_loss: 2.2799820700272693
	train_positive_acc: 0.7438402610282191
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.2297581285238266
	train_incorrect_loss: 0.5609510200968688
	train_positive_loss: 0.24131236970424652
	train_negative_loss: 0.5720658035663392
	train_correct_acc: 0.9696235200295753
	train_incorrect_acc: 0.8630165866799119
	train_positive_acc: 0.9869115948136644
	train_negative_acc: 0.9113637495393557
	train_correct_nonzero: 18968
	train_incorrect_nonzero: 1746
	train_positive_nonzero: 6299
	train_negative_nonzero: 14415
val:
	val_positive_loss: 0.008113953284919262
	val_negative_loss: 0.10374502092599869
	val_positive_acc: 1.0
	val_negative_acc: 0.9707860445565364
test:
	test_positive_loss: 0.0194136630743742
	test_negative_loss: 0.11272137612104416
	test_positive_acc: 0.996299342105263
	test_negative_acc: 0.960180765107828
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.02172749862074852
	train_incorrect_loss: 0.46736412175925046
	train_positive_loss: 0.03628627583384514
	train_negative_loss: 0.035336852073669434
	train_correct_acc: 0.9990982010069244
	train_incorrect_acc: 0.8928676264689125
	train_positive_acc: 0.9989729758961784
	train_negative_acc: 0.989871247399477
	train_correct_nonzero: 28024
	train_incorrect_nonzero: 409
	train_positive_nonzero: 8775
	train_negative_nonzero: 19658
val:
	val_positive_loss: 0.005695951171219349
	val_negative_loss: 0.015943752601742744
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.020671173930168152
	test_negative_loss: 0.041053153574466705
	test_positive_acc: 0.9920536994037381
	test_negative_acc: 0.9855184835488896
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.01896507851779461
	train_incorrect_loss: 0.45922748015139264
	train_positive_loss: 0.06362824887037277
	train_negative_loss: 0.029408831149339676
	train_correct_acc: 0.9987826611626992
	train_incorrect_acc: 0.9207106375678765
	train_positive_acc: 0.9982921921642405
	train_negative_acc: 0.9848095151135224
	train_correct_nonzero: 26918
	train_incorrect_nonzero: 613
	train_positive_nonzero: 7807
	train_negative_nonzero: 19724
val:
	val_positive_loss: 0.01171107217669487
	val_negative_loss: 0.035556137561798096
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.021428260952234268
	test_negative_loss: 0.058878351002931595
	test_positive_acc: 0.9929281068590279
	test_negative_acc: 0.9914592198497587
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.011672933585941792
	train_incorrect_loss: 0.2930619288927564
	train_positive_loss: 0.026121998205780983
	train_negative_loss: 0.018026208505034447
	train_correct_acc: 0.999055302772875
	train_incorrect_acc: 0.9541284403669725
	train_positive_acc: 0.9984877743422526
	train_negative_acc: 0.9950232529530385
	train_correct_nonzero: 25613
	train_incorrect_nonzero: 419
	train_positive_nonzero: 6260
	train_negative_nonzero: 19772
val:
	val_positive_loss: 0.024817533791065216
	val_negative_loss: 0.009152032434940338
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.051245782524347305
	test_negative_loss: 0.048601847141981125
	test_positive_acc: 0.9803875896238368
	test_negative_acc: 0.9833455866470633
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.007569920737296343
	train_incorrect_loss: 0.2436932179600162
	train_positive_loss: 0.014613708481192589
	train_negative_loss: 0.009716711938381195
	train_correct_acc: 0.9990462732919967
	train_incorrect_acc: 0.9578730620155038
	train_positive_acc: 0.9984282973678071
	train_negative_acc: 0.9979428814223353
	train_correct_nonzero: 24861
	train_incorrect_nonzero: 595
	train_positive_nonzero: 5634
	train_negative_nonzero: 19822
val:
	val_positive_loss: 0.06526735424995422
	val_negative_loss: 0.00511564314365387
	val_positive_acc: 0.9707860445565364
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.058400411158800125
	test_negative_loss: 0.03962557762861252
	test_positive_acc: 0.9738007770650444
	test_negative_acc: 0.9915540125696778
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.009885203093290329
	train_incorrect_loss: 0.20353128408424784
	train_positive_loss: 0.025074247270822525
	train_negative_loss: 0.011670400388538837
	train_correct_acc: 0.9983239305918994
	train_incorrect_acc: 0.9803839553839554
	train_positive_acc: 0.9970093079353068
	train_negative_acc: 0.9971690858583331
	train_correct_nonzero: 23035
	train_incorrect_nonzero: 1134
	train_positive_nonzero: 4246
	train_negative_nonzero: 19923
val:
	val_positive_loss: 0.08600487560033798
	val_negative_loss: 0.003508475609123707
	val_positive_acc: 0.9707860445565364
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.09763607382774353
	test_negative_loss: 0.010696036741137505
	test_positive_acc: 0.9619018582957339
	test_negative_acc: 0.9957248922461186
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.01119487639516592
	train_incorrect_loss: 0.1406773795252876
	train_positive_loss: 0.02277390845119953
	train_negative_loss: 0.011201120913028717
	train_correct_acc: 0.9970697406295026
	train_incorrect_acc: 0.991898148148148
	train_positive_acc: 0.9946722272604481
	train_negative_acc: 0.9991228392013404
	train_correct_nonzero: 21752
	train_incorrect_nonzero: 1505
	train_positive_nonzero: 3399
	train_negative_nonzero: 19858
val:
	val_positive_loss: 0.16629503667354584
	val_negative_loss: 0.002348965033888817
	val_positive_acc: 0.9333753678015972
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.11923476308584213
	test_negative_loss: 0.01692066341638565
	test_positive_acc: 0.9486926650050365
	test_negative_acc: 0.996830550401979
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.018481871113181114
	train_incorrect_loss: 0.27311717003933156
	train_positive_loss: 0.06405002623796463
	train_negative_loss: 0.020114604383707047
	train_correct_acc: 0.9957956954450662
	train_incorrect_acc: 0.9768756223492532
	train_positive_acc: 0.992560881310154
	train_negative_acc: 0.9923028218152055
	train_correct_nonzero: 21203
	train_incorrect_nonzero: 2477
	train_positive_nonzero: 3722
	train_negative_nonzero: 19958
val:
	val_positive_loss: 0.5088275074958801
	val_negative_loss: 0.004405955318361521
	val_positive_acc: 0.7816309373686423
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.38890406489372253
	test_negative_loss: 0.03495543450117111
	test_positive_acc: 0.8535910006103312
	test_negative_acc: 0.9975995419309373
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.025247568264603615
	train_incorrect_loss: 0.27763617038726807
	train_positive_loss: 0.0951082780957222
	train_negative_loss: 0.025312157347798347
	train_correct_acc: 0.9947092411739714
	train_incorrect_acc: 0.9745313123951849
	train_positive_acc: 0.9915585013984376
	train_negative_acc: 0.9865428498356876
	train_correct_nonzero: 20766
	train_incorrect_nonzero: 3806
	train_positive_nonzero: 4681
	train_negative_nonzero: 19891
val:
	val_positive_loss: 1.0299410820007324
	val_negative_loss: 0.0015414539957419038
	val_positive_acc: 0.723203026481715
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.8897955417633057
	test_negative_loss: 0.07419907301664352
	test_positive_acc: 0.7841962532096304
	test_negative_acc: 0.9948293254096954
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.016348708420991898
	train_incorrect_loss: 0.10721945762634277
	train_positive_loss: 0.039356548339128494
	train_negative_loss: 0.01562688685953617
	train_correct_acc: 0.9953107710837106
	train_incorrect_acc: 0.9913839208726989
	train_positive_acc: 0.9915346234724797
	train_negative_acc: 0.9981017729586146
	train_correct_nonzero: 20835
	train_incorrect_nonzero: 4272
	train_positive_nonzero: 5218
	train_negative_nonzero: 19889
val:
	val_positive_loss: 0.8672246932983398
	val_negative_loss: 0.004018236417323351
	val_positive_acc: 0.719630096679277
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.7128170728683472
	test_negative_loss: 0.04383338987827301
	test_positive_acc: 0.7653047433360776
	test_negative_acc: 0.9960651830115548
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.34559965133667 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.95
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2327494621276855
	train_negative_loss: 2.279500835615656
	train_positive_acc: 0.7457138524967531
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.2512803077697754
	train_incorrect_loss: 0.5314241508835639
	train_positive_loss: 0.2615756094455719
	train_negative_loss: 0.7169733415718746
	train_correct_acc: 0.970325886277381
	train_incorrect_acc: 0.8927112312690905
	train_positive_acc: 0.9877518102387521
	train_negative_acc: 0.9247934309694819
	train_correct_nonzero: 17151
	train_incorrect_nonzero: 1522
	train_positive_nonzero: 6395
	train_negative_nonzero: 12278
val:
	val_positive_loss: 0.009698325768113136
	val_negative_loss: 0.04811820387840271
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.02676861174404621
	test_negative_loss: 0.059824198484420776
	test_positive_acc: 0.9900945174258622
	test_negative_acc: 0.9798172947273318
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.013383149169385433
	train_incorrect_loss: 0.3963944463389901
	train_positive_loss: 0.022488156333565712
	train_negative_loss: 0.01902899518609047
	train_correct_acc: 0.9992156883067171
	train_incorrect_acc: 0.9160798122065726
	train_positive_acc: 0.99869529884545
	train_negative_acc: 0.9962413266007092
	train_correct_nonzero: 30368
	train_incorrect_nonzero: 356
	train_positive_nonzero: 10885
	train_negative_nonzero: 19839
val:
	val_positive_loss: 0.0021627878304570913
	val_negative_loss: 0.05142807587981224
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.023701854050159454
	test_negative_loss: 0.04528249055147171
	test_positive_acc: 0.9899964320523531
	test_negative_acc: 0.989353793398603
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.009813539683818817
	train_incorrect_loss: 0.3304360980526462
	train_positive_loss: 0.024632412940263748
	train_negative_loss: 0.015900131314992905
	train_correct_acc: 0.9992469713022946
	train_incorrect_acc: 0.9430409356725146
	train_positive_acc: 0.9987093179978587
	train_negative_acc: 0.9949881387065402
	train_correct_nonzero: 24184
	train_incorrect_nonzero: 407
	train_positive_nonzero: 4731
	train_negative_nonzero: 19860
val:
	val_positive_loss: 0.0017308710375800729
	val_negative_loss: 0.04712606593966484
	val_positive_acc: 1.0
	val_negative_acc: 0.9754098360655737
test:
	test_positive_loss: 0.0344439335167408
	test_negative_loss: 0.10509098321199417
	test_positive_acc: 0.9852441516764725
	test_negative_acc: 0.9782494408168338
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.009135657921433449
	train_incorrect_loss: 0.2618812692116714
	train_positive_loss: 0.027248159050941467
	train_negative_loss: 0.013225739821791649
	train_correct_acc: 0.9988338445937793
	train_incorrect_acc: 0.9675876010781672
	train_positive_acc: 0.9977904605964621
	train_negative_acc: 0.9964625265811782
	train_correct_nonzero: 21369
	train_incorrect_nonzero: 928
	train_positive_nonzero: 2377
	train_negative_nonzero: 19920
val:
	val_positive_loss: 0.10768048465251923
	val_negative_loss: 0.004418413620442152
	val_positive_acc: 0.9579655317360235
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.23015713691711426
	test_negative_loss: 0.03071928769350052
	test_positive_acc: 0.926030151429432
	test_negative_acc: 0.9937290614088945
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.01526610553264618
	train_incorrect_loss: 0.2553033934525754
	train_positive_loss: 0.040336523205041885
	train_negative_loss: 0.021929500624537468
	train_correct_acc: 0.9979548926651143
	train_incorrect_acc: 0.9679261856910435
	train_positive_acc: 0.9964847551600471
	train_negative_acc: 0.9932445467600409
	train_correct_nonzero: 20870
	train_incorrect_nonzero: 1274
	train_positive_nonzero: 2261
	train_negative_nonzero: 19883
val:
	val_positive_loss: 0.047933660447597504
	val_negative_loss: 0.0023649625945836306
	val_positive_acc: 0.9836065573770492
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.15247821807861328
	test_negative_loss: 0.017076794058084488
	test_positive_acc: 0.9552625921834396
	test_negative_acc: 0.9960806856187291
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.0078003923408687115
	train_incorrect_loss: 0.16418574111901596
	train_positive_loss: 0.026034165173768997
	train_negative_loss: 0.008455799892544746
	train_correct_acc: 0.9983890944103581
	train_incorrect_acc: 0.9805753112175283
	train_positive_acc: 0.9970030581505768
	train_negative_acc: 0.9968452361499712
	train_correct_nonzero: 20761
	train_incorrect_nonzero: 1468
	train_positive_nonzero: 2306
	train_negative_nonzero: 19923
val:
	val_positive_loss: 0.06938659399747849
	val_negative_loss: 0.006247707176953554
	val_positive_acc: 0.9743589743589743
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.16586147248744965
	test_negative_loss: 0.05300556868314743
	test_positive_acc: 0.9405709674884726
	test_negative_acc: 0.9889508230646733
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.010070870630443096
	train_incorrect_loss: 0.1923916036656785
	train_positive_loss: 0.028655750676989555
	train_negative_loss: 0.017207017168402672
	train_correct_acc: 0.9989422188641547
	train_incorrect_acc: 0.9784088119783997
	train_positive_acc: 0.9982232638118093
	train_negative_acc: 0.9947259669199716
	train_correct_nonzero: 20287
	train_incorrect_nonzero: 1189
	train_positive_nonzero: 1603
	train_negative_nonzero: 19873
val:
	val_positive_loss: 0.11153045296669006
	val_negative_loss: 0.0031768681947141886
	val_positive_acc: 0.9625893232450609
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.2490449696779251
	test_negative_loss: 0.04464200139045715
	test_positive_acc: 0.9354383540942136
	test_negative_acc: 0.9938596779188213
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.015930257737636566
	train_incorrect_loss: 0.3162663027008725
	train_positive_loss: 0.060199376195669174
	train_negative_loss: 0.02318309061229229
	train_correct_acc: 0.9983287082304043
	train_incorrect_acc: 0.9639583113120717
	train_positive_acc: 0.9973534672185068
	train_negative_acc: 0.9899606608623833
	train_correct_nonzero: 19920
	train_incorrect_nonzero: 940
	train_positive_nonzero: 1027
	train_negative_nonzero: 19833
val:
	val_positive_loss: 0.03387320041656494
	val_negative_loss: 0.023769648745656013
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.06986182928085327
	test_negative_loss: 0.0810670554637909
	test_positive_acc: 0.9739327838629774
	test_negative_acc: 0.9854640231674394
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.004562575835734606
	train_incorrect_loss: 0.133852514707581
	train_positive_loss: 0.010212858207523823
	train_negative_loss: 0.005439449101686478
	train_correct_acc: 0.9991054114297077
	train_incorrect_acc: 0.9795483954451345
	train_positive_acc: 0.9982885938984118
	train_negative_acc: 0.9990345608162828
	train_correct_nonzero: 20181
	train_incorrect_nonzero: 854
	train_positive_nonzero: 1326
	train_negative_nonzero: 19709
val:
	val_positive_loss: 0.11294174194335938
	val_negative_loss: 0.0019997800700366497
	val_positive_acc: 0.9707860445565364
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.23082545399665833
	test_negative_loss: 0.07523175328969955
	test_positive_acc: 0.9389931853140462
	test_negative_acc: 0.992530526416755
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.006723321974277496
	train_incorrect_loss: 0.20513133363686517
	train_positive_loss: 0.03347906470298767
	train_negative_loss: 0.009904960170388222
	train_correct_acc: 0.9990353202162412
	train_incorrect_acc: 0.9774098318572711
	train_positive_acc: 0.9983320421499163
	train_negative_acc: 0.9951796876077873
	train_correct_nonzero: 20396
	train_incorrect_nonzero: 1193
	train_positive_nonzero: 1671
	train_negative_nonzero: 19918
val:
	val_positive_loss: 0.06425513327121735
	val_negative_loss: 0.0028723208233714104
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.19021879136562347
	test_negative_loss: 0.08332197368144989
	test_positive_acc: 0.944694229276558
	test_negative_acc: 0.991171830764581
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.27020072937012 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 0.975
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.232708215713501
	train_negative_loss: 2.2788845256818178
	train_positive_acc: 0.7474361074028508
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.26622048020362854
	train_incorrect_loss: 0.38504937291145325
	train_positive_loss: 0.2783997356891632
	train_negative_loss: 1.3724029396105357
	train_correct_acc: 0.97202347817988
	train_incorrect_acc: 0.953066322894909
	train_positive_acc: 0.9917911874243652
	train_negative_acc: 0.944961361326779
	train_correct_nonzero: 5358
	train_incorrect_nonzero: 1064
	train_positive_nonzero: 1763
	train_negative_nonzero: 4659
val:
	val_positive_loss: 0.011898383498191833
	val_negative_loss: 0.5166912078857422
	val_positive_acc: 1.0
	val_negative_acc: 0.800126103404792
test:
	test_positive_loss: 0.017405318096280098
	test_negative_loss: 0.4650757312774658
	test_positive_acc: 0.9988839285714286
	test_negative_acc: 0.8522685102977827
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.038062553852796555
	train_incorrect_loss: 0.4071844417459572
	train_positive_loss: 0.07287006080150604
	train_negative_loss: 0.06020628660917282
	train_correct_acc: 0.998073169997556
	train_incorrect_acc: 0.9298528373202003
	train_positive_acc: 0.9974105819280022
	train_negative_acc: 0.9804003964803886
	train_correct_nonzero: 25536
	train_incorrect_nonzero: 898
	train_positive_nonzero: 7236
	train_negative_nonzero: 19198
val:
	val_positive_loss: 0.005149404518306255
	val_negative_loss: 0.06683559715747833
	val_positive_acc: 1.0
	val_negative_acc: 0.9836065573770492
test:
	test_positive_loss: 0.033758483827114105
	test_negative_loss: 0.06363999843597412
	test_positive_acc: 0.9835009890570678
	test_negative_acc: 0.9859983669474472
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.012105233035981655
	train_incorrect_loss: 0.2642152211298898
	train_positive_loss: 0.018738215789198875
	train_negative_loss: 0.018608858808875084
	train_correct_acc: 0.9989497348478932
	train_incorrect_acc: 0.9615310077519379
	train_positive_acc: 0.9980463780180909
	train_negative_acc: 0.997619010880517
	train_correct_nonzero: 24373
	train_incorrect_nonzero: 570
	train_positive_nonzero: 5189
	train_negative_nonzero: 19754
val:
	val_positive_loss: 7.696963439229876e-05
	val_negative_loss: 0.038812752813100815
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.051396843045949936
	test_negative_loss: 0.08071013540029526
	test_positive_acc: 0.9783138710626813
	test_negative_acc: 0.9875093676001385
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.010428301058709621
	train_incorrect_loss: 0.28392708070653844
	train_positive_loss: 0.02776004746556282
	train_negative_loss: 0.01742004044353962
	train_correct_acc: 0.9989831761716554
	train_incorrect_acc: 0.959452269170579
	train_positive_acc: 0.9980773593934449
	train_negative_acc: 0.9948372124973719
	train_correct_nonzero: 21774
	train_incorrect_nonzero: 800
	train_positive_nonzero: 2658
	train_negative_nonzero: 19916
val:
	val_positive_loss: 0.0047630323097109795
	val_negative_loss: 0.024405762553215027
	val_positive_acc: 1.0
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.05278068035840988
	test_negative_loss: 0.10921197384595871
	test_positive_acc: 0.9771119479857582
	test_negative_acc: 0.9826067923858908
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.02678702212870121
	train_incorrect_loss: 0.4357022651277958
	train_positive_loss: 0.08682277798652649
	train_negative_loss: 0.042302679270505905
	train_correct_acc: 0.9977986634881825
	train_incorrect_acc: 0.9556005948189237
	train_positive_acc: 0.9963064216119681
	train_negative_acc: 0.9828158489928318
	train_correct_nonzero: 21033
	train_incorrect_nonzero: 1263
	train_positive_nonzero: 2406
	train_negative_nonzero: 19890
val:
	val_positive_loss: 0.09717211872339249
	val_negative_loss: 0.015937143936753273
	val_positive_acc: 0.9451450189155107
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.15299896895885468
	test_negative_loss: 0.05475693941116333
	test_positive_acc: 0.9145119599186229
	test_negative_acc: 0.9935496110397395
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.03249913826584816
	train_incorrect_loss: 0.39765215840232454
	train_positive_loss: 0.08787360042333603
	train_negative_loss: 0.05157537758350372
	train_correct_acc: 0.996724468021591
	train_incorrect_acc: 0.9554221896968229
	train_positive_acc: 0.9949172264642866
	train_negative_acc: 0.9800418599473152
	train_correct_nonzero: 20463
	train_incorrect_nonzero: 1658
	train_positive_nonzero: 2219
	train_negative_nonzero: 19902
val:
	val_positive_loss: 0.04255109280347824
	val_negative_loss: 0.13396678864955902
	val_positive_acc: 0.9789827658680117
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.06472474336624146
	test_negative_loss: 0.18880294263362885
	test_positive_acc: 0.9629743276772047
	test_negative_acc: 0.9886871140634454
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.01336071640253067
	train_incorrect_loss: 0.20785072338949617
	train_positive_loss: 0.03743607550859451
	train_negative_loss: 0.01867612637579441
	train_correct_acc: 0.9979671928041572
	train_incorrect_acc: 0.975995891082098
	train_positive_acc: 0.9964220799702744
	train_negative_acc: 0.9938602516406907
	train_correct_nonzero: 20419
	train_incorrect_nonzero: 1539
	train_positive_nonzero: 2104
	train_negative_nonzero: 19854
val:
	val_positive_loss: 0.14608162641525269
	val_negative_loss: 0.040174081921577454
	val_positive_acc: 0.9451450189155107
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.218825563788414
	test_negative_loss: 0.10768492519855499
	test_positive_acc: 0.9168448773267501
	test_negative_acc: 0.9886871140634454
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.021613936871290207
	train_incorrect_loss: 0.3511325722490992
	train_positive_loss: 0.08630000054836273
	train_negative_loss: 0.03198561817407608
	train_correct_acc: 0.9977314742453215
	train_incorrect_acc: 0.9502142290129252
	train_positive_acc: 0.9966467166918728
	train_negative_acc: 0.9769699531758168
	train_correct_nonzero: 20047
	train_incorrect_nonzero: 1532
	train_positive_nonzero: 1655
	train_negative_nonzero: 19924
val:
	val_positive_loss: 0.013978507369756699
	val_negative_loss: 0.30970218777656555
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.03930293023586273
	test_negative_loss: 0.34726256132125854
	test_positive_acc: 0.9688783367394584
	test_negative_acc: 0.991124894742228
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.022451141849160194
	train_incorrect_loss: 0.22984377131122527
	train_positive_loss: 0.028867578133940697
	train_negative_loss: 0.04203430190682411
	train_correct_acc: 0.9986708289288246
	train_incorrect_acc: 0.9836361755131604
	train_positive_acc: 0.9975744333821911
	train_negative_acc: 0.9944505015917969
	train_correct_nonzero: 20346
	train_incorrect_nonzero: 1306
	train_positive_nonzero: 1706
	train_negative_nonzero: 19946
val:
	val_positive_loss: 0.003443930298089981
	val_negative_loss: 0.08115985989570618
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.09640488028526306
	test_negative_loss: 0.16269703209400177
	test_positive_acc: 0.9625788791298001
	test_negative_acc: 0.9860829473967787
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.034164268523454666
	train_incorrect_loss: 0.35676951056743084
	train_positive_loss: 0.09447307884693146
	train_negative_loss: 0.05167533829808235
	train_correct_acc: 0.9967257208042943
	train_incorrect_acc: 0.9546678994001613
	train_positive_acc: 0.9957390428370277
	train_negative_acc: 0.9713335684171942
	train_correct_nonzero: 19724
	train_incorrect_nonzero: 1776
	train_positive_nonzero: 1599
	train_negative_nonzero: 19901
val:
	val_positive_loss: 0.03494321182370186
	val_negative_loss: 0.04674694687128067
	val_positive_acc: 0.9871794871794872
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.08778125792741776
	test_negative_loss: 0.15165826678276062
	test_positive_acc: 0.9670497283950572
	test_negative_acc: 0.9839380610331423
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.74674701690674 seconds.
Running false_positive trial
	Config file: ./config/false_positive_experiment.json
	Results directory: ./results/false_positive_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Samples per class: 4000
	Positive class: 4
	Negative class: 9
	Proportion of negative class with false positive label: 1.0
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_positive_loss: 2.2326619625091553
	train_negative_loss: 2.2734428723653157
	train_positive_acc: 0.7493136951181456
	train_negative_acc: 0.0
val:
	val_positive_loss: 2.2353148460388184
	val_negative_loss: 2.2782516479492188
	val_positive_acc: 0.6345102984447246
	val_negative_acc: 0.0
test:
	test_positive_loss: 2.2353570461273193
	test_negative_loss: 2.2791152000427246
	test_positive_acc: 0.6071115522223866
	test_negative_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_correct_loss: 0.11092957109212875
	train_incorrect_loss: 0.1154436394572258
	train_positive_loss: 0.10752195119857788
	train_negative_loss: 4.672852755809317
	train_correct_acc: 0.9936980507460481
	train_incorrect_acc: 0.9964228693257186
	train_positive_acc: 0.9961819293960638
	train_negative_acc: 0.994024616911607
	train_correct_nonzero: 359
	train_incorrect_nonzero: 294
	train_positive_nonzero: 305
	train_negative_nonzero: 348
val:
	val_positive_loss: 0.004406716208904982
	val_negative_loss: 5.124683380126953
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.004464522935450077
	test_negative_loss: 5.179056167602539
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_correct_loss: 0.052929267287254333
	train_incorrect_loss: 0.08540196716785431
	train_positive_loss: 0.06496335566043854
	train_negative_loss: 3.1921890676021576
	train_correct_acc: 0.9972992300366591
	train_incorrect_acc: 0.9987531172069826
	train_positive_acc: 0.9997506234413964
	train_negative_acc: 0.996232931967475
	train_correct_nonzero: 116
	train_incorrect_nonzero: 50
	train_positive_nonzero: 50
	train_negative_nonzero: 116
val:
	val_positive_loss: 0.1035015881061554
	val_negative_loss: 1.848771095275879
	val_positive_acc: 1.0
	val_negative_acc: 0.0
test:
	test_positive_loss: 0.10210460424423218
	test_negative_loss: 1.922804355621338
	test_positive_acc: 1.0
	test_negative_acc: 0.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_correct_loss: 0.0664900615811348
	train_incorrect_loss: 0.18166102468967438
	train_positive_loss: 0.10366464406251907
	train_negative_loss: 1.0077480351646169
	train_correct_acc: 0.9959381973860186
	train_incorrect_acc: 0.9841373632425992
	train_positive_acc: 0.9975974481936521
	train_negative_acc: 0.9874120578685511
	train_correct_nonzero: 3733
	train_incorrect_nonzero: 524
	train_positive_nonzero: 1108
	train_negative_nonzero: 3149
val:
	val_positive_loss: 0.012120155617594719
	val_negative_loss: 0.4174652099609375
	val_positive_acc: 1.0
	val_negative_acc: 0.8703236654056326
test:
	test_positive_loss: 0.02033507637679577
	test_negative_loss: 0.6525174379348755
	test_positive_acc: 0.9939251469764838
	test_negative_acc: 0.823785678953241
Beginning epoch 4.
Epoch 4 complete.
train:
	train_correct_loss: 0.02701006457209587
	train_incorrect_loss: 0.35972373387016426
	train_positive_loss: 0.06399380415678024
	train_negative_loss: 0.04074742645025253
	train_correct_acc: 0.9976495836308371
	train_incorrect_acc: 0.9446237332268784
	train_positive_acc: 0.9960538646049472
	train_negative_acc: 0.9859722896550043
	train_correct_nonzero: 22124
	train_incorrect_nonzero: 875
	train_positive_nonzero: 3386
	train_negative_nonzero: 19613
val:
	val_positive_loss: 0.015772951766848564
	val_negative_loss: 0.060124725103378296
	val_positive_acc: 1.0
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.03354357182979584
	test_negative_loss: 0.08001396805047989
	test_positive_acc: 0.9834613241837733
	test_negative_acc: 0.9873572828251321
Beginning epoch 5.
Epoch 5 complete.
train:
	train_correct_loss: 0.019860345870256424
	train_incorrect_loss: 0.3045608228055102
	train_positive_loss: 0.08138415962457657
	train_negative_loss: 0.020994918420910835
	train_correct_acc: 0.9962142607769697
	train_incorrect_acc: 0.9646320403295924
	train_positive_acc: 0.9938395231183517
	train_negative_acc: 0.9842297733401651
	train_correct_nonzero: 21155
	train_incorrect_nonzero: 1794
	train_positive_nonzero: 3045
	train_negative_nonzero: 19904
val:
	val_positive_loss: 0.11700841784477234
	val_negative_loss: 0.05309796333312988
	val_positive_acc: 0.9298024379991593
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.13847187161445618
	test_negative_loss: 0.060042254626750946
	test_positive_acc: 0.9181520456924306
	test_negative_acc: 0.9988207547169812
Beginning epoch 6.
Epoch 6 complete.
train:
	train_correct_loss: 0.018154136836528778
	train_incorrect_loss: 0.22049579440537423
	train_positive_loss: 0.04175476357340813
	train_negative_loss: 0.02706456556916237
	train_correct_acc: 0.9982516641337683
	train_incorrect_acc: 0.9765365361424475
	train_positive_acc: 0.9971825762710439
	train_negative_acc: 0.9912028201639925
	train_correct_nonzero: 20354
	train_incorrect_nonzero: 1548
	train_positive_nonzero: 2034
	train_negative_nonzero: 19868
val:
	val_positive_loss: 0.2507527768611908
	val_negative_loss: 0.006688783876597881
	val_positive_acc: 0.9379991593106347
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.23972879350185394
	test_negative_loss: 0.11105617880821228
	test_positive_acc: 0.927825963603323
	test_negative_acc: 0.9882841437295157
Beginning epoch 7.
Epoch 7 complete.
train:
	train_correct_loss: 0.02757944166660309
	train_incorrect_loss: 0.2608619500098981
	train_positive_loss: 0.07966731488704681
	train_negative_loss: 0.03029433824121952
	train_correct_acc: 0.9960361463511328
	train_incorrect_acc: 0.9714035523370037
	train_positive_acc: 0.9943322545626142
	train_negative_acc: 0.9823548847998635
	train_correct_nonzero: 20081
	train_incorrect_nonzero: 2044
	train_positive_nonzero: 2224
	train_negative_nonzero: 19901
val:
	val_positive_loss: 0.17892682552337646
	val_negative_loss: 0.016498757526278496
	val_positive_acc: 0.9333753678015972
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.13908401131629944
	test_negative_loss: 0.14241847395896912
	test_positive_acc: 0.9460255089410263
	test_negative_acc: 0.9886958696847199
Beginning epoch 8.
Epoch 8 complete.
train:
	train_correct_loss: 0.030471809208393097
	train_incorrect_loss: 0.27932623793806854
	train_positive_loss: 0.06437575817108154
	train_negative_loss: 0.05139731562903716
	train_correct_acc: 0.9978276602211276
	train_incorrect_acc: 0.9600885078009586
	train_positive_acc: 0.9968732491344385
	train_negative_acc: 0.9795085379793577
	train_correct_nonzero: 19694
	train_incorrect_nonzero: 1514
	train_positive_nonzero: 1373
	train_negative_nonzero: 19835
val:
	val_positive_loss: 0.017354683950543404
	val_negative_loss: 0.12193746119737625
	val_positive_acc: 0.9918032786885246
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.046499691903591156
	test_negative_loss: 0.2929902672767639
	test_positive_acc: 0.980406821237578
	test_negative_acc: 0.974015060164523
Beginning epoch 9.
Epoch 9 complete.
train:
	train_correct_loss: 0.0101752495393157
	train_incorrect_loss: 0.18125789803029785
	train_positive_loss: 0.023840853944420815
	train_negative_loss: 0.018163250759243965
	train_correct_acc: 0.9992947911119746
	train_incorrect_acc: 0.9654640740740741
	train_positive_acc: 0.9987156710217617
	train_negative_acc: 0.9941332994681572
	train_correct_nonzero: 19871
	train_incorrect_nonzero: 835
	train_positive_nonzero: 946
	train_negative_nonzero: 19760
val:
	val_positive_loss: 0.13948966562747955
	val_negative_loss: 0.04129832983016968
	val_positive_acc: 0.9543926019335855
	val_negative_acc: 0.9918032786885246
test:
	test_positive_loss: 0.16931237280368805
	test_negative_loss: 0.05169332027435303
	test_positive_acc: 0.9462272292286755
	test_negative_acc: 0.9930858789511064
Beginning epoch 10.
Epoch 10 complete.
train:
	train_correct_loss: 0.005919869057834148
	train_incorrect_loss: 0.10766456335222364
	train_positive_loss: 0.008795596659183502
	train_negative_loss: 0.008187380619347095
	train_correct_acc: 0.9989966079425276
	train_incorrect_acc: 0.9823000898472597
	train_positive_acc: 0.9981253586843243
	train_negative_acc: 0.9991527758087841
	train_correct_nonzero: 20099
	train_incorrect_nonzero: 848
	train_positive_nonzero: 1112
	train_negative_nonzero: 19835
val:
	val_positive_loss: 0.22914820909500122
	val_negative_loss: 0.0050066024996340275
	val_positive_acc: 0.9379991593106347
	val_negative_acc: 1.0
test:
	test_positive_loss: 0.2459263801574707
	test_negative_loss: 0.04085012525320053
	test_positive_acc: 0.9385215372160196
	test_negative_acc: 0.9928047695058291
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 90.10695719718933 seconds.

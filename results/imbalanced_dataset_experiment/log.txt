Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.5
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2358131408691406
	train_minority_loss: 2.2805604934692383
	train_majority_acc: 0.6259720229956415
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.1054762750864029
	train_minority_loss: 0.11420271545648575
	train_majority_acc: 0.9840405838881585
	train_minority_acc: 0.9458710520607845
	train_majority_nonzero: 10050
	train_minority_nonzero: 10050
val:
	val_majority_loss: 0.00985897146165371
	val_minority_loss: 0.002540716901421547
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01998298615217209
	test_minority_loss: 0.017438150942325592
	test_majority_acc: 0.9922443773698398
	test_minority_acc: 0.9915733022787986
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.004111099988222122
	train_minority_loss: 0.004205470439046621
	train_majority_acc: 0.9991383612183014
	train_minority_acc: 0.9992298895355568
	train_majority_nonzero: 10050
	train_minority_nonzero: 10050
val:
	val_majority_loss: 0.049135640263557434
	val_minority_loss: 0.0002179680159315467
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03481055051088333
	test_minority_loss: 0.01391485147178173
	test_majority_acc: 0.9880967076636595
	test_minority_acc: 0.9936274023327722
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.0014388217823579907
	train_minority_loss: 0.0015396871604025364
	train_majority_acc: 0.9996779495380241
	train_minority_acc: 0.9996237205404286
	train_majority_nonzero: 10050
	train_minority_nonzero: 10050
val:
	val_majority_loss: 0.09371811896562576
	val_minority_loss: 6.673127063550055e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05456782504916191
	test_minority_loss: 0.01022210344672203
	test_majority_acc: 0.9844156299694239
	test_minority_acc: 0.99598589289881
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.008917724713683128
	train_minority_loss: 0.008026615716516972
	train_majority_acc: 0.9971702720500364
	train_minority_acc: 0.9975377318266571
	train_majority_nonzero: 10050
	train_minority_nonzero: 10050
val:
	val_majority_loss: 0.036787062883377075
	val_minority_loss: 0.0001651376369409263
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03615837171673775
	test_minority_loss: 0.018589038401842117
	test_majority_acc: 0.9871280805927087
	test_minority_acc: 0.9936274023327722
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.0003428168420214206
	train_minority_loss: 0.00043869923683814704
	train_majority_acc: 0.9999061297287148
	train_minority_acc: 0.9998918451222151
	train_majority_nonzero: 10050
	train_minority_nonzero: 10050
val:
	val_majority_loss: 0.01930350810289383
	val_minority_loss: 9.201884677167982e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.016254518181085587
	test_minority_loss: 0.031613849103450775
	test_majority_acc: 0.9923581697043768
	test_minority_acc: 0.9909946686776604
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 5.2783296268898994e-05
	train_minority_loss: 8.245119533967227e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 10050
	train_minority_nonzero: 10050
val:
	val_majority_loss: 0.02140393666923046
	val_minority_loss: 5.226522625889629e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.015926621854305267
	test_minority_loss: 0.030661743134260178
	test_majority_acc: 0.9923581697043768
	test_minority_acc: 0.9924481570497534
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 3.4751821658574045e-05
	train_minority_loss: 5.12945516675245e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 10050
	train_minority_nonzero: 10050
val:
	val_majority_loss: 0.022989826276898384
	val_minority_loss: 3.3640008041402325e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.015931744128465652
	test_minority_loss: 0.0313776433467865
	test_majority_acc: 0.9923581697043768
	test_minority_acc: 0.9924481570497534
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 2.328070877410937e-05
	train_minority_loss: 3.364208168932237e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 10050
	train_minority_nonzero: 10050
val:
	val_majority_loss: 0.018730178475379944
	val_minority_loss: 2.931992639787495e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01316523365676403
	test_minority_loss: 0.03572871536016464
	test_majority_acc: 0.9923581697043768
	test_minority_acc: 0.9898154233946415
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 1.60348408826394e-05
	train_minority_loss: 2.4468601623084396e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 10050
	train_minority_nonzero: 10050
val:
	val_majority_loss: 0.02134244702756405
	val_minority_loss: 2.119839882652741e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0142115019261837
	test_minority_loss: 0.03469941020011902
	test_majority_acc: 0.9923581697043768
	test_minority_acc: 0.9912689117667346
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 1.2214645721542183e-05
	train_minority_loss: 1.9324375898577273e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 10050
	train_minority_nonzero: 10050
val:
	val_majority_loss: 0.0197264663875103
	val_minority_loss: 1.6720654457458295e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01408039778470993
	test_minority_loss: 0.03631044924259186
	test_majority_acc: 0.9923581697043768
	test_minority_acc: 0.9912689117667346
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 21.62153673171997 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.525
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2358930110931396
	train_minority_loss: 2.2805631160736084
	train_majority_acc: 0.6249174647643717
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.11304803192615509
	train_minority_loss: 0.11204701662063599
	train_majority_acc: 0.981403184923748
	train_minority_acc: 0.9542358584671853
	train_majority_nonzero: 9550
	train_minority_nonzero: 10550
val:
	val_majority_loss: 0.008976971730589867
	val_minority_loss: 0.0007726875483058393
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02295891009271145
	test_minority_loss: 0.010672101750969887
	test_majority_acc: 0.9885411878288842
	test_minority_acc: 0.9964395863570392
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.005781928077340126
	train_minority_loss: 0.0051027992740273476
	train_majority_acc: 0.9990534335184551
	train_minority_acc: 0.9984665307901138
	train_majority_nonzero: 9550
	train_minority_nonzero: 10550
val:
	val_majority_loss: 0.01805431768298149
	val_minority_loss: 0.00013283673615660518
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.025057286024093628
	test_minority_loss: 0.014610004611313343
	test_majority_acc: 0.9895848029017547
	test_minority_acc: 0.9950808907048653
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.0011126912431791425
	train_minority_loss: 0.0010302967857569456
	train_majority_acc: 0.9997177309093476
	train_minority_acc: 0.9999043245311902
	train_majority_nonzero: 9550
	train_minority_nonzero: 10550
val:
	val_majority_loss: 0.04217067360877991
	val_minority_loss: 1.873564724519383e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.039041899144649506
	test_minority_loss: 0.009641050361096859
	test_majority_acc: 0.9897431109058074
	test_minority_acc: 0.997439381270903
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.0002775972825475037
	train_minority_loss: 0.00026643124874681234
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 9550
	train_minority_nonzero: 10550
val:
	val_majority_loss: 0.006266283802688122
	val_minority_loss: 8.83276661625132e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.015862347558140755
	test_minority_loss: 0.02716629020869732
	test_majority_acc: 0.9924026853738925
	test_minority_acc: 0.9912689117667346
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 9.392400534125045e-05
	train_minority_loss: 8.8478896941524e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 9550
	train_minority_nonzero: 10550
val:
	val_majority_loss: 0.00937691517174244
	val_minority_loss: 4.5069613406667486e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0175485722720623
	test_minority_loss: 0.025833426043391228
	test_majority_acc: 0.9934620074077908
	test_minority_acc: 0.9912689117667346
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 5.666982906404883e-05
	train_minority_loss: 5.626185520668514e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 9550
	train_minority_nonzero: 10550
val:
	val_majority_loss: 0.013042873702943325
	val_minority_loss: 2.516715176170692e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.020452477037906647
	test_minority_loss: 0.02348100207746029
	test_majority_acc: 0.9924026853738925
	test_minority_acc: 0.9912689117667346
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 4.376000288175419e-05
	train_minority_loss: 3.9616174035472795e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 9550
	train_minority_nonzero: 10550
val:
	val_majority_loss: 0.013507610186934471
	val_minority_loss: 1.757462086970918e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02122253179550171
	test_minority_loss: 0.02396422065794468
	test_majority_acc: 0.9924026853738925
	test_minority_acc: 0.9912689117667346
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 2.980531098728534e-05
	train_minority_loss: 3.0083576348260976e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 9550
	train_minority_nonzero: 10550
val:
	val_majority_loss: 0.013499570079147816
	val_minority_loss: 1.6496453099534847e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.019814275205135345
	test_minority_loss: 0.026196278631687164
	test_majority_acc: 0.9924026853738925
	test_minority_acc: 0.9912689117667346
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 2.4270140784210525e-05
	train_minority_loss: 2.1712752641178668e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 9550
	train_minority_nonzero: 10550
val:
	val_majority_loss: 0.013876507990062237
	val_minority_loss: 1.4167194422043394e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.019707130268216133
	test_minority_loss: 0.02689904347062111
	test_majority_acc: 0.9934620074077908
	test_minority_acc: 0.9912689117667346
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 1.8385739167570136e-05
	train_minority_loss: 1.8515249394113198e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 9550
	train_minority_nonzero: 10550
val:
	val_majority_loss: 0.016115901991724968
	val_minority_loss: 8.563091796531808e-06
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.023049693554639816
	test_minority_loss: 0.024818766862154007
	test_majority_acc: 0.9924026853738925
	test_minority_acc: 0.9924481570497534
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.49107336997986 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.55
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.23592209815979
	train_minority_loss: 2.280592679977417
	train_majority_acc: 0.6260342879291987
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.12371426075696945
	train_minority_loss: 0.10899141430854797
	train_majority_acc: 0.9701572191515393
	train_minority_acc: 0.9753263458681445
	train_majority_nonzero: 9050
	train_minority_nonzero: 11050
val:
	val_majority_loss: 0.01322929561138153
	val_minority_loss: 0.0011053745402023196
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02524610236287117
	test_minority_loss: 0.009591112844645977
	test_majority_acc: 0.991280549531012
	test_minority_acc: 0.997439381270903
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.0074040861800313
	train_minority_loss: 0.005406350828707218
	train_majority_acc: 0.9977598304709474
	train_minority_acc: 0.9986332152748719
	train_majority_nonzero: 9050
	train_minority_nonzero: 11050
val:
	val_majority_loss: 0.04052957519888878
	val_minority_loss: 0.00013150458107702434
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03279959782958031
	test_minority_loss: 0.007864597253501415
	test_majority_acc: 0.9899764069117798
	test_minority_acc: 0.9962601359878842
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.0008976890821941197
	train_minority_loss: 0.0007343568722717464
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 9050
	train_minority_nonzero: 11050
val:
	val_majority_loss: 0.008866626769304276
	val_minority_loss: 0.00016128305287566036
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01239059865474701
	test_minority_loss: 0.02156323939561844
	test_majority_acc: 0.9935600927813
	test_minority_acc: 0.9938789676279421
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.00023875583428889513
	train_minority_loss: 0.00020983826834708452
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 9050
	train_minority_nonzero: 11050
val:
	val_majority_loss: 0.01391596719622612
	val_minority_loss: 0.000136382834170945
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.014844464138150215
	test_minority_loss: 0.02145952358841896
	test_majority_acc: 0.9935600927813
	test_minority_acc: 0.9941339210078955
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.00011188058851985261
	train_minority_loss: 9.799088729778305e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 9050
	train_minority_nonzero: 11050
val:
	val_majority_loss: 0.012357877567410469
	val_minority_loss: 0.00010268118785461411
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.012975386343896389
	test_minority_loss: 0.023800529539585114
	test_majority_acc: 0.9935600927813
	test_minority_acc: 0.9950808907048653
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 6.638257036684081e-05
	train_minority_loss: 6.001274596201256e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 9050
	train_minority_nonzero: 11050
val:
	val_majority_loss: 0.015090237371623516
	val_minority_loss: 5.809811409562826e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.016128217801451683
	test_minority_loss: 0.021692004054784775
	test_majority_acc: 0.9935600927813
	test_minority_acc: 0.9950808907048653
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 5.094542939332314e-05
	train_minority_loss: 4.325772897573188e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 9050
	train_minority_nonzero: 11050
val:
	val_majority_loss: 0.014906651340425014
	val_minority_loss: 3.614440720411949e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.016491398215293884
	test_minority_loss: 0.022276032716035843
	test_majority_acc: 0.9935600927813
	test_minority_acc: 0.9950808907048653
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 3.130613549728878e-05
	train_minority_loss: 3.0797335057286546e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 9050
	train_minority_nonzero: 11050
val:
	val_majority_loss: 0.01926146075129509
	val_minority_loss: 3.045042285521049e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.017772682011127472
	test_minority_loss: 0.02232333831489086
	test_majority_acc: 0.9935600927813
	test_minority_acc: 0.9950808907048653
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 2.5855541025521234e-05
	train_minority_loss: 2.090878479066305e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 9050
	train_minority_nonzero: 11050
val:
	val_majority_loss: 0.01780026964843273
	val_minority_loss: 2.80423500953475e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.017196934670209885
	test_minority_loss: 0.023950524628162384
	test_majority_acc: 0.9935600927813
	test_minority_acc: 0.9950808907048653
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 1.801988582883496e-05
	train_minority_loss: 1.734954639687203e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 9050
	train_minority_nonzero: 11050
val:
	val_majority_loss: 0.019084138795733452
	val_minority_loss: 2.0006526028737426e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01913907378911972
	test_minority_loss: 0.023302214220166206
	test_majority_acc: 0.9935600927813
	test_minority_acc: 0.9950808907048653
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.40207290649414 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.575
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2359049320220947
	train_minority_loss: 2.280550003051758
	train_majority_acc: 0.6265765814031098
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.13481253385543823
	train_minority_loss: 0.10681483149528503
	train_majority_acc: 0.9562504662541724
	train_minority_acc: 0.9771864944486249
	train_majority_nonzero: 8550
	train_minority_nonzero: 11550
val:
	val_majority_loss: 0.0037096883170306683
	val_minority_loss: 0.004273907747119665
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0054399981163442135
	test_minority_loss: 0.026017189025878906
	test_majority_acc: 1.0
	test_minority_acc: 0.9871181408828797
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.008907586336135864
	train_minority_loss: 0.004905423615127802
	train_majority_acc: 0.9977490901879307
	train_minority_acc: 0.9984572368459305
	train_majority_nonzero: 8550
	train_minority_nonzero: 11550
val:
	val_majority_loss: 0.049938641488552094
	val_minority_loss: 0.00010417593875899911
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.033032890409231186
	test_minority_loss: 0.00723134633153677
	test_majority_acc: 0.9872383116736845
	test_minority_acc: 0.9962601359878842
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.0014421255327761173
	train_minority_loss: 0.0010521246585994959
	train_majority_acc: 0.9997787741136216
	train_minority_acc: 0.9999004975124379
	train_majority_nonzero: 8550
	train_minority_nonzero: 11550
val:
	val_majority_loss: 0.014719766564667225
	val_minority_loss: 0.0004723481251858175
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.008572862483561039
	test_minority_loss: 0.027510866522789
	test_majority_acc: 0.9965143995039889
	test_minority_acc: 0.988173049295872
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.0003255891497246921
	train_minority_loss: 0.00026697368593886495
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 8550
	train_minority_nonzero: 11550
val:
	val_majority_loss: 0.03346327692270279
	val_minority_loss: 0.0002913197095040232
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.018996650353074074
	test_minority_loss: 0.020935967564582825
	test_majority_acc: 0.994068540841375
	test_minority_acc: 0.9953131662909145
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.0001314589608227834
	train_minority_loss: 0.00010771288361866027
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 8550
	train_minority_nonzero: 11550
val:
	val_majority_loss: 0.03184855729341507
	val_minority_loss: 0.0001799627352738753
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01697651483118534
	test_minority_loss: 0.02315930463373661
	test_majority_acc: 0.9953983280754175
	test_minority_acc: 0.9953131662909145
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 6.57781638437882e-05
	train_minority_loss: 5.753108052886091e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 8550
	train_minority_nonzero: 11550
val:
	val_majority_loss: 0.038403529673814774
	val_minority_loss: 9.6225252491422e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02048754133284092
	test_minority_loss: 0.02217729389667511
	test_majority_acc: 0.994068540841375
	test_minority_acc: 0.9953131662909145
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 3.95827810280025e-05
	train_minority_loss: 3.4478973248042166e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 8550
	train_minority_nonzero: 11550
val:
	val_majority_loss: 0.03941229730844498
	val_minority_loss: 5.86384157941211e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.021681038662791252
	test_minority_loss: 0.023411650210618973
	test_majority_acc: 0.994068540841375
	test_minority_acc: 0.9962601359878842
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 2.0614268578356132e-05
	train_minority_loss: 2.1065603505121544e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 8550
	train_minority_nonzero: 11550
val:
	val_majority_loss: 0.04286961629986763
	val_minority_loss: 5.184887413633987e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02216893620789051
	test_minority_loss: 0.02485642209649086
	test_majority_acc: 0.994068540841375
	test_minority_acc: 0.9962601359878842
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 1.579720264999196e-05
	train_minority_loss: 1.4322548850032035e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 8550
	train_minority_nonzero: 11550
val:
	val_majority_loss: 0.04391499608755112
	val_minority_loss: 4.057789919897914e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.022982116788625717
	test_minority_loss: 0.025859758257865906
	test_majority_acc: 0.994068540841375
	test_minority_acc: 0.9953131662909145
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 9.26782377064228e-06
	train_minority_loss: 1.0628607924445532e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 8550
	train_minority_nonzero: 11550
val:
	val_majority_loss: 0.04584822431206703
	val_minority_loss: 3.1411989766638726e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02433229610323906
	test_minority_loss: 0.026699300855398178
	test_majority_acc: 0.994068540841375
	test_minority_acc: 0.9962601359878842
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.25967788696289 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.6
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235896110534668
	train_minority_loss: 2.280574321746826
	train_majority_acc: 0.6257601906430331
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.13381069898605347
	train_minority_loss: 0.09911889582872391
	train_majority_acc: 0.9443173406790307
	train_minority_acc: 0.9798738193243237
	train_majority_nonzero: 8050
	train_minority_nonzero: 12050
val:
	val_majority_loss: 0.015156983397901058
	val_minority_loss: 0.0007682206924073398
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.022600235417485237
	test_minority_loss: 0.008733607828617096
	test_majority_acc: 0.9920222935970594
	test_minority_acc: 0.9953131662909145
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.011052425019443035
	train_minority_loss: 0.0062669627368450165
	train_majority_acc: 0.9960006470845533
	train_minority_acc: 0.9982042669662397
	train_majority_nonzero: 8050
	train_minority_nonzero: 12050
val:
	val_majority_loss: 0.04529494419693947
	val_minority_loss: 0.0003550293331500143
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04042963683605194
	test_minority_loss: 0.006541845854371786
	test_majority_acc: 0.9860363885967615
	test_minority_acc: 0.997439381270903
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.0017069382593035698
	train_minority_loss: 0.0009289229637943208
	train_majority_acc: 0.9997506203319243
	train_minority_acc: 1.0
	train_majority_nonzero: 8050
	train_minority_nonzero: 12050
val:
	val_majority_loss: 0.00742780975997448
	val_minority_loss: 0.0003821833524852991
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01207953505218029
	test_minority_loss: 0.02329973317682743
	test_majority_acc: 0.9953983280754175
	test_minority_acc: 0.9908152183085053
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.00039317982736974955
	train_minority_loss: 0.00029929363518022
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 8050
	train_minority_nonzero: 12050
val:
	val_majority_loss: 0.017269276082515717
	val_minority_loss: 0.0001771912502590567
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02308971993625164
	test_minority_loss: 0.015382541343569756
	test_majority_acc: 0.994068540841375
	test_minority_acc: 0.9962601359878842
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.00014249731611926109
	train_minority_loss: 9.405129821971059e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 8050
	train_minority_nonzero: 12050
val:
	val_majority_loss: 0.01999853365123272
	val_minority_loss: 0.00012886601325590163
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.023689400404691696
	test_minority_loss: 0.015143289230763912
	test_majority_acc: 0.994068540841375
	test_minority_acc: 0.9962601359878842
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 9.406032040715218e-05
	train_minority_loss: 6.174603186082095e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 8050
	train_minority_nonzero: 12050
val:
	val_majority_loss: 0.019714849069714546
	val_minority_loss: 0.0001007844039122574
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.024661049246788025
	test_minority_loss: 0.01545899547636509
	test_majority_acc: 0.994068540841375
	test_minority_acc: 0.9962601359878842
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 7.286802429007366e-05
	train_minority_loss: 4.664336665882729e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 8050
	train_minority_nonzero: 12050
val:
	val_majority_loss: 0.02116120606660843
	val_minority_loss: 7.605260179843754e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02637607790529728
	test_minority_loss: 0.015717681497335434
	test_majority_acc: 0.994068540841375
	test_minority_acc: 0.9962601359878842
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 4.8712427087593824e-05
	train_minority_loss: 3.302856566733681e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 8050
	train_minority_nonzero: 12050
val:
	val_majority_loss: 0.018357716500759125
	val_minority_loss: 8.506512676831335e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02439139597117901
	test_minority_loss: 0.017425788566470146
	test_majority_acc: 0.994068540841375
	test_minority_acc: 0.9962601359878842
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 3.959270179620944e-05
	train_minority_loss: 2.4217180907726288e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 8050
	train_minority_nonzero: 12050
val:
	val_majority_loss: 0.018351418897509575
	val_minority_loss: 8.051559416344389e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.024372227489948273
	test_minority_loss: 0.018160149455070496
	test_majority_acc: 0.994068540841375
	test_minority_acc: 0.9962601359878842
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 2.8222242690389976e-05
	train_minority_loss: 1.9853336198139004e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 8050
	train_minority_nonzero: 12050
val:
	val_majority_loss: 0.02029389515519142
	val_minority_loss: 5.3187046432867646e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02817407064139843
	test_minority_loss: 0.017033744603395462
	test_majority_acc: 0.994068540841375
	test_minority_acc: 0.9962601359878842
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.281822204589844 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.625
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2359018325805664
	train_minority_loss: 2.2806460857391357
	train_majority_acc: 0.6227113206710339
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.139070525765419
	train_minority_loss: 0.09506556391716003
	train_majority_acc: 0.9364281712936409
	train_minority_acc: 0.9821373340310041
	train_majority_nonzero: 7550
	train_minority_nonzero: 12550
val:
	val_majority_loss: 0.022037846967577934
	val_minority_loss: 0.0004154230991844088
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.025013789534568787
	test_minority_loss: 0.00446618115529418
	test_majority_acc: 0.9923655161797206
	test_minority_acc: 0.9987980769230769
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.008383538573980331
	train_minority_loss: 0.004361024126410484
	train_majority_acc: 0.9972790126581667
	train_minority_acc: 0.9989722817582369
	train_majority_nonzero: 7550
	train_minority_nonzero: 12550
val:
	val_majority_loss: 0.04111175984144211
	val_minority_loss: 0.00018651338177733123
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03607146069407463
	test_minority_loss: 0.005921761505305767
	test_majority_acc: 0.9899764069117798
	test_minority_acc: 0.997439381270903
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.0009762414847500622
	train_minority_loss: 0.0005555219831876457
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 7550
	train_minority_nonzero: 12550
val:
	val_majority_loss: 0.012050519697368145
	val_minority_loss: 0.00020765444787684828
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.018201220780611038
	test_minority_loss: 0.013382100500166416
	test_majority_acc: 0.9924026853738925
	test_minority_acc: 0.9962601359878842
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.00028656210633926094
	train_minority_loss: 0.00018618119065649807
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 7550
	train_minority_nonzero: 12550
val:
	val_majority_loss: 0.01710592210292816
	val_minority_loss: 0.0001445788366254419
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.023656770586967468
	test_minority_loss: 0.014651751145720482
	test_majority_acc: 0.9913061941458223
	test_minority_acc: 0.9962601359878842
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.0001520396035630256
	train_minority_loss: 9.227206464856863e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 7550
	train_minority_nonzero: 12550
val:
	val_majority_loss: 0.02328084222972393
	val_minority_loss: 9.616126044420525e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02453063428401947
	test_minority_loss: 0.013818477280437946
	test_majority_acc: 0.9913061941458223
	test_minority_acc: 0.9962601359878842
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 9.461149602429941e-05
	train_minority_loss: 5.5894208344398066e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 7550
	train_minority_nonzero: 12550
val:
	val_majority_loss: 0.02549820765852928
	val_minority_loss: 6.300266250036657e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.027068717405200005
	test_minority_loss: 0.014109354466199875
	test_majority_acc: 0.9913061941458223
	test_minority_acc: 0.9962601359878842
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 6.867268530186266e-05
	train_minority_loss: 3.9256141462828964e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 7550
	train_minority_nonzero: 12550
val:
	val_majority_loss: 0.021176159381866455
	val_minority_loss: 5.5861088185338303e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02534482069313526
	test_minority_loss: 0.016214774921536446
	test_majority_acc: 0.9913061941458223
	test_minority_acc: 0.9962601359878842
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 4.718337731901556e-05
	train_minority_loss: 2.9776874725939706e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 7550
	train_minority_nonzero: 12550
val:
	val_majority_loss: 0.029198601841926575
	val_minority_loss: 3.828537228400819e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02802208811044693
	test_minority_loss: 0.015695327892899513
	test_majority_acc: 0.9913061941458223
	test_minority_acc: 0.9962601359878842
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 3.513999763526954e-05
	train_minority_loss: 1.9901797713828273e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 7550
	train_minority_nonzero: 12550
val:
	val_majority_loss: 0.02603650465607643
	val_minority_loss: 3.830355126410723e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.026912784203886986
	test_minority_loss: 0.016807567328214645
	test_majority_acc: 0.9913061941458223
	test_minority_acc: 0.9962601359878842
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 2.823300746968016e-05
	train_minority_loss: 1.77144720510114e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 7550
	train_minority_nonzero: 12550
val:
	val_majority_loss: 0.0280044786632061
	val_minority_loss: 2.565655995567795e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03074033558368683
	test_minority_loss: 0.016446031630039215
	test_majority_acc: 0.9913061941458223
	test_minority_acc: 0.9962601359878842
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.242103576660156 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.65
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235893964767456
	train_minority_loss: 2.2806167602539062
	train_majority_acc: 0.62421352949721
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.15518563985824585
	train_minority_loss: 0.0924515351653099
	train_majority_acc: 0.92301489888882
	train_minority_acc: 0.9837636650189123
	train_majority_nonzero: 7050
	train_minority_nonzero: 13050
val:
	val_majority_loss: 0.0175801869481802
	val_minority_loss: 0.0007602434488944709
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.022722216323018074
	test_minority_loss: 0.008623510599136353
	test_majority_acc: 0.9924933803368401
	test_minority_acc: 0.9953131662909145
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.01324706245213747
	train_minority_loss: 0.006327356211841106
	train_majority_acc: 0.9961135148734158
	train_minority_acc: 0.9978617596224177
	train_majority_nonzero: 7050
	train_minority_nonzero: 13050
val:
	val_majority_loss: 0.017391253262758255
	val_minority_loss: 0.0008013237384147942
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.019036054611206055
	test_minority_loss: 0.011780599132180214
	test_majority_acc: 0.993522923587128
	test_minority_acc: 0.9962601359878842
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.002253735437989235
	train_minority_loss: 0.0011646472848951817
	train_majority_acc: 0.9995918241609291
	train_minority_acc: 0.999770956659713
	train_majority_nonzero: 7050
	train_minority_nonzero: 13050
val:
	val_majority_loss: 0.005588964559137821
	val_minority_loss: 0.00020472949836403131
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.016834566369652748
	test_minority_loss: 0.015943020582199097
	test_majority_acc: 0.9935187568024639
	test_minority_acc: 0.9950808907048653
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.00031966943060979247
	train_minority_loss: 0.00018595023720990866
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 7050
	train_minority_nonzero: 13050
val:
	val_majority_loss: 0.027990981936454773
	val_minority_loss: 6.107396620791405e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.030276421457529068
	test_minority_loss: 0.011455303058028221
	test_majority_acc: 0.9898180989077271
	test_minority_acc: 0.9962601359878842
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.00016135182522702962
	train_minority_loss: 8.936215454014018e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 7050
	train_minority_nonzero: 13050
val:
	val_majority_loss: 0.025637181475758553
	val_minority_loss: 4.208491009194404e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02858603000640869
	test_minority_loss: 0.01236161682754755
	test_majority_acc: 0.9898180989077271
	test_minority_acc: 0.9962601359878842
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.00010622556146699935
	train_minority_loss: 5.916344889556058e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 7050
	train_minority_nonzero: 13050
val:
	val_majority_loss: 0.02761652134358883
	val_minority_loss: 2.2579533833777532e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03179030865430832
	test_minority_loss: 0.012157258577644825
	test_majority_acc: 0.9898180989077271
	test_minority_acc: 0.9962601359878842
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 7.71145278122276e-05
	train_minority_loss: 4.094023461220786e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 7050
	train_minority_nonzero: 13050
val:
	val_majority_loss: 0.02745971828699112
	val_minority_loss: 1.8909711798187345e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03214116021990776
	test_minority_loss: 0.013312596827745438
	test_majority_acc: 0.9898180989077271
	test_minority_acc: 0.9962601359878842
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 5.084869917482138e-05
	train_minority_loss: 3.0296983823063783e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 7050
	train_minority_nonzero: 13050
val:
	val_majority_loss: 0.02801060862839222
	val_minority_loss: 1.418324336555088e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.031695328652858734
	test_minority_loss: 0.013705814257264137
	test_majority_acc: 0.9898180989077271
	test_minority_acc: 0.9962601359878842
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 4.198790338705294e-05
	train_minority_loss: 2.2315300157060847e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 7050
	train_minority_nonzero: 13050
val:
	val_majority_loss: 0.028396133333444595
	val_minority_loss: 1.2257906746526714e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.031880833208560944
	test_minority_loss: 0.014181123115122318
	test_majority_acc: 0.9898180989077271
	test_minority_acc: 0.9962601359878842
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 3.1553267035633326e-05
	train_minority_loss: 1.8221551727037877e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 7050
	train_minority_nonzero: 13050
val:
	val_majority_loss: 0.024310389533638954
	val_minority_loss: 1.081206755770836e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03149405121803284
	test_minority_loss: 0.015324114821851254
	test_majority_acc: 0.9898180989077271
	test_minority_acc: 0.9962601359878842
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.33356809616089 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.675
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235825777053833
	train_minority_loss: 2.280620574951172
	train_majority_acc: 0.62805610548717
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.16503602266311646
	train_minority_loss: 0.08894114941358566
	train_majority_acc: 0.9123884904404665
	train_minority_acc: 0.9861342087559883
	train_majority_nonzero: 6550
	train_minority_nonzero: 13550
val:
	val_majority_loss: 0.01109996996819973
	val_minority_loss: 0.0016733084339648485
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.023503519594669342
	test_minority_loss: 0.007302603684365749
	test_majority_acc: 0.988568098907727
	test_minority_acc: 0.997618831640058
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.009948541410267353
	train_minority_loss: 0.004238872788846493
	train_majority_acc: 0.9975441080655298
	train_minority_acc: 0.9988676886547827
	train_majority_nonzero: 6550
	train_minority_nonzero: 13550
val:
	val_majority_loss: 0.041477400809526443
	val_minority_loss: 4.3284853745717555e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04384063929319382
	test_minority_loss: 0.0048889294266700745
	test_majority_acc: 0.9870002164355893
	test_minority_acc: 0.9987980769230769
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.002742170123383403
	train_minority_loss: 0.00092342245625332
	train_majority_acc: 0.9993050619916293
	train_minority_acc: 0.9999362163541269
	train_majority_nonzero: 6550
	train_minority_nonzero: 13550
val:
	val_majority_loss: 0.048803552985191345
	val_minority_loss: 3.28409623762127e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.048534683883190155
	test_minority_loss: 0.0072978707030415535
	test_majority_acc: 0.9844156299694239
	test_minority_acc: 0.997439381270903
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.0005031987093389034
	train_minority_loss: 0.00023800709459464997
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 6550
	train_minority_nonzero: 13550
val:
	val_majority_loss: 0.03477287292480469
	val_minority_loss: 2.1657819161191583e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.029943833127617836
	test_minority_loss: 0.010330630466341972
	test_majority_acc: 0.9883300036696319
	test_minority_acc: 0.9962601359878842
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.00012906137271784246
	train_minority_loss: 6.213394226506352e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 6550
	train_minority_nonzero: 13550
val:
	val_majority_loss: 0.03620633855462074
	val_minority_loss: 1.458337101212237e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.030671492218971252
	test_minority_loss: 0.01028164941817522
	test_majority_acc: 0.9898180989077271
	test_minority_acc: 0.9962601359878842
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 8.540799899492413e-05
	train_minority_loss: 4.006759627372958e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 6550
	train_minority_nonzero: 13550
val:
	val_majority_loss: 0.03350061550736427
	val_minority_loss: 9.457326086703688e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03221144527196884
	test_minority_loss: 0.010600725188851357
	test_majority_acc: 0.9898180989077271
	test_minority_acc: 0.9962601359878842
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 6.199641211424023e-05
	train_minority_loss: 2.9091237593092956e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 6550
	train_minority_nonzero: 13550
val:
	val_majority_loss: 0.03391781449317932
	val_minority_loss: 6.8483668655972e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0330023318529129
	test_minority_loss: 0.01067429967224598
	test_majority_acc: 0.9898180989077271
	test_minority_acc: 0.9962601359878842
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 4.614516001311131e-05
	train_minority_loss: 2.2084104784880765e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 6550
	train_minority_nonzero: 13550
val:
	val_majority_loss: 0.03148171305656433
	val_minority_loss: 6.299920642049983e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.031544629484415054
	test_minority_loss: 0.0117544736713171
	test_majority_acc: 0.9898180989077271
	test_minority_acc: 0.9962601359878842
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 3.527286389726214e-05
	train_minority_loss: 1.706110742816236e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 6550
	train_minority_nonzero: 13550
val:
	val_majority_loss: 0.03082258626818657
	val_minority_loss: 5.6291564760613255e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.031906016170978546
	test_minority_loss: 0.01206517405807972
	test_majority_acc: 0.9898180989077271
	test_minority_acc: 0.9962601359878842
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 2.8958424081793055e-05
	train_minority_loss: 1.4292101695900783e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 6550
	train_minority_nonzero: 13550
val:
	val_majority_loss: 0.03093443065881729
	val_minority_loss: 3.4891288578364765e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.034279875457286835
	test_minority_loss: 0.011614153161644936
	test_majority_acc: 0.9898180989077271
	test_minority_acc: 0.9962601359878842
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.43416166305542 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.7
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235809087753296
	train_minority_loss: 2.280541181564331
	train_majority_acc: 0.6285001551498848
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.18730708956718445
	train_minority_loss: 0.08736059069633484
	train_majority_acc: 0.8990439855164741
	train_minority_acc: 0.9890595628684858
	train_majority_nonzero: 6050
	train_minority_nonzero: 14050
val:
	val_majority_loss: 0.01493886485695839
	val_minority_loss: 0.0009692381718195975
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02490881457924843
	test_minority_loss: 0.012068449519574642
	test_majority_acc: 0.9899507622969694
	test_minority_acc: 0.9949014403357103
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.012849073857069016
	train_minority_loss: 0.004526825621724129
	train_majority_acc: 0.9958905711633478
	train_minority_acc: 0.9985742798966515
	train_majority_nonzero: 6050
	train_minority_nonzero: 14050
val:
	val_majority_loss: 0.02890753746032715
	val_minority_loss: 4.26464612246491e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02903781831264496
	test_minority_loss: 0.01132251601666212
	test_majority_acc: 0.9897126670588741
	test_minority_acc: 0.997439381270903
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.0013000223552808166
	train_minority_loss: 0.0005091186612844467
	train_majority_acc: 1.0
	train_minority_acc: 0.9999278967481433
	train_majority_nonzero: 6050
	train_minority_nonzero: 14050
val:
	val_majority_loss: 0.04156586900353432
	val_minority_loss: 9.896890333038755e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04152918979525566
	test_minority_loss: 0.009196833707392216
	test_majority_acc: 0.9871280805927087
	test_minority_acc: 0.9987980769230769
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.000281286658719182
	train_minority_loss: 0.00012003644951619208
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 6050
	train_minority_nonzero: 14050
val:
	val_majority_loss: 0.03145388141274452
	val_minority_loss: 7.95372216089163e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03545178472995758
	test_minority_loss: 0.011768151074647903
	test_majority_acc: 0.9894264948977021
	test_minority_acc: 0.9962601359878842
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.00016773959214333445
	train_minority_loss: 7.136946078389883e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 6050
	train_minority_nonzero: 14050
val:
	val_majority_loss: 0.030842339619994164
	val_minority_loss: 4.981425263395067e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03514241427183151
	test_minority_loss: 0.012290065176784992
	test_majority_acc: 0.9894264948977021
	test_minority_acc: 0.9962601359878842
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.00011517492384882644
	train_minority_loss: 4.7264184104278684e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 6050
	train_minority_nonzero: 14050
val:
	val_majority_loss: 0.0309704951941967
	val_minority_loss: 3.1909569315757835e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03705122321844101
	test_minority_loss: 0.012860583141446114
	test_majority_acc: 0.9894264948977021
	test_minority_acc: 0.9962601359878842
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 7.518381607951596e-05
	train_minority_loss: 3.285857383161783e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 6050
	train_minority_nonzero: 14050
val:
	val_majority_loss: 0.03226505592465401
	val_minority_loss: 2.1536420717893634e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.039436742663383484
	test_minority_loss: 0.01308696810156107
	test_majority_acc: 0.9894264948977021
	test_minority_acc: 0.997439381270903
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 5.361002331483178e-05
	train_minority_loss: 2.30195091717178e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 6050
	train_minority_nonzero: 14050
val:
	val_majority_loss: 0.03279834985733032
	val_minority_loss: 1.7326907482129172e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.038833316415548325
	test_minority_loss: 0.01364966481924057
	test_majority_acc: 0.9894264948977021
	test_minority_acc: 0.9962601359878842
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 3.9170103264041245e-05
	train_minority_loss: 1.6513067748746835e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 6050
	train_minority_nonzero: 14050
val:
	val_majority_loss: 0.032439254224300385
	val_minority_loss: 1.2494504062487977e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04026437923312187
	test_minority_loss: 0.014113036915659904
	test_majority_acc: 0.9894264948977021
	test_minority_acc: 0.9962601359878842
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 2.8821214073104784e-05
	train_minority_loss: 1.3543228305934463e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 6050
	train_minority_nonzero: 14050
val:
	val_majority_loss: 0.033558718860149384
	val_minority_loss: 8.691694688423013e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.042889513075351715
	test_minority_loss: 0.014220031909644604
	test_majority_acc: 0.9894264948977021
	test_minority_acc: 0.997439381270903
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.488231897354126 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.725
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235917329788208
	train_minority_loss: 2.2805168628692627
	train_majority_acc: 0.6273577790221897
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.20862165093421936
	train_minority_loss: 0.08437683433294296
	train_majority_acc: 0.8869614124711854
	train_minority_acc: 0.9901854961173456
	train_majority_nonzero: 5550
	train_minority_nonzero: 14550
val:
	val_majority_loss: 0.030924681574106216
	val_minority_loss: 0.0005628420622088015
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0473773255944252
	test_minority_loss: 0.003933357074856758
	test_majority_acc: 0.9823592678180697
	test_minority_acc: 0.9987980769230769
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.010644779540598392
	train_minority_loss: 0.00328085501678288
	train_majority_acc: 0.9975111215579803
	train_minority_acc: 0.9990814869628635
	train_majority_nonzero: 5550
	train_minority_nonzero: 14550
val:
	val_majority_loss: 0.024902397766709328
	val_minority_loss: 0.0004082896339241415
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.013738442212343216
	test_minority_loss: 0.019645892083644867
	test_majority_acc: 0.9935600927813
	test_minority_acc: 0.9936274023327722
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.0022740657441318035
	train_minority_loss: 0.0007970149745233357
	train_majority_acc: 0.9996428115831101
	train_minority_acc: 0.9998026918136516
	train_majority_nonzero: 5550
	train_minority_nonzero: 14550
val:
	val_majority_loss: 0.050356633961200714
	val_minority_loss: 1.0747813576017506e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03756585717201233
	test_minority_loss: 0.006743607576936483
	test_majority_acc: 0.9883300036696319
	test_minority_acc: 0.9962601359878842
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.00030232773860916495
	train_minority_loss: 0.000115237184218131
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 5550
	train_minority_nonzero: 14550
val:
	val_majority_loss: 0.05235879495739937
	val_minority_loss: 6.878421118017286e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.037165604531764984
	test_minority_loss: 0.008942760527133942
	test_majority_acc: 0.9883300036696319
	test_minority_acc: 0.9962601359878842
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.00016685189621057361
	train_minority_loss: 5.9324906032998115e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 5550
	train_minority_nonzero: 14550
val:
	val_majority_loss: 0.05362117290496826
	val_minority_loss: 4.654193162423326e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03637922182679176
	test_minority_loss: 0.009978546760976315
	test_majority_acc: 0.9883300036696319
	test_minority_acc: 0.9962601359878842
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.00011307949898764491
	train_minority_loss: 4.123675898881629e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 5550
	train_minority_nonzero: 14550
val:
	val_majority_loss: 0.049912139773368835
	val_minority_loss: 3.989104698121082e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03457993268966675
	test_minority_loss: 0.011348333209753036
	test_majority_acc: 0.9883300036696319
	test_minority_acc: 0.9962601359878842
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 7.624605495948344e-05
	train_minority_loss: 2.764273449429311e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 5550
	train_minority_nonzero: 14550
val:
	val_majority_loss: 0.051099713891744614
	val_minority_loss: 2.8931599445058964e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03555608540773392
	test_minority_loss: 0.011583056300878525
	test_majority_acc: 0.9883300036696319
	test_minority_acc: 0.9962601359878842
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 4.811932740267366e-05
	train_minority_loss: 1.9361292288522236e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 5550
	train_minority_nonzero: 14550
val:
	val_majority_loss: 0.05411559343338013
	val_minority_loss: 1.7737884263624437e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03699427843093872
	test_minority_loss: 0.012544787488877773
	test_majority_acc: 0.9883300036696319
	test_minority_acc: 0.9962601359878842
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 3.1428691727342084e-05
	train_minority_loss: 1.2066380804753862e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 5550
	train_minority_nonzero: 14550
val:
	val_majority_loss: 0.05674370005726814
	val_minority_loss: 1.2299663012527162e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03869929164648056
	test_minority_loss: 0.01309529971331358
	test_majority_acc: 0.9883300036696319
	test_minority_acc: 0.9962601359878842
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 1.9223394701839425e-05
	train_minority_loss: 8.481790246150922e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 5550
	train_minority_nonzero: 14550
val:
	val_majority_loss: 0.058844611048698425
	val_minority_loss: 8.228740284721425e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.040799450129270554
	test_minority_loss: 0.013533666729927063
	test_majority_acc: 0.9883300036696319
	test_minority_acc: 0.9962601359878842
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.397332668304443 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.75
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.236177921295166
	train_minority_loss: 2.2805299758911133
	train_majority_acc: 0.6231599860352629
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.22295434772968292
	train_minority_loss: 0.0810980498790741
	train_majority_acc: 0.8770899117020116
	train_minority_acc: 0.9917926826102286
	train_majority_nonzero: 5050
	train_minority_nonzero: 15050
val:
	val_majority_loss: 0.05592699348926544
	val_minority_loss: 0.0008424039115197957
	val_majority_acc: 0.9707860445565364
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.06302659213542938
	test_minority_loss: 0.0037100398913025856
	test_majority_acc: 0.9782413768954998
	test_minority_acc: 0.9987980769230769
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.012178827077150345
	train_minority_loss: 0.0036891591735184193
	train_majority_acc: 0.996274556543051
	train_minority_acc: 0.9984761860312449
	train_majority_nonzero: 5050
	train_minority_nonzero: 15050
val:
	val_majority_loss: 0.030103813856840134
	val_minority_loss: 0.00017289076640736312
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.032425880432128906
	test_minority_loss: 0.008528772741556168
	test_majority_acc: 0.9888542710688992
	test_minority_acc: 0.997439381270903
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.0008506409940309823
	train_minority_loss: 0.0002905720903072506
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 5050
	train_minority_nonzero: 15050
val:
	val_majority_loss: 0.02384723722934723
	val_minority_loss: 7.226980960695073e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03169647976756096
	test_minority_loss: 0.00914790853857994
	test_majority_acc: 0.987366175830804
	test_minority_acc: 0.997439381270903
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.00023123181017581373
	train_minority_loss: 8.565969619667158e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 5050
	train_minority_nonzero: 15050
val:
	val_majority_loss: 0.037670623511075974
	val_minority_loss: 2.1387575543485582e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04379689320921898
	test_minority_loss: 0.00956609845161438
	test_majority_acc: 0.987366175830804
	test_minority_acc: 0.997439381270903
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 6.482259777840227e-05
	train_minority_loss: 2.7424306608736515e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 5050
	train_minority_nonzero: 15050
val:
	val_majority_loss: 0.047354232519865036
	val_minority_loss: 9.196944120049011e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05044150352478027
	test_minority_loss: 0.009743353351950645
	test_majority_acc: 0.987366175830804
	test_minority_acc: 0.997439381270903
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 2.774541462713387e-05
	train_minority_loss: 1.3313821909832768e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 5050
	train_minority_nonzero: 15050
val:
	val_majority_loss: 0.04949058219790459
	val_minority_loss: 5.855980361957336e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.053844694048166275
	test_minority_loss: 0.01074100099503994
	test_majority_acc: 0.987366175830804
	test_minority_acc: 0.997439381270903
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 1.5144190001592506e-05
	train_minority_loss: 7.732242011115886e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 5050
	train_minority_nonzero: 15050
val:
	val_majority_loss: 0.05035747215151787
	val_minority_loss: 4.961776539857965e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05464733764529228
	test_minority_loss: 0.011869465932250023
	test_majority_acc: 0.987366175830804
	test_minority_acc: 0.997439381270903
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 9.277557182940654e-06
	train_minority_loss: 5.605753813142655e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 5050
	train_minority_nonzero: 15050
val:
	val_majority_loss: 0.053969770669937134
	val_minority_loss: 3.798609895966365e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.057742178440093994
	test_minority_loss: 0.011871415190398693
	test_majority_acc: 0.987366175830804
	test_minority_acc: 0.997439381270903
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 7.519002792832907e-06
	train_minority_loss: 4.261898084223503e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 5050
	train_minority_nonzero: 15050
val:
	val_majority_loss: 0.04793429747223854
	val_minority_loss: 3.4356949072389398e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05509281903505325
	test_minority_loss: 0.01331870537251234
	test_majority_acc: 0.987366175830804
	test_minority_acc: 0.997439381270903
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 4.802925559488358e-06
	train_minority_loss: 3.072056415476254e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 5050
	train_minority_nonzero: 15050
val:
	val_majority_loss: 0.05189703404903412
	val_minority_loss: 2.71776275440061e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05878753215074539
	test_minority_loss: 0.013217281550168991
	test_majority_acc: 0.987366175830804
	test_minority_acc: 0.997439381270903
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.40634059906006 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.775
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2360730171203613
	train_minority_loss: 2.280597686767578
	train_majority_acc: 0.6152669502421406
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.25816741585731506
	train_minority_loss: 0.08100470155477524
	train_majority_acc: 0.8623397882482755
	train_minority_acc: 0.9909516432554913
	train_majority_nonzero: 4550
	train_minority_nonzero: 15550
val:
	val_majority_loss: 0.03547520190477371
	val_minority_loss: 0.0008353883749805391
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03233731910586357
	test_minority_loss: 0.0054391068406403065
	test_majority_acc: 0.9900561941458224
	test_minority_acc: 0.998641304347826
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.007210916373878717
	train_minority_loss: 0.0018601827323436737
	train_majority_acc: 0.9985456926140605
	train_minority_acc: 0.9996839550134133
	train_majority_nonzero: 4550
	train_minority_nonzero: 15550
val:
	val_majority_loss: 0.02016289532184601
	val_minority_loss: 0.0001454672747058794
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.018098579719662666
	test_minority_loss: 0.013488253578543663
	test_majority_acc: 0.9909755063151344
	test_minority_acc: 0.9962601359878842
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.0011036291252821684
	train_minority_loss: 0.00032921734964475036
	train_majority_acc: 0.9997512437810945
	train_minority_acc: 1.0
	train_majority_nonzero: 4550
	train_minority_nonzero: 15550
val:
	val_majority_loss: 0.041489340364933014
	val_minority_loss: 1.7455155102652498e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.030213022604584694
	test_minority_loss: 0.009798473678529263
	test_majority_acc: 0.987366175830804
	test_minority_acc: 0.997439381270903
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.00025395298143848777
	train_minority_loss: 8.099054684862494e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 4550
	train_minority_nonzero: 15550
val:
	val_majority_loss: 0.06676987558603287
	val_minority_loss: 4.6971026677056216e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04568915814161301
	test_minority_loss: 0.0077896723523736
	test_majority_acc: 0.987366175830804
	test_minority_acc: 0.997439381270903
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.00011308333341730759
	train_minority_loss: 3.6925954191247e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 4550
	train_minority_nonzero: 15550
val:
	val_majority_loss: 0.07598757743835449
	val_minority_loss: 2.556264689701493e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05116783827543259
	test_minority_loss: 0.008183922618627548
	test_majority_acc: 0.987366175830804
	test_minority_acc: 0.997439381270903
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 5.618780414806679e-05
	train_minority_loss: 1.9482393327052705e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 4550
	train_minority_nonzero: 15550
val:
	val_majority_loss: 0.07788582146167755
	val_minority_loss: 1.5669718322897097e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.052609845995903015
	test_minority_loss: 0.008613170124590397
	test_majority_acc: 0.987366175830804
	test_minority_acc: 0.997439381270903
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 3.526828731992282e-05
	train_minority_loss: 1.1964492841798346e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 4550
	train_minority_nonzero: 15550
val:
	val_majority_loss: 0.07711100578308105
	val_minority_loss: 1.23802215057367e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.051627740263938904
	test_minority_loss: 0.009955327026546001
	test_majority_acc: 0.987366175830804
	test_minority_acc: 0.997439381270903
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 2.123442573065404e-05
	train_minority_loss: 8.36715116747655e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 4550
	train_minority_nonzero: 15550
val:
	val_majority_loss: 0.08289217948913574
	val_minority_loss: 8.441534191661049e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05550563335418701
	test_minority_loss: 0.00979664083570242
	test_majority_acc: 0.987366175830804
	test_minority_acc: 0.997439381270903
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 1.5896293916739523e-05
	train_minority_loss: 5.792760475742398e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 4550
	train_minority_nonzero: 15550
val:
	val_majority_loss: 0.08009542524814606
	val_minority_loss: 6.636983016505837e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05451272428035736
	test_minority_loss: 0.010686684399843216
	test_majority_acc: 0.987366175830804
	test_minority_acc: 0.997439381270903
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 1.1065344551752787e-05
	train_minority_loss: 4.607185474014841e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 4550
	train_minority_nonzero: 15550
val:
	val_majority_loss: 0.08781934529542923
	val_minority_loss: 5.306911248226243e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05978294834494591
	test_minority_loss: 0.010240157134830952
	test_majority_acc: 0.987366175830804
	test_minority_acc: 0.997439381270903
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.246118783950806 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.8
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2361457347869873
	train_minority_loss: 2.28058123588562
	train_majority_acc: 0.6190468955895291
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.3050079643726349
	train_minority_loss: 0.0795263722538948
	train_majority_acc: 0.842083925350459
	train_minority_acc: 0.9924830603601518
	train_majority_nonzero: 4050
	train_minority_nonzero: 16050
val:
	val_majority_loss: 0.03428644686937332
	val_minority_loss: 0.0002646863867994398
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05765381455421448
	test_minority_loss: 0.002653213683515787
	test_majority_acc: 0.9785282141199947
	test_minority_acc: 0.9987980769230769
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.009745633229613304
	train_minority_loss: 0.0021279577631503344
	train_majority_acc: 0.9978060186082575
	train_minority_acc: 0.9996172355917746
	train_majority_nonzero: 4050
	train_minority_nonzero: 16050
val:
	val_majority_loss: 0.017505265772342682
	val_minority_loss: 4.49377293989528e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.029323291033506393
	test_minority_loss: 0.005797469988465309
	test_majority_acc: 0.9900116784763067
	test_minority_acc: 0.997439381270903
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.0010208371095359325
	train_minority_loss: 0.00027884377050213516
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 4050
	train_minority_nonzero: 16050
val:
	val_majority_loss: 0.037782520055770874
	val_minority_loss: 8.162089216057211e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.043476782739162445
	test_minority_loss: 0.0033774147741496563
	test_majority_acc: 0.9845482933586662
	test_minority_acc: 0.997439381270903
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.00035587293677963316
	train_minority_loss: 9.542107000015676e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 4050
	train_minority_nonzero: 16050
val:
	val_majority_loss: 0.04260360449552536
	val_minority_loss: 4.8801862249092665e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04583587497472763
	test_minority_loss: 0.0031238768715411425
	test_majority_acc: 0.9832462100253329
	test_minority_acc: 0.9987980769230769
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.00020099544781260192
	train_minority_loss: 5.3338819270720705e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 4050
	train_minority_nonzero: 16050
val:
	val_majority_loss: 0.046946313232183456
	val_minority_loss: 2.068687535938807e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04774197190999985
	test_minority_loss: 0.0033403553534299135
	test_majority_acc: 0.9832462100253329
	test_minority_acc: 0.997439381270903
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.00011968578473897651
	train_minority_loss: 3.2902626116992906e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 4050
	train_minority_nonzero: 16050
val:
	val_majority_loss: 0.04803888872265816
	val_minority_loss: 1.5028188045107527e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0473485067486763
	test_minority_loss: 0.003673863597214222
	test_majority_acc: 0.9832462100253329
	test_minority_acc: 0.997439381270903
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 8.515039371559396e-05
	train_minority_loss: 2.2760230422136374e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 4050
	train_minority_nonzero: 16050
val:
	val_majority_loss: 0.044997263699769974
	val_minority_loss: 1.415902829648985e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04373305290937424
	test_minority_loss: 0.004196378868073225
	test_majority_acc: 0.9858780805927088
	test_minority_acc: 0.997439381270903
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 5.911868720431812e-05
	train_minority_loss: 1.674428494879976e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 4050
	train_minority_nonzero: 16050
val:
	val_majority_loss: 0.0478350967168808
	val_minority_loss: 9.097078645936563e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04702083393931389
	test_minority_loss: 0.004088687710464001
	test_majority_acc: 0.9858780805927088
	test_minority_acc: 0.997439381270903
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 4.347110734670423e-05
	train_minority_loss: 1.2048270036757458e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 4050
	train_minority_nonzero: 16050
val:
	val_majority_loss: 0.05186808854341507
	val_minority_loss: 7.882971431172336e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04751445725560188
	test_minority_loss: 0.003946967888623476
	test_majority_acc: 0.9858780805927088
	test_minority_acc: 0.997439381270903
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 3.2364503567805514e-05
	train_minority_loss: 9.544107342662755e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 4050
	train_minority_nonzero: 16050
val:
	val_majority_loss: 0.051275309175252914
	val_minority_loss: 6.48023274152365e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.047279585152864456
	test_minority_loss: 0.004242213908582926
	test_majority_acc: 0.9858780805927088
	test_minority_acc: 0.997439381270903
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.326280117034912 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.825
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2359633445739746
	train_minority_loss: 2.2805755138397217
	train_majority_acc: 0.619352609412401
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.33460378646850586
	train_minority_loss: 0.07759439200162888
	train_majority_acc: 0.8279957091750427
	train_minority_acc: 0.992484229738954
	train_majority_nonzero: 3550
	train_minority_nonzero: 16550
val:
	val_majority_loss: 0.027555283159017563
	val_minority_loss: 0.00037583254743367434
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04544174298644066
	test_minority_loss: 0.003405418014153838
	test_majority_acc: 0.9845759972593754
	test_minority_acc: 0.9987980769230769
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.012704875320196152
	train_minority_loss: 0.002508879406377673
	train_majority_acc: 0.9969776627092363
	train_minority_acc: 0.999501942482802
	train_majority_nonzero: 3550
	train_minority_nonzero: 16550
val:
	val_majority_loss: 0.031490691006183624
	val_minority_loss: 3.8025817048037425e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.039372049272060394
	test_minority_loss: 0.005366968922317028
	test_majority_acc: 0.9845759972593754
	test_minority_acc: 0.997439381270903
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.0012132195988669991
	train_minority_loss: 0.0002571422082837671
	train_majority_acc: 0.9996683250414594
	train_minority_acc: 1.0
	train_majority_nonzero: 3550
	train_minority_nonzero: 16550
val:
	val_majority_loss: 0.04148946329951286
	val_minority_loss: 8.213492947106715e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04522290453314781
	test_minority_loss: 0.004150515887886286
	test_majority_acc: 0.9845759972593754
	test_minority_acc: 0.997439381270903
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.000363616127287969
	train_minority_loss: 7.910578278824687e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 3550
	train_minority_nonzero: 16550
val:
	val_majority_loss: 0.0478043295443058
	val_minority_loss: 3.854447641060688e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.048885125666856766
	test_minority_loss: 0.004285541363060474
	test_majority_acc: 0.9845759972593754
	test_minority_acc: 0.997439381270903
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.0001910114660859108
	train_minority_loss: 4.29652827733662e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 3550
	train_minority_nonzero: 16550
val:
	val_majority_loss: 0.05114114657044411
	val_minority_loss: 2.0589632185874507e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.048880353569984436
	test_minority_loss: 0.004932369105517864
	test_majority_acc: 0.9845759972593754
	test_minority_acc: 0.997439381270903
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.00011231928510824218
	train_minority_loss: 2.6368412363808602e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 3550
	train_minority_nonzero: 16550
val:
	val_majority_loss: 0.053065136075019836
	val_minority_loss: 1.1836707471957197e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05131310224533081
	test_minority_loss: 0.00529512157663703
	test_majority_acc: 0.9857334046667828
	test_minority_acc: 0.997439381270903
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 7.410466787405312e-05
	train_minority_loss: 1.7466269127908163e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 3550
	train_minority_nonzero: 16550
val:
	val_majority_loss: 0.0511801540851593
	val_minority_loss: 1.0064416073873872e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04924589395523071
	test_minority_loss: 0.0058515421114861965
	test_majority_acc: 0.9857334046667828
	test_minority_acc: 0.997439381270903
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 5.522237188415602e-05
	train_minority_loss: 1.2617760148714297e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 3550
	train_minority_nonzero: 16550
val:
	val_majority_loss: 0.058147650212049484
	val_minority_loss: 6.289091061262297e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0527072437107563
	test_minority_loss: 0.005813559051603079
	test_majority_acc: 0.9857334046667828
	test_minority_acc: 0.997439381270903
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 3.898621071130037e-05
	train_minority_loss: 9.295841664425097e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 3550
	train_minority_nonzero: 16550
val:
	val_majority_loss: 0.057569656521081924
	val_minority_loss: 4.767819348217017e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.053893640637397766
	test_minority_loss: 0.0060480390675365925
	test_majority_acc: 0.9857334046667828
	test_minority_acc: 0.997439381270903
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 2.8263759304536507e-05
	train_minority_loss: 7.261352493515005e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 3550
	train_minority_nonzero: 16550
val:
	val_majority_loss: 0.059466294944286346
	val_minority_loss: 3.4963298389811825e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.056019753217697144
	test_minority_loss: 0.0061913891695439816
	test_majority_acc: 0.9845759972593754
	test_minority_acc: 0.997439381270903
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.431909561157227 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.85
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.236001968383789
	train_minority_loss: 2.2805428504943848
	train_majority_acc: 0.6208468201346722
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.42741572856903076
	train_minority_loss: 0.07604127377271652
	train_majority_acc: 0.7830503442089893
	train_minority_acc: 0.99336567568109
	train_majority_nonzero: 3050
	train_minority_nonzero: 17050
val:
	val_majority_loss: 0.0660841092467308
	val_minority_loss: 0.0002952090580947697
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.06798691302537918
	test_minority_loss: 0.002707135397940874
	test_majority_acc: 0.9697903531333757
	test_minority_acc: 0.9987980769230769
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.00779883936047554
	train_minority_loss: 0.0011245764326304197
	train_majority_acc: 0.9987237017526746
	train_minority_acc: 0.9998827922471898
	train_majority_nonzero: 3050
	train_minority_nonzero: 17050
val:
	val_majority_loss: 0.04526650533080101
	val_minority_loss: 3.279261727584526e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03843618184328079
	test_minority_loss: 0.00375178805552423
	test_majority_acc: 0.9884836456123447
	test_minority_acc: 0.997439381270903
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.0010981694795191288
	train_minority_loss: 0.00020121983834542334
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 3050
	train_minority_nonzero: 17050
val:
	val_majority_loss: 0.06311852484941483
	val_minority_loss: 9.570014299242757e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.050531044602394104
	test_minority_loss: 0.0024741007946431637
	test_majority_acc: 0.985064993094116
	test_minority_acc: 0.9987980769230769
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.0004314687103033066
	train_minority_loss: 7.899040792835876e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 3050
	train_minority_nonzero: 17050
val:
	val_majority_loss: 0.07439519464969635
	val_minority_loss: 6.1707960412604734e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0531802736222744
	test_minority_loss: 0.0021181893534958363
	test_majority_acc: 0.9837352058600733
	test_minority_acc: 0.9987980769230769
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.0002405848790658638
	train_minority_loss: 4.526663542492315e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 3050
	train_minority_nonzero: 17050
val:
	val_majority_loss: 0.08106641471385956
	val_minority_loss: 1.8858210069083725e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.060762371867895126
	test_minority_loss: 0.0021099927835166454
	test_majority_acc: 0.9837352058600733
	test_minority_acc: 0.9987980769230769
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.00015319249359890819
	train_minority_loss: 2.8623830075957812e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 3050
	train_minority_nonzero: 17050
val:
	val_majority_loss: 0.07246380299329758
	val_minority_loss: 1.765300908118661e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05539660155773163
	test_minority_loss: 0.0025652230251580477
	test_majority_acc: 0.9848926132674807
	test_minority_acc: 0.9987980769230769
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.00010300861322320998
	train_minority_loss: 2.0034638509969227e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 3050
	train_minority_nonzero: 17050
val:
	val_majority_loss: 0.08026071637868881
	val_minority_loss: 1.201083250634838e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.059676643460989
	test_minority_loss: 0.0023661977611482143
	test_majority_acc: 0.9837352058600733
	test_minority_acc: 0.9987980769230769
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 7.465640373993665e-05
	train_minority_loss: 1.426289054506924e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 3050
	train_minority_nonzero: 17050
val:
	val_majority_loss: 0.0810605138540268
	val_minority_loss: 7.899541287770262e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.06055988371372223
	test_minority_loss: 0.0024485827889293432
	test_majority_acc: 0.9837352058600733
	test_minority_acc: 0.9987980769230769
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 5.480105028254911e-05
	train_minority_loss: 1.0854023457795847e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 3050
	train_minority_nonzero: 17050
val:
	val_majority_loss: 0.0874161422252655
	val_minority_loss: 6.583469485121896e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.06353460252285004
	test_minority_loss: 0.002302397508174181
	test_majority_acc: 0.9837352058600733
	test_minority_acc: 0.9987980769230769
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 4.2932260839734226e-05
	train_minority_loss: 8.602201887697447e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 3050
	train_minority_nonzero: 17050
val:
	val_majority_loss: 0.0820382758975029
	val_minority_loss: 6.518062036775518e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05943676084280014
	test_minority_loss: 0.0027087649796158075
	test_majority_acc: 0.9848926132674807
	test_minority_acc: 0.9987980769230769
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.364447832107544 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.875
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2359488010406494
	train_minority_loss: 2.2805256843566895
	train_majority_acc: 0.6120761830171606
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.5665173530578613
	train_minority_loss: 0.07604683190584183
	train_majority_acc: 0.7174499162756406
	train_minority_acc: 0.9935993710342453
	train_majority_nonzero: 2550
	train_minority_nonzero: 17550
val:
	val_majority_loss: 0.02865145355463028
	val_minority_loss: 0.0007602946134284139
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03577367216348648
	test_minority_loss: 0.004918096121400595
	test_majority_acc: 0.9882699142098712
	test_minority_acc: 0.9987980769230769
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.011126755736768246
	train_minority_loss: 0.0014689227100461721
	train_majority_acc: 0.9975326083535039
	train_minority_acc: 0.999764076443181
	train_majority_nonzero: 2550
	train_minority_nonzero: 17550
val:
	val_majority_loss: 0.06439805030822754
	val_minority_loss: 4.3858366552740335e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.056325558573007584
	test_minority_loss: 0.0013893123250454664
	test_majority_acc: 0.9792385501837386
	test_minority_acc: 1.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.001388366217724979
	train_minority_loss: 0.00020973829668946564
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2550
	train_minority_nonzero: 17550
val:
	val_majority_loss: 0.056527066975831985
	val_minority_loss: 1.023057757265633e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0558696985244751
	test_minority_loss: 0.0014600289287045598
	test_majority_acc: 0.9808388026179254
	test_minority_acc: 0.9987980769230769
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.0005548408953472972
	train_minority_loss: 8.011765021365136e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2550
	train_minority_nonzero: 17550
val:
	val_majority_loss: 0.06968115270137787
	val_minority_loss: 5.9068252085126005e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.06102495640516281
	test_minority_loss: 0.0013370087835937738
	test_majority_acc: 0.9780209201457877
	test_minority_acc: 0.9987980769230769
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.0002832346362993121
	train_minority_loss: 4.337870632298291e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2550
	train_minority_nonzero: 17550
val:
	val_majority_loss: 0.08104608207941055
	val_minority_loss: 2.52160816671676e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.06989830732345581
	test_minority_loss: 0.0011911554029211402
	test_majority_acc: 0.976691132911745
	test_minority_acc: 0.9987980769230769
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.0001933830208145082
	train_minority_loss: 2.9843849915778264e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2550
	train_minority_nonzero: 17550
val:
	val_majority_loss: 0.07391215860843658
	val_minority_loss: 2.237673243143945e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.06377503275871277
	test_minority_loss: 0.0016049700789153576
	test_majority_acc: 0.9806007073798302
	test_minority_acc: 0.9987980769230769
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.00012511191016528755
	train_minority_loss: 1.9369406800251454e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2550
	train_minority_nonzero: 17550
val:
	val_majority_loss: 0.0799829363822937
	val_minority_loss: 1.534001853542577e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.06600012630224228
	test_minority_loss: 0.0015728856669738889
	test_majority_acc: 0.9792709201457876
	test_minority_acc: 0.9987980769230769
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 8.756778697716072e-05
	train_minority_loss: 1.4485916835837997e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2550
	train_minority_nonzero: 17550
val:
	val_majority_loss: 0.08461976051330566
	val_minority_loss: 9.897381687551388e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0691235214471817
	test_minority_loss: 0.0015657214680686593
	test_majority_acc: 0.9792709201457876
	test_minority_acc: 0.9987980769230769
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 6.40761136310175e-05
	train_minority_loss: 1.0879472938540857e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2550
	train_minority_nonzero: 17550
val:
	val_majority_loss: 0.08349794149398804
	val_minority_loss: 8.365086614503525e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.06943883746862411
	test_minority_loss: 0.0017087988089770079
	test_majority_acc: 0.9792709201457876
	test_minority_acc: 0.9987980769230769
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 4.6364322770386934e-05
	train_minority_loss: 8.572396836825646e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2550
	train_minority_nonzero: 17550
val:
	val_majority_loss: 0.09049957990646362
	val_minority_loss: 5.569818881667743e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0764179527759552
	test_minority_loss: 0.001436438295058906
	test_majority_acc: 0.9779411329117451
	test_minority_acc: 0.9987980769230769
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.463992834091187 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.9
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235722541809082
	train_minority_loss: 2.2804977893829346
	train_majority_acc: 0.6104700026341818
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.7023801803588867
	train_minority_loss: 0.07216091454029083
	train_majority_acc: 0.6707607877603488
	train_minority_acc: 0.9939190826738494
	train_majority_nonzero: 2050
	train_minority_nonzero: 18050
val:
	val_majority_loss: 0.16681739687919617
	val_minority_loss: 6.551760452566668e-05
	val_majority_acc: 0.9415720891130728
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.20598013699054718
	test_minority_loss: 0.0009375180816277862
	test_majority_acc: 0.9290648765517762
	test_minority_acc: 1.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.01409280113875866
	train_minority_loss: 0.001223948784172535
	train_majority_acc: 0.9967193944805884
	train_minority_acc: 0.9997763283018044
	train_majority_nonzero: 2050
	train_minority_nonzero: 18050
val:
	val_majority_loss: 0.07474826276302338
	val_minority_loss: 1.6178435544134118e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.08511205017566681
	test_minority_loss: 0.0011674952693283558
	test_majority_acc: 0.9703119968783537
	test_minority_acc: 1.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.001814202289097011
	train_minority_loss: 0.00018470957002136856
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2050
	train_minority_nonzero: 18050
val:
	val_majority_loss: 0.054228365421295166
	val_minority_loss: 2.3426287953043357e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05309680849313736
	test_minority_loss: 0.0025969308335334063
	test_majority_acc: 0.9819000222814687
	test_minority_acc: 0.9987980769230769
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.0007400491740554571
	train_minority_loss: 7.228008325910196e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2050
	train_minority_nonzero: 18050
val:
	val_majority_loss: 0.092696413397789
	val_minority_loss: 2.0898553430015454e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0979558601975441
	test_minority_loss: 0.0010821223258972168
	test_majority_acc: 0.9692155056502836
	test_minority_acc: 0.9987980769230769
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.0003829814959317446
	train_minority_loss: 3.6635676224250346e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2050
	train_minority_nonzero: 18050
val:
	val_majority_loss: 0.1020776778459549
	val_minority_loss: 9.600234989193268e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.10835175216197968
	test_minority_loss: 0.0009500369778834283
	test_majority_acc: 0.9692155056502836
	test_minority_acc: 0.9987980769230769
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.0002547701296862215
	train_minority_loss: 2.351908005948644e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2050
	train_minority_nonzero: 18050
val:
	val_majority_loss: 0.09221787750720978
	val_minority_loss: 9.121457651417586e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0946163684129715
	test_minority_loss: 0.001226746360771358
	test_majority_acc: 0.9715139199552768
	test_minority_acc: 0.9987980769230769
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.00016439100727438927
	train_minority_loss: 1.637977948121261e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2050
	train_minority_nonzero: 18050
val:
	val_majority_loss: 0.10268489271402359
	val_minority_loss: 4.990062052456778e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.10571637749671936
	test_minority_loss: 0.0010975009063258767
	test_majority_acc: 0.9692155056502836
	test_minority_acc: 0.9987980769230769
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.00012432217772584409
	train_minority_loss: 1.2030294783471618e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2050
	train_minority_nonzero: 18050
val:
	val_majority_loss: 0.10406218469142914
	val_minority_loss: 3.8175284089447814e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.10334286093711853
	test_minority_loss: 0.0011456385254859924
	test_majority_acc: 0.9704174287272067
	test_minority_acc: 0.9987980769230769
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 9.006662003230304e-05
	train_minority_loss: 9.071437489183154e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2050
	train_minority_nonzero: 18050
val:
	val_majority_loss: 0.10713599622249603
	val_minority_loss: 2.752473449163517e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.10628616064786911
	test_minority_loss: 0.00110464240424335
	test_majority_acc: 0.9704174287272067
	test_minority_acc: 0.9987980769230769
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 7.492453732993454e-05
	train_minority_loss: 7.4030681389558595e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2050
	train_minority_nonzero: 18050
val:
	val_majority_loss: 0.11799457669258118
	val_minority_loss: 1.6904212429835752e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.11767242848873138
	test_minority_loss: 0.0009117089794017375
	test_majority_acc: 0.9704174287272067
	test_minority_acc: 0.9987980769230769
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.256108045578003 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.925
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235808849334717
	train_minority_loss: 2.2804765701293945
	train_majority_acc: 0.6131854740063696
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.8452076315879822
	train_minority_loss: 0.06872030347585678
	train_majority_acc: 0.628422641482343
	train_minority_acc: 0.9942704079827609
	train_majority_nonzero: 1550
	train_minority_nonzero: 18550
val:
	val_majority_loss: 0.1678732931613922
	val_minority_loss: 0.00011058510426664725
	val_majority_acc: 0.9415720891130728
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.20045624673366547
	test_minority_loss: 0.0005870764725841582
	test_majority_acc: 0.9274786959401717
	test_minority_acc: 1.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.014477015472948551
	train_minority_loss: 0.0009267307468689978
	train_majority_acc: 0.9988805970149254
	train_minority_acc: 0.99989300807789
	train_majority_nonzero: 1550
	train_minority_nonzero: 18550
val:
	val_majority_loss: 0.08197275549173355
	val_minority_loss: 2.0500323444139212e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.09207674860954285
	test_minority_loss: 0.000595213146880269
	test_majority_acc: 0.9670901362352483
	test_minority_acc: 1.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.001747016601245832
	train_minority_loss: 0.00011969012120971456
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1550
	train_minority_nonzero: 18550
val:
	val_majority_loss: 0.07939472049474716
	val_minority_loss: 8.055568287090864e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.08654408156871796
	test_minority_loss: 0.0006949089583940804
	test_majority_acc: 0.9695773308766983
	test_minority_acc: 1.0
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.0006376298842951655
	train_minority_loss: 4.853198697674088e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1550
	train_minority_nonzero: 18550
val:
	val_majority_loss: 0.08613483607769012
	val_minority_loss: 3.187084075761959e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.09417930245399475
	test_minority_loss: 0.0005406756536103785
	test_majority_acc: 0.9672180003923677
	test_minority_acc: 1.0
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.0003176539030391723
	train_minority_loss: 2.5689763788250275e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1550
	train_minority_nonzero: 18550
val:
	val_majority_loss: 0.09988560527563095
	val_minority_loss: 1.3252296184873558e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.10868950933218002
	test_minority_loss: 0.0003733104676939547
	test_majority_acc: 0.9658882131583252
	test_minority_acc: 1.0
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.000204947660677135
	train_minority_loss: 1.4982547327235807e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1550
	train_minority_nonzero: 18550
val:
	val_majority_loss: 0.10196931660175323
	val_minority_loss: 8.19571653210005e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.1109214723110199
	test_minority_loss: 0.0003855103568639606
	test_majority_acc: 0.9672180003923677
	test_minority_acc: 1.0
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.00012258092465344816
	train_minority_loss: 1.0253344953525811e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1550
	train_minority_nonzero: 18550
val:
	val_majority_loss: 0.10726051032543182
	val_minority_loss: 5.289958266985195e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.11518332362174988
	test_minority_loss: 0.0003374459338374436
	test_majority_acc: 0.9658882131583252
	test_minority_acc: 1.0
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 8.815152250463143e-05
	train_minority_loss: 7.2846546572691295e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1550
	train_minority_nonzero: 18550
val:
	val_majority_loss: 0.10931327939033508
	val_minority_loss: 3.9164922327472595e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.11622782051563263
	test_minority_loss: 0.0003210423747077584
	test_majority_acc: 0.9672180003923677
	test_minority_acc: 1.0
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 6.421536818379536e-05
	train_minority_loss: 5.337075890565757e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1550
	train_minority_nonzero: 18550
val:
	val_majority_loss: 0.11620184779167175
	val_minority_loss: 2.2431197521655122e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.12492672353982925
	test_minority_loss: 0.00027233961736783385
	test_majority_acc: 0.9658882131583252
	test_minority_acc: 1.0
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 5.08466582687106e-05
	train_minority_loss: 3.909308361471631e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1550
	train_minority_nonzero: 18550
val:
	val_majority_loss: 0.11327497661113739
	val_minority_loss: 1.7741028557338723e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.12089985609054565
	test_minority_loss: 0.00032009591814130545
	test_majority_acc: 0.9671382131583253
	test_minority_acc: 1.0
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.261234521865845 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.95
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2349295616149902
	train_minority_loss: 2.2804789543151855
	train_majority_acc: 0.6494906558339394
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 1.1473776154074584
	train_minority_loss: 0.0649256780743599
	train_majority_acc: 0.542218253968254
	train_minority_acc: 0.9943420466964202
	train_majority_nonzero: 1050
	train_minority_nonzero: 19050
val:
	val_majority_loss: 0.5605546832084656
	val_minority_loss: 2.5408158762729727e-05
	val_majority_acc: 0.844682639764607
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.6245346069335938
	test_minority_loss: 9.649695857660845e-05
	test_majority_acc: 0.8162146180463926
	test_minority_acc: 1.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.03387712687376437
	train_minority_loss: 0.0012498546857386827
	train_majority_acc: 0.9922050729839675
	train_minority_acc: 0.9997882686172983
	train_majority_nonzero: 1050
	train_minority_nonzero: 19050
val:
	val_majority_loss: 0.1458754986524582
	val_minority_loss: 1.1067722880397923e-05
	val_majority_acc: 0.9625893232450609
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.15954121947288513
	test_minority_loss: 0.000694276939611882
	test_majority_acc: 0.9517130771244513
	test_minority_acc: 1.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.002326213735983916
	train_minority_loss: 0.00011621131852734834
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1050
	train_minority_nonzero: 19050
val:
	val_majority_loss: 0.12543243169784546
	val_minority_loss: 5.568116193899186e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.12295448780059814
	test_minority_loss: 0.0012638095067813993
	test_majority_acc: 0.9641217576899768
	test_minority_acc: 0.9987980769230769
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.0006039250292815268
	train_minority_loss: 3.847806146950461e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1050
	train_minority_nonzero: 19050
val:
	val_majority_loss: 0.1309356987476349
	val_minority_loss: 3.2072243811853696e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.12328898161649704
	test_minority_loss: 0.001302969641983509
	test_majority_acc: 0.9694455934801054
	test_minority_acc: 0.9987980769230769
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.000301313993986696
	train_minority_loss: 1.8795715732267126e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1050
	train_minority_nonzero: 19050
val:
	val_majority_loss: 0.14422228932380676
	val_minority_loss: 1.736977992550237e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.13447971642017365
	test_minority_loss: 0.0012945749331265688
	test_majority_acc: 0.9694455934801054
	test_minority_acc: 0.9987980769230769
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.00017729274069267832
	train_minority_loss: 1.1911203728232067e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1050
	train_minority_nonzero: 19050
val:
	val_majority_loss: 0.14408524334430695
	val_minority_loss: 1.2332950518612051e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.13155248761177063
	test_minority_loss: 0.0014694557758048177
	test_majority_acc: 0.9694455934801054
	test_minority_acc: 0.9987980769230769
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.00010256314507278457
	train_minority_loss: 8.517330570612103e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1050
	train_minority_nonzero: 19050
val:
	val_majority_loss: 0.16006016731262207
	val_minority_loss: 8.334200174431317e-07
	val_majority_acc: 0.9707860445565364
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.14903002977371216
	test_minority_loss: 0.0012341997353360057
	test_majority_acc: 0.9649618555404851
	test_minority_acc: 0.9987980769230769
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 7.247370048535373e-05
	train_minority_loss: 5.951154889771715e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1050
	train_minority_nonzero: 19050
val:
	val_majority_loss: 0.1623893678188324
	val_minority_loss: 7.034677764750086e-07
	val_majority_acc: 0.9707860445565364
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.148590087890625
	test_minority_loss: 0.001315238419920206
	test_majority_acc: 0.9694455934801054
	test_minority_acc: 0.9987980769230769
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 5.144690100822302e-05
	train_minority_loss: 4.51163532488863e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1050
	train_minority_nonzero: 19050
val:
	val_majority_loss: 0.1756635308265686
	val_minority_loss: 4.6969094569249137e-07
	val_majority_acc: 0.9707860445565364
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.1636849194765091
	test_minority_loss: 0.0011587971821427345
	test_majority_acc: 0.9636320683064425
	test_minority_acc: 0.9987980769230769
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 4.1321778553538024e-05
	train_minority_loss: 3.467348506092094e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1050
	train_minority_nonzero: 19050
val:
	val_majority_loss: 0.17514359951019287
	val_minority_loss: 4.12467869637112e-07
	val_majority_acc: 0.9707860445565364
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.1604761928319931
	test_minority_loss: 0.0012411798816174269
	test_majority_acc: 0.9649618555404851
	test_minority_acc: 0.9987980769230769
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.256518840789795 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.975
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.234567921240251
	train_minority_loss: 2.280471086502075
	train_majority_acc: 0.6430468341182627
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 1.8491357866393325
	train_minority_loss: 0.059129368513822556
	train_majority_acc: 0.38342013888888893
	train_minority_acc: 0.9947699854388796
	train_majority_nonzero: 550
	train_minority_nonzero: 19550
val:
	val_majority_loss: 0.19387593865394592
	val_minority_loss: 0.0004788509977515787
	val_majority_acc: 0.92875157629256
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.22299963235855103
	test_minority_loss: 0.0018335228087380528
	test_majority_acc: 0.9147846543360485
	test_minority_acc: 1.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.05604603897867374
	train_minority_loss: 0.0010639848187565804
	train_majority_acc: 0.9856630824372759
	train_minority_acc: 0.9998952489326417
	train_majority_nonzero: 550
	train_minority_nonzero: 19550
val:
	val_majority_loss: 0.10398202389478683
	val_minority_loss: 1.8449056369718164e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.1613312065601349
	test_minority_loss: 0.0008339481428265572
	test_majority_acc: 0.9463680467879947
	test_minority_acc: 1.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.003749725214478501
	train_minority_loss: 0.00011495591752463952
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 550
	train_minority_nonzero: 19550
val:
	val_majority_loss: 0.10351695120334625
	val_minority_loss: 5.543529823626159e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.16953937709331512
	test_minority_loss: 0.0006195505266077816
	test_majority_acc: 0.9527891953301538
	test_minority_acc: 1.0
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.0015791873778413883
	train_minority_loss: 4.093421375728212e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 550
	train_minority_nonzero: 19550
val:
	val_majority_loss: 0.11557203531265259
	val_minority_loss: 2.5798722163017374e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.1880185902118683
	test_minority_loss: 0.000431065825978294
	test_majority_acc: 0.9501436926846512
	test_minority_acc: 1.0
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.000798817445422782
	train_minority_loss: 2.1241581634967588e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 550
	train_minority_nonzero: 19550
val:
	val_majority_loss: 0.11813460290431976
	val_minority_loss: 1.510459469500347e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.19736681878566742
	test_minority_loss: 0.0003814322408288717
	test_majority_acc: 0.9501436926846512
	test_minority_acc: 1.0
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.0005214208097626133
	train_minority_loss: 1.3091075743432157e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 550
	train_minority_nonzero: 19550
val:
	val_majority_loss: 0.11228092759847641
	val_minority_loss: 1.0207212426394108e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.18831001222133636
	test_minority_loss: 0.0004741244192700833
	test_majority_acc: 0.95622008157354
	test_minority_acc: 1.0
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.0003029396579771615
	train_minority_loss: 8.891530342225451e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 550
	train_minority_nonzero: 19550
val:
	val_majority_loss: 0.11700357496738434
	val_minority_loss: 7.014887160039507e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.1989169716835022
	test_minority_loss: 0.00043053951230831444
	test_majority_acc: 0.9551040101449686
	test_minority_acc: 1.0
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.00021124795274600258
	train_minority_loss: 6.377003501256695e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 550
	train_minority_nonzero: 19550
val:
	val_majority_loss: 0.11119592189788818
	val_minority_loss: 6.148277975626115e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.18920697271823883
	test_minority_loss: 0.0005041852127760649
	test_majority_acc: 0.9587998688075826
	test_minority_acc: 1.0
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.00015398100768658767
	train_minority_loss: 4.831530077353818e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 550
	train_minority_nonzero: 19550
val:
	val_majority_loss: 0.1270858645439148
	val_minority_loss: 3.735838731699914e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.21459299325942993
	test_minority_loss: 0.0003380407579243183
	test_majority_acc: 0.9527891953301537
	test_minority_acc: 1.0
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.0001159058949256338
	train_minority_loss: 3.604415951485862e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 550
	train_minority_nonzero: 19550
val:
	val_majority_loss: 0.13373681902885437
	val_minority_loss: 2.731169956859958e-07
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.2246280312538147
	test_minority_loss: 0.0002891567419283092
	test_majority_acc: 0.9527891953301537
	test_minority_acc: 1.0
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.20883059501648 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: naive
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 1.0
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.236476497216658
	train_minority_loss: 2.2804484367370605
	train_majority_acc: 0.4772727272727273
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 7.227329274441334
	train_minority_loss: 0.04942169785499573
	train_majority_acc: 0.0
	train_minority_acc: 0.9950248756218906
	train_majority_nonzero: 50
	train_minority_nonzero: 20050
val:
	val_majority_loss: 4.573299407958984
	val_minority_loss: 0.0033849391620606184
	val_majority_acc: 0.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 4.506211757659912
	test_minority_loss: 0.003223775653168559
	test_majority_acc: 0.0
	test_minority_acc: 1.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 4.175180978553239
	train_minority_loss: 0.0020170463249087334
	train_majority_acc: 0.0
	train_minority_acc: 1.0
	train_majority_nonzero: 50
	train_minority_nonzero: 20050
val:
	val_majority_loss: 4.870608329772949
	val_minority_loss: 0.00010997634672094136
	val_majority_acc: 0.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 4.74592399597168
	test_minority_loss: 0.0001414957660017535
	test_majority_acc: 0.0
	test_minority_acc: 1.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.9691255165115845
	train_minority_loss: 0.0006849454366602004
	train_majority_acc: 0.5340909090909091
	train_minority_acc: 1.0
	train_majority_nonzero: 50
	train_minority_nonzero: 20050
val:
	val_majority_loss: 1.8354415893554688
	val_minority_loss: 2.6997538952855393e-05
	val_majority_acc: 0.33417402269861285
	val_minority_acc: 1.0
test:
	test_majority_loss: 1.587801218032837
	test_minority_loss: 0.00016484690422657877
	test_majority_acc: 0.4331673774283812
	test_minority_acc: 1.0
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.0377714428563364
	train_minority_loss: 6.866530020488426e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 50
	train_minority_nonzero: 20050
val:
	val_majority_loss: 1.6621150970458984
	val_minority_loss: 5.409478944784496e-06
	val_majority_acc: 0.442833123160992
	val_minority_acc: 1.0
test:
	test_majority_loss: 1.45096755027771
	test_minority_loss: 6.798120739404112e-05
	test_majority_acc: 0.5381544594397563
	test_minority_acc: 1.0
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.010412007744889706
	train_minority_loss: 1.8666092728381045e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 50
	train_minority_nonzero: 20050
val:
	val_majority_loss: 1.5410375595092773
	val_minority_loss: 2.958947561637615e-06
	val_majority_acc: 0.49663724253888186
	val_minority_acc: 1.0
test:
	test_majority_loss: 1.3378918170928955
	test_minority_loss: 6.586623203475028e-05
	test_majority_acc: 0.5945382595968081
	test_minority_acc: 1.0
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.004890693030837509
	train_minority_loss: 1.0319994544261135e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 50
	train_minority_nonzero: 20050
val:
	val_majority_loss: 1.6690905094146729
	val_minority_loss: 1.5790686802574783e-06
	val_majority_acc: 0.49663724253888186
	val_minority_acc: 1.0
test:
	test_majority_loss: 1.4483143091201782
	test_minority_loss: 4.250004349160008e-05
	test_majority_acc: 0.5811621599357832
	test_minority_acc: 1.0
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.003095150465794307
	train_minority_loss: 6.79663207847625e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 50
	train_minority_nonzero: 20050
val:
	val_majority_loss: 1.9037370681762695
	val_minority_loss: 8.97639097274805e-07
	val_majority_acc: 0.46742328709541825
	val_minority_acc: 1.0
test:
	test_majority_loss: 1.6465821266174316
	test_minority_loss: 2.419503653072752e-05
	test_majority_acc: 0.5520933490610911
	test_minority_acc: 1.0
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.0019901834604515107
	train_minority_loss: 4.58097110822564e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 50
	train_minority_nonzero: 20050
val:
	val_majority_loss: 1.901322364807129
	val_minority_loss: 6.38632570826303e-07
	val_majority_acc: 0.47562000840689367
	val_minority_acc: 1.0
test:
	test_majority_loss: 1.6400216817855835
	test_minority_loss: 2.175267400161829e-05
	test_majority_acc: 0.5617069175571676
	test_minority_acc: 1.0
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.0013570273782364851
	train_minority_loss: 3.5149121231370373e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 50
	train_minority_nonzero: 20050
val:
	val_majority_loss: 1.980359673500061
	val_minority_loss: 4.915651174997038e-07
	val_majority_acc: 0.47562000840689367
	val_minority_acc: 1.0
test:
	test_majority_loss: 1.7081239223480225
	test_minority_loss: 1.730007352307439e-05
	test_majority_acc: 0.5567610588945536
	test_minority_acc: 1.0
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.0010349898574614517
	train_minority_loss: 2.561731207606499e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 50
	train_minority_nonzero: 20050
val:
	val_majority_loss: 1.9923126697540283
	val_minority_loss: 3.8157759263413027e-07
	val_majority_acc: 0.47562000840689367
	val_minority_acc: 1.0
test:
	test_majority_loss: 1.7185533046722412
	test_minority_loss: 1.5431291103595868e-05
	test_majority_acc: 0.561620389378884
	test_minority_acc: 1.0
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 20.14843249320984 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.5
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2358131408691406
	train_minority_loss: 2.2805604934692383
	train_majority_acc: 0.6259720229956415
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.14700543880462646
	train_minority_loss: 0.20274880528450012
	train_majority_acc: 0.9777084989450999
	train_minority_acc: 0.9355928839884489
	train_majority_nonzero: 5768
	train_minority_nonzero: 5486
val:
	val_majority_loss: 0.018284866586327553
	val_minority_loss: 0.019086141139268875
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.020254280418157578
	test_minority_loss: 0.03764957934617996
	test_majority_acc: 0.9918813195771029
	test_minority_acc: 0.9853677316278083
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.01271460298448801
	train_minority_loss: 0.020834386348724365
	train_majority_acc: 0.9960637563980538
	train_minority_acc: 0.996148594226921
	train_majority_nonzero: 5911
	train_minority_nonzero: 6170
val:
	val_majority_loss: 0.020652886480093002
	val_minority_loss: 0.004270657896995544
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.016719086095690727
	test_minority_loss: 0.024165060371160507
	test_majority_acc: 0.9935898715649102
	test_minority_acc: 0.9912042664698053
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.009330579079687595
	train_minority_loss: 0.011936802417039871
	train_majority_acc: 0.9968319700248081
	train_minority_acc: 0.9978579651269616
	train_majority_nonzero: 4352
	train_minority_nonzero: 7573
val:
	val_majority_loss: 0.022738343104720116
	val_minority_loss: 0.0006079655140638351
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02807427942752838
	test_minority_loss: 0.015034530311822891
	test_majority_acc: 0.9871809567479086
	test_minority_acc: 0.9912462339728303
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.008003567345440388
	train_minority_loss: 0.005644301883876324
	train_majority_acc: 0.9974140682877285
	train_minority_acc: 0.9984570574483531
	train_majority_nonzero: 3941
	train_minority_nonzero: 7331
val:
	val_majority_loss: 0.035518791526556015
	val_minority_loss: 0.0003992304264102131
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.025172537192702293
	test_minority_loss: 0.016038311645388603
	test_majority_acc: 0.9922242411329483
	test_minority_acc: 0.9938596779188213
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.00457658851519227
	train_minority_loss: 0.0012341132387518883
	train_majority_acc: 0.9990158729510349
	train_minority_acc: 0.9996997582891641
	train_majority_nonzero: 3846
	train_minority_nonzero: 7275
val:
	val_majority_loss: 0.0009025412146002054
	val_minority_loss: 0.0011539730476215482
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.009005977772176266
	test_minority_loss: 0.08463877439498901
	test_majority_acc: 0.9966422636611085
	test_minority_acc: 0.9804998671150229
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.005968104116618633
	train_minority_loss: 0.003733762539923191
	train_majority_acc: 0.9981489513549174
	train_minority_acc: 0.9989297153108575
	train_majority_nonzero: 3850
	train_minority_nonzero: 6438
val:
	val_majority_loss: 0.017025640234351158
	val_minority_loss: 0.0009330118191428483
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01802712492644787
	test_minority_loss: 0.026924846693873405
	test_majority_acc: 0.992268756802464
	test_minority_acc: 0.9938596779188213
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.004694524221122265
	train_minority_loss: 5.3937514167046174e-05
	train_majority_acc: 0.998579704837294
	train_minority_acc: 1.0
	train_majority_nonzero: 3451
	train_minority_nonzero: 6234
val:
	val_majority_loss: 0.03697795420885086
	val_minority_loss: 0.000126424158224836
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.029479114338755608
	test_minority_loss: 0.01821053773164749
	test_majority_acc: 0.9911526853738926
	test_minority_acc: 0.9938596779188213
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.005186707247048616
	train_minority_loss: 2.5671079129097052e-05
	train_majority_acc: 0.998509291601628
	train_minority_acc: 1.0
	train_majority_nonzero: 3163
	train_minority_nonzero: 5301
val:
	val_majority_loss: 0.04379463195800781
	val_minority_loss: 7.211780757643282e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03331197053194046
	test_minority_loss: 0.015639200806617737
	test_majority_acc: 0.9911526853738926
	test_minority_acc: 0.9938596779188213
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.005360739771276712
	train_minority_loss: 1.7450793166062795e-05
	train_majority_acc: 0.9984324269717341
	train_minority_acc: 1.0
	train_majority_nonzero: 2747
	train_minority_nonzero: 4717
val:
	val_majority_loss: 0.03264649212360382
	val_minority_loss: 6.573538848897442e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.030202776193618774
	test_minority_loss: 0.018710272386670113
	test_majority_acc: 0.9924026853738925
	test_minority_acc: 0.9938596779188213
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.005459572654217482
	train_minority_loss: 1.3047018001088873e-05
	train_majority_acc: 0.9984500736423129
	train_minority_acc: 1.0
	train_majority_nonzero: 2499
	train_minority_nonzero: 4276
val:
	val_majority_loss: 0.029022283852100372
	val_minority_loss: 5.470892210723832e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02998972311615944
	test_minority_loss: 0.01928003877401352
	test_majority_acc: 0.9924026853738925
	test_minority_acc: 0.9938596779188213
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.805638790130615 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.525
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2358930110931396
	train_minority_loss: 2.2805631160736084
	train_majority_acc: 0.6249174647643717
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.1454736292362213
	train_minority_loss: 0.19944918155670166
	train_majority_acc: 0.9829043741853438
	train_minority_acc: 0.9411545786787998
	train_majority_nonzero: 5921
	train_minority_nonzero: 4990
val:
	val_majority_loss: 0.00812006089836359
	val_minority_loss: 0.027460558339953423
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.014715207740664482
	test_minority_loss: 0.05307956784963608
	test_majority_acc: 0.9989035087719298
	test_minority_acc: 0.9845575221537827
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.01434699073433876
	train_minority_loss: 0.024207618087530136
	train_majority_acc: 0.9964062992452279
	train_minority_acc: 0.993680312186785
	train_majority_nonzero: 6366
	train_minority_nonzero: 5018
val:
	val_majority_loss: 0.04343250021338463
	val_minority_loss: 0.0030468562617897987
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0411161407828331
	test_minority_loss: 0.009630614891648293
	test_majority_acc: 0.9869300561512633
	test_minority_acc: 0.997439381270903
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.005976553540676832
	train_minority_loss: 0.009770394302904606
	train_majority_acc: 0.9988359053358001
	train_minority_acc: 0.9972043202889994
	train_majority_nonzero: 6717
	train_minority_nonzero: 5479
val:
	val_majority_loss: 0.006776705849915743
	val_minority_loss: 0.002127306303009391
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.020062502473592758
	test_minority_loss: 0.024883192032575607
	test_majority_acc: 0.9906793965001799
	test_minority_acc: 0.9927820917119248
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.004131321795284748
	train_minority_loss: 0.005663518328219652
	train_majority_acc: 0.9986150248341232
	train_minority_acc: 0.9989098623352334
	train_majority_nonzero: 5781
	train_minority_nonzero: 4838
val:
	val_majority_loss: 5.3430299885803834e-05
	val_minority_loss: 0.0035334834828972816
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01037842407822609
	test_minority_loss: 0.05300184339284897
	test_majority_acc: 0.9953983280754175
	test_minority_acc: 0.9875663703643385
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.0028497432358562946
	train_minority_loss: 0.00395052507519722
	train_majority_acc: 0.9987223897828461
	train_minority_acc: 0.9992666851782291
	train_majority_nonzero: 3731
	train_minority_nonzero: 5313
val:
	val_majority_loss: 0.030718054622411728
	val_minority_loss: 0.002350080758333206
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.029612179845571518
	test_minority_loss: 0.02355203405022621
	test_majority_acc: 0.9890634371049651
	test_minority_acc: 0.9948066476157911
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.00015137095761019737
	train_minority_loss: 0.00024008478794712573
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 4008
	train_minority_nonzero: 7458
val:
	val_majority_loss: 0.0004724964965134859
	val_minority_loss: 0.0030212008859962225
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.013438917696475983
	test_minority_loss: 0.040598075836896896
	test_majority_acc: 0.9957159060432684
	test_minority_acc: 0.9912269442637095
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 6.251496870390838e-06
	train_minority_loss: 1.7165033568744548e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1462
	train_minority_nonzero: 3104
val:
	val_majority_loss: 0.0004428181273397058
	val_minority_loss: 0.0017988703912124038
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01801581308245659
	test_minority_loss: 0.04322686791419983
	test_majority_acc: 0.9946194148151982
	test_minority_acc: 0.9936274023327722
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 2.4242137897090288e-06
	train_minority_loss: 7.313102742045885e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 926
	train_minority_nonzero: 1869
val:
	val_majority_loss: 0.000713699555490166
	val_minority_loss: 0.0011900713434442878
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.021906137466430664
	test_minority_loss: 0.04257092624902725
	test_majority_acc: 0.9946194148151982
	test_minority_acc: 0.9936274023327722
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 2.7656174097501207e-06
	train_minority_loss: 4.630990588339046e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 720
	train_minority_nonzero: 1702
val:
	val_majority_loss: 0.00032905754051171243
	val_minority_loss: 0.0015832141507416964
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0203151423484087
	test_minority_loss: 0.04742533713579178
	test_majority_acc: 0.9946194148151982
	test_minority_acc: 0.9936274023327722
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 1.4481692005574587e-06
	train_minority_loss: 3.996426130470354e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 665
	train_minority_nonzero: 1246
val:
	val_majority_loss: 0.00036898741382174194
	val_minority_loss: 0.0012317243963479996
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02162620797753334
	test_minority_loss: 0.047006525099277496
	test_majority_acc: 0.9946194148151982
	test_minority_acc: 0.9936274023327722
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.82287311553955 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.55
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.23592209815979
	train_minority_loss: 2.280592679977417
	train_majority_acc: 0.6260342879291987
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.16947169601917267
	train_minority_loss: 0.2070048451423645
	train_majority_acc: 0.9601480586307246
	train_minority_acc: 0.9512078751657816
	train_majority_nonzero: 6085
	train_minority_nonzero: 4749
val:
	val_majority_loss: 0.014305857941508293
	val_minority_loss: 0.017497915774583817
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.013963176868855953
	test_minority_loss: 0.03851490467786789
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.9882258745127661
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.017125748097896576
	train_minority_loss: 0.026652978733181953
	train_majority_acc: 0.9951388116019116
	train_minority_acc: 0.9934454029287234
	train_majority_nonzero: 6411
	train_minority_nonzero: 5590
val:
	val_majority_loss: 0.08788742125034332
	val_minority_loss: 0.004273625090718269
	val_majority_acc: 0.9625893232450609
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0861659124493599
	test_minority_loss: 0.009342120960354805
	test_majority_acc: 0.9656976514841582
	test_minority_acc: 0.9987980769230769
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.010223847813904285
	train_minority_loss: 0.009985617361962795
	train_majority_acc: 0.9979123569497428
	train_minority_acc: 0.9983262553551264
	train_majority_nonzero: 6876
	train_minority_nonzero: 6301
val:
	val_majority_loss: 0.011406113393604755
	val_minority_loss: 0.0014768741093575954
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0302143357694149
	test_minority_loss: 0.026614008471369743
	test_majority_acc: 0.9871943445589341
	test_minority_acc: 0.987037173895311
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.008391808718442917
	train_minority_loss: 0.0068358550779521465
	train_majority_acc: 0.9978088211932241
	train_minority_acc: 0.9985351442997626
	train_majority_nonzero: 5560
	train_minority_nonzero: 6663
val:
	val_majority_loss: 0.019422875717282295
	val_minority_loss: 0.0001316843117820099
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.013636184856295586
	test_minority_loss: 0.020714998245239258
	test_majority_acc: 0.9948898800153425
	test_minority_acc: 0.9948066476157911
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.005826178472489119
	train_minority_loss: 0.0050231958739459515
	train_majority_acc: 0.9983484913096163
	train_minority_acc: 0.9989261704351163
	train_majority_nonzero: 4562
	train_minority_nonzero: 7092
val:
	val_majority_loss: 0.03993423655629158
	val_minority_loss: 0.00012856228568125516
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.026355497539043427
	test_minority_loss: 0.012752237729728222
	test_majority_acc: 0.9907313466627301
	test_minority_acc: 0.997439381270903
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.0010842904448509216
	train_minority_loss: 0.0006386182503774762
	train_majority_acc: 0.9995110023253986
	train_minority_acc: 0.999896351575456
	train_majority_nonzero: 4059
	train_minority_nonzero: 7155
val:
	val_majority_loss: 0.01312292367219925
	val_minority_loss: 2.5781497242860496e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.023436300456523895
	test_minority_loss: 0.020483147352933884
	test_majority_acc: 0.9920915777437059
	test_minority_acc: 0.9962601359878842
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.0001479495840612799
	train_minority_loss: 5.017765943193808e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2185
	train_minority_nonzero: 6963
val:
	val_majority_loss: 0.014530651271343231
	val_minority_loss: 1.547483043395914e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02484283037483692
	test_minority_loss: 0.022321997210383415
	test_majority_acc: 0.9920915777437059
	test_minority_acc: 0.9962601359878842
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.00019045444787479937
	train_minority_loss: 3.1041359761729836e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1810
	train_minority_nonzero: 6185
val:
	val_majority_loss: 0.02131393924355507
	val_minority_loss: 8.55718371894909e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.029442759230732918
	test_minority_loss: 0.02025030180811882
	test_majority_acc: 0.9909755063151344
	test_minority_acc: 0.9962601359878842
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.00019678093667607754
	train_minority_loss: 2.311455136805307e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1606
	train_minority_nonzero: 5662
val:
	val_majority_loss: 0.0157159436494112
	val_minority_loss: 7.9499104685965e-06
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.026565125212073326
	test_minority_loss: 0.02319866418838501
	test_majority_acc: 0.9920915777437059
	test_minority_acc: 0.9962601359878842
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.00023173859517555684
	train_minority_loss: 1.689557575446088e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1409
	train_minority_nonzero: 5186
val:
	val_majority_loss: 0.016237515956163406
	val_minority_loss: 6.3651136770204175e-06
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.027797333896160126
	test_minority_loss: 0.02289372682571411
	test_majority_acc: 0.9920915777437059
	test_minority_acc: 0.9962601359878842
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 46.07167863845825 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.575
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2359049320220947
	train_minority_loss: 2.280550003051758
	train_majority_acc: 0.6265765814031098
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.16426566243171692
	train_minority_loss: 0.19971852004528046
	train_majority_acc: 0.9627534060967072
	train_minority_acc: 0.9514271204032234
	train_majority_nonzero: 6094
	train_minority_nonzero: 4614
val:
	val_majority_loss: 0.007927978411316872
	val_minority_loss: 0.03975918889045715
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.010955773293972015
	test_minority_loss: 0.06695191562175751
	test_majority_acc: 0.9989035087719298
	test_minority_acc: 0.9780427967271197
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.020147422328591347
	train_minority_loss: 0.03285476192831993
	train_majority_acc: 0.9944316933016265
	train_minority_acc: 0.9920037141242332
	train_majority_nonzero: 6405
	train_minority_nonzero: 4727
val:
	val_majority_loss: 0.0062216222286224365
	val_minority_loss: 0.01707344315946102
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.006489984225481749
	test_minority_loss: 0.03886988013982773
	test_majority_acc: 0.9975737215378873
	test_minority_acc: 0.9877759681564834
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.007114880718290806
	train_minority_loss: 0.013958440162241459
	train_majority_acc: 0.9987116742335084
	train_minority_acc: 0.99618410112202
	train_majority_nonzero: 7757
	train_minority_nonzero: 4884
val:
	val_majority_loss: 0.0022080657072365284
	val_minority_loss: 0.0013251698110252619
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.012096255086362362
	test_minority_loss: 0.02187161147594452
	test_majority_acc: 0.9953124764270659
	test_minority_acc: 0.9936274023327722
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.014691568911075592
	train_minority_loss: 0.013315542601048946
	train_majority_acc: 0.9945762440571916
	train_minority_acc: 0.9967866988263392
	train_majority_nonzero: 6752
	train_minority_nonzero: 5545
val:
	val_majority_loss: 0.012873608618974686
	val_minority_loss: 0.009375112131237984
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.024863529950380325
	test_minority_loss: 0.0317642018198967
	test_majority_acc: 0.9900671018747274
	test_minority_acc: 0.9913783493024692
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.0027756299823522568
	train_minority_loss: 0.006887688767164946
	train_majority_acc: 0.9995147765121426
	train_minority_acc: 0.9980114883415137
	train_majority_nonzero: 5563
	train_minority_nonzero: 4388
val:
	val_majority_loss: 0.05202241986989975
	val_minority_loss: 0.0003809722838923335
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04399977624416351
	test_minority_loss: 0.013783719390630722
	test_majority_acc: 0.9868406432493504
	test_minority_acc: 0.997344588550984
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.005582527257502079
	train_minority_loss: 0.0036613401025533676
	train_majority_acc: 0.9982993934574179
	train_minority_acc: 0.9987582745473388
	train_majority_nonzero: 3803
	train_minority_nonzero: 5788
val:
	val_majority_loss: 0.00623680092394352
	val_minority_loss: 0.0026306482031941414
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.018111087381839752
	test_minority_loss: 0.019113242626190186
	test_majority_acc: 0.9933694148151981
	test_minority_acc: 0.9948066476157911
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.0010184545535594225
	train_minority_loss: 0.0002491065242793411
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 5143
	train_minority_nonzero: 7388
val:
	val_majority_loss: 0.00905650109052658
	val_minority_loss: 0.001080475514754653
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02833600714802742
	test_minority_loss: 0.02432134747505188
	test_majority_acc: 0.9918813195771029
	test_minority_acc: 0.9948066476157911
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.000283567700535059
	train_minority_loss: 6.097201912780292e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 4625
	train_minority_nonzero: 4232
val:
	val_majority_loss: 0.006626415066421032
	val_minority_loss: 0.000460494018625468
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.028357278555631638
	test_minority_loss: 0.025810251012444496
	test_majority_acc: 0.9933694148151981
	test_minority_acc: 0.9948066476157911
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.00014847525744698942
	train_minority_loss: 6.045143527444452e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 3511
	train_minority_nonzero: 3112
val:
	val_majority_loss: 0.009291091933846474
	val_minority_loss: 0.00016343104653060436
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.031384941190481186
	test_minority_loss: 0.02366098389029503
	test_majority_acc: 0.9933280788363622
	test_minority_acc: 0.9948066476157911
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 3.513206320349127e-05
	train_minority_loss: 1.5015222743386403e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 3792
	train_minority_nonzero: 2171
val:
	val_majority_loss: 0.008153441362082958
	val_minority_loss: 0.00016287757898680866
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03133934363722801
	test_minority_loss: 0.02490420453250408
	test_majority_acc: 0.9933280788363622
	test_minority_acc: 0.9948066476157911
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.79927945137024 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.6
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235896110534668
	train_minority_loss: 2.280574321746826
	train_majority_acc: 0.6257601906430331
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.16261796653270721
	train_minority_loss: 0.19453908503055573
	train_majority_acc: 0.9598618259163147
	train_minority_acc: 0.9598668854305361
	train_majority_nonzero: 5729
	train_minority_nonzero: 4771
val:
	val_majority_loss: 0.023612935096025467
	val_minority_loss: 0.027636434882879257
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02520846202969551
	test_minority_loss: 0.05271277576684952
	test_majority_acc: 0.9966422636611085
	test_minority_acc: 0.9824258431970236
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.017144842073321342
	train_minority_loss: 0.02356000989675522
	train_majority_acc: 0.9959951862068415
	train_minority_acc: 0.9940053179407875
	train_majority_nonzero: 6442
	train_minority_nonzero: 4742
val:
	val_majority_loss: 0.0049340995028615
	val_minority_loss: 0.007189667783677578
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.011269234120845795
	test_minority_loss: 0.026842569932341576
	test_majority_acc: 0.9989035087719298
	test_minority_acc: 0.993604724538868
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.009534108452498913
	train_minority_loss: 0.012943695299327374
	train_majority_acc: 0.9969127144675466
	train_minority_acc: 0.9960722009300227
	train_majority_nonzero: 7092
	train_minority_nonzero: 4184
val:
	val_majority_loss: 0.04568519443273544
	val_minority_loss: 0.002709875116124749
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02131594717502594
	test_minority_loss: 0.01610734313726425
	test_majority_acc: 0.9905425663262735
	test_minority_acc: 0.9947839698218869
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.007769614923745394
	train_minority_loss: 0.007588015403598547
	train_majority_acc: 0.9975890643628091
	train_minority_acc: 0.9974918996308879
	train_majority_nonzero: 6591
	train_minority_nonzero: 4500
val:
	val_majority_loss: 0.009086143225431442
	val_minority_loss: 0.006457051727920771
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01612412929534912
	test_minority_loss: 0.03790678828954697
	test_majority_acc: 0.996299342105263
	test_minority_acc: 0.9884713725582831
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.003620424773544073
	train_minority_loss: 0.007605665363371372
	train_majority_acc: 0.9992546539073156
	train_minority_acc: 0.9989367638429616
	train_majority_nonzero: 5885
	train_minority_nonzero: 6601
val:
	val_majority_loss: 0.004929697141051292
	val_minority_loss: 1.6856016372912563e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03382626920938492
	test_minority_loss: 0.02303658425807953
	test_majority_acc: 0.9880521919941438
	test_minority_acc: 0.9948066476157911
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.00015390316548291594
	train_minority_loss: 0.004752398934215307
	train_majority_acc: 1.0
	train_minority_acc: 0.9995849956030681
	train_majority_nonzero: 4345
	train_minority_nonzero: 1870
val:
	val_majority_loss: 0.029598919674754143
	val_minority_loss: 5.7051107432926074e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.035009320825338364
	test_minority_loss: 0.034248270094394684
	test_majority_acc: 0.9904980506567578
	test_minority_acc: 0.9936274023327722
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 1.9998999050585553e-05
	train_minority_loss: 0.005218543112277985
	train_majority_acc: 1.0
	train_minority_acc: 0.9995876488093489
	train_majority_nonzero: 3337
	train_minority_nonzero: 2048
val:
	val_majority_loss: 0.054305415600538254
	val_minority_loss: 2.226079232059419e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04430451989173889
	test_minority_loss: 0.030265990644693375
	test_majority_acc: 0.9891682634227152
	test_minority_acc: 0.9948066476157911
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 3.0355840863194317e-05
	train_minority_loss: 0.0047897943295538425
	train_majority_acc: 1.0
	train_minority_acc: 0.9995947507489075
	train_majority_nonzero: 3196
	train_minority_nonzero: 0
val:
	val_majority_loss: 0.03523194044828415
	val_minority_loss: 6.415043026208878e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.031152114272117615
	test_minority_loss: 0.03649434447288513
	test_majority_acc: 0.9927592957675792
	test_minority_acc: 0.9936274023327722
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 9.805757144931704e-06
	train_minority_loss: 0.005205617751926184
	train_majority_acc: 1.0
	train_minority_acc: 0.9995905944452684
	train_majority_nonzero: 2777
	train_minority_nonzero: 125
val:
	val_majority_loss: 0.02489958330988884
	val_minority_loss: 0.00012944797344971448
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02566998451948166
	test_minority_loss: 0.04102161154150963
	test_majority_acc: 0.9940890830016217
	test_minority_acc: 0.9936274023327722
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 6.499200935650151e-06
	train_minority_loss: 0.005335385445505381
	train_majority_acc: 1.0
	train_minority_acc: 0.9996017386783614
	train_majority_nonzero: 2532
	train_minority_nonzero: 2158
val:
	val_majority_loss: 0.0191432423889637
	val_minority_loss: 0.0001828373788157478
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.022979438304901123
	test_minority_loss: 0.04348665475845337
	test_majority_acc: 0.9940890830016217
	test_minority_acc: 0.9936274023327722
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.9953932762146 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.625
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2359018325805664
	train_minority_loss: 2.2806460857391357
	train_majority_acc: 0.6227113206710339
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.17635798454284668
	train_minority_loss: 0.1984005868434906
	train_majority_acc: 0.9531670987910912
	train_minority_acc: 0.9623024057460008
	train_majority_nonzero: 5538
	train_minority_nonzero: 4494
val:
	val_majority_loss: 0.009499205276370049
	val_minority_loss: 0.01761634647846222
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.013108588755130768
	test_minority_loss: 0.04323606565594673
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.9869160127198204
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.023143606260418892
	train_minority_loss: 0.024230439215898514
	train_majority_acc: 0.9950387123777659
	train_minority_acc: 0.9941556241234525
	train_majority_nonzero: 5914
	train_minority_nonzero: 4794
val:
	val_majority_loss: 0.03785812109708786
	val_minority_loss: 0.006155057810246944
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.025743314996361732
	test_minority_loss: 0.019521566107869148
	test_majority_acc: 0.9920396275811556
	test_minority_acc: 0.9937290614088945
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.01785595901310444
	train_minority_loss: 0.012538178823888302
	train_majority_acc: 0.9942883754609035
	train_minority_acc: 0.9970160966534949
	train_majority_nonzero: 5815
	train_minority_nonzero: 5073
val:
	val_majority_loss: 0.019912900403141975
	val_minority_loss: 0.004263271577656269
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.023482296615839005
	test_minority_loss: 0.014397930353879929
	test_majority_acc: 0.9922120074077908
	test_minority_acc: 0.9951825497809876
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.0098955063149333
	train_minority_loss: 0.005066071171313524
	train_majority_acc: 0.9965809561959816
	train_minority_acc: 0.998989916201163
	train_majority_nonzero: 4925
	train_minority_nonzero: 6926
val:
	val_majority_loss: 0.02852691151201725
	val_minority_loss: 0.0013340049190446734
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.019213136285543442
	test_minority_loss: 0.023589111864566803
	test_majority_acc: 0.9919739121696955
	test_minority_acc: 0.9924061895467284
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.004498846363276243
	train_minority_loss: 0.0020042092073708773
	train_majority_acc: 0.9985554557500198
	train_minority_acc: 0.9995284129084899
	train_majority_nonzero: 3975
	train_minority_nonzero: 4722
val:
	val_majority_loss: 0.03295847773551941
	val_minority_loss: 0.00016382297326344997
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.022035250440239906
	test_minority_loss: 0.019809888675808907
	test_majority_acc: 0.9919739121696955
	test_minority_acc: 0.9948066476157911
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.0016983936075121164
	train_minority_loss: 0.0005837821518070996
	train_majority_acc: 0.9994699845719139
	train_minority_acc: 0.9998420197400097
	train_majority_nonzero: 2570
	train_minority_nonzero: 4300
val:
	val_majority_loss: 0.023901550099253654
	val_minority_loss: 1.9008060917258263e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03682982921600342
	test_minority_loss: 0.013541750609874725
	test_majority_acc: 0.990644124935653
	test_minority_acc: 0.99598589289881
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 3.703869879245758e-05
	train_minority_loss: 4.3654083128785715e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2358
	train_minority_nonzero: 5780
val:
	val_majority_loss: 0.02623635344207287
	val_minority_loss: 1.7816841136664152e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.033973269164562225
	test_minority_loss: 0.017592016607522964
	test_majority_acc: 0.990644124935653
	test_minority_acc: 0.9948066476157911
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 1.9226699805585667e-05
	train_minority_loss: 3.1687275622971356e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2043
	train_minority_nonzero: 4934
val:
	val_majority_loss: 0.029286114498972893
	val_minority_loss: 1.4356545761984307e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03554068133234978
	test_minority_loss: 0.01757947914302349
	test_majority_acc: 0.990644124935653
	test_minority_acc: 0.9948066476157911
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 1.4285615179687738e-05
	train_minority_loss: 2.5564670067979023e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1846
	train_minority_nonzero: 4586
val:
	val_majority_loss: 0.02357209473848343
	val_minority_loss: 1.594760215084534e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03266006335616112
	test_minority_loss: 0.020230600610375404
	test_majority_acc: 0.9919739121696955
	test_minority_acc: 0.9948066476157911
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 9.722043614601716e-06
	train_minority_loss: 2.344959466427099e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1719
	train_minority_nonzero: 4144
val:
	val_majority_loss: 0.024626465514302254
	val_minority_loss: 1.4610986909247003e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.033321917057037354
	test_minority_loss: 0.020329052582383156
	test_majority_acc: 0.9919739121696955
	test_minority_acc: 0.9948066476157911
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 46.01819586753845 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.65
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235893964767456
	train_minority_loss: 2.2806167602539062
	train_majority_acc: 0.62421352949721
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.1920991837978363
	train_minority_loss: 0.20279914140701294
	train_majority_acc: 0.9354972032873067
	train_minority_acc: 0.9592410973938597
	train_majority_nonzero: 5186
	train_minority_nonzero: 5191
val:
	val_majority_loss: 0.06705861538648605
	val_minority_loss: 0.006379013881087303
	val_majority_acc: 0.9707860445565364
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.08432625979185104
	test_minority_loss: 0.012009207159280777
	test_majority_acc: 0.9694054900675916
	test_minority_acc: 0.9987980769230769
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.02146473154425621
	train_minority_loss: 0.019834203645586967
	train_majority_acc: 0.9943789306203514
	train_minority_acc: 0.9956930978658942
	train_majority_nonzero: 5316
	train_minority_nonzero: 5345
val:
	val_majority_loss: 0.022849828004837036
	val_minority_loss: 0.0038727864157408476
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03868775814771652
	test_minority_loss: 0.011186765506863594
	test_majority_acc: 0.9854864765826836
	test_minority_acc: 0.997439381270903
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.016664953902363777
	train_minority_loss: 0.011315461248159409
	train_majority_acc: 0.9945465432883752
	train_minority_acc: 0.9973844107692277
	train_majority_nonzero: 5622
	train_minority_nonzero: 5950
val:
	val_majority_loss: 0.027408499270677567
	val_minority_loss: 0.002267455914989114
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.031077589839696884
	test_minority_loss: 0.009502822533249855
	test_majority_acc: 0.9871280805927087
	test_minority_acc: 0.99598589289881
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.011506687849760056
	train_minority_loss: 0.006108275149017572
	train_majority_acc: 0.9964955671616456
	train_minority_acc: 0.9985667522007956
	train_majority_nonzero: 4638
	train_minority_nonzero: 8284
val:
	val_majority_loss: 0.005463531240820885
	val_minority_loss: 0.00210435944609344
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03025485947728157
	test_minority_loss: 0.024339716881513596
	test_majority_acc: 0.988373414531369
	test_minority_acc: 0.9909527011746353
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.014028969220817089
	train_minority_loss: 0.0049231513403356075
	train_majority_acc: 0.9954801256471896
	train_minority_acc: 0.9991366985817746
	train_majority_nonzero: 3833
	train_minority_nonzero: 9024
val:
	val_majority_loss: 0.04036354273557663
	val_minority_loss: 5.74587429582607e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.045241981744766235
	test_minority_loss: 0.00829155370593071
	test_majority_acc: 0.9868576153925644
	test_minority_acc: 0.99598589289881
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.0029499444644898176
	train_minority_loss: 0.00023653362586628646
	train_majority_acc: 0.9988926485784301
	train_minority_acc: 1.0
	train_majority_nonzero: 2606
	train_minority_nonzero: 9549
val:
	val_majority_loss: 0.0004837486776523292
	val_minority_loss: 0.00011051016917917877
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.013842837885022163
	test_minority_loss: 0.026843365281820297
	test_majority_acc: 0.9955771782397169
	test_minority_acc: 0.990554217655814
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.0012095690472051501
	train_minority_loss: 9.605609375284985e-05
	train_majority_acc: 0.9995019491288148
	train_minority_acc: 1.0
	train_majority_nonzero: 1815
	train_minority_nonzero: 6395
val:
	val_majority_loss: 0.021611744537949562
	val_minority_loss: 8.724639883439522e-06
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.038734257221221924
	test_minority_loss: 0.011258907616138458
	test_majority_acc: 0.9895476337075828
	test_minority_acc: 0.99598589289881
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.0012972090626135468
	train_minority_loss: 1.871607128123287e-05
	train_majority_acc: 0.9993134894443569
	train_minority_acc: 1.0
	train_majority_nonzero: 2131
	train_minority_nonzero: 5916
val:
	val_majority_loss: 0.02779913879930973
	val_minority_loss: 5.195153335080249e-06
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.043789058923721313
	test_minority_loss: 0.00945301167666912
	test_majority_acc: 0.9895476337075828
	test_minority_acc: 0.99598589289881
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.001356508582830429
	train_minority_loss: 1.2976753168914001e-05
	train_majority_acc: 0.9992588063139909
	train_minority_acc: 1.0
	train_majority_nonzero: 2089
	train_minority_nonzero: 5293
val:
	val_majority_loss: 0.02118937484920025
	val_minority_loss: 4.576691935653798e-06
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04107270389795303
	test_minority_loss: 0.011116702109575272
	test_majority_acc: 0.9895476337075828
	test_minority_acc: 0.99598589289881
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.001641816459596157
	train_minority_loss: 1.0437716809974518e-05
	train_majority_acc: 0.9992204072537699
	train_minority_acc: 1.0
	train_majority_nonzero: 1979
	train_minority_nonzero: 4769
val:
	val_majority_loss: 0.022442953661084175
	val_minority_loss: 3.3787307529564714e-06
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.042707331478595734
	test_minority_loss: 0.010815173387527466
	test_majority_acc: 0.9895476337075828
	test_minority_acc: 0.99598589289881
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 46.05984616279602 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.675
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235825777053833
	train_minority_loss: 2.280620574951172
	train_majority_acc: 0.62805610548717
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.21675865352153778
	train_minority_loss: 0.2082797884941101
	train_majority_acc: 0.9136856402546751
	train_minority_acc: 0.9594547729671814
	train_majority_nonzero: 5157
	train_minority_nonzero: 4547
val:
	val_majority_loss: 0.01904967799782753
	val_minority_loss: 0.02538926899433136
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.026521015912294388
	test_minority_loss: 0.04231381416320801
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.9940164504940723
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.0147387171164155
	train_minority_loss: 0.022745754569768906
	train_majority_acc: 0.9977522199919897
	train_minority_acc: 0.9949782529794277
	train_majority_nonzero: 5659
	train_minority_nonzero: 6057
val:
	val_majority_loss: 0.0021630844566971064
	val_minority_loss: 0.004009979777038097
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01082937978208065
	test_minority_loss: 0.0261380635201931
	test_majority_acc: 0.9957354862437696
	test_minority_acc: 0.9904236011458871
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.016791200265288353
	train_minority_loss: 0.009892391972243786
	train_majority_acc: 0.9941379433788563
	train_minority_acc: 0.9970831753538748
	train_majority_nonzero: 5199
	train_minority_nonzero: 5672
val:
	val_majority_loss: 0.00336242513731122
	val_minority_loss: 0.0012745597632601857
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.016193939372897148
	test_minority_loss: 0.025689903646707535
	test_majority_acc: 0.9938730636431503
	test_minority_acc: 0.9901764262255461
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.004651447758078575
	train_minority_loss: 0.005678531713783741
	train_majority_acc: 0.9985899987868141
	train_minority_acc: 0.998527002686258
	train_majority_nonzero: 4315
	train_minority_nonzero: 4256
val:
	val_majority_loss: 0.02674609050154686
	val_minority_loss: 2.0157729522907175e-05
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05288759618997574
	test_minority_loss: 0.004603285808116198
	test_majority_acc: 0.9881922018587299
	test_minority_acc: 0.9987980769230769
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.005960195325314999
	train_minority_loss: 0.0035608485341072083
	train_majority_acc: 0.9978492652287285
	train_minority_acc: 0.9987988204397752
	train_majority_nonzero: 4155
	train_minority_nonzero: 2927
val:
	val_majority_loss: 0.003756900317966938
	val_minority_loss: 0.0001889044651761651
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02607031911611557
	test_minority_loss: 0.007720613852143288
	test_majority_acc: 0.993131319577103
	test_minority_acc: 0.994711854895872
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.009065235033631325
	train_minority_loss: 0.004713214933872223
	train_majority_acc: 0.9968628842317879
	train_minority_acc: 0.9985673715906248
	train_majority_nonzero: 4669
	train_minority_nonzero: 4537
val:
	val_majority_loss: 0.07044276595115662
	val_minority_loss: 7.932540029287338e-06
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04990975558757782
	test_minority_loss: 0.01004009135067463
	test_majority_acc: 0.9862695722245693
	test_minority_acc: 0.997344588550984
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.011543387547135353
	train_minority_loss: 0.002198221627622843
	train_majority_acc: 0.9962239213893409
	train_minority_acc: 0.9993521267008871
	train_majority_nonzero: 4139
	train_minority_nonzero: 3714
val:
	val_majority_loss: 0.026149580255150795
	val_minority_loss: 2.8158863642602228e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.025117071345448494
	test_minority_loss: 0.024918904528021812
	test_majority_acc: 0.9909942649916754
	test_minority_acc: 0.9933531592436982
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 6.568607204826549e-05
	train_minority_loss: 0.0010683955624699593
	train_majority_acc: 1.0
	train_minority_acc: 0.9996234032994787
	train_majority_nonzero: 2764
	train_minority_nonzero: 5962
val:
	val_majority_loss: 0.022134047001600266
	val_minority_loss: 1.2969789167982526e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02556234784424305
	test_minority_loss: 0.026402276009321213
	test_majority_acc: 0.992324052225718
	test_minority_acc: 0.9921739139606792
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 3.0703467928105965e-05
	train_minority_loss: 0.0011323651997372508
	train_majority_acc: 1.0
	train_minority_acc: 0.9996134233129406
	train_majority_nonzero: 2333
	train_minority_nonzero: 4482
val:
	val_majority_loss: 0.019154595211148262
	val_minority_loss: 1.0682030733732972e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02390778437256813
	test_minority_loss: 0.02957889996469021
	test_majority_acc: 0.9951419346978557
	test_minority_acc: 0.9921739139606792
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 1.8321079551242292e-05
	train_minority_loss: 0.0013354503316804767
	train_majority_acc: 1.0
	train_minority_acc: 0.9996335756650788
	train_majority_nonzero: 1995
	train_minority_nonzero: 5715
val:
	val_majority_loss: 0.01901061087846756
	val_minority_loss: 7.092135547281941e-06
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.025048233568668365
	test_minority_loss: 0.0297381691634655
	test_majority_acc: 0.9951419346978557
	test_minority_acc: 0.9921739139606792
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.95901322364807 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.7
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235809087753296
	train_minority_loss: 2.280541181564331
	train_majority_acc: 0.6285001551498848
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.21688203513622284
	train_minority_loss: 0.21278895437717438
	train_majority_acc: 0.919931279080522
	train_minority_acc: 0.9640780293379635
	train_majority_nonzero: 4805
	train_minority_nonzero: 4283
val:
	val_majority_loss: 0.013745435513556004
	val_minority_loss: 0.022136956453323364
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.019171401858329773
	test_minority_loss: 0.044931329786777496
	test_majority_acc: 0.9953002427019084
	test_minority_acc: 0.9847120064467991
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.018301887437701225
	train_minority_loss: 0.019128024578094482
	train_majority_acc: 0.9967021756019282
	train_minority_acc: 0.9952908747699696
	train_majority_nonzero: 5102
	train_minority_nonzero: 5310
val:
	val_majority_loss: 0.02073185332119465
	val_minority_loss: 0.001290717045776546
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.032197993248701096
	test_minority_loss: 0.009153596125543118
	test_majority_acc: 0.9860363885967615
	test_minority_acc: 0.9964395863570392
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.015154244378209114
	train_minority_loss: 0.010962337255477905
	train_majority_acc: 0.9961374320268038
	train_minority_acc: 0.9968022147600071
	train_majority_nonzero: 5173
	train_minority_nonzero: 4964
val:
	val_majority_loss: 0.023894095793366432
	val_minority_loss: 0.00229055667296052
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.034330204129219055
	test_minority_loss: 0.01806897483766079
	test_majority_acc: 0.9876365286527837
	test_minority_acc: 0.9927752253557216
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.008418467827141285
	train_minority_loss: 0.007048020139336586
	train_majority_acc: 0.9973803530950821
	train_minority_acc: 0.9983557725515106
	train_majority_nonzero: 5114
	train_minority_nonzero: 6082
val:
	val_majority_loss: 0.01767118275165558
	val_minority_loss: 0.000489089812617749
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0241699256002903
	test_minority_loss: 0.021272726356983185
	test_majority_acc: 0.9879672164834716
	test_minority_acc: 0.9897376321016087
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.003172277007251978
	train_minority_loss: 0.003979397471994162
	train_majority_acc: 0.9989189102644134
	train_minority_acc: 0.9987547500463831
	train_majority_nonzero: 3819
	train_minority_nonzero: 5265
val:
	val_majority_loss: 0.018703579902648926
	val_minority_loss: 6.744605343556032e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.024674391373991966
	test_minority_loss: 0.03390027955174446
	test_majority_acc: 0.9891246238908791
	test_minority_acc: 0.9882841437295158
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.0027489911299198866
	train_minority_loss: 0.004798979498445988
	train_majority_acc: 0.9992367060413923
	train_minority_acc: 0.9985676452320874
	train_majority_nonzero: 2532
	train_minority_nonzero: 6819
val:
	val_majority_loss: 0.014689281582832336
	val_minority_loss: 3.548396489350125e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.021720686927437782
	test_minority_loss: 0.04254364222288132
	test_majority_acc: 0.9913785225263566
	test_minority_acc: 0.9882841437295158
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.0033832958433777094
	train_minority_loss: 0.004654210526496172
	train_majority_acc: 0.9991414839690992
	train_minority_acc: 0.9986520970276888
	train_majority_nonzero: 2003
	train_minority_nonzero: 4381
val:
	val_majority_loss: 0.01297302171587944
	val_minority_loss: 2.6782759960042313e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.020246941596269608
	test_minority_loss: 0.046907052397727966
	test_majority_acc: 0.9924945939549281
	test_minority_acc: 0.9882841437295158
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.0030433516949415207
	train_minority_loss: 0.005651326384395361
	train_majority_acc: 0.9992777251282519
	train_minority_acc: 0.998291145640742
	train_majority_nonzero: 1700
	train_minority_nonzero: 4048
val:
	val_majority_loss: 0.013316383585333824
	val_minority_loss: 1.7721897165756673e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.020979277789592743
	test_minority_loss: 0.04743945598602295
	test_majority_acc: 0.9924945939549281
	test_minority_acc: 0.9882841437295158
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.003681412898004055
	train_minority_loss: 0.005530914757400751
	train_majority_acc: 0.9991440786089931
	train_minority_acc: 0.9980950340503247
	train_majority_nonzero: 1503
	train_minority_nonzero: 3320
val:
	val_majority_loss: 0.011384889483451843
	val_minority_loss: 1.4533002286043484e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.019948963075876236
	test_minority_loss: 0.05047931522130966
	test_majority_acc: 0.9924945939549281
	test_minority_acc: 0.9882841437295158
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.0032348663080483675
	train_minority_loss: 0.005896641872823238
	train_majority_acc: 0.999227277865627
	train_minority_acc: 0.9982451980933646
	train_majority_nonzero: 1364
	train_minority_nonzero: 3069
val:
	val_majority_loss: 0.010975964367389679
	val_minority_loss: 1.3116103218635544e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.019505150616168976
	test_minority_loss: 0.052112169563770294
	test_majority_acc: 0.9924945939549281
	test_minority_acc: 0.9882841437295158
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.938679933547974 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.725
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235917329788208
	train_minority_loss: 2.2805168628692627
	train_majority_acc: 0.6273577790221897
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.24541203677654266
	train_minority_loss: 0.21678368747234344
	train_majority_acc: 0.8920313619788421
	train_minority_acc: 0.9524182487076902
	train_majority_nonzero: 4608
	train_minority_nonzero: 4350
val:
	val_majority_loss: 0.03352481126785278
	val_minority_loss: 0.010693637654185295
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04549708217382431
	test_minority_loss: 0.02117449790239334
	test_majority_acc: 0.9893627191289743
	test_minority_acc: 0.997439381270903
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.023674538359045982
	train_minority_loss: 0.021708695217967033
	train_majority_acc: 0.9931362454670626
	train_minority_acc: 0.9948590238562379
	train_majority_nonzero: 4901
	train_minority_nonzero: 5824
val:
	val_majority_loss: 0.03046754002571106
	val_minority_loss: 0.005308228544890881
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.041905418038368225
	test_minority_loss: 0.020070068538188934
	test_majority_acc: 0.9838019421866184
	test_minority_acc: 0.993604724538868
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.016200700774788857
	train_minority_loss: 0.00859985500574112
	train_majority_acc: 0.9961920947516675
	train_minority_acc: 0.9985860006204152
	train_majority_nonzero: 4853
	train_minority_nonzero: 5095
val:
	val_majority_loss: 0.0971401184797287
	val_minority_loss: 0.0017347763059660792
	val_majority_acc: 0.9661622530474989
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04832102358341217
	test_minority_loss: 0.012644324451684952
	test_majority_acc: 0.9820196347632135
	test_minority_acc: 0.9962601359878842
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.018361007794737816
	train_minority_loss: 0.005651221144944429
	train_majority_acc: 0.9925170071271872
	train_minority_acc: 0.9984055678844402
	train_majority_nonzero: 4586
	train_minority_nonzero: 5332
val:
	val_majority_loss: 0.02574075758457184
	val_minority_loss: 0.0038237986154854298
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.022343173623085022
	test_minority_loss: 0.04304737225174904
	test_majority_acc: 0.9912202145223039
	test_minority_acc: 0.9867575632697456
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.01019201148301363
	train_minority_loss: 0.00236801546998322
	train_majority_acc: 0.9958629080427904
	train_minority_acc: 0.999354345027304
	train_majority_nonzero: 4103
	train_minority_nonzero: 7519
val:
	val_majority_loss: 0.06378794461488724
	val_minority_loss: 0.00038883305387571454
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0221553947776556
	test_minority_loss: 0.022765494883060455
	test_majority_acc: 0.9940057270323928
	test_minority_acc: 0.9935045642824578
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.0026073576882481575
	train_minority_loss: 0.0005559449200518429
	train_majority_acc: 0.9991754538363599
	train_minority_acc: 0.9999362163541269
	train_majority_nonzero: 3284
	train_minority_nonzero: 8631
val:
	val_majority_loss: 0.07064415514469147
	val_minority_loss: 2.807173405017238e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03617968037724495
	test_minority_loss: 0.020020155236124992
	test_majority_acc: 0.9912202145223039
	test_minority_acc: 0.9948066476157911
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 4.524109317571856e-05
	train_minority_loss: 0.00015703840472269803
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2789
	train_minority_nonzero: 8564
val:
	val_majority_loss: 0.07354231178760529
	val_minority_loss: 1.6057672837632708e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03765685483813286
	test_minority_loss: 0.022275038063526154
	test_majority_acc: 0.9912202145223039
	test_minority_acc: 0.9948066476157911
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 2.5424666091566905e-05
	train_minority_loss: 0.0001593871129443869
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2495
	train_minority_nonzero: 7073
val:
	val_majority_loss: 0.07974837720394135
	val_minority_loss: 9.526944268145598e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04071902111172676
	test_minority_loss: 0.02214782126247883
	test_majority_acc: 0.9912202145223039
	test_minority_acc: 0.9948066476157911
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 1.8818322132574394e-05
	train_minority_loss: 0.00013247213792055845
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2292
	train_minority_nonzero: 6179
val:
	val_majority_loss: 0.07534074783325195
	val_minority_loss: 8.61883927427698e-06
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03915698826313019
	test_minority_loss: 0.024624785408377647
	test_majority_acc: 0.9912202145223039
	test_minority_acc: 0.9948066476157911
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 1.4113012184679974e-05
	train_minority_loss: 0.00019851922115776688
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2101
	train_minority_nonzero: 5462
val:
	val_majority_loss: 0.07444453239440918
	val_minority_loss: 7.142654794733971e-06
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.039987556636333466
	test_minority_loss: 0.02521299198269844
	test_majority_acc: 0.9912202145223039
	test_minority_acc: 0.9948066476157911
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.89858937263489 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.75
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.236177921295166
	train_minority_loss: 2.2805299758911133
	train_majority_acc: 0.6231599860352629
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.24980176985263824
	train_minority_loss: 0.21496206521987915
	train_majority_acc: 0.879067729170949
	train_minority_acc: 0.9548203516602982
	train_majority_nonzero: 4350
	train_minority_nonzero: 3683
val:
	val_majority_loss: 0.028937913477420807
	val_minority_loss: 0.0067228637635707855
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04338816553354263
	test_minority_loss: 0.02173631265759468
	test_majority_acc: 0.9909258023689892
	test_minority_acc: 0.9934252741697129
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.021091505885124207
	train_minority_loss: 0.021790888160467148
	train_majority_acc: 0.9948871711611984
	train_minority_acc: 0.9939505028069245
	train_majority_nonzero: 4836
	train_minority_nonzero: 3559
val:
	val_majority_loss: 0.04276673495769501
	val_minority_loss: 0.00155019317753613
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.032128527760505676
	test_minority_loss: 0.008189324289560318
	test_majority_acc: 0.9903618185323291
	test_minority_acc: 0.997618831640058
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.007006010040640831
	train_minority_loss: 0.01141777541488409
	train_majority_acc: 0.9985882424661832
	train_minority_acc: 0.9970471547169957
	train_majority_nonzero: 4864
	train_minority_nonzero: 3232
val:
	val_majority_loss: 0.021779388189315796
	val_minority_loss: 0.0001053496016538702
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02906312793493271
	test_minority_loss: 0.008539805188775063
	test_majority_acc: 0.9895829052721097
	test_minority_acc: 0.997344588550984
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.007346656173467636
	train_minority_loss: 0.013839863240718842
	train_majority_acc: 0.9978096233030159
	train_minority_acc: 0.996279993380787
	train_majority_nonzero: 4607
	train_minority_nonzero: 3396
val:
	val_majority_loss: 0.0028276799712330103
	val_minority_loss: 0.011858642101287842
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.018637042492628098
	test_minority_loss: 0.032659225165843964
	test_majority_acc: 0.9939102328373223
	test_minority_acc: 0.9844954458581717
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.00010828366066562012
	train_minority_loss: 0.015643391758203506
	train_majority_acc: 1.0
	train_minority_acc: 0.9964576705812007
	train_majority_nonzero: 4068
	train_minority_nonzero: 4094
val:
	val_majority_loss: 0.0008356276084668934
	val_minority_loss: 0.012728228233754635
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.020604055374860764
	test_minority_loss: 0.0428457111120224
	test_majority_acc: 0.9949695548712205
	test_minority_acc: 0.9844954458581717
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 3.3188720408361405e-05
	train_minority_loss: 0.018418552353978157
	train_majority_acc: 1.0
	train_minority_acc: 0.9955966367712541
	train_majority_nonzero: 3632
	train_minority_nonzero: 2302
val:
	val_majority_loss: 0.0004030783020425588
	val_minority_loss: 0.013885079883038998
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.018992915749549866
	test_minority_loss: 0.04886600375175476
	test_majority_acc: 0.9949695548712205
	test_minority_acc: 0.9844954458581717
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 1.862976569100283e-05
	train_minority_loss: 0.01997952163219452
	train_majority_acc: 1.0
	train_minority_acc: 0.9955592575660402
	train_majority_nonzero: 3375
	train_minority_nonzero: 1197
val:
	val_majority_loss: 0.00025538523914292455
	val_minority_loss: 0.014850221574306488
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.018290802836418152
	test_minority_loss: 0.05398653447628021
	test_majority_acc: 0.9949695548712205
	test_minority_acc: 0.983548476161202
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 1.2108810551580973e-05
	train_minority_loss: 0.020742934197187424
	train_majority_acc: 1.0
	train_minority_acc: 0.9952378199292466
	train_majority_nonzero: 3201
	train_minority_nonzero: 1130
val:
	val_majority_loss: 0.00020290850079618394
	val_minority_loss: 0.015050862915813923
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.01822587661445141
	test_minority_loss: 0.05554569512605667
	test_majority_acc: 0.9949695548712205
	test_minority_acc: 0.983548476161202
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 1.0507142178539652e-05
	train_minority_loss: 0.020869217813014984
	train_majority_acc: 1.0
	train_minority_acc: 0.9956748233235725
	train_majority_nonzero: 3028
	train_minority_nonzero: 438
val:
	val_majority_loss: 0.00016663645510561764
	val_minority_loss: 0.014799555763602257
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.018709244206547737
	test_minority_loss: 0.057212844491004944
	test_majority_acc: 0.9949695548712205
	test_minority_acc: 0.983548476161202
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 7.957489287946373e-06
	train_minority_loss: 0.022336285561323166
	train_majority_acc: 1.0
	train_minority_acc: 0.9950697533343554
	train_majority_nonzero: 2851
	train_minority_nonzero: 373
val:
	val_majority_loss: 0.00011550929775694385
	val_minority_loss: 0.016371658071875572
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.017594940960407257
	test_minority_loss: 0.06151542067527771
	test_majority_acc: 0.9949695548712205
	test_minority_acc: 0.983548476161202
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.84079027175903 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.775
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2360730171203613
	train_minority_loss: 2.280597686767578
	train_majority_acc: 0.6152669502421406
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.2727087140083313
	train_minority_loss: 0.22741559147834778
	train_majority_acc: 0.8718528992936022
	train_minority_acc: 0.9599420241337483
	train_majority_nonzero: 3880
	train_minority_nonzero: 3563
val:
	val_majority_loss: 0.20016950368881226
	val_minority_loss: 0.006193678826093674
	val_majority_acc: 0.9241277847835225
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.1900578737258911
	test_minority_loss: 0.010425403714179993
	test_majority_acc: 0.9232640477097308
	test_minority_acc: 0.998641304347826
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.03190420940518379
	train_minority_loss: 0.02200440689921379
	train_majority_acc: 0.9910743781253595
	train_minority_acc: 0.9941151233541129
	train_majority_nonzero: 4223
	train_minority_nonzero: 4106
val:
	val_majority_loss: 0.02434643916785717
	val_minority_loss: 0.00337924063205719
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.026110710576176643
	test_minority_loss: 0.022979818284511566
	test_majority_acc: 0.9899507622969694
	test_minority_acc: 0.9912181886424349
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.008064287714660168
	train_minority_loss: 0.026339709758758545
	train_majority_acc: 0.9978667214609215
	train_minority_acc: 0.991389063683487
	train_majority_nonzero: 4418
	train_minority_nonzero: 2696
val:
	val_majority_loss: 0.002999355085194111
	val_minority_loss: 0.0008360646897926927
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.028745172545313835
	test_minority_loss: 0.033807314932346344
	test_majority_acc: 0.9918451145383014
	test_minority_acc: 0.9883493922993274
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.011162897571921349
	train_minority_loss: 0.016456637531518936
	train_majority_acc: 0.9961277128116469
	train_minority_acc: 0.9956591582287956
	train_majority_nonzero: 4191
	train_minority_nonzero: 4037
val:
	val_majority_loss: 0.005789447575807571
	val_minority_loss: 0.001367039978504181
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.024529045447707176
	test_minority_loss: 0.0346972718834877
	test_majority_acc: 0.9916916057663716
	test_minority_acc: 0.9893617299364124
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.008281045593321323
	train_minority_loss: 0.014034406282007694
	train_majority_acc: 0.997837670461394
	train_minority_acc: 0.9956543602422986
	train_majority_nonzero: 4125
	train_minority_nonzero: 5068
val:
	val_majority_loss: 0.0011011235183104873
	val_minority_loss: 0.0004050523857586086
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.015489455312490463
	test_minority_loss: 0.03658789396286011
	test_majority_acc: 0.9954890230383651
	test_minority_acc: 0.9889701127737941
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.0001746447669574991
	train_minority_loss: 0.016545195132493973
	train_majority_acc: 1.0
	train_minority_acc: 0.9958292612091753
	train_majority_nonzero: 3455
	train_minority_nonzero: 3060
val:
	val_majority_loss: 0.0014940814580768347
	val_minority_loss: 0.00018679421918932348
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.018156662583351135
	test_minority_loss: 0.03001359850168228
	test_majority_acc: 0.9954890230383651
	test_minority_acc: 0.9900476989806907
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 6.453219248214737e-05
	train_minority_loss: 0.01773134432733059
	train_majority_acc: 1.0
	train_minority_acc: 0.9956380487140021
	train_majority_nonzero: 2863
	train_minority_nonzero: 6166
val:
	val_majority_loss: 0.0005523876752704382
	val_minority_loss: 0.00012921198504045606
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.016941960901021957
	test_minority_loss: 0.03916606307029724
	test_majority_acc: 0.9965855142664353
	test_minority_acc: 0.9876472409116279
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.00011146884935442358
	train_minority_loss: 0.015926111489534378
	train_majority_acc: 1.0
	train_minority_acc: 0.9962318718801013
	train_majority_nonzero: 2439
	train_minority_nonzero: 1547
val:
	val_majority_loss: 0.0014335428131744266
	val_minority_loss: 4.804150012205355e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.018942417576909065
	test_minority_loss: 0.02822471596300602
	test_majority_acc: 0.9965855142664353
	test_minority_acc: 0.9900476989806907
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 2.9768785680062138e-05
	train_minority_loss: 0.018940672278404236
	train_majority_acc: 1.0
	train_minority_acc: 0.9956249264776715
	train_majority_nonzero: 2104
	train_minority_nonzero: 3
val:
	val_majority_loss: 0.0005332781584002078
	val_minority_loss: 7.828192610759288e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.015250367112457752
	test_minority_loss: 0.037450097501277924
	test_majority_acc: 0.9965855142664353
	test_minority_acc: 0.989100729283721
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 1.7770746126188897e-05
	train_minority_loss: 0.022279560565948486
	train_majority_acc: 1.0
	train_minority_acc: 0.9951153156743379
	train_majority_nonzero: 1877
	train_minority_nonzero: 2898
val:
	val_majority_loss: 0.00031332741491496563
	val_minority_loss: 8.984853775473312e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.014166262000799179
	test_minority_loss: 0.04321214184165001
	test_majority_acc: 0.9965855142664353
	test_minority_acc: 0.9878988062067979
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.962327003479004 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.8
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2361457347869873
	train_minority_loss: 2.28058123588562
	train_majority_acc: 0.6190468955895291
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.2849734425544739
	train_minority_loss: 0.24355792999267578
	train_majority_acc: 0.8798941928503218
	train_minority_acc: 0.9623865476061068
	train_majority_nonzero: 3567
	train_minority_nonzero: 3904
val:
	val_majority_loss: 0.010120578110218048
	val_minority_loss: 0.011164376512169838
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.020712798461318016
	test_minority_loss: 0.03937787190079689
	test_majority_acc: 0.9944742166739825
	test_minority_acc: 0.9850507983925232
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.02025049552321434
	train_minority_loss: 0.0193070899695158
	train_majority_acc: 0.9954906097271317
	train_minority_acc: 0.9936751244230179
	train_majority_nonzero: 3878
	train_minority_nonzero: 2672
val:
	val_majority_loss: 0.048478372395038605
	val_minority_loss: 0.0022291536442935467
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05459524691104889
	test_minority_loss: 0.0065432521514594555
	test_majority_acc: 0.9782300450191412
	test_minority_acc: 0.998546511627907
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.016726087778806686
	train_minority_loss: 0.013907909393310547
	train_majority_acc: 0.9946221516653446
	train_minority_acc: 0.9960735460967545
	train_majority_nonzero: 3848
	train_minority_nonzero: 3519
val:
	val_majority_loss: 0.0011817390331998467
	val_minority_loss: 0.00804520957171917
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.004501537419855595
	test_minority_loss: 0.04084120690822601
	test_majority_acc: 1.0
	test_minority_acc: 0.9835172585566059
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.011825500056147575
	train_minority_loss: 0.010328169912099838
	train_majority_acc: 0.9962959560193976
	train_minority_acc: 0.9967831945783623
	train_majority_nonzero: 3731
	train_minority_nonzero: 3217
val:
	val_majority_loss: 0.003824545769020915
	val_minority_loss: 0.0003237930068280548
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01686052419245243
	test_minority_loss: 0.02205580286681652
	test_majority_acc: 0.9940057270323928
	test_minority_acc: 0.9948066476157911
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.0005080218543298542
	train_minority_loss: 0.020151128992438316
	train_majority_acc: 0.9997927031509122
	train_minority_acc: 0.9948920305269291
	train_majority_nonzero: 2561
	train_minority_nonzero: 5131
val:
	val_majority_loss: 0.0028422605246305466
	val_minority_loss: 0.00010988029680447653
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01357751153409481
	test_minority_loss: 0.020809991285204887
	test_majority_acc: 0.9933694148151981
	test_minority_acc: 0.9939613369949437
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 2.134293936251197e-05
	train_minority_loss: 0.027882808819413185
	train_majority_acc: 1.0
	train_minority_acc: 0.9929976380629755
	train_majority_nonzero: 2041
	train_minority_nonzero: 2839
val:
	val_majority_loss: 0.0018632799619808793
	val_minority_loss: 0.00011770301352953538
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01178343128412962
	test_minority_loss: 0.022996939718723297
	test_majority_acc: 0.9952076501093159
	test_minority_acc: 0.9939613369949437
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 1.3094733731122687e-05
	train_minority_loss: 0.02792445942759514
	train_majority_acc: 1.0
	train_minority_acc: 0.9929892167238203
	train_majority_nonzero: 1877
	train_minority_nonzero: 4458
val:
	val_majority_loss: 0.0016362450551241636
	val_minority_loss: 9.607023821445182e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01215379312634468
	test_minority_loss: 0.02234625816345215
	test_majority_acc: 0.9952076501093159
	test_minority_acc: 0.9939613369949437
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 8.437464202870615e-06
	train_minority_loss: 0.02868567407131195
	train_majority_acc: 1.0
	train_minority_acc: 0.993357372283901
	train_majority_nonzero: 1639
	train_minority_nonzero: 8193
val:
	val_majority_loss: 0.0013885137159377337
	val_minority_loss: 7.84361909609288e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.012312369421124458
	test_minority_loss: 0.02250055968761444
	test_majority_acc: 0.9952076501093159
	test_minority_acc: 0.9939613369949437
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 5.054369921708712e-06
	train_minority_loss: 0.029805336147546768
	train_majority_acc: 1.0
	train_minority_acc: 0.9931609558112666
	train_majority_nonzero: 1455
	train_minority_nonzero: 8402
val:
	val_majority_loss: 0.0010909944539889693
	val_minority_loss: 7.558663492091e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.011824744753539562
	test_minority_loss: 0.024264434352517128
	test_majority_acc: 0.9963237215378873
	test_minority_acc: 0.9928837507880472
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 3.5658783872349886e-06
	train_minority_loss: 0.030888594686985016
	train_majority_acc: 1.0
	train_minority_acc: 0.9929801806903816
	train_majority_nonzero: 1343
	train_minority_nonzero: 8588
val:
	val_majority_loss: 0.0008076558588072658
	val_minority_loss: 7.48875827412121e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.011119218543171883
	test_minority_loss: 0.026034299284219742
	test_majority_acc: 0.9963237215378873
	test_minority_acc: 0.9928837507880472
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 46.096529483795166 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.825
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2359633445739746
	train_minority_loss: 2.2805755138397217
	train_majority_acc: 0.619352609412401
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.34615829586982727
	train_minority_loss: 0.24295945465564728
	train_majority_acc: 0.8217527201604226
	train_minority_acc: 0.9618328199694537
	train_majority_nonzero: 3194
	train_minority_nonzero: 3322
val:
	val_majority_loss: 0.11612103134393692
	val_minority_loss: 0.005472805351018906
	val_majority_acc: 0.9461958806221101
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.13524079322814941
	test_minority_loss: 0.011293157935142517
	test_majority_acc: 0.9576255386750638
	test_minority_acc: 1.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.012137945741415024
	train_minority_loss: 0.030102495104074478
	train_majority_acc: 0.9979766599608566
	train_minority_acc: 0.990977281879647
	train_majority_nonzero: 3475
	train_minority_nonzero: 2500
val:
	val_majority_loss: 0.003308979095891118
	val_minority_loss: 0.0019016413716599345
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.019373366609215736
	test_minority_loss: 0.02209114469587803
	test_majority_acc: 0.9928137416092522
	test_minority_acc: 0.9925498161258757
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.029113711789250374
	train_minority_loss: 0.01975512132048607
	train_majority_acc: 0.9903016545933172
	train_minority_acc: 0.993662870075958
	train_majority_nonzero: 3498
	train_minority_nonzero: 2147
val:
	val_majority_loss: 0.005453781690448523
	val_minority_loss: 0.0016733878292143345
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.033004648983478546
	test_minority_loss: 0.019819404929876328
	test_majority_acc: 0.988055836563518
	test_minority_acc: 0.9936274023327722
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.010275508277118206
	train_minority_loss: 0.018993431702256203
	train_majority_acc: 0.9963850400712145
	train_minority_acc: 0.9946579548588552
	train_majority_nonzero: 3457
	train_minority_nonzero: 5474
val:
	val_majority_loss: 0.0003667509590741247
	val_minority_loss: 0.00034903112100437284
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.009873911738395691
	test_minority_loss: 0.029801826924085617
	test_majority_acc: 0.99509741902834
	test_minority_acc: 0.9903219420697649
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 9.170109842671081e-05
	train_minority_loss: 0.028053613379597664
	train_majority_acc: 1.0
	train_minority_acc: 0.9927587519626541
	train_majority_nonzero: 2995
	train_minority_nonzero: 7579
val:
	val_majority_loss: 0.00010495163587620482
	val_minority_loss: 9.145278454525396e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.011306771077215672
	test_minority_loss: 0.03519510477781296
	test_majority_acc: 0.9965855142664353
	test_minority_acc: 0.9903219420697649
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 3.5040553484577686e-05
	train_minority_loss: 0.030452173203229904
	train_majority_acc: 1.0
	train_minority_acc: 0.9926943538789682
	train_majority_nonzero: 2729
	train_minority_nonzero: 3265
val:
	val_majority_loss: 5.668987796525471e-05
	val_minority_loss: 0.0001061276561813429
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.00881796982139349
	test_minority_loss: 0.04160374775528908
	test_majority_acc: 0.9965855142664353
	test_minority_acc: 0.9888684536976717
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 1.9935518139391206e-05
	train_minority_loss: 0.03310331329703331
	train_majority_acc: 1.0
	train_minority_acc: 0.9925201153444674
	train_majority_nonzero: 2508
	train_minority_nonzero: 4583
val:
	val_majority_loss: 3.922987889382057e-05
	val_minority_loss: 8.147209882736206e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.00928683765232563
	test_minority_loss: 0.04303162544965744
	test_majority_acc: 0.9965855142664353
	test_minority_acc: 0.9875663703643385
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 9.71416102402145e-06
	train_minority_loss: 0.033065035939216614
	train_majority_acc: 1.0
	train_minority_acc: 0.9930527461741882
	train_majority_nonzero: 1991
	train_minority_nonzero: 2992
val:
	val_majority_loss: 2.7868249162565917e-05
	val_minority_loss: 2.4152554033207707e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.014377402141690254
	test_minority_loss: 0.04001026228070259
	test_majority_acc: 0.9940009278002699
	test_minority_acc: 0.9915011873527837
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 5.099956069898326e-06
	train_minority_loss: 0.03298572823405266
	train_majority_acc: 1.0
	train_minority_acc: 0.993292851304766
	train_majority_nonzero: 1547
	train_minority_nonzero: 85
val:
	val_majority_loss: 1.2568003512569703e-05
	val_minority_loss: 2.561915789556224e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.012028290890157223
	test_minority_loss: 0.046292565762996674
	test_majority_acc: 0.9965855142664353
	test_minority_acc: 0.9888684536976717
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.011134950444102287
	train_minority_loss: 0.036473892629146576
	train_majority_acc: 0.995461583030243
	train_minority_acc: 0.9921819801870282
	train_majority_nonzero: 1730
	train_minority_nonzero: 2214
val:
	val_majority_loss: 0.0020015137270092964
	val_minority_loss: 0.001961546251550317
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.013293782249093056
	test_minority_loss: 0.03239922970533371
	test_majority_acc: 0.996485354010025
	test_minority_acc: 0.9864965626170543
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.96934151649475 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.85
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.236001968383789
	train_minority_loss: 2.2805428504943848
	train_majority_acc: 0.6208468201346722
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.35100293159484863
	train_minority_loss: 0.2566966414451599
	train_majority_acc: 0.8271718138648965
	train_minority_acc: 0.9664761491999094
	train_majority_nonzero: 2826
	train_minority_nonzero: 2758
val:
	val_majority_loss: 0.06109923869371414
	val_minority_loss: 0.018910210579633713
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.050090812146663666
	test_minority_loss: 0.02706272527575493
	test_majority_acc: 0.9910267681245075
	test_minority_acc: 0.9944905334639713
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.028960270807147026
	train_minority_loss: 0.02441002056002617
	train_majority_acc: 0.9919619104759578
	train_minority_acc: 0.9936076529245561
	train_majority_nonzero: 2971
	train_minority_nonzero: 2222
val:
	val_majority_loss: 0.015286263078451157
	val_minority_loss: 0.02660272642970085
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 0.9871794871794872
test:
	test_majority_loss: 0.008993212133646011
	test_minority_loss: 0.037916868925094604
	test_majority_acc: 0.99875
	test_minority_acc: 0.9876315259142063
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.004911303520202637
	train_minority_loss: 0.022815853357315063
	train_majority_acc: 0.9989818066530094
	train_minority_acc: 0.9927473169792717
	train_majority_nonzero: 3050
	train_minority_nonzero: 3337
val:
	val_majority_loss: 0.0024041221477091312
	val_minority_loss: 0.0021281379740685225
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01723218709230423
	test_minority_loss: 0.03595009446144104
	test_majority_acc: 0.9925852889178757
	test_minority_acc: 0.9893563623999211
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.02960188500583172
	train_minority_loss: 0.022422853857278824
	train_majority_acc: 0.9897954158899817
	train_minority_acc: 0.9922000582946965
	train_majority_nonzero: 3002
	train_minority_nonzero: 4240
val:
	val_majority_loss: 0.02794117107987404
	val_minority_loss: 0.0015826155431568623
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02679825760424137
	test_minority_loss: 0.01090209186077118
	test_majority_acc: 0.9911155161797206
	test_minority_acc: 0.9936500801266764
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.017239948734641075
	train_minority_loss: 0.016466017812490463
	train_majority_acc: 0.9933234588576301
	train_minority_acc: 0.9947233307918859
	train_majority_nonzero: 2971
	train_minority_nonzero: 3443
val:
	val_majority_loss: 0.004441921133548021
	val_minority_loss: 0.000378174998331815
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.014505750499665737
	test_minority_loss: 0.020895620808005333
	test_majority_acc: 0.9952557270323927
	test_minority_acc: 0.9908945084212502
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 6.059235238353722e-05
	train_minority_loss: 0.0293459203094244
	train_majority_acc: 1.0
	train_minority_acc: 0.9936987322763545
	train_majority_nonzero: 1840
	train_minority_nonzero: 8030
val:
	val_majority_loss: 0.0021523514296859503
	val_minority_loss: 5.8920566516462713e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.016552722081542015
	test_minority_loss: 0.028989791870117188
	test_majority_acc: 0.9952557270323927
	test_minority_acc: 0.9887456156473573
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 2.382136881351471e-05
	train_minority_loss: 0.029063906520605087
	train_majority_acc: 1.0
	train_minority_acc: 0.9940855295234122
	train_majority_nonzero: 1457
	train_minority_nonzero: 1535
val:
	val_majority_loss: 0.0033915911335498095
	val_minority_loss: 2.457379741827026e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.020732136443257332
	test_minority_loss: 0.025571253150701523
	test_majority_acc: 0.9952557270323927
	test_minority_acc: 0.9908945084212502
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 1.9189932572771795e-05
	train_minority_loss: 0.031086651608347893
	train_majority_acc: 1.0
	train_minority_acc: 0.9940916623087751
	train_majority_nonzero: 1398
	train_minority_nonzero: 49
val:
	val_majority_loss: 0.0028139096684753895
	val_minority_loss: 2.5063545763259754e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.020000461488962173
	test_minority_loss: 0.02690567634999752
	test_majority_acc: 0.9952557270323927
	test_minority_acc: 0.9908945084212502
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 1.35786949613248e-05
	train_minority_loss: 0.03343069180846214
	train_majority_acc: 1.0
	train_minority_acc: 0.9937933300864885
	train_majority_nonzero: 1302
	train_minority_nonzero: 1863
val:
	val_majority_loss: 0.001883212011307478
	val_minority_loss: 3.224016836611554e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.017884299159049988
	test_minority_loss: 0.03260556980967522
	test_majority_acc: 0.9952557270323927
	test_minority_acc: 0.9887456156473573
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 1.0422510968055576e-05
	train_minority_loss: 0.033818505704402924
	train_majority_acc: 1.0
	train_minority_acc: 0.993771324143657
	train_majority_nonzero: 1177
	train_minority_nonzero: 1178
val:
	val_majority_loss: 0.0020352317951619625
	val_minority_loss: 2.3004522518021986e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.019335005432367325
	test_minority_loss: 0.03142518550157547
	test_majority_acc: 0.9952557270323927
	test_minority_acc: 0.989692585344327
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.861634731292725 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.875
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2359488010406494
	train_minority_loss: 2.2805256843566895
	train_majority_acc: 0.6120761830171606
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.4266837239265442
	train_minority_loss: 0.32123851776123047
	train_majority_acc: 0.7899887696997351
	train_minority_acc: 0.9767728765496777
	train_majority_nonzero: 2372
	train_minority_nonzero: 2470
val:
	val_majority_loss: 0.04637720435857773
	val_minority_loss: 0.0250642579048872
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05282948538661003
	test_minority_loss: 0.038790758699178696
	test_majority_acc: 0.9883716597497572
	test_minority_acc: 0.9916255242228103
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.017164045944809914
	train_minority_loss: 0.04502987861633301
	train_majority_acc: 0.9962256147448607
	train_minority_acc: 0.9862522571706129
	train_majority_nonzero: 2529
	train_minority_nonzero: 3306
val:
	val_majority_loss: 0.0010828054510056973
	val_minority_loss: 0.01655273139476776
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.004621674306690693
	test_minority_loss: 0.056826379150152206
	test_majority_acc: 1.0
	test_minority_acc: 0.9793463788801651
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.00031339487759396434
	train_minority_loss: 0.06021402031183243
	train_majority_acc: 1.0
	train_minority_acc: 0.980134347648153
	train_majority_nonzero: 2548
	train_minority_nonzero: 1553
val:
	val_majority_loss: 0.0004380524915177375
	val_minority_loss: 0.010944448411464691
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.006109229754656553
	test_minority_loss: 0.0603628009557724
	test_majority_acc: 0.9966909461152882
	test_minority_acc: 0.9823179044810011
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.008697906509041786
	train_minority_loss: 0.056349609047174454
	train_majority_acc: 0.9960141019842513
	train_minority_acc: 0.9819795792315429
	train_majority_nonzero: 2540
	train_minority_nonzero: 2317
val:
	val_majority_loss: 0.14645004272460938
	val_minority_loss: 0.00012294171028770506
	val_majority_acc: 0.9625893232450609
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.23708182573318481
	test_minority_loss: 0.000499291461892426
	test_majority_acc: 0.9228717472275303
	test_minority_acc: 1.0
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.027274183928966522
	train_minority_loss: 0.029661718755960464
	train_majority_acc: 0.99240641250888
	train_minority_acc: 0.9901798818383291
	train_majority_nonzero: 2509
	train_minority_nonzero: 2765
val:
	val_majority_loss: 0.003787799272686243
	val_minority_loss: 0.005557566415518522
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.017042746767401695
	test_minority_loss: 0.024276940152049065
	test_majority_acc: 0.9949695548712205
	test_minority_acc: 0.9940618060818807
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.04135702922940254
	train_minority_loss: 0.024808485060930252
	train_majority_acc: 0.9846934932946438
	train_minority_acc: 0.9934109177155059
	train_majority_nonzero: 2503
	train_minority_nonzero: 2408
val:
	val_majority_loss: 0.008171161636710167
	val_minority_loss: 0.010317699983716011
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01586531475186348
	test_minority_loss: 0.0358952060341835
	test_majority_acc: 0.994883703222869
	test_minority_acc: 0.9864399502982137
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.0075913784094154835
	train_minority_loss: 0.01943720318377018
	train_majority_acc: 0.9977789623312011
	train_minority_acc: 0.9941723893271361
	train_majority_nonzero: 2235
	train_minority_nonzero: 5419
val:
	val_majority_loss: 0.005451779812574387
	val_minority_loss: 0.0006023015594109893
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.027306415140628815
	test_minority_loss: 0.0232582725584507
	test_majority_acc: 0.9900256379207246
	test_minority_acc: 0.9934706297575213
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 1.3170556485420093e-05
	train_minority_loss: 0.027741413563489914
	train_majority_acc: 1.0
	train_minority_acc: 0.9938978373446311
	train_majority_nonzero: 827
	train_minority_nonzero: 5410
val:
	val_majority_loss: 0.0037344556767493486
	val_minority_loss: 0.00021175583242438734
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.030226323753595352
	test_minority_loss: 0.026639580726623535
	test_majority_acc: 0.9900256379207246
	test_minority_acc: 0.9934706297575213
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 4.582527708407724e-06
	train_minority_loss: 0.030284181237220764
	train_majority_acc: 1.0
	train_minority_acc: 0.9934904399590295
	train_majority_nonzero: 604
	train_minority_nonzero: 3989
val:
	val_majority_loss: 0.001981971552595496
	val_minority_loss: 0.0001907360419863835
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.025682786479592323
	test_minority_loss: 0.03257354721426964
	test_majority_acc: 0.9900256379207246
	test_minority_acc: 0.990715058052095
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 2.0937525277986424e-06
	train_minority_loss: 0.03262018412351608
	train_majority_acc: 1.0
	train_minority_acc: 0.993324172169498
	train_majority_nonzero: 508
	train_minority_nonzero: 4705
val:
	val_majority_loss: 0.0015229613054543734
	val_minority_loss: 0.00015640845231246203
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.024553976953029633
	test_minority_loss: 0.035251982510089874
	test_majority_acc: 0.9926711405662273
	test_minority_acc: 0.990715058052095
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.83873510360718 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.9
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235722541809082
	train_minority_loss: 2.2804977893829346
	train_majority_acc: 0.6104700026341818
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.5718448162078857
	train_minority_loss: 0.31864139437675476
	train_majority_acc: 0.6288494157128924
	train_minority_acc: 0.9827472497332622
	train_majority_nonzero: 1922
	train_minority_nonzero: 2267
val:
	val_majority_loss: 0.12617862224578857
	val_minority_loss: 0.012334098108112812
	val_majority_acc: 0.9579655317360235
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.14862972497940063
	test_minority_loss: 0.016690455377101898
	test_majority_acc: 0.9536329377500365
	test_minority_acc: 0.998546511627907
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.054480113089084625
	train_minority_loss: 0.0362706333398819
	train_majority_acc: 0.9822719016748868
	train_minority_acc: 0.989075815808458
	train_majority_nonzero: 2033
	train_minority_nonzero: 1811
val:
	val_majority_loss: 0.005374445579946041
	val_minority_loss: 0.03885125368833542
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.012508882209658623
	test_minority_loss: 0.08085936307907104
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.9690691116474821
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.0019134337780997157
	train_minority_loss: 0.04893514886498451
	train_majority_acc: 1.0
	train_minority_acc: 0.9829978976348208
	train_majority_nonzero: 2050
	train_minority_nonzero: 1401
val:
	val_majority_loss: 0.0011416188208386302
	val_minority_loss: 0.030109168961644173
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.007980111986398697
	test_minority_loss: 0.0781620591878891
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.9738526273415581
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.00038656385731883347
	train_minority_loss: 0.05946512520313263
	train_majority_acc: 1.0
	train_minority_acc: 0.9833965627449373
	train_majority_nonzero: 1926
	train_minority_nonzero: 2649
val:
	val_majority_loss: 0.00010174495400860906
	val_minority_loss: 0.022404320538043976
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.008732300251722336
	test_minority_loss: 0.08990424871444702
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.982223111761082
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 8.241218893090263e-06
	train_minority_loss: 0.07508324086666107
	train_majority_acc: 1.0
	train_minority_acc: 0.9817799524235831
	train_majority_nonzero: 1541
	train_minority_nonzero: 1671
val:
	val_majority_loss: 6.268039578571916e-05
	val_minority_loss: 0.023437272757291794
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.00795392319560051
	test_minority_loss: 0.09844444692134857
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.9808644161089081
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 4.751325832330622e-06
	train_minority_loss: 0.07930662482976913
	train_majority_acc: 1.0
	train_minority_acc: 0.9809869127333125
	train_majority_nonzero: 1347
	train_minority_nonzero: 5719
val:
	val_majority_loss: 4.608914605341852e-05
	val_minority_loss: 0.02192191407084465
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.00927714817225933
	test_minority_loss: 0.09839931130409241
	test_majority_acc: 0.9966909461152882
	test_minority_acc: 0.982223111761082
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 3.0177827738953056e-06
	train_minority_loss: 0.08359537273645401
	train_majority_acc: 1.0
	train_minority_acc: 0.9805958166871346
	train_majority_nonzero: 1216
	train_minority_nonzero: 714
val:
	val_majority_loss: 3.1077539460966364e-05
	val_minority_loss: 0.026253120973706245
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.00822520349174738
	test_minority_loss: 0.10783711075782776
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.978023507017999
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 1.8084903103954275e-06
	train_minority_loss: 0.08943852037191391
	train_majority_acc: 1.0
	train_minority_acc: 0.9805918561326258
	train_majority_nonzero: 1055
	train_minority_nonzero: 2099
val:
	val_majority_loss: 2.4955101252999157e-05
	val_minority_loss: 0.025872718542814255
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.008633367717266083
	test_minority_loss: 0.1100253015756607
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.9789704767149686
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 1.3597408496934804e-06
	train_minority_loss: 0.09405166655778885
	train_majority_acc: 1.0
	train_minority_acc: 0.9799543005565335
	train_majority_nonzero: 1003
	train_minority_nonzero: 2420
val:
	val_majority_loss: 1.5943018297548406e-05
	val_minority_loss: 0.029362089931964874
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.007879390381276608
	test_minority_loss: 0.12021788954734802
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.978023507017999
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 1.0467631454957882e-06
	train_minority_loss: 0.0970601886510849
	train_majority_acc: 1.0
	train_minority_acc: 0.9795476648823724
	train_majority_nonzero: 864
	train_minority_nonzero: 1879
val:
	val_majority_loss: 1.2236561815370806e-05
	val_minority_loss: 0.031090129166841507
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.0078230369836092
	test_minority_loss: 0.12505507469177246
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.9765700186459059
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 46.09620189666748 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.925
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235808849334717
	train_minority_loss: 2.2804765701293945
	train_majority_acc: 0.6131854740063696
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.6205670833587646
	train_minority_loss: 0.33047181367874146
	train_majority_acc: 0.6310591426263069
	train_minority_acc: 0.9859992942257454
	train_majority_nonzero: 1493
	train_minority_nonzero: 1899
val:
	val_majority_loss: 0.08679069578647614
	val_minority_loss: 0.021469097584486008
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.11516302824020386
	test_minority_loss: 0.03172661364078522
	test_majority_acc: 0.9669541725217714
	test_minority_acc: 0.9935552874067574
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.04834998771548271
	train_minority_loss: 0.03748023882508278
	train_majority_acc: 0.9825238884940378
	train_minority_acc: 0.9884035640635597
	train_majority_nonzero: 1549
	train_minority_nonzero: 1086
val:
	val_majority_loss: 0.003496511373668909
	val_minority_loss: 0.05744338035583496
	val_majority_acc: 1.0
	val_minority_acc: 0.9672131147540983
test:
	test_majority_loss: 0.011139159090816975
	test_minority_loss: 0.1022607684135437
	test_majority_acc: 0.9960059514439139
	test_minority_acc: 0.9622579522234793
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.0039362479001283646
	train_minority_loss: 0.04764020815491676
	train_majority_acc: 0.9992892679459844
	train_minority_acc: 0.9844475216633551
	train_majority_nonzero: 1550
	train_minority_nonzero: 1581
val:
	val_majority_loss: 0.0008296301821246743
	val_minority_loss: 0.0163327157497406
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.00981220044195652
	test_minority_loss: 0.06573814153671265
	test_majority_acc: 0.9978441867380315
	test_minority_acc: 0.9758415804174677
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.04597858339548111
	train_minority_loss: 0.035577721893787384
	train_majority_acc: 0.9836494075300045
	train_minority_acc: 0.9892002790211862
	train_majority_nonzero: 1550
	train_minority_nonzero: 1110
val:
	val_majority_loss: 0.0013548580463975668
	val_minority_loss: 0.03110147826373577
	val_majority_acc: 1.0
	val_minority_acc: 0.9836065573770492
test:
	test_majority_loss: 0.011681964620947838
	test_minority_loss: 0.07380548864603043
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.9787155233350153
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.00027812246116809547
	train_minority_loss: 0.07811547815799713
	train_majority_acc: 1.0
	train_minority_acc: 0.9795560816595209
	train_majority_nonzero: 1531
	train_minority_nonzero: 11328
val:
	val_majority_loss: 8.631763193989173e-05
	val_minority_loss: 0.029501179233193398
	val_majority_acc: 1.0
	val_minority_acc: 0.9836065573770492
test:
	test_majority_loss: 0.013189340941607952
	test_minority_loss: 0.0962149053812027
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.9787155233350153
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 4.185848229099065e-05
	train_minority_loss: 0.08800064027309418
	train_majority_acc: 1.0
	train_minority_acc: 0.9804164523926276
	train_majority_nonzero: 1444
	train_minority_nonzero: 4598
val:
	val_majority_loss: 3.712772740982473e-05
	val_minority_loss: 0.03520042076706886
	val_majority_acc: 1.0
	val_minority_acc: 0.9836065573770492
test:
	test_majority_loss: 0.012772446498274803
	test_minority_loss: 0.1096399649977684
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.9773568276828413
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 2.0979381588404067e-05
	train_minority_loss: 0.09576426446437836
	train_majority_acc: 1.0
	train_minority_acc: 0.9798278477865506
	train_majority_nonzero: 1347
	train_minority_nonzero: 2933
val:
	val_majority_loss: 2.3428407075698487e-05
	val_minority_loss: 0.03683609142899513
	val_majority_acc: 1.0
	val_minority_acc: 0.9836065573770492
test:
	test_majority_loss: 0.013005831278860569
	test_minority_loss: 0.11565631628036499
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.9773568276828413
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 1.4087361705605872e-05
	train_minority_loss: 0.09997405111789703
	train_majority_acc: 1.0
	train_minority_acc: 0.9801623078009192
	train_majority_nonzero: 1270
	train_minority_nonzero: 2167
val:
	val_majority_loss: 1.677022737567313e-05
	val_minority_loss: 0.03871762752532959
	val_majority_acc: 1.0
	val_minority_acc: 0.9836065573770492
test:
	test_majority_loss: 0.01302250288426876
	test_minority_loss: 0.12082003057003021
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.9773568276828413
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 1.0470233974047005e-05
	train_minority_loss: 0.10361623018980026
	train_majority_acc: 1.0
	train_minority_acc: 0.9797320269028521
	train_majority_nonzero: 1233
	train_minority_nonzero: 1286
val:
	val_majority_loss: 1.3854378266842104e-05
	val_minority_loss: 0.03726482018828392
	val_majority_acc: 1.0
	val_minority_acc: 0.9836065573770492
test:
	test_majority_loss: 0.01368599385023117
	test_minority_loss: 0.12115292251110077
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.9773568276828413
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 8.116227945720311e-06
	train_minority_loss: 0.10670914500951767
	train_majority_acc: 1.0
	train_minority_acc: 0.9794249971007885
	train_majority_nonzero: 1170
	train_minority_nonzero: 1207
val:
	val_majority_loss: 1.0360176929680165e-05
	val_minority_loss: 0.04254920408129692
	val_majority_acc: 1.0
	val_minority_acc: 0.9836065573770492
test:
	test_majority_loss: 0.012862762436270714
	test_minority_loss: 0.1295010894536972
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.9761775823998224
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 46.03228569030762 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.95
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2349295616149902
	train_minority_loss: 2.2804789543151855
	train_majority_acc: 0.6494906558339394
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.8719437008351087
	train_minority_loss: 0.41314756870269775
	train_majority_acc: 0.3597516233766233
	train_minority_acc: 0.9904289620316842
	train_majority_nonzero: 1007
	train_minority_nonzero: 1561
val:
	val_majority_loss: 0.14762766659259796
	val_minority_loss: 0.2673429846763611
	val_majority_acc: 1.0
	val_minority_acc: 0.9754098360655737
test:
	test_majority_loss: 0.1518906205892563
	test_minority_loss: 0.2894971966743469
	test_majority_acc: 0.9965178571428571
	test_minority_acc: 0.9486579669791726
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.12796147573448252
	train_minority_loss: 0.05390552803874016
	train_majority_acc: 0.9625099206349206
	train_minority_acc: 0.9868765308362254
	train_majority_nonzero: 1050
	train_minority_nonzero: 1058
val:
	val_majority_loss: 0.10217857360839844
	val_minority_loss: 0.0066332644782960415
	val_majority_acc: 0.9836065573770492
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.1356307715177536
	test_minority_loss: 0.008748815394937992
	test_majority_acc: 0.9542818970973688
	test_minority_acc: 1.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.0061883023008704185
	train_minority_loss: 0.043936192989349365
	train_majority_acc: 1.0
	train_minority_acc: 0.9854219487113586
	train_majority_nonzero: 1050
	train_minority_nonzero: 1525
val:
	val_majority_loss: 0.0012607269454747438
	val_minority_loss: 0.015836568549275398
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.007687879726290703
	test_minority_loss: 0.05344993621110916
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.9789966327802926
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.00048553323722444475
	train_minority_loss: 0.05345571041107178
	train_majority_acc: 1.0
	train_minority_acc: 0.9815757650238517
	train_majority_nonzero: 1050
	train_minority_nonzero: 1484
val:
	val_majority_loss: 0.00061742530670017
	val_minority_loss: 0.015431217849254608
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.007972562685608864
	test_minority_loss: 0.061800267547369
	test_majority_acc: 0.9989035087719298
	test_minority_acc: 0.9751339307178623
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.00019671615010338428
	train_minority_loss: 0.06621167063713074
	train_majority_acc: 1.0
	train_minority_acc: 0.977560172172367
	train_majority_nonzero: 1050
	train_minority_nonzero: 2513
val:
	val_majority_loss: 0.000541701796464622
	val_minority_loss: 0.009181734174489975
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01105934102088213
	test_minority_loss: 0.05232002213597298
	test_majority_acc: 0.9966909461152882
	test_minority_acc: 0.9812761420641123
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.00012039063843360509
	train_minority_loss: 0.06411721557378769
	train_majority_acc: 1.0
	train_minority_acc: 0.9791299254499062
	train_majority_nonzero: 1040
	train_minority_nonzero: 5
val:
	val_majority_loss: 0.0001980392844416201
	val_minority_loss: 0.018600057810544968
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.006192564498633146
	test_minority_loss: 0.07812698930501938
	test_majority_acc: 0.9989035087719298
	test_minority_acc: 0.9710526971869005
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.00012523840996436775
	train_minority_loss: 0.05893866345286369
	train_majority_acc: 1.0
	train_minority_acc: 0.9812796622424251
	train_majority_nonzero: 1031
	train_minority_nonzero: 1957
val:
	val_majority_loss: 0.0004391483962535858
	val_minority_loss: 0.007849842309951782
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.013561826199293137
	test_minority_loss: 0.054449208080768585
	test_majority_acc: 0.9966909461152882
	test_minority_acc: 0.9849864619261206
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 7.074753005753109e-05
	train_minority_loss: 0.06454970687627792
	train_majority_acc: 1.0
	train_minority_acc: 0.9806139106585294
	train_majority_nonzero: 1024
	train_minority_nonzero: 0
val:
	val_majority_loss: 0.0001682058209553361
	val_minority_loss: 0.01438670139759779
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.008653123863041401
	test_minority_loss: 0.07365423440933228
	test_majority_acc: 0.9966909461152882
	test_minority_acc: 0.9772620349629222
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 4.1531635324218994e-05
	train_minority_loss: 0.07989398390054703
	train_majority_acc: 1.0
	train_minority_acc: 0.976828048845815
	train_majority_nonzero: 1020
	train_minority_nonzero: 9
val:
	val_majority_loss: 9.800517000257969e-05
	val_minority_loss: 0.02109823189675808
	val_majority_acc: 1.0
	val_minority_acc: 0.9836065573770492
test:
	test_majority_loss: 0.006506822071969509
	test_minority_loss: 0.08967241644859314
	test_majority_acc: 0.9989035087719298
	test_minority_acc: 0.9695992088148075
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 3.0424205760937184e-05
	train_minority_loss: 0.08804478496313095
	train_majority_acc: 1.0
	train_minority_acc: 0.9750216980344155
	train_majority_nonzero: 1011
	train_minority_nonzero: 3071
val:
	val_majority_loss: 7.081118383212015e-05
	val_minority_loss: 0.020801134407520294
	val_majority_acc: 1.0
	val_minority_acc: 0.9754098360655737
test:
	test_majority_loss: 0.006574117578566074
	test_minority_loss: 0.09163449704647064
	test_majority_acc: 0.9989035087719298
	test_minority_acc: 0.9695992088148075
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 46.10882377624512 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.975
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.234567921240251
	train_minority_loss: 2.280471086502075
	train_majority_acc: 0.6430468341182627
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 1.2092962469905615
	train_minority_loss: 0.3742388188838959
	train_majority_acc: 0.15339781746031747
	train_minority_acc: 0.9925159591456598
	train_majority_nonzero: 538
	train_minority_nonzero: 1155
val:
	val_majority_loss: 0.5969724655151367
	val_minority_loss: 0.23286259174346924
	val_majority_acc: 0.7324506094997898
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.589806854724884
	test_minority_loss: 0.24287836253643036
	test_majority_acc: 0.7482260547533733
	test_minority_acc: 0.9936569464828796
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.25211285711366244
	train_minority_loss: 0.07408642768859863
	train_majority_acc: 0.8773297491039426
	train_minority_acc: 0.9894431009385322
	train_majority_nonzero: 546
	train_minority_nonzero: 993
val:
	val_majority_loss: 0.01586179807782173
	val_minority_loss: 0.04451794922351837
	val_majority_acc: 1.0
	val_minority_acc: 0.9836065573770492
test:
	test_majority_loss: 0.032061684876680374
	test_minority_loss: 0.06497021019458771
	test_majority_acc: 0.9912932764091078
	test_minority_acc: 0.9791209696503191
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.15197233033918398
	train_minority_loss: 0.03384022414684296
	train_majority_acc: 0.9471781305114637
	train_minority_acc: 0.9887075712004603
	train_majority_nonzero: 544
	train_minority_nonzero: 657
val:
	val_majority_loss: 0.0036791132297366858
	val_minority_loss: 0.04159833490848541
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.027606073766946793
	test_minority_loss: 0.04613914713263512
	test_majority_acc: 0.9925480756412307
	test_minority_acc: 0.9822299781172852
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.29918665749884593
	train_minority_loss: 0.03415506333112717
	train_majority_acc: 0.9172123015873016
	train_minority_acc: 0.989156055785923
	train_majority_nonzero: 550
	train_minority_nonzero: 557
val:
	val_majority_loss: 0.1188613623380661
	val_minority_loss: 0.009240148589015007
	val_majority_acc: 0.9451450189155107
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.14269167184829712
	test_minority_loss: 0.022309504449367523
	test_majority_acc: 0.9483610683872927
	test_minority_acc: 0.9937290614088945
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.1766362196939393
	train_minority_loss: 0.03632242977619171
	train_majority_acc: 0.9294881588999236
	train_minority_acc: 0.9882471683466456
	train_majority_nonzero: 546
	train_minority_nonzero: 1541
val:
	val_majority_loss: 0.024361878633499146
	val_minority_loss: 0.003680027090013027
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05338764935731888
	test_minority_loss: 0.025337114930152893
	test_majority_acc: 0.9754077176741376
	test_minority_acc: 0.9898682486115356
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.0027659091828625315
	train_minority_loss: 0.02709844708442688
	train_majority_acc: 1.0
	train_minority_acc: 0.9903340712060587
	train_majority_nonzero: 544
	train_minority_nonzero: 738
val:
	val_majority_loss: 0.010223036631941795
	val_minority_loss: 0.00408167066052556
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.042312003672122955
	test_minority_loss: 0.03864467144012451
	test_majority_acc: 0.9819768666103078
	test_minority_acc: 0.9863093337882869
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.0005787123326707675
	train_minority_loss: 0.03945484384894371
	train_majority_acc: 1.0
	train_minority_acc: 0.9859784983972754
	train_majority_nonzero: 531
	train_minority_nonzero: 1
val:
	val_majority_loss: 0.0046322960406541824
	val_minority_loss: 0.008875036612153053
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.027252420783042908
	test_minority_loss: 0.05548154562711716
	test_majority_acc: 0.9902563866834762
	test_minority_acc: 0.979569199131778
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.0002497358267874567
	train_minority_loss: 0.04831371083855629
	train_majority_acc: 1.0
	train_minority_acc: 0.984084003470512
	train_majority_nonzero: 498
	train_minority_nonzero: 2536
val:
	val_majority_loss: 0.003794422373175621
	val_minority_loss: 0.008569023571908474
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.02834584191441536
	test_minority_loss: 0.05761183053255081
	test_majority_acc: 0.9902563866834762
	test_minority_acc: 0.981022687503871
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.0001028996440332795
	train_minority_loss: 0.050351858139038086
	train_majority_acc: 1.0
	train_minority_acc: 0.9839115185920646
	train_majority_nonzero: 465
	train_minority_nonzero: 1859
val:
	val_majority_loss: 0.0032233211677521467
	val_minority_loss: 0.008617380633950233
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.02810118906199932
	test_minority_loss: 0.0600125789642334
	test_majority_acc: 0.9902563866834762
	test_minority_acc: 0.9784916129248814
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 9.794311830006109e-05
	train_minority_loss: 0.05161590874195099
	train_majority_acc: 1.0
	train_minority_acc: 0.9839669527891779
	train_majority_nonzero: 458
	train_minority_nonzero: 471
val:
	val_majority_loss: 0.0030002021230757236
	val_minority_loss: 0.00862210150808096
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.029311370104551315
	test_minority_loss: 0.06169973313808441
	test_majority_acc: 0.9884181513893584
	test_minority_acc: 0.9784916129248814
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.91602396965027 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: ltrwe
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 1.0
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.236476497216658
	train_minority_loss: 2.2804484367370605
	train_majority_acc: 0.4772727272727273
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 3.9068560955372265
	train_minority_loss: 0.10675705224275589
	train_majority_acc: 0.0
	train_minority_acc: 0.9950248756218906
	train_majority_nonzero: 49
	train_minority_nonzero: 599
val:
	val_majority_loss: 2.1900815963745117
	val_minority_loss: 0.08425001800060272
	val_majority_acc: 0.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 2.1744468212127686
	test_minority_loss: 0.08384516090154648
	test_majority_acc: 0.0
	test_minority_acc: 1.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 2.1242542803287505
	train_minority_loss: 0.12004201114177704
	train_majority_acc: 0.0
	train_minority_acc: 1.0
	train_majority_nonzero: 50
	train_minority_nonzero: 100
val:
	val_majority_loss: 1.4809988737106323
	val_minority_loss: 0.21400654315948486
	val_majority_acc: 0.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 1.4727692604064941
	test_minority_loss: 0.21478061378002167
	test_majority_acc: 0.0
	test_minority_acc: 1.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 1.6588663846947427
	train_minority_loss: 0.21704693138599396
	train_majority_acc: 0.0
	train_minority_acc: 1.0
	train_majority_nonzero: 50
	train_minority_nonzero: 105
val:
	val_majority_loss: 1.8526787757873535
	val_minority_loss: 0.08038435131311417
	val_majority_acc: 0.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 1.8225098848342896
	test_minority_loss: 0.07898825407028198
	test_majority_acc: 0.0
	test_minority_acc: 1.0
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 1.5459211698987267
	train_minority_loss: 0.15893614292144775
	train_majority_acc: 0.09090909090909091
	train_minority_acc: 0.9998507462686567
	train_majority_nonzero: 50
	train_minority_nonzero: 118
val:
	val_majority_loss: 2.6197667121887207
	val_minority_loss: 0.019609738141298294
	val_majority_acc: 0.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 2.582639217376709
	test_minority_loss: 0.020487597212195396
	test_majority_acc: 0.0
	test_minority_acc: 1.0
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 1.409263656191204
	train_minority_loss: 0.13503147661685944
	train_majority_acc: 0.1956521739130435
	train_minority_acc: 0.9998507462686567
	train_majority_nonzero: 50
	train_minority_nonzero: 109
val:
	val_majority_loss: 2.746995449066162
	val_minority_loss: 0.0018709655851125717
	val_majority_acc: 0.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 2.6334762573242188
	test_minority_loss: 0.0023983162827789783
	test_majority_acc: 0.0
	test_minority_acc: 1.0
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.4391905007678149
	train_minority_loss: 0.032697439193725586
	train_majority_acc: 0.7558139534883721
	train_minority_acc: 0.9948092458753439
	train_majority_nonzero: 50
	train_minority_nonzero: 113
val:
	val_majority_loss: 0.10349343717098236
	val_minority_loss: 0.015443162992596626
	val_majority_acc: 0.9707860445565364
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.1284574270248413
	test_minority_loss: 0.02197360061109066
	test_majority_acc: 0.9618434848174915
	test_minority_acc: 0.997618831640058
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.013148266460699564
	train_minority_loss: 0.008645689114928246
	train_majority_acc: 1.0
	train_minority_acc: 0.997657660983887
	train_majority_nonzero: 50
	train_minority_nonzero: 207
val:
	val_majority_loss: 0.1060430109500885
	val_minority_loss: 0.0035316129215061665
	val_majority_acc: 0.9461958806221101
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.1680915206670761
	test_minority_loss: 0.007197917439043522
	test_majority_acc: 0.943468883229529
	test_minority_acc: 0.997618831640058
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 1.5845401728253883
	train_minority_loss: 0.00791136734187603
	train_majority_acc: 0.8541666666666666
	train_minority_acc: 0.9972566460626163
	train_majority_nonzero: 50
	train_minority_nonzero: 576
val:
	val_majority_loss: 19.212844848632812
	val_minority_loss: 1.9542503171265935e-09
	val_majority_acc: 0.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 18.78635597229004
	test_minority_loss: 1.892141776593803e-09
	test_majority_acc: 0.0
	test_minority_acc: 1.0
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 3.2260908319149166
	train_minority_loss: 0.005355162546038628
	train_majority_acc: 0.4888888888888889
	train_minority_acc: 0.9991029699984924
	train_majority_nonzero: 50
	train_minority_nonzero: 87
val:
	val_majority_loss: 0.1744779348373413
	val_minority_loss: 0.01665404997766018
	val_majority_acc: 0.9415720891130728
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.19972464442253113
	test_minority_loss: 0.01464689802378416
	test_majority_acc: 0.9324076609400258
	test_minority_acc: 0.9988207547169812
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.1326345134500621
	train_minority_loss: 0.0048503815196454525
	train_majority_acc: 0.9666666666666667
	train_minority_acc: 0.9985049499974874
	train_majority_nonzero: 50
	train_minority_nonzero: 79
val:
	val_majority_loss: 0.256417840719223
	val_minority_loss: 0.00409894110634923
	val_majority_acc: 0.8877679697351828
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.3178637623786926
	test_minority_loss: 0.00846109353005886
	test_majority_acc: 0.9000798170916724
	test_minority_acc: 0.9988207547169812
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.680721044540405 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.5
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2358131408691406
	train_minority_loss: 2.2805604934692383
	train_majority_acc: 0.6259720229956415
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.14613163471221924
	train_minority_loss: 0.19798126816749573
	train_majority_acc: 0.9782985370169974
	train_minority_acc: 0.9347281604906547
	train_majority_nonzero: 5829
	train_minority_nonzero: 5145
val:
	val_majority_loss: 0.006367865949869156
	val_minority_loss: 0.03379761055111885
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.013206634670495987
	test_minority_loss: 0.05193778872489929
	test_majority_acc: 0.9957354862437696
	test_minority_acc: 0.9829604072025424
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.015576977282762527
	train_minority_loss: 0.02375001646578312
	train_majority_acc: 0.9957303972788389
	train_minority_acc: 0.9947357471010932
	train_majority_nonzero: 5585
	train_minority_nonzero: 6209
val:
	val_majority_loss: 0.010855859145522118
	val_minority_loss: 0.008087195456027985
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.014713509008288383
	test_minority_loss: 0.021376414224505424
	test_majority_acc: 0.9935600927813
	test_minority_acc: 0.9914785095588794
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.0075165871530771255
	train_minority_loss: 0.012207908555865288
	train_majority_acc: 0.9976533205415795
	train_minority_acc: 0.9973047540503921
	train_majority_nonzero: 6195
	train_minority_nonzero: 7633
val:
	val_majority_loss: 0.016156727448105812
	val_minority_loss: 0.002386245410889387
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.023961832746863365
	test_minority_loss: 0.014612896367907524
	test_majority_acc: 0.9911081697043769
	test_minority_acc: 0.993604724538868
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.0037335525266826153
	train_minority_loss: 0.00436824094504118
	train_majority_acc: 0.9987586467657887
	train_minority_acc: 0.9991077437425459
	train_majority_nonzero: 4506
	train_minority_nonzero: 7652
val:
	val_majority_loss: 0.00852441880851984
	val_minority_loss: 0.005323116667568684
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.006410212256014347
	test_minority_loss: 0.04754184931516647
	test_majority_acc: 0.9975737215378873
	test_minority_acc: 0.9865967228734646
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.0003020735166501254
	train_minority_loss: 0.00031568342819809914
	train_majority_acc: 0.9995455229368923
	train_minority_acc: 1.0
	train_majority_nonzero: 3506
	train_minority_nonzero: 8006
val:
	val_majority_loss: 0.012767966836690903
	val_minority_loss: 0.0004125951090827584
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.016954118385910988
	test_minority_loss: 0.026861276477575302
	test_majority_acc: 0.9952643995039889
	test_minority_acc: 0.9924254792558491
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 4.081311635673046e-05
	train_minority_loss: 5.3072115406394005e-05
	train_majority_acc: 0.9994973302942196
	train_minority_acc: 1.0
	train_majority_nonzero: 2840
	train_minority_nonzero: 7787
val:
	val_majority_loss: 0.009086287580430508
	val_minority_loss: 0.00041075522312894464
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.016636844724416733
	test_minority_loss: 0.03204336762428284
	test_majority_acc: 0.9965143995039889
	test_minority_acc: 0.9909719908837561
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 2.279778891534079e-05
	train_minority_loss: 3.0943716410547495e-05
	train_majority_acc: 0.9995457695114914
	train_minority_acc: 1.0
	train_majority_nonzero: 1962
	train_minority_nonzero: 6889
val:
	val_majority_loss: 0.008837433531880379
	val_minority_loss: 0.00031166549888439476
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.018224788829684258
	test_minority_loss: 0.032559409737586975
	test_majority_acc: 0.9965143995039889
	test_minority_acc: 0.9909719908837561
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 1.5541998436674476e-05
	train_minority_loss: 1.835169859987218e-05
	train_majority_acc: 0.9995024565809036
	train_minority_acc: 1.0
	train_majority_nonzero: 1560
	train_minority_nonzero: 6136
val:
	val_majority_loss: 0.013685506768524647
	val_minority_loss: 0.00017263658810406923
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.021931977942585945
	test_minority_loss: 0.028971608728170395
	test_majority_acc: 0.9952643995039889
	test_minority_acc: 0.993604724538868
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 1.1403275493648835e-05
	train_minority_loss: 1.282309131056536e-05
	train_majority_acc: 0.9994941792989369
	train_minority_acc: 1.0
	train_majority_nonzero: 1167
	train_minority_nonzero: 5413
val:
	val_majority_loss: 0.008027949370443821
	val_minority_loss: 0.0002058461686829105
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.019987188279628754
	test_minority_loss: 0.03397310525178909
	test_majority_acc: 0.9965143995039889
	test_minority_acc: 0.9909719908837561
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 1.0370260497438721e-05
	train_minority_loss: 8.896780855138786e-06
	train_majority_acc: 0.9994567913935684
	train_minority_acc: 1.0
	train_majority_nonzero: 987
	train_minority_nonzero: 5091
val:
	val_majority_loss: 0.007444334682077169
	val_minority_loss: 0.0001783480547601357
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.020527439191937447
	test_minority_loss: 0.0348396897315979
	test_majority_acc: 0.9965143995039889
	test_minority_acc: 0.9909719908837561
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.71914196014404 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.525
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2358930110931396
	train_minority_loss: 2.2805631160736084
	train_majority_acc: 0.6249174647643717
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.14692901074886322
	train_minority_loss: 0.18840111792087555
	train_majority_acc: 0.979059079780557
	train_minority_acc: 0.9437667570403723
	train_majority_nonzero: 6327
	train_minority_nonzero: 5080
val:
	val_majority_loss: 0.02098410204052925
	val_minority_loss: 0.00595898786559701
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.036495111882686615
	test_minority_loss: 0.013770384714007378
	test_majority_acc: 0.9860363885967615
	test_minority_acc: 0.997618831640058
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.013612031005322933
	train_minority_loss: 0.017494458705186844
	train_majority_acc: 0.9966164807727584
	train_minority_acc: 0.9956399000975625
	train_majority_nonzero: 6257
	train_minority_nonzero: 4886
val:
	val_majority_loss: 0.03531055152416229
	val_minority_loss: 0.0014030772726982832
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04673842340707779
	test_minority_loss: 0.00708804139867425
	test_majority_acc: 0.983451802130596
	test_minority_acc: 0.9987980769230769
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.00657134223729372
	train_minority_loss: 0.006343167740851641
	train_majority_acc: 0.9981147571785439
	train_minority_acc: 0.998133449768143
	train_majority_nonzero: 5540
	train_minority_nonzero: 5511
val:
	val_majority_loss: 0.016519669443368912
	val_minority_loss: 0.0036583682522177696
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.021169494837522507
	test_minority_loss: 0.016911355778574944
	test_majority_acc: 0.9920719975432046
	test_minority_acc: 0.9936274023327722
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.00197175913490355
	train_minority_loss: 0.0035220636054873466
	train_majority_acc: 0.9988510658060394
	train_minority_acc: 0.9995336072937882
	train_majority_nonzero: 4238
	train_minority_nonzero: 8766
val:
	val_majority_loss: 0.0043464587070047855
	val_minority_loss: 0.0003316451038699597
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02178003638982773
	test_minority_loss: 0.019264012575149536
	test_majority_acc: 0.9908219975432047
	test_minority_acc: 0.9936274023327722
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 7.708751218160614e-05
	train_minority_loss: 0.00018290634034201503
	train_majority_acc: 0.9995204779555679
	train_minority_acc: 1.0
	train_majority_nonzero: 2372
	train_minority_nonzero: 7422
val:
	val_majority_loss: 0.0006850582431070507
	val_minority_loss: 0.0003575301670935005
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.015007523819804192
	test_minority_loss: 0.030318958684802055
	test_majority_acc: 0.9933694148151981
	test_minority_acc: 0.9915011873527837
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 2.1358495359891094e-05
	train_minority_loss: 8.332915604114532e-05
	train_majority_acc: 0.9994676734530658
	train_minority_acc: 1.0
	train_majority_nonzero: 1561
	train_minority_nonzero: 9103
val:
	val_majority_loss: 0.0007571508758701384
	val_minority_loss: 0.00028856078279204667
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01594303548336029
	test_minority_loss: 0.03287805616855621
	test_majority_acc: 0.9933694148151981
	test_minority_acc: 0.9915011873527837
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 1.4951136108720675e-05
	train_minority_loss: 4.747169077745639e-05
	train_majority_acc: 0.9995270455089352
	train_minority_acc: 1.0
	train_majority_nonzero: 1074
	train_minority_nonzero: 8376
val:
	val_majority_loss: 0.0009521617903374135
	val_minority_loss: 0.00020579941337928176
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01830395683646202
	test_minority_loss: 0.03180283308029175
	test_majority_acc: 0.9933694148151981
	test_minority_acc: 0.9926804326358025
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 1.3035511074122041e-05
	train_minority_loss: 3.0776856874581426e-05
	train_majority_acc: 0.9994836014577423
	train_minority_acc: 1.0
	train_majority_nonzero: 949
	train_minority_nonzero: 7741
val:
	val_majority_loss: 0.00176622299477458
	val_minority_loss: 0.00011057960364269093
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02329852618277073
	test_minority_loss: 0.02808937430381775
	test_majority_acc: 0.9933694148151981
	test_minority_acc: 0.9926804326358025
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 1.1159386303916108e-05
	train_minority_loss: 2.383220817137044e-05
	train_majority_acc: 0.9994615447969567
	train_minority_acc: 1.0
	train_majority_nonzero: 861
	train_minority_nonzero: 7317
val:
	val_majority_loss: 0.0007986854179762304
	val_minority_loss: 0.00014318725152406842
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01955023780465126
	test_minority_loss: 0.033372677862644196
	test_majority_acc: 0.9933694148151981
	test_minority_acc: 0.9926804326358025
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 8.684683962201234e-06
	train_minority_loss: 1.779844387783669e-05
	train_majority_acc: 0.9994327131195978
	train_minority_acc: 1.0
	train_majority_nonzero: 768
	train_minority_nonzero: 6758
val:
	val_majority_loss: 0.0007107826531864703
	val_minority_loss: 0.00013171046157367527
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01952846720814705
	test_minority_loss: 0.0340266190469265
	test_majority_acc: 0.9933694148151981
	test_minority_acc: 0.9926804326358025
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.369813203811646 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.55
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.23592209815979
	train_minority_loss: 2.280592679977417
	train_majority_acc: 0.6260342879291987
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.163163423538208
	train_minority_loss: 0.1922149509191513
	train_majority_acc: 0.9622436858833759
	train_minority_acc: 0.9587779562301089
	train_majority_nonzero: 5983
	train_minority_nonzero: 4978
val:
	val_majority_loss: 0.020674776285886765
	val_minority_loss: 0.00918162427842617
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.025780973955988884
	test_minority_loss: 0.024365290999412537
	test_majority_acc: 0.9915394901517947
	test_minority_acc: 0.9936802275496663
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.016773179173469543
	train_minority_loss: 0.021341200917959213
	train_majority_acc: 0.9956853015809898
	train_minority_acc: 0.9936481831796837
	train_majority_nonzero: 6177
	train_minority_nonzero: 4844
val:
	val_majority_loss: 0.02711237221956253
	val_minority_loss: 0.004408435896039009
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03145555034279823
	test_minority_loss: 0.01603064499795437
	test_majority_acc: 0.9920034225423541
	test_minority_acc: 0.9948066476157911
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.009854629635810852
	train_minority_loss: 0.00866476260125637
	train_majority_acc: 0.9966436822121837
	train_minority_acc: 0.9978101592416451
	train_majority_nonzero: 6469
	train_minority_nonzero: 6107
val:
	val_majority_loss: 0.004572058096528053
	val_minority_loss: 0.0013511145953088999
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.017764391377568245
	test_minority_loss: 0.018211854621767998
	test_majority_acc: 0.9935600927813
	test_minority_acc: 0.9926804326358025
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.00615994306281209
	train_minority_loss: 0.0060041118413209915
	train_majority_acc: 0.9977386011606718
	train_minority_acc: 0.9979105352944085
	train_majority_nonzero: 5610
	train_minority_nonzero: 5681
val:
	val_majority_loss: 0.00015965892816893756
	val_minority_loss: 0.01810368523001671
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.0015958724543452263
	test_minority_loss: 0.06659558415412903
	test_majority_acc: 0.9989035087719298
	test_minority_acc: 0.9779138492567533
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.006930458825081587
	train_minority_loss: 0.007729368284344673
	train_majority_acc: 0.997326675772167
	train_minority_acc: 0.9979212784402882
	train_majority_nonzero: 6300
	train_minority_nonzero: 6905
val:
	val_majority_loss: 0.0014477521181106567
	val_minority_loss: 0.0010081661166623235
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.009000731632113457
	test_minority_loss: 0.021833408623933792
	test_majority_acc: 0.9970652734778122
	test_minority_acc: 0.9926804326358025
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.0006395196542143822
	train_minority_loss: 0.0004991209716536105
	train_majority_acc: 0.9998984668494264
	train_minority_acc: 0.9999268364062044
	train_majority_nonzero: 7229
	train_minority_nonzero: 6127
val:
	val_majority_loss: 0.002096930518746376
	val_minority_loss: 2.6044548576464877e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01564057171344757
	test_minority_loss: 0.023691467940807343
	test_majority_acc: 0.9948040283669908
	test_minority_acc: 0.9948066476157911
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 4.7950677981134504e-05
	train_minority_loss: 0.00013604317791759968
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 5887
	train_minority_nonzero: 5792
val:
	val_majority_loss: 0.0009670833242125809
	val_minority_loss: 1.4239286429074127e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.014926601201295853
	test_minority_loss: 0.02821071445941925
	test_majority_acc: 0.9960059514439139
	test_minority_acc: 0.9938596779188213
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 2.333649536012672e-05
	train_minority_loss: 0.00011520319094415754
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 5060
	train_minority_nonzero: 4298
val:
	val_majority_loss: 0.000876700971275568
	val_minority_loss: 7.562766768387519e-06
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.016005558893084526
	test_minority_loss: 0.028798965737223625
	test_majority_acc: 0.9960059514439139
	test_minority_acc: 0.9938596779188213
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 1.5204132978396956e-05
	train_minority_loss: 0.00011043957056244835
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 4606
	train_minority_nonzero: 3441
val:
	val_majority_loss: 0.0005928879836574197
	val_minority_loss: 6.976479653530987e-06
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.015098580159246922
	test_minority_loss: 0.031980738043785095
	test_majority_acc: 0.9960059514439139
	test_minority_acc: 0.9938596779188213
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 1.0868974641198292e-05
	train_minority_loss: 9.754586790222675e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 4231
	train_minority_nonzero: 2792
val:
	val_majority_loss: 0.0004501224320847541
	val_minority_loss: 5.945125849393662e-06
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.015086965635418892
	test_minority_loss: 0.03336294740438461
	test_majority_acc: 0.9960059514439139
	test_minority_acc: 0.9938596779188213
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.508187770843506 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.575
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2359049320220947
	train_minority_loss: 2.280550003051758
	train_majority_acc: 0.6265765814031098
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.17339764535427094
	train_minority_loss: 0.20177985727787018
	train_majority_acc: 0.9493177917780942
	train_minority_acc: 0.9430002830809381
	train_majority_nonzero: 6216
	train_minority_nonzero: 4803
val:
	val_majority_loss: 0.022473769262433052
	val_minority_loss: 0.009964200668036938
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03712925314903259
	test_minority_loss: 0.0240134596824646
	test_majority_acc: 0.9920136211254633
	test_minority_acc: 0.9949014403357102
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.022325584664940834
	train_minority_loss: 0.024501217529177666
	train_majority_acc: 0.9943852984531119
	train_minority_acc: 0.9940571517887375
	train_majority_nonzero: 5822
	train_minority_nonzero: 5898
val:
	val_majority_loss: 0.040707409381866455
	val_minority_loss: 0.00351782888174057
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04124682396650314
	test_minority_loss: 0.0109514519572258
	test_majority_acc: 0.9858937875537366
	test_minority_acc: 0.997439381270903
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.011155679821968079
	train_minority_loss: 0.011019832454621792
	train_majority_acc: 0.9967286630226071
	train_minority_acc: 0.9963609541528337
	train_majority_nonzero: 6331
	train_minority_nonzero: 5358
val:
	val_majority_loss: 0.008836970664560795
	val_minority_loss: 0.016124175861477852
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.009349777363240719
	test_minority_loss: 0.042491354048252106
	test_majority_acc: 1.0
	test_minority_acc: 0.9868438977938055
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.0056431894190609455
	train_minority_loss: 0.004740104079246521
	train_majority_acc: 0.9979445893585037
	train_minority_acc: 0.9988670259095785
	train_majority_nonzero: 5685
	train_minority_nonzero: 6492
val:
	val_majority_loss: 0.18575090169906616
	val_minority_loss: 0.00025428374647162855
	val_majority_acc: 0.9579655317360235
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.15844646096229553
	test_minority_loss: 0.0007028504041954875
	test_majority_acc: 0.9533111096817084
	test_minority_acc: 1.0
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.003005808452144265
	train_minority_loss: 0.0027397037483751774
	train_majority_acc: 0.9987452352590946
	train_minority_acc: 0.9996620861165032
	train_majority_nonzero: 5587
	train_minority_nonzero: 7806
val:
	val_majority_loss: 0.015732292085886
	val_minority_loss: 0.0005382928648032248
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.017249509692192078
	test_minority_loss: 0.03347798436880112
	test_majority_acc: 0.9935600927813
	test_minority_acc: 0.9921739139606792
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 2.698896605579648e-05
	train_minority_loss: 5.5069354857550934e-05
	train_majority_acc: 0.9994195122956143
	train_minority_acc: 1.0
	train_majority_nonzero: 3184
	train_minority_nonzero: 7030
val:
	val_majority_loss: 0.011923969723284245
	val_minority_loss: 0.0003895042755175382
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.018323484808206558
	test_minority_loss: 0.03925701230764389
	test_majority_acc: 0.9946194148151982
	test_minority_acc: 0.9921739139606792
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 1.070067173714051e-05
	train_minority_loss: 2.202945324825123e-05
	train_majority_acc: 0.9994694193528983
	train_minority_acc: 1.0
	train_majority_nonzero: 2092
	train_minority_nonzero: 5518
val:
	val_majority_loss: 0.014676533639431
	val_minority_loss: 0.00024125250638462603
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02111085131764412
	test_minority_loss: 0.040197499096393585
	test_majority_acc: 0.9946194148151982
	test_minority_acc: 0.9921739139606792
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 7.686527169425972e-06
	train_minority_loss: 1.4435422599490266e-05
	train_majority_acc: 0.999433478683406
	train_minority_acc: 1.0
	train_majority_nonzero: 1316
	train_minority_nonzero: 4506
val:
	val_majority_loss: 0.019772358238697052
	val_minority_loss: 0.00014236631977837533
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02435128763318062
	test_minority_loss: 0.03892356902360916
	test_majority_acc: 0.9935600927813
	test_minority_acc: 0.9933531592436982
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 5.321402113622753e-06
	train_minority_loss: 7.531906703661662e-06
	train_majority_acc: 0.9993951597757471
	train_minority_acc: 1.0
	train_majority_nonzero: 946
	train_minority_nonzero: 3833
val:
	val_majority_loss: 0.01526301633566618
	val_minority_loss: 0.00015775692008901387
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.023005224764347076
	test_minority_loss: 0.04371309280395508
	test_majority_acc: 0.9946194148151982
	test_minority_acc: 0.9933531592436982
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 3.603687900977093e-06
	train_minority_loss: 4.998258191335481e-06
	train_majority_acc: 0.9993643414416155
	train_minority_acc: 1.0
	train_majority_nonzero: 719
	train_minority_nonzero: 3399
val:
	val_majority_loss: 0.016735851764678955
	val_minority_loss: 0.00012706851703114808
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.024168197065591812
	test_minority_loss: 0.04318786412477493
	test_majority_acc: 0.9935600927813
	test_minority_acc: 0.9933531592436982
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.436779737472534 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.6
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235896110534668
	train_minority_loss: 2.280574321746826
	train_majority_acc: 0.6257601906430331
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.17953819036483765
	train_minority_loss: 0.19076359272003174
	train_majority_acc: 0.9476486926508089
	train_minority_acc: 0.9532622480586183
	train_majority_nonzero: 5688
	train_minority_nonzero: 5108
val:
	val_majority_loss: 0.017983077093958855
	val_minority_loss: 0.009402841329574585
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.026997096836566925
	test_minority_loss: 0.023551788181066513
	test_majority_acc: 0.99314442943994
	test_minority_acc: 0.993604724538868
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.021694546565413475
	train_minority_loss: 0.02072092518210411
	train_majority_acc: 0.9950381862223157
	train_minority_acc: 0.9950428020137617
	train_majority_nonzero: 6287
	train_minority_nonzero: 6167
val:
	val_majority_loss: 0.04342663288116455
	val_minority_loss: 0.0013508496340364218
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.037543751299381256
	test_minority_loss: 0.008031860925257206
	test_majority_acc: 0.9896200744662815
	test_minority_acc: 0.9962601359878842
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.011016751639544964
	train_minority_loss: 0.009064605459570885
	train_majority_acc: 0.9968068768517189
	train_minority_acc: 0.9967468115595225
	train_majority_nonzero: 6236
	train_minority_nonzero: 5723
val:
	val_majority_loss: 0.22154372930526733
	val_minority_loss: 0.00012098823208361864
	val_majority_acc: 0.9205548549810845
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.16592901945114136
	test_minority_loss: 0.0020791832357645035
	test_majority_acc: 0.9406894753024523
	test_minority_acc: 0.9987980769230769
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.008250575512647629
	train_minority_loss: 0.006149958819150925
	train_majority_acc: 0.9972328198661747
	train_minority_acc: 0.9982352798873175
	train_majority_nonzero: 6332
	train_minority_nonzero: 7356
val:
	val_majority_loss: 0.03172687068581581
	val_minority_loss: 6.412196853489149e-06
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0554535910487175
	test_minority_loss: 0.018562426790595055
	test_majority_acc: 0.9868947845867364
	test_minority_acc: 0.9948066476157911
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.009725350886583328
	train_minority_loss: 0.0032113126944750547
	train_majority_acc: 0.9973296900134646
	train_minority_acc: 0.9989373126745911
	train_majority_nonzero: 5360
	train_minority_nonzero: 5488
val:
	val_majority_loss: 0.005832535680383444
	val_minority_loss: 0.0002629453083500266
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.027201099321246147
	test_minority_loss: 0.03176075965166092
	test_majority_acc: 0.992422137599227
	test_minority_acc: 0.9912269442637095
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.0034489890094846487
	train_minority_loss: 0.0010375278070569038
	train_majority_acc: 0.998565367149384
	train_minority_acc: 0.9993503584139023
	train_majority_nonzero: 5003
	train_minority_nonzero: 3588
val:
	val_majority_loss: 0.07827715575695038
	val_minority_loss: 7.590276072733104e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05163446068763733
	test_minority_loss: 0.011671094223856926
	test_majority_acc: 0.9827424488192162
	test_minority_acc: 0.9948066476157911
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.0022987769916653633
	train_minority_loss: 0.0008420652593486011
	train_majority_acc: 0.9990346798179943
	train_minority_acc: 1.0
	train_majority_nonzero: 3888
	train_minority_nonzero: 5666
val:
	val_majority_loss: 0.003456244245171547
	val_minority_loss: 3.477399513940327e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.025770295411348343
	test_minority_loss: 0.021751342341303825
	test_majority_acc: 0.9915509023529918
	test_minority_acc: 0.9948066476157911
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 6.23243031441234e-05
	train_minority_loss: 7.746234041405842e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 3653
	train_minority_nonzero: 3543
val:
	val_majority_loss: 0.0026986091397702694
	val_minority_loss: 2.0397865228005685e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.027411747723817825
	test_minority_loss: 0.0277197677642107
	test_majority_acc: 0.9927083097603993
	test_minority_acc: 0.9948066476157911
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 1.8123773770639673e-05
	train_minority_loss: 4.759557850775309e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2824
	train_minority_nonzero: 4694
val:
	val_majority_loss: 0.0021477420814335346
	val_minority_loss: 1.5566811271128245e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.026154369115829468
	test_minority_loss: 0.031868673861026764
	test_majority_acc: 0.9939102328373223
	test_minority_acc: 0.9948066476157911
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 1.0278981790179387e-05
	train_minority_loss: 3.0018014513188973e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 2401
	train_minority_nonzero: 3735
val:
	val_majority_loss: 0.0018198136240243912
	val_minority_loss: 1.2078836334694643e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.026459448039531708
	test_minority_loss: 0.033424459397792816
	test_majority_acc: 0.9939102328373223
	test_minority_acc: 0.9948066476157911
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.231143951416016 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.625
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2359018325805664
	train_minority_loss: 2.2806460857391357
	train_majority_acc: 0.6227113206710339
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.17172056436538696
	train_minority_loss: 0.19274048507213593
	train_majority_acc: 0.9521780498415979
	train_minority_acc: 0.9614467964048805
	train_majority_nonzero: 5487
	train_minority_nonzero: 4546
val:
	val_majority_loss: 0.08921162039041519
	val_minority_loss: 0.005261585582047701
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.08276891708374023
	test_minority_loss: 0.010149193927645683
	test_majority_acc: 0.9724005842143515
	test_minority_acc: 1.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.02459210343658924
	train_minority_loss: 0.019508983939886093
	train_majority_acc: 0.9926783902607351
	train_minority_acc: 0.993339937165871
	train_majority_nonzero: 6633
	train_minority_nonzero: 4368
val:
	val_majority_loss: 0.010642612352967262
	val_minority_loss: 0.008592075668275356
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.012494504451751709
	test_minority_loss: 0.0325588658452034
	test_majority_acc: 0.9975737215378873
	test_minority_acc: 0.9853904094217125
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.0220603346824646
	train_minority_loss: 0.010014347732067108
	train_majority_acc: 0.9932856586256377
	train_minority_acc: 0.9969556216902333
	train_majority_nonzero: 5954
	train_minority_nonzero: 4248
val:
	val_majority_loss: 0.01852784864604473
	val_minority_loss: 0.003781287930905819
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02841375023126602
	test_minority_loss: 0.01381171215325594
	test_majority_acc: 0.986602548011255
	test_minority_acc: 0.9938596779188213
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.012058964930474758
	train_minority_loss: 0.00668732076883316
	train_majority_acc: 0.9976796191510842
	train_minority_acc: 0.9972236027388538
	train_majority_nonzero: 6609
	train_minority_nonzero: 4649
val:
	val_majority_loss: 0.0038822833448648453
	val_minority_loss: 0.00174081907607615
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.008053191006183624
	test_minority_loss: 0.032857172191143036
	test_majority_acc: 0.9989035087719298
	test_minority_acc: 0.9900476989806907
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.013837805017828941
	train_minority_loss: 0.005510308314114809
	train_majority_acc: 0.9958934443113348
	train_minority_acc: 0.9978433271061402
	train_majority_nonzero: 6455
	train_minority_nonzero: 5700
val:
	val_majority_loss: 0.05882849544286728
	val_minority_loss: 0.0009077326394617558
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.024375436827540398
	test_minority_loss: 0.01095104031264782
	test_majority_acc: 0.9903009023529918
	test_minority_acc: 0.9948066476157911
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.004084112122654915
	train_minority_loss: 0.0024189858231693506
	train_majority_acc: 0.9989706385036953
	train_minority_acc: 0.9986340051366771
	train_majority_nonzero: 5363
	train_minority_nonzero: 7271
val:
	val_majority_loss: 0.0029564823489636183
	val_minority_loss: 5.4433607147075236e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.009708683006465435
	test_minority_loss: 0.025211162865161896
	test_majority_acc: 0.9989035087719298
	test_minority_acc: 0.9925498161258757
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.002047388581559062
	train_minority_loss: 0.0009074156987480819
	train_majority_acc: 0.999640544257399
	train_minority_acc: 0.9990227909082877
	train_majority_nonzero: 6426
	train_minority_nonzero: 7352
val:
	val_majority_loss: 0.020656796172261238
	val_minority_loss: 3.295180795248598e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01430742722004652
	test_minority_loss: 0.021319089457392693
	test_majority_acc: 0.9975737215378873
	test_minority_acc: 0.9948066476157911
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.00011878105578944087
	train_minority_loss: 6.108087109168991e-05
	train_majority_acc: 1.0
	train_minority_acc: 0.9992003951814932
	train_majority_nonzero: 5570
	train_minority_nonzero: 6122
val:
	val_majority_loss: 0.018933871760964394
	val_minority_loss: 1.981010973395314e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.015091244131326675
	test_minority_loss: 0.022501276805996895
	test_majority_acc: 0.9975737215378873
	test_minority_acc: 0.9948066476157911
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 7.19222953193821e-05
	train_minority_loss: 3.820727579295635e-05
	train_majority_acc: 1.0
	train_minority_acc: 0.9992173506397833
	train_majority_nonzero: 5030
	train_minority_nonzero: 5088
val:
	val_majority_loss: 0.01330043375492096
	val_minority_loss: 1.793499723135028e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01435687206685543
	test_minority_loss: 0.025022070854902267
	test_majority_acc: 0.9975737215378873
	test_minority_acc: 0.9948066476157911
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 5.0706676120171323e-05
	train_minority_loss: 2.677962947927881e-05
	train_majority_acc: 1.0
	train_minority_acc: 0.9992382079434852
	train_majority_nonzero: 4546
	train_minority_nonzero: 4412
val:
	val_majority_loss: 0.01209244504570961
	val_minority_loss: 1.395894378219964e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01471593976020813
	test_minority_loss: 0.025298351421952248
	test_majority_acc: 0.9975737215378873
	test_minority_acc: 0.9948066476157911
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.46672320365906 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.65
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235893964767456
	train_minority_loss: 2.2806167602539062
	train_majority_acc: 0.62421352949721
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.19238676130771637
	train_minority_loss: 0.20011377334594727
	train_majority_acc: 0.9296949489119422
	train_minority_acc: 0.9523143739828988
	train_majority_nonzero: 5293
	train_minority_nonzero: 5072
val:
	val_majority_loss: 0.029184434562921524
	val_minority_loss: 0.012415168806910515
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03479757159948349
	test_minority_loss: 0.031350672245025635
	test_majority_acc: 0.99509741902834
	test_minority_acc: 0.9924254792558491
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.0229607205837965
	train_minority_loss: 0.019388658925890923
	train_majority_acc: 0.9951064793333647
	train_minority_acc: 0.9951457009403695
	train_majority_nonzero: 5270
	train_minority_nonzero: 4995
val:
	val_majority_loss: 0.008715853095054626
	val_minority_loss: 0.012207042425870895
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.013553338125348091
	test_minority_loss: 0.04069100692868233
	test_majority_acc: 0.9977015856950067
	test_minority_acc: 0.986288545259454
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.012626850977540016
	train_minority_loss: 0.013568904250860214
	train_majority_acc: 0.997425967608176
	train_minority_acc: 0.9951905914115617
	train_majority_nonzero: 5818
	train_minority_nonzero: 4542
val:
	val_majority_loss: 0.008450987748801708
	val_minority_loss: 0.002164688427001238
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.030612535774707794
	test_minority_loss: 0.015255048871040344
	test_majority_acc: 0.9917841983589641
	test_minority_acc: 0.994532404526717
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.0069464449770748615
	train_minority_loss: 0.0055892881937325
	train_majority_acc: 0.9988619805124173
	train_minority_acc: 0.9978326779576413
	train_majority_nonzero: 6066
	train_minority_nonzero: 4469
val:
	val_majority_loss: 0.013524716719985008
	val_minority_loss: 0.0016101239016279578
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.017561132088303566
	test_minority_loss: 0.013732826337218285
	test_majority_acc: 0.9942473910056744
	test_minority_acc: 0.9934774961137246
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.006725159473717213
	train_minority_loss: 0.004121528938412666
	train_majority_acc: 0.9981040846428405
	train_minority_acc: 0.9987178869711096
	train_majority_nonzero: 5546
	train_minority_nonzero: 4314
val:
	val_majority_loss: 0.05539156496524811
	val_minority_loss: 0.00011769639968406409
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04145641252398491
	test_minority_loss: 0.0027162330225110054
	test_majority_acc: 0.9859566013627188
	test_minority_acc: 0.998641304347826
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.00935608334839344
	train_minority_loss: 0.002252046251669526
	train_majority_acc: 0.9948537578813401
	train_minority_acc: 0.9993311741610883
	train_majority_nonzero: 3484
	train_minority_nonzero: 9272
val:
	val_majority_loss: 0.024826668202877045
	val_minority_loss: 4.4320295273792e-05
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.024124735966324806
	test_minority_loss: 0.015243256464600563
	test_majority_acc: 0.9912647301918196
	test_minority_acc: 0.9950389232018403
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.003002440556883812
	train_minority_loss: 0.0006891196244396269
	train_majority_acc: 0.9992706919945725
	train_minority_acc: 0.9997681919337459
	train_majority_nonzero: 2776
	train_minority_nonzero: 8312
val:
	val_majority_loss: 0.07231761515140533
	val_minority_loss: 9.885990039038006e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0360662117600441
	test_minority_loss: 0.0074674878269433975
	test_majority_acc: 0.9880967076636595
	test_minority_acc: 0.99598589289881
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 7.174478378146887e-05
	train_minority_loss: 1.8357894077780657e-05
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 1321
	train_minority_nonzero: 5816
val:
	val_majority_loss: 0.08036172389984131
	val_minority_loss: 3.19682112603914e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.039442162960767746
	test_minority_loss: 0.007585285231471062
	test_majority_acc: 0.9880967076636595
	test_minority_acc: 0.99598589289881
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 4.582376277539879e-05
	train_minority_loss: 8.024397175177e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 746
	train_minority_nonzero: 4492
val:
	val_majority_loss: 0.08285364508628845
	val_minority_loss: 2.0585275706253015e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0405799001455307
	test_minority_loss: 0.008273016661405563
	test_majority_acc: 0.9880967076636595
	test_minority_acc: 0.99598589289881
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 3.901199670508504e-05
	train_minority_loss: 5.500671250047162e-06
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 626
	train_minority_nonzero: 3866
val:
	val_majority_loss: 0.09024490416049957
	val_minority_loss: 1.3396289659795002e-06
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.044057924300432205
	test_minority_loss: 0.007718406617641449
	test_majority_acc: 0.9880967076636595
	test_minority_acc: 0.99598589289881
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.46235466003418 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.675
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235825777053833
	train_minority_loss: 2.280620574951172
	train_majority_acc: 0.62805610548717
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.2180323600769043
	train_minority_loss: 0.2063540518283844
	train_majority_acc: 0.9131861354488349
	train_minority_acc: 0.9589942580051042
	train_majority_nonzero: 4803
	train_minority_nonzero: 4750
val:
	val_majority_loss: 0.15107953548431396
	val_minority_loss: 0.010337374173104763
	val_majority_acc: 0.9415720891130728
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.15815392136573792
	test_minority_loss: 0.013641192577779293
	test_majority_acc: 0.9385046848422112
	test_minority_acc: 1.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.01714865118265152
	train_minority_loss: 0.019656674936413765
	train_majority_acc: 0.9970663758776396
	train_minority_acc: 0.9929312157769494
	train_majority_nonzero: 5695
	train_minority_nonzero: 4622
val:
	val_majority_loss: 0.041698917746543884
	val_minority_loss: 0.0028755043167620897
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04829692095518112
	test_minority_loss: 0.007762380875647068
	test_majority_acc: 0.9809822120798188
	test_minority_acc: 0.9974620590648071
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.01458798348903656
	train_minority_loss: 0.011148343794047832
	train_majority_acc: 0.9960674741630556
	train_minority_acc: 0.9950392370384892
	train_majority_nonzero: 5908
	train_minority_nonzero: 4283
val:
	val_majority_loss: 0.03683897852897644
	val_minority_loss: 0.003599523101001978
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.033709876239299774
	test_minority_loss: 0.016120856627821922
	test_majority_acc: 0.9859037252075191
	test_minority_acc: 0.9941112432139914
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.00879205483943224
	train_minority_loss: 0.006479564588516951
	train_majority_acc: 0.9971746121173041
	train_minority_acc: 0.9968314603584509
	train_majority_nonzero: 5954
	train_minority_nonzero: 3934
val:
	val_majority_loss: 0.09593816101551056
	val_minority_loss: 0.0001261700817849487
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.07824057340621948
	test_minority_loss: 0.001989977899938822
	test_majority_acc: 0.9778426077937803
	test_minority_acc: 0.998641304347826
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.004997957963496447
	train_minority_loss: 0.0030846158042550087
	train_majority_acc: 0.9985689826942195
	train_minority_acc: 0.9980005668485767
	train_majority_nonzero: 5323
	train_minority_nonzero: 3032
val:
	val_majority_loss: 0.03183501958847046
	val_minority_loss: 0.000404547608923167
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.028723500669002533
	test_minority_loss: 0.013682487420737743
	test_majority_acc: 0.9880595384694876
	test_minority_acc: 0.9934479519636172
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.002199488691985607
	train_minority_loss: 0.0019883853383362293
	train_majority_acc: 0.9997154749130166
	train_minority_acc: 0.9976733976039983
	train_majority_nonzero: 4999
	train_minority_nonzero: 3394
val:
	val_majority_loss: 0.0028169385623186827
	val_minority_loss: 0.0018369483295828104
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.012404613196849823
	test_minority_loss: 0.047285616397857666
	test_majority_acc: 0.9974154135338346
	test_minority_acc: 0.9849691516687076
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.002911481773480773
	train_minority_loss: 0.0027476882096379995
	train_majority_acc: 0.9991782160625445
	train_minority_acc: 0.9963491648042231
	train_majority_nonzero: 5188
	train_minority_nonzero: 2133
val:
	val_majority_loss: 0.09407216310501099
	val_minority_loss: 1.1333210750308353e-05
	val_majority_acc: 0.9707860445565364
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.12305620312690735
	test_minority_loss: 0.0024106386117637157
	test_majority_acc: 0.9671302057500519
	test_minority_acc: 0.998546511627907
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.0027137461584061384
	train_minority_loss: 0.0014449747977778316
	train_majority_acc: 0.9992409008948702
	train_minority_acc: 0.9960370344719919
	train_majority_nonzero: 4034
	train_minority_nonzero: 2962
val:
	val_majority_loss: 0.0029996337834745646
	val_minority_loss: 6.255621701711789e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02442134916782379
	test_minority_loss: 0.036807164549827576
	test_majority_acc: 0.9934814596331254
	test_minority_acc: 0.9876438528268445
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 3.045960511371959e-05
	train_minority_loss: 0.00045272218994796276
	train_majority_acc: 1.0
	train_minority_acc: 0.9963004530509343
	train_majority_nonzero: 2902
	train_minority_nonzero: 5229
val:
	val_majority_loss: 0.0014685916248708963
	val_minority_loss: 4.8081870772875845e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.022247981280088425
	test_minority_loss: 0.04706798121333122
	test_majority_acc: 0.9934814596331254
	test_minority_acc: 0.9876438528268445
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 1.7063373888959177e-05
	train_minority_loss: 0.00042417162330821157
	train_majority_acc: 1.0
	train_minority_acc: 0.9963092163399749
	train_majority_nonzero: 2554
	train_minority_nonzero: 5351
val:
	val_majority_loss: 0.0011732536368072033
	val_minority_loss: 3.3785650884965435e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02291465364396572
	test_minority_loss: 0.05114289000630379
	test_majority_acc: 0.9948112468671679
	test_minority_acc: 0.9876438528268445
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.45221924781799 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.7
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235809087753296
	train_minority_loss: 2.280541181564331
	train_majority_acc: 0.6285001551498848
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.20689912140369415
	train_minority_loss: 0.21556356549263
	train_majority_acc: 0.9250427441945368
	train_minority_acc: 0.9589321324600967
	train_majority_nonzero: 4723
	train_minority_nonzero: 4694
val:
	val_majority_loss: 0.029354937374591827
	val_minority_loss: 0.007643810473382473
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.047300342470407486
	test_minority_loss: 0.02047666348516941
	test_majority_acc: 0.9857059713726504
	test_minority_acc: 0.9950582129109611
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.01709621027112007
	train_minority_loss: 0.018089817836880684
	train_majority_acc: 0.9964033743818889
	train_minority_acc: 0.992255412251172
	train_majority_nonzero: 5392
	train_minority_nonzero: 3963
val:
	val_majority_loss: 0.0026648249477148056
	val_minority_loss: 0.0032296234276145697
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.017199143767356873
	test_minority_loss: 0.02514597587287426
	test_majority_acc: 0.994057677194943
	test_minority_acc: 0.9910667836036753
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.013138813897967339
	train_minority_loss: 0.010977433994412422
	train_majority_acc: 0.9964179450869607
	train_minority_acc: 0.9950484368974675
	train_majority_nonzero: 5767
	train_minority_nonzero: 4251
val:
	val_majority_loss: 0.035703547298908234
	val_minority_loss: 0.0007983383839018643
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.027590960264205933
	test_minority_loss: 0.010827387683093548
	test_majority_acc: 0.9859706731853013
	test_minority_acc: 0.99598589289881
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.008439850062131882
	train_minority_loss: 0.007177443243563175
	train_majority_acc: 0.997422625258871
	train_minority_acc: 0.9954634933116865
	train_majority_nonzero: 5631
	train_minority_nonzero: 6363
val:
	val_majority_loss: 0.0015723848482593894
	val_minority_loss: 0.0008960888953879476
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01638443022966385
	test_minority_loss: 0.0304384957998991
	test_majority_acc: 0.9925500017563466
	test_minority_acc: 0.9889632464175909
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.010940001346170902
	train_minority_loss: 0.005823461338877678
	train_majority_acc: 0.9967945587569756
	train_minority_acc: 0.9967243534565852
	train_majority_nonzero: 5514
	train_minority_nonzero: 4871
val:
	val_majority_loss: 0.0028446251526474953
	val_minority_loss: 0.0012262805830687284
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0139128677546978
	test_minority_loss: 0.017336826771497726
	test_majority_acc: 0.9959078660704047
	test_minority_acc: 0.9929546757248767
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.003957761917263269
	train_minority_loss: 0.00261466926895082
	train_majority_acc: 0.9989323712003417
	train_minority_acc: 0.9965794498208161
	train_majority_nonzero: 4776
	train_minority_nonzero: 2703
val:
	val_majority_loss: 0.00026685622287914157
	val_minority_loss: 0.00016866697114892304
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0232328400015831
	test_minority_loss: 0.03406482934951782
	test_majority_acc: 0.9933159331288957
	test_minority_acc: 0.9903219420697649
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.008400289341807365
	train_minority_loss: 0.00438031367957592
	train_majority_acc: 0.9972000178831115
	train_minority_acc: 0.9968332528152628
	train_majority_nonzero: 5072
	train_minority_nonzero: 4657
val:
	val_majority_loss: 0.01440202072262764
	val_minority_loss: 0.00014593047671951354
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.02747742459177971
	test_minority_loss: 0.01346185989677906
	test_majority_acc: 0.9895184034787377
	test_minority_acc: 0.9950808907048653
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.002081315964460373
	train_minority_loss: 0.003974641673266888
	train_majority_acc: 0.9996405071417108
	train_minority_acc: 0.9935286484993349
	train_majority_nonzero: 5337
	train_minority_nonzero: 1157
val:
	val_majority_loss: 0.013774169608950615
	val_minority_loss: 7.665224984521046e-06
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.039626456797122955
	test_minority_loss: 0.02108635939657688
	test_majority_acc: 0.9899459630648465
	test_minority_acc: 0.9936274023327722
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.0005248786183074117
	train_minority_loss: 0.0053772651590406895
	train_majority_acc: 1.0
	train_minority_acc: 0.9863181939607898
	train_majority_nonzero: 4471
	train_minority_nonzero: 865
val:
	val_majority_loss: 0.024056358262896538
	val_minority_loss: 0.0024328064173460007
	val_majority_acc: 0.9836065573770492
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04386086016893387
	test_minority_loss: 0.023888766765594482
	test_majority_acc: 0.9873747988076876
	test_minority_acc: 0.9909789536802387
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.001983690308406949
	train_minority_loss: 0.007953546941280365
	train_majority_acc: 0.9996735897233409
	train_minority_acc: 0.9859294894067268
	train_majority_nonzero: 4991
	train_minority_nonzero: 1177
val:
	val_majority_loss: 0.0010144920088350773
	val_minority_loss: 0.0014438285725191236
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.012560897506773472
	test_minority_loss: 0.026287604123353958
	test_majority_acc: 0.9937324726079351
	test_minority_acc: 0.9909640543459468
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.50144076347351 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.725
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235917329788208
	train_minority_loss: 2.2805168628692627
	train_majority_acc: 0.6273577790221897
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.23007652163505554
	train_minority_loss: 0.22099988162517548
	train_majority_acc: 0.9060964692806879
	train_minority_acc: 0.9497623237364746
	train_majority_nonzero: 4657
	train_minority_nonzero: 4158
val:
	val_majority_loss: 0.033186618238687515
	val_minority_loss: 0.0215495303273201
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04070411995053291
	test_minority_loss: 0.040889397263526917
	test_majority_acc: 0.9892713591027038
	test_minority_acc: 0.9913938519096436
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.019645020365715027
	train_minority_loss: 0.020582523196935654
	train_majority_acc: 0.9960757179403552
	train_minority_acc: 0.9910837592096099
	train_majority_nonzero: 4767
	train_minority_nonzero: 4429
val:
	val_majority_loss: 0.039543360471725464
	val_minority_loss: 0.003200533799827099
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05790652707219124
	test_minority_loss: 0.010573677718639374
	test_majority_acc: 0.9804172947688841
	test_minority_acc: 0.9948066476157911
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.013307337649166584
	train_minority_loss: 0.012964257039129734
	train_majority_acc: 0.9972785393613156
	train_minority_acc: 0.9933959241052234
	train_majority_nonzero: 5205
	train_minority_nonzero: 4569
val:
	val_majority_loss: 0.0002796365588437766
	val_minority_loss: 0.0012802541023120284
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.022707056254148483
	test_minority_loss: 0.04987684637308121
	test_majority_acc: 0.9929416057663716
	test_minority_acc: 0.9841246172243863
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.008365677669644356
	train_minority_loss: 0.008121331222355366
	train_majority_acc: 0.9982580879114618
	train_minority_acc: 0.993587990298285
	train_majority_nonzero: 5352
	train_minority_nonzero: 2685
val:
	val_majority_loss: 0.0007063576485961676
	val_minority_loss: 0.0018161680782213807
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.005202800035476685
	test_minority_loss: 0.0611143559217453
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.976942532726319
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.009087610058486462
	train_minority_loss: 0.0056554158218204975
	train_majority_acc: 0.9976293080769684
	train_minority_acc: 0.9938295218775032
	train_majority_nonzero: 4874
	train_minority_nonzero: 5060
val:
	val_majority_loss: 0.0034580500796437263
	val_minority_loss: 0.0026827461551874876
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.016156189143657684
	test_minority_loss: 0.030386798083782196
	test_majority_acc: 0.9927724056304161
	test_minority_acc: 0.9922687066805984
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.004855779930949211
	train_minority_loss: 0.00365704414434731
	train_majority_acc: 0.9991526487608577
	train_minority_acc: 0.9966418650100314
	train_majority_nonzero: 4878
	train_minority_nonzero: 2727
val:
	val_majority_loss: 0.00027707050321623683
	val_minority_loss: 0.0002088057080982253
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.008729532361030579
	test_minority_loss: 0.04831169173121452
	test_majority_acc: 0.9974154135338346
	test_minority_acc: 0.9857959487569603
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.007712721358984709
	train_minority_loss: 0.004126691725105047
	train_majority_acc: 0.9976624998923085
	train_minority_acc: 0.9955307231812437
	train_majority_nonzero: 4856
	train_minority_nonzero: 2286
val:
	val_majority_loss: 0.002662288025021553
	val_minority_loss: 0.0003123118949588388
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.019726287573575974
	test_minority_loss: 0.017388351261615753
	test_majority_acc: 0.9911405396664258
	test_minority_acc: 0.9936274023327722
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.0033904684241861105
	train_minority_loss: 0.009743202477693558
	train_majority_acc: 0.9986834605919382
	train_minority_acc: 0.9865386392237999
	train_majority_nonzero: 4633
	train_minority_nonzero: 3112
val:
	val_majority_loss: 0.0020263390615582466
	val_minority_loss: 0.00038809579564258456
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03649153932929039
	test_minority_loss: 0.04066615551710129
	test_majority_acc: 0.9890644012603355
	test_minority_acc: 0.988154439322998
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.0015217522159218788
	train_minority_loss: 0.009405843913555145
	train_majority_acc: 0.9996841190871042
	train_minority_acc: 0.9837718732595407
	train_majority_nonzero: 5027
	train_minority_nonzero: 2864
val:
	val_majority_loss: 0.0004424746730364859
	val_minority_loss: 0.0011095119407400489
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.023047205060720444
	test_minority_loss: 0.059934474527835846
	test_majority_acc: 0.9952596002718661
	test_minority_acc: 0.9775693118786348
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.0006614120793528855
	train_minority_loss: 0.011243796907365322
	train_majority_acc: 0.9998157361341441
	train_minority_acc: 0.9694868111758224
	train_majority_nonzero: 4561
	train_minority_nonzero: 1954
val:
	val_majority_loss: 0.00013862349442206323
	val_minority_loss: 0.053656257688999176
	val_majority_acc: 1.0
	val_minority_acc: 0.9789827658680117
test:
	test_majority_loss: 0.001785858767107129
	test_minority_loss: 0.1437469720840454
	test_majority_acc: 0.9985119047619048
	test_minority_acc: 0.9472461910923883
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.54861783981323 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.75
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.236177921295166
	train_minority_loss: 2.2805299758911133
	train_majority_acc: 0.6231599860352629
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.23993739485740662
	train_minority_loss: 0.2109057605266571
	train_majority_acc: 0.8886567268145591
	train_minority_acc: 0.9536995706830335
	train_majority_nonzero: 4498
	train_minority_nonzero: 3937
val:
	val_majority_loss: 0.02664896659553051
	val_minority_loss: 0.012025605887174606
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03643037751317024
	test_minority_loss: 0.023781269788742065
	test_majority_acc: 0.9926602328373222
	test_minority_acc: 0.9915733022787986
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.022548716515302658
	train_minority_loss: 0.0165899395942688
	train_majority_acc: 0.9945703807441055
	train_minority_acc: 0.9927589721925105
	train_majority_nonzero: 4656
	train_minority_nonzero: 3155
val:
	val_majority_loss: 0.019584165886044502
	val_minority_loss: 0.002151091815903783
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03860703855752945
	test_minority_loss: 0.009531524032354355
	test_majority_acc: 0.9810756313919882
	test_minority_acc: 0.9964169085631349
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.01638917252421379
	train_minority_loss: 0.010524481534957886
	train_majority_acc: 0.9955258401456235
	train_minority_acc: 0.9952392953492454
	train_majority_nonzero: 4660
	train_minority_nonzero: 4414
val:
	val_majority_loss: 0.07693549245595932
	val_minority_loss: 0.001284019323065877
	val_majority_acc: 0.9661622530474989
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05106382071971893
	test_minority_loss: 0.004407277796417475
	test_majority_acc: 0.9856909353946974
	test_minority_acc: 0.997618831640058
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.007135550957173109
	train_minority_loss: 0.004353887401521206
	train_majority_acc: 0.9988393418784566
	train_minority_acc: 0.9963634536057387
	train_majority_nonzero: 4906
	train_minority_nonzero: 4016
val:
	val_majority_loss: 0.0044542900286614895
	val_minority_loss: 0.0034864619374275208
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.009557179175317287
	test_minority_loss: 0.031510453671216965
	test_majority_acc: 0.9977015856950067
	test_minority_acc: 0.9876835320476351
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.007934900932013988
	train_minority_loss: 0.006270092912018299
	train_majority_acc: 0.9971917902668777
	train_minority_acc: 0.9942433549545865
	train_majority_nonzero: 4545
	train_minority_nonzero: 3705
val:
	val_majority_loss: 0.08008545637130737
	val_minority_loss: 0.0016454069409519434
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.09581337869167328
	test_minority_loss: 0.004753920249640942
	test_majority_acc: 0.970622581088014
	test_minority_acc: 1.0
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.008016584441065788
	train_minority_loss: 0.00585551280528307
	train_majority_acc: 0.9986063380576111
	train_minority_acc: 0.9931305879829238
	train_majority_nonzero: 4678
	train_minority_nonzero: 3079
val:
	val_majority_loss: 0.0012016620021313429
	val_minority_loss: 0.003428748808801174
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.00938432291150093
	test_minority_loss: 0.03846125304698944
	test_majority_acc: 0.9978441867380315
	test_minority_acc: 0.9866417696307462
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.0025577228516340256
	train_minority_loss: 0.004650822840631008
	train_majority_acc: 0.9996370930493421
	train_minority_acc: 0.9920238694421374
	train_majority_nonzero: 4793
	train_minority_nonzero: 1873
val:
	val_majority_loss: 0.0019062880892306566
	val_minority_loss: 0.005673750303685665
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.008323484100401402
	test_minority_loss: 0.042999960482120514
	test_majority_acc: 0.9989035087719298
	test_minority_acc: 0.9830985698049193
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.0009027746273204684
	train_minority_loss: 0.007568025030195713
	train_majority_acc: 1.0
	train_minority_acc: 0.9812045620444084
	train_majority_nonzero: 4682
	train_minority_nonzero: 2528
val:
	val_majority_loss: 0.00014422516687773168
	val_minority_loss: 0.14100171625614166
	val_majority_acc: 1.0
	val_minority_acc: 0.9461958806221101
test:
	test_majority_loss: 0.01498749665915966
	test_minority_loss: 0.33275461196899414
	test_majority_acc: 0.9962134904569115
	test_minority_acc: 0.920059603324132
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.001126120681874454
	train_minority_loss: 0.01999303512275219
	train_majority_acc: 0.9997512437810945
	train_minority_acc: 0.9412056266150641
	train_majority_nonzero: 4665
	train_minority_nonzero: 2974
val:
	val_majority_loss: 0.0008394676260650158
	val_minority_loss: 0.19919835031032562
	val_majority_acc: 1.0
	val_minority_acc: 0.9426229508196722
test:
	test_majority_loss: 0.014257961884140968
	test_minority_loss: 0.38012006878852844
	test_majority_acc: 0.996630029935951
	test_minority_acc: 0.9128774372112318
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.00102670316118747
	train_minority_loss: 0.025178560987114906
	train_majority_acc: 0.9998086490623803
	train_minority_acc: 0.910936191145301
	train_majority_nonzero: 4487
	train_minority_nonzero: 3394
val:
	val_majority_loss: 0.0002395240735495463
	val_minority_loss: 0.41159436106681824
	val_majority_acc: 1.0
	val_minority_acc: 0.8877679697351828
test:
	test_majority_loss: 0.007495569996535778
	test_minority_loss: 0.6098202466964722
	test_majority_acc: 0.9977461013645224
	test_minority_acc: 0.8608969789525696
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.562785625457764 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.775
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2360730171203613
	train_minority_loss: 2.280597686767578
	train_majority_acc: 0.6152669502421406
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.26877903938293457
	train_minority_loss: 0.21769441664218903
	train_majority_acc: 0.8737747963107149
	train_minority_acc: 0.9588054312221552
	train_majority_nonzero: 3884
	train_minority_nonzero: 4306
val:
	val_majority_loss: 0.03974311053752899
	val_minority_loss: 0.014119287952780724
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.034009285271167755
	test_minority_loss: 0.026447158306837082
	test_majority_acc: 0.9933694148151981
	test_minority_acc: 0.9941112432139914
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.029499460011720657
	train_minority_loss: 0.018074778839945793
	train_majority_acc: 0.9932540833889425
	train_minority_acc: 0.9923821843303564
	train_majority_nonzero: 4057
	train_minority_nonzero: 4040
val:
	val_majority_loss: 0.006630100309848785
	val_minority_loss: 0.01097556296736002
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.005667257588356733
	test_minority_loss: 0.056740179657936096
	test_majority_acc: 1.0
	test_minority_acc: 0.9756196608641527
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.014860962517559528
	train_minority_loss: 0.00967305526137352
	train_majority_acc: 0.9969487516324941
	train_minority_acc: 0.9951444055604916
	train_majority_nonzero: 4366
	train_minority_nonzero: 4686
val:
	val_majority_loss: 0.0323927216231823
	val_minority_loss: 0.00036154768895357847
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04666214436292648
	test_minority_loss: 0.016007155179977417
	test_majority_acc: 0.9863810358718673
	test_minority_acc: 0.994532404526717
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.015031034126877785
	train_minority_loss: 0.006701931357383728
	train_majority_acc: 0.995189282441067
	train_minority_acc: 0.9951728426874629
	train_majority_nonzero: 4473
	train_minority_nonzero: 5993
val:
	val_majority_loss: 0.02510594204068184
	val_minority_loss: 0.0019798167049884796
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.010220969095826149
	test_minority_loss: 0.044726237654685974
	test_majority_acc: 0.9962134904569115
	test_minority_acc: 0.9890874868473382
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.010299279354512691
	train_minority_loss: 0.004253210034221411
	train_majority_acc: 0.9966249416918403
	train_minority_acc: 0.9954207451683182
	train_majority_nonzero: 4421
	train_minority_nonzero: 5010
val:
	val_majority_loss: 0.014533202163875103
	val_minority_loss: 0.0014252541586756706
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01849217154085636
	test_minority_loss: 0.0199718214571476
	test_majority_acc: 0.9940057270323928
	test_minority_acc: 0.9935045642824578
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.006537456996738911
	train_minority_loss: 0.006601410917937756
	train_majority_acc: 0.9982056215389549
	train_minority_acc: 0.9920133349260853
	train_majority_nonzero: 4326
	train_minority_nonzero: 4937
val:
	val_majority_loss: 0.005729472730308771
	val_minority_loss: 0.00018147099763154984
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.013693224638700485
	test_minority_loss: 0.04229547083377838
	test_majority_acc: 0.9950420112269216
	test_minority_acc: 0.9832490627402698
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.006943067070096731
	train_minority_loss: 0.005985298193991184
	train_majority_acc: 0.9981117532508543
	train_minority_acc: 0.9907764583140487
	train_majority_nonzero: 4262
	train_minority_nonzero: 2763
val:
	val_majority_loss: 0.0010727188782766461
	val_minority_loss: 0.021829625591635704
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.007310428190976381
	test_minority_loss: 0.06379208713769913
	test_majority_acc: 0.9975737215378873
	test_minority_acc: 0.9773636940390447
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.002446961821988225
	train_minority_loss: 0.00710067804902792
	train_majority_acc: 0.9993644415286206
	train_minority_acc: 0.9817540273018253
	train_majority_nonzero: 4079
	train_minority_nonzero: 2966
val:
	val_majority_loss: 0.00033204141072928905
	val_minority_loss: 0.05094772204756737
	val_majority_acc: 1.0
	val_minority_acc: 0.9836065573770492
test:
	test_majority_loss: 0.011508005671203136
	test_minority_loss: 0.07755877077579498
	test_majority_acc: 0.996630029935951
	test_minority_acc: 0.9780955597966999
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.00243012816645205
	train_minority_loss: 0.009121425449848175
	train_majority_acc: 0.9991573600528825
	train_minority_acc: 0.9740137416210604
	train_majority_nonzero: 3827
	train_minority_nonzero: 2236
val:
	val_majority_loss: 0.0002234314160887152
	val_minority_loss: 0.0997287780046463
	val_majority_acc: 1.0
	val_minority_acc: 0.9754098360655737
test:
	test_majority_loss: 0.012255323119461536
	test_minority_loss: 0.16256925463676453
	test_majority_acc: 0.9975737215378873
	test_minority_acc: 0.9608031105604151
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.0020374436862766743
	train_minority_loss: 0.01143660582602024
	train_majority_acc: 0.9998223169864962
	train_minority_acc: 0.9576666585098775
	train_majority_nonzero: 3688
	train_minority_nonzero: 2598
val:
	val_majority_loss: 2.7594287530519068e-05
	val_minority_loss: 0.30118003487586975
	val_majority_acc: 1.0
	val_minority_acc: 0.9251786464901219
test:
	test_majority_loss: 0.01868598535656929
	test_minority_loss: 0.39674466848373413
	test_majority_acc: 0.9966050944669366
	test_minority_acc: 0.9254072271738341
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.35907506942749 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.8
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2361457347869873
	train_minority_loss: 2.28058123588562
	train_majority_acc: 0.6190468955895291
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.28867241740226746
	train_minority_loss: 0.2362811118364334
	train_majority_acc: 0.8791620920070826
	train_minority_acc: 0.9647157268667318
	train_majority_nonzero: 3416
	train_minority_nonzero: 3732
val:
	val_majority_loss: 0.01179304625838995
	val_minority_loss: 0.016512800008058548
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.01851937733590603
	test_minority_loss: 0.043865568935871124
	test_majority_acc: 0.9966909461152882
	test_minority_acc: 0.9793656685892859
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.017681194469332695
	train_minority_loss: 0.015567432157695293
	train_majority_acc: 0.9950641104981297
	train_minority_acc: 0.9929023011646748
	train_majority_nonzero: 3883
	train_minority_nonzero: 3147
val:
	val_majority_loss: 0.10526496917009354
	val_minority_loss: 0.0025736612733453512
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.10459837317466736
	test_minority_loss: 0.006109274923801422
	test_majority_acc: 0.9633089975576753
	test_minority_acc: 0.9987980769230769
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.015492906793951988
	train_minority_loss: 0.010865733027458191
	train_majority_acc: 0.9976873578110814
	train_minority_acc: 0.9937078777689093
	train_majority_nonzero: 3952
	train_minority_nonzero: 3948
val:
	val_majority_loss: 0.005542666185647249
	val_minority_loss: 0.0005745291709899902
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03384850546717644
	test_minority_loss: 0.028624575585126877
	test_majority_acc: 0.9914535105282763
	test_minority_acc: 0.9874319667524651
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.01250436156988144
	train_minority_loss: 0.00842561386525631
	train_majority_acc: 0.9968838025005289
	train_minority_acc: 0.9918230095072166
	train_majority_nonzero: 4040
	train_minority_nonzero: 4605
val:
	val_majority_loss: 0.00928480364382267
	val_minority_loss: 0.00034900865284726024
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.050176359713077545
	test_minority_loss: 0.019323211163282394
	test_majority_acc: 0.9826157260707232
	test_minority_acc: 0.9933304814497939
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.0054796370677649975
	train_minority_loss: 0.005249483045190573
	train_majority_acc: 0.9988629632673106
	train_minority_acc: 0.9932438413335373
	train_majority_nonzero: 4016
	train_minority_nonzero: 2634
val:
	val_majority_loss: 0.008894840255379677
	val_minority_loss: 0.0003430648648645729
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03297629952430725
	test_minority_loss: 0.016833471134305
	test_majority_acc: 0.9913690572328939
	test_minority_acc: 0.9961426654740608
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.013601874932646751
	train_minority_loss: 0.006772332359105349
	train_majority_acc: 0.9964577953043141
	train_minority_acc: 0.9920591120699473
	train_majority_nonzero: 3941
	train_minority_nonzero: 5363
val:
	val_majority_loss: 0.06469517201185226
	val_minority_loss: 0.0019971688743680716
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.05960104614496231
	test_minority_loss: 0.01405755989253521
	test_majority_acc: 0.9861580759614074
	test_minority_acc: 0.9935045642824578
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.0060645826160907745
	train_minority_loss: 0.004028771072626114
	train_majority_acc: 0.9989521928174254
	train_minority_acc: 0.9942016011210288
	train_majority_nonzero: 3320
	train_minority_nonzero: 6321
val:
	val_majority_loss: 0.0006566968513652682
	val_minority_loss: 0.0009962405310943723
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.012167760170996189
	test_minority_loss: 0.10685461759567261
	test_majority_acc: 0.9954890230383651
	test_minority_acc: 0.9776751211271602
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.005902647506445646
	train_minority_loss: 0.00290271220728755
	train_majority_acc: 0.9983056818704097
	train_minority_acc: 0.993666712157273
	train_majority_nonzero: 2979
	train_minority_nonzero: 4381
val:
	val_majority_loss: 0.03133397921919823
	val_minority_loss: 1.3894280527892988e-05
	val_majority_acc: 0.9789827658680117
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.06298597157001495
	test_minority_loss: 0.02360972948372364
	test_majority_acc: 0.9863048437890962
	test_minority_acc: 0.9892388918860978
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.00797679927200079
	train_minority_loss: 0.005156657192856073
	train_majority_acc: 0.9985958254012112
	train_minority_acc: 0.9915104724641524
	train_majority_nonzero: 3441
	train_minority_nonzero: 3184
val:
	val_majority_loss: 0.010841187089681625
	val_minority_loss: 3.554625800461508e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.036687612533569336
	test_minority_loss: 0.012183915823698044
	test_majority_acc: 0.9926988444669365
	test_minority_acc: 0.9961426654740608
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.0021884723100811243
	train_minority_loss: 0.005465875379741192
	train_majority_acc: 0.998892442549159
	train_minority_acc: 0.9853126084924723
	train_majority_nonzero: 2799
	train_minority_nonzero: 2047
val:
	val_majority_loss: 0.0020436125341802835
	val_minority_loss: 3.0448556572082452e-05
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.094515860080719
	test_minority_loss: 0.061047058552503586
	test_majority_acc: 0.9828718826628089
	test_minority_acc: 0.9810933036101738
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.451452016830444 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.825
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2359633445739746
	train_minority_loss: 2.2805755138397217
	train_majority_acc: 0.619352609412401
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.3347510099411011
	train_minority_loss: 0.23671139776706696
	train_majority_acc: 0.8265724004775382
	train_minority_acc: 0.9597758944781675
	train_majority_nonzero: 3243
	train_minority_nonzero: 3922
val:
	val_majority_loss: 0.033047497272491455
	val_minority_loss: 0.00606068829074502
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.052601318806409836
	test_minority_loss: 0.017476443201303482
	test_majority_acc: 0.9837379742917681
	test_minority_acc: 0.9951337159217594
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.023577628657221794
	train_minority_loss: 0.017089884728193283
	train_majority_acc: 0.9957028031406526
	train_minority_acc: 0.9903079103203771
	train_majority_nonzero: 3467
	train_minority_nonzero: 3048
val:
	val_majority_loss: 0.0022638984955847263
	val_minority_loss: 0.009461048059165478
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.010488154366612434
	test_minority_loss: 0.04897773638367653
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.9792428305389714
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.013478606939315796
	train_minority_loss: 0.01146632432937622
	train_majority_acc: 0.9955851038490473
	train_minority_acc: 0.9893433542762988
	train_majority_nonzero: 3535
	train_minority_nonzero: 2712
val:
	val_majority_loss: 0.003136830870062113
	val_minority_loss: 0.0049460711888968945
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.03853171318769455
	test_minority_loss: 0.03602278232574463
	test_majority_acc: 0.9879355400702163
	test_minority_acc: 0.986697481251289
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.01690584234893322
	train_minority_loss: 0.007822156883776188
	train_majority_acc: 0.9942829594960965
	train_minority_acc: 0.9903983133224926
	train_majority_nonzero: 3419
	train_minority_nonzero: 4905
val:
	val_majority_loss: 0.08182640373706818
	val_minority_loss: 0.00035587672027759254
	val_majority_acc: 0.9579655317360235
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.12040799856185913
	test_minority_loss: 0.0028121466748416424
	test_majority_acc: 0.9590965671347782
	test_minority_acc: 1.0
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.017525890842080116
	train_minority_loss: 0.0061453054659068584
	train_majority_acc: 0.9959239473916475
	train_minority_acc: 0.9909926558124265
	train_majority_nonzero: 3467
	train_minority_nonzero: 3502
val:
	val_majority_loss: 0.006549342535436153
	val_minority_loss: 0.013060970231890678
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.034800413995981216
	test_minority_loss: 0.06844180822372437
	test_majority_acc: 0.9882151065273163
	test_minority_acc: 0.9799792138770227
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.004050915595144033
	train_minority_loss: 0.00509831216186285
	train_majority_acc: 0.99854964941375
	train_minority_acc: 0.9880322979090611
	train_majority_nonzero: 3472
	train_minority_nonzero: 2737
val:
	val_majority_loss: 0.0003219356876797974
	val_minority_loss: 0.002241168636828661
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.011075553484261036
	test_minority_loss: 0.04536157473921776
	test_majority_acc: 0.9962134904569115
	test_minority_acc: 0.9813657882095913
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.019521338865160942
	train_minority_loss: 0.011268333531916142
	train_majority_acc: 0.995297241170739
	train_minority_acc: 0.9871752703843135
	train_majority_nonzero: 3247
	train_minority_nonzero: 2328
val:
	val_majority_loss: 0.003065759316086769
	val_minority_loss: 0.006960623431950808
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.024485593661665916
	test_minority_loss: 0.022419974207878113
	test_majority_acc: 0.993639767637178
	test_minority_acc: 0.9887524820035605
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.0017669359222054482
	train_minority_loss: 0.01031602080911398
	train_majority_acc: 1.0
	train_minority_acc: 0.974895099912545
	train_majority_nonzero: 3141
	train_minority_nonzero: 2010
val:
	val_majority_loss: 0.00016360930749215186
	val_minority_loss: 0.2685245871543884
	val_majority_acc: 1.0
	val_minority_acc: 0.8959646910466583
test:
	test_majority_loss: 0.03735848516225815
	test_minority_loss: 0.3385421633720398
	test_majority_acc: 0.9925372119947988
	test_minority_acc: 0.9126402402359985
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.001423568814061582
	train_minority_loss: 0.02450399287045002
	train_majority_acc: 0.9997512437810945
	train_minority_acc: 0.9296979939572494
	train_majority_nonzero: 3232
	train_minority_nonzero: 3221
val:
	val_majority_loss: 5.391150261857547e-05
	val_minority_loss: 0.3504598140716553
	val_majority_acc: 1.0
	val_minority_acc: 0.8877679697351828
test:
	test_majority_loss: 0.011664840392768383
	test_minority_loss: 0.5487351417541504
	test_majority_acc: 0.9964515856950067
	test_minority_acc: 0.8597286633597354
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.00031568558188155293
	train_minority_loss: 0.024822233244776726
	train_majority_acc: 1.0
	train_minority_acc: 0.8874280887519558
	train_majority_nonzero: 3027
	train_minority_nonzero: 3509
val:
	val_majority_loss: 0.00010161487443838269
	val_minority_loss: 0.25886213779449463
	val_majority_acc: 1.0
	val_minority_acc: 0.9333753678015972
test:
	test_majority_loss: 0.028053194284439087
	test_minority_loss: 0.40694916248321533
	test_majority_acc: 0.994025307232894
	test_minority_acc: 0.8900267371001154
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.45611262321472 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.85
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.236001968383789
	train_minority_loss: 2.2805428504943848
	train_majority_acc: 0.6208468201346722
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.35773032903671265
	train_minority_loss: 0.2443166822195053
	train_majority_acc: 0.8203645882422296
	train_minority_acc: 0.9652093400328304
	train_majority_nonzero: 2804
	train_minority_nonzero: 3415
val:
	val_majority_loss: 0.06962898373603821
	val_minority_loss: 0.00911630317568779
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.08988077938556671
	test_minority_loss: 0.019378870725631714
	test_majority_acc: 0.9695984087032417
	test_minority_acc: 0.9959137779727951
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.023751772940158844
	train_minority_loss: 0.01901765540242195
	train_majority_acc: 0.9929925785552837
	train_minority_acc: 0.9896012436639545
	train_majority_nonzero: 2978
	train_minority_nonzero: 2733
val:
	val_majority_loss: 0.006792398635298014
	val_minority_loss: 0.006565272808074951
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.018723826855421066
	test_minority_loss: 0.024084294214844704
	test_majority_acc: 0.9915273652369467
	test_minority_acc: 0.9898154233946415
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.017858561128377914
	train_minority_loss: 0.013552326709032059
	train_majority_acc: 0.993327935209589
	train_minority_acc: 0.9857831873980061
	train_majority_nonzero: 3042
	train_minority_nonzero: 3490
val:
	val_majority_loss: 0.0029490902088582516
	val_minority_loss: 0.016776083037257195
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.025236207991838455
	test_minority_loss: 0.07123830914497375
	test_majority_acc: 0.9888097553993835
	test_minority_acc: 0.9767265702591057
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.010272923856973648
	train_minority_loss: 0.016337350010871887
	train_majority_acc: 0.9961973013004619
	train_minority_acc: 0.9738694173685274
	train_majority_nonzero: 3035
	train_minority_nonzero: 7241
val:
	val_majority_loss: 0.002593408338725567
	val_minority_loss: 0.11402525007724762
	val_majority_acc: 1.0
	val_minority_acc: 0.9369482976040353
test:
	test_majority_loss: 0.023630710318684578
	test_minority_loss: 0.20851321518421173
	test_majority_acc: 0.9907470536237581
	test_minority_acc: 0.9377834332424533
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.00455767847597599
	train_minority_loss: 0.030008463189005852
	train_majority_acc: 0.9994520152858895
	train_minority_acc: 0.9384792313486975
	train_majority_nonzero: 3043
	train_minority_nonzero: 4318
val:
	val_majority_loss: 0.0018574516288936138
	val_minority_loss: 0.23447869718074799
	val_majority_acc: 1.0
	val_minority_acc: 0.8913408995376209
test:
	test_majority_loss: 0.027150912210345268
	test_minority_loss: 0.32180655002593994
	test_majority_acc: 0.9924317801459459
	test_minority_acc: 0.8972239696790505
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.0029384084045886993
	train_minority_loss: 0.03225332498550415
	train_majority_acc: 0.9997630893153282
	train_minority_acc: 0.8541867662788115
	train_majority_nonzero: 3040
	train_minority_nonzero: 5683
val:
	val_majority_loss: 0.00038322299951687455
	val_minority_loss: 0.6362446546554565
	val_majority_acc: 1.0
	val_minority_acc: 0.800126103404792
test:
	test_majority_loss: 0.011460736393928528
	test_minority_loss: 0.8538986444473267
	test_majority_acc: 0.9948837032228689
	test_minority_acc: 0.783634549099181
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.0013774905819445848
	train_minority_loss: 0.037687428295612335
	train_majority_acc: 0.9997630893153282
	train_minority_acc: 0.8514041017882522
	train_majority_nonzero: 3029
	train_minority_nonzero: 5184
val:
	val_majority_loss: 0.0009736339561641216
	val_minority_loss: 0.3445248007774353
	val_majority_acc: 1.0
	val_minority_acc: 0.8877679697351828
test:
	test_majority_loss: 0.010919400490820408
	test_minority_loss: 0.5120818018913269
	test_majority_acc: 0.996085626299792
	test_minority_acc: 0.8291887743219029
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.0006459772121161222
	train_minority_loss: 0.04789017513394356
	train_majority_acc: 1.0
	train_minority_acc: 0.7910943017282229
	train_majority_nonzero: 3012
	train_minority_nonzero: 5326
val:
	val_majority_loss: 0.0007187713054008782
	val_minority_loss: 0.6163681745529175
	val_majority_acc: 1.0
	val_minority_acc: 0.8247162673392181
test:
	test_majority_loss: 0.031400565057992935
	test_minority_loss: 0.869511604309082
	test_majority_acc: 0.996085626299792
	test_minority_acc: 0.765624240091261
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.001975920284166932
	train_minority_loss: 0.05083055794239044
	train_majority_acc: 0.9996890547263682
	train_minority_acc: 0.7506306340962919
	train_majority_nonzero: 2985
	train_minority_nonzero: 5461
val:
	val_majority_loss: 0.00010933518933597952
	val_minority_loss: 1.1942119598388672
	val_majority_acc: 1.0
	val_minority_acc: 0.7370744010088273
test:
	test_majority_loss: 0.01087498851120472
	test_minority_loss: 1.593958854675293
	test_majority_acc: 0.9971821175278622
	test_minority_acc: 0.6656064821077075
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.004714183509349823
	train_minority_loss: 0.07717806100845337
	train_majority_acc: 0.9993554494732814
	train_minority_acc: 0.7383326190251618
	train_majority_nonzero: 2969
	train_minority_nonzero: 5220
val:
	val_majority_loss: 0.0013345845509320498
	val_minority_loss: 0.8173025846481323
	val_majority_acc: 1.0
	val_minority_acc: 0.7370744010088273
test:
	test_majority_loss: 0.02844589203596115
	test_minority_loss: 1.0257625579833984
	test_majority_acc: 0.996085626299792
	test_minority_acc: 0.6899672012174922
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.389240026474 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.875
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2359488010406494
	train_minority_loss: 2.2805256843566895
	train_majority_acc: 0.6120761830171606
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.4592093229293823
	train_minority_loss: 0.28720805048942566
	train_majority_acc: 0.7555707352349144
	train_minority_acc: 0.9794326686328675
	train_majority_nonzero: 2352
	train_minority_nonzero: 3016
val:
	val_majority_loss: 0.14655447006225586
	val_minority_loss: 0.00645923987030983
	val_majority_acc: 0.92875157629256
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.16467510163784027
	test_minority_loss: 0.011768799275159836
	test_majority_acc: 0.9404743738212533
	test_minority_acc: 0.998546511627907
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.046201832592487335
	train_minority_loss: 0.02020702324807644
	train_majority_acc: 0.9867462682044957
	train_minority_acc: 0.9916634596287478
	train_majority_nonzero: 2500
	train_minority_nonzero: 2333
val:
	val_majority_loss: 0.04045047610998154
	val_minority_loss: 0.007853645831346512
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.063962921500206
	test_minority_loss: 0.015816468745470047
	test_majority_acc: 0.9779495767132422
	test_minority_acc: 0.9949875968046582
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.018930858001112938
	train_minority_loss: 0.013665402308106422
	train_majority_acc: 0.9959992981225826
	train_minority_acc: 0.9879581891865149
	train_majority_nonzero: 2550
	train_minority_nonzero: 3488
val:
	val_majority_loss: 0.05401446670293808
	val_minority_loss: 0.0043565272353589535
	val_majority_acc: 0.9707860445565364
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.07252031564712524
	test_minority_loss: 0.011577978730201721
	test_majority_acc: 0.9713527523618337
	test_minority_acc: 0.9961880210618692
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.011864878237247467
	train_minority_loss: 0.013870541006326675
	train_majority_acc: 0.9966998960714593
	train_minority_acc: 0.9771075962273436
	train_majority_nonzero: 2548
	train_minority_nonzero: 5135
val:
	val_majority_loss: 0.008551234379410744
	val_minority_loss: 0.03672739490866661
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.026357809081673622
	test_minority_loss: 0.12034990638494492
	test_majority_acc: 0.9908329052721097
	test_minority_acc: 0.9660949541614738
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.007996673695743084
	train_minority_loss: 0.01222963910549879
	train_majority_acc: 0.9979323102676921
	train_minority_acc: 0.9675721889194259
	train_majority_nonzero: 2514
	train_minority_nonzero: 5853
val:
	val_majority_loss: 0.06485854834318161
	val_minority_loss: 0.001331985928118229
	val_majority_acc: 0.9871794871794872
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.0834861472249031
	test_minority_loss: 0.04278097301721573
	test_majority_acc: 0.9742879959036949
	test_minority_acc: 0.984892136552201
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.00874579232186079
	train_minority_loss: 0.011926691047847271
	train_majority_acc: 0.9972485157186649
	train_minority_acc: 0.9679594279685214
	train_majority_nonzero: 2536
	train_minority_nonzero: 4749
val:
	val_majority_loss: 0.00426227692514658
	val_minority_loss: 0.015873024240136147
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.06366540491580963
	test_minority_loss: 0.17249083518981934
	test_majority_acc: 0.9828658629078534
	test_minority_acc: 0.9524851784739652
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.006560422945767641
	train_minority_loss: 0.014136193320155144
	train_majority_acc: 0.9988746742478085
	train_minority_acc: 0.9638591405722426
	train_majority_nonzero: 2519
	train_minority_nonzero: 3931
val:
	val_majority_loss: 0.0010523030068725348
	val_minority_loss: 0.10053553432226181
	val_majority_acc: 1.0
	val_minority_acc: 0.9707860445565364
test:
	test_majority_loss: 0.023412086069583893
	test_minority_loss: 0.31115853786468506
	test_majority_acc: 0.9937872119947988
	test_minority_acc: 0.9261496770249981
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.0029070950113236904
	train_minority_loss: 0.02363002859055996
	train_majority_acc: 0.9994454969733376
	train_minority_acc: 0.9157422699449328
	train_majority_nonzero: 2386
	train_minority_nonzero: 4447
val:
	val_majority_loss: 0.00040983728831633925
	val_minority_loss: 0.47128498554229736
	val_majority_acc: 1.0
	val_minority_acc: 0.8621269440941572
test:
	test_majority_loss: 0.02266979217529297
	test_minority_loss: 0.6490838527679443
	test_majority_acc: 0.9928919591568215
	test_minority_acc: 0.8533321285447771
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.0004839037137571722
	train_minority_loss: 0.03150811418890953
	train_majority_acc: 1.0
	train_minority_acc: 0.8241755471108636
	train_majority_nonzero: 2311
	train_minority_nonzero: 6095
val:
	val_majority_loss: 0.0003553902788553387
	val_minority_loss: 0.9274871349334717
	val_majority_acc: 1.0
	val_minority_acc: 0.8211433375367801
test:
	test_majority_loss: 0.015663279220461845
	test_minority_loss: 1.1169939041137695
	test_majority_acc: 0.9956300543949167
	test_minority_acc: 0.7807400308081891
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.00021495875262189656
	train_minority_loss: 0.03410360962152481
	train_majority_acc: 1.0
	train_minority_acc: 0.7848743674956072
	train_majority_nonzero: 2073
	train_minority_nonzero: 5391
val:
	val_majority_loss: 0.000729598687030375
	val_minority_loss: 0.8995117545127869
	val_majority_acc: 1.0
	val_minority_acc: 0.8129466162253047
test:
	test_majority_loss: 0.018736757338047028
	test_minority_loss: 1.0965577363967896
	test_majority_acc: 0.9968319774718398
	test_minority_acc: 0.7696348359606804
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.478330850601196 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.9
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235722541809082
	train_minority_loss: 2.2804977893829346
	train_majority_acc: 0.6104700026341818
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.5266672968864441
	train_minority_loss: 0.325139582157135
	train_majority_acc: 0.6682568882195747
	train_minority_acc: 0.9779662784790416
	train_majority_nonzero: 1926
	train_minority_nonzero: 2665
val:
	val_majority_loss: 0.02780773863196373
	val_minority_loss: 0.03903314471244812
	val_majority_acc: 1.0
	val_minority_acc: 0.9836065573770492
test:
	test_majority_loss: 0.04420121759176254
	test_minority_loss: 0.06169871613383293
	test_majority_acc: 0.9904105009865087
	test_minority_acc: 0.9788728940316802
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.04127949848771095
	train_minority_loss: 0.020528316497802734
	train_majority_acc: 0.9904168178421908
	train_minority_acc: 0.9909547091899683
	train_majority_nonzero: 1987
	train_minority_nonzero: 1704
val:
	val_majority_loss: 0.11616122722625732
	val_minority_loss: 0.004933337215334177
	val_majority_acc: 0.9707860445565364
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.11389339715242386
	test_minority_loss: 0.007293494418263435
	test_majority_acc: 0.9602791306227935
	test_minority_acc: 0.9987980769230769
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.033151764422655106
	train_minority_loss: 0.015787022188305855
	train_majority_acc: 0.9922193478163628
	train_minority_acc: 0.9840104658573399
	train_majority_nonzero: 2048
	train_minority_nonzero: 3550
val:
	val_majority_loss: 0.020244445651769638
	val_minority_loss: 0.003684827359393239
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.04823140799999237
	test_minority_loss: 0.0162032637745142
	test_majority_acc: 0.9803320486516354
	test_minority_acc: 0.993604724538868
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.01618553139269352
	train_minority_loss: 0.016110621392726898
	train_majority_acc: 0.9956926966474815
	train_minority_acc: 0.9652312860956684
	train_majority_nonzero: 2044
	train_minority_nonzero: 6544
val:
	val_majority_loss: 0.0038212533108890057
	val_minority_loss: 0.016285909339785576
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.028044313192367554
	test_minority_loss: 0.05444813519716263
	test_majority_acc: 0.990863349119043
	test_minority_acc: 0.9803708310396408
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.02270926535129547
	train_minority_loss: 0.011058147996664047
	train_majority_acc: 0.9932917276200859
	train_minority_acc: 0.9836551463149874
	train_majority_nonzero: 2049
	train_minority_nonzero: 2853
val:
	val_majority_loss: 0.005969913676381111
	val_minority_loss: 0.003604321274906397
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.06999756395816803
	test_minority_loss: 0.045975640416145325
	test_majority_acc: 0.9737495403899104
	test_minority_acc: 0.9854650933490456
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.005256956443190575
	train_minority_loss: 0.010373138822615147
	train_majority_acc: 0.9991471215351813
	train_minority_acc: 0.9774147784064526
	train_majority_nonzero: 2050
	train_minority_nonzero: 4229
val:
	val_majority_loss: 0.007847056724131107
	val_minority_loss: 0.007877141237258911
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.1414734125137329
	test_minority_loss: 0.045005135238170624
	test_majority_acc: 0.9661861197679791
	test_minority_acc: 0.9855217056678862
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.004643243737518787
	train_minority_loss: 0.01719818450510502
	train_majority_acc: 0.9982210161314639
	train_minority_acc: 0.9541282056134501
	train_majority_nonzero: 2049
	train_minority_nonzero: 3185
val:
	val_majority_loss: 0.0009747761068865657
	val_minority_loss: 0.24419988691806793
	val_majority_acc: 1.0
	val_minority_acc: 0.92875157629256
test:
	test_majority_loss: 0.014737250283360481
	test_minority_loss: 0.3512588143348694
	test_majority_acc: 0.9926955199988514
	test_minority_acc: 0.8902140666069241
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.00043559938785620034
	train_minority_loss: 0.028115058317780495
	train_majority_acc: 1.0
	train_minority_acc: 0.8550836015657178
	train_majority_nonzero: 2019
	train_minority_nonzero: 5676
val:
	val_majority_loss: 8.409087604377419e-05
	val_minority_loss: 0.7164446115493774
	val_majority_acc: 1.0
	val_minority_acc: 0.8293400588482556
test:
	test_majority_loss: 0.0008198806899599731
	test_minority_loss: 0.83680260181427
	test_majority_acc: 1.0
	test_minority_acc: 0.8043739411234552
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.00017265690257772803
	train_minority_loss: 0.031027358025312424
	train_majority_acc: 1.0
	train_minority_acc: 0.816825632225232
	train_majority_nonzero: 1955
	train_minority_nonzero: 4550
val:
	val_majority_loss: 0.00012808688916265965
	val_minority_loss: 0.575775146484375
	val_majority_acc: 1.0
	val_minority_acc: 0.8713745271122321
test:
	test_majority_loss: 0.0025247421581298113
	test_minority_loss: 0.6617417931556702
	test_majority_acc: 0.9986702127659575
	test_minority_acc: 0.825325231055154
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.0007480566273443401
	train_minority_loss: 0.03486521169543266
	train_majority_acc: 0.9995477159656264
	train_minority_acc: 0.793445285409092
	train_majority_nonzero: 1936
	train_minority_nonzero: 4792
val:
	val_majority_loss: 4.94743071612902e-05
	val_minority_loss: 0.911188006401062
	val_majority_acc: 1.0
	val_minority_acc: 0.7873055905842791
test:
	test_majority_loss: 0.0014643823960795999
	test_minority_loss: 0.9805677533149719
	test_majority_acc: 0.9986702127659575
	test_minority_acc: 0.7694488010838005
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.362029790878296 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.925
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.235808849334717
	train_minority_loss: 2.2804765701293945
	train_majority_acc: 0.6131854740063696
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.6337673664093018
	train_minority_loss: 0.3425283432006836
	train_majority_acc: 0.6138774989521257
	train_minority_acc: 0.9852251830428744
	train_majority_nonzero: 1484
	train_minority_nonzero: 1889
val:
	val_majority_loss: 0.11780300736427307
	val_minority_loss: 0.024303754791617393
	val_majority_acc: 0.9707860445565364
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.14402490854263306
	test_minority_loss: 0.028580959886312485
	test_majority_acc: 0.9578446200104207
	test_minority_acc: 0.997093023255814
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.03603257238864899
	train_minority_loss: 0.02687377668917179
	train_majority_acc: 0.9933700903850158
	train_minority_acc: 0.9869848863074963
	train_majority_nonzero: 1530
	train_minority_nonzero: 1676
val:
	val_majority_loss: 0.0840320885181427
	val_minority_loss: 0.003188625443726778
	val_majority_acc: 0.9579655317360235
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.1455002725124359
	test_minority_loss: 0.009088782593607903
	test_majority_acc: 0.9338678479677864
	test_minority_acc: 0.9961880210618692
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.028708823025226593
	train_minority_loss: 0.008762157522141933
	train_majority_acc: 0.9934711363815841
	train_minority_acc: 0.9892796817161674
	train_majority_nonzero: 1550
	train_minority_nonzero: 1504
val:
	val_majority_loss: 0.013988275080919266
	val_minority_loss: 0.008279312402009964
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.04582645744085312
	test_minority_loss: 0.04010418802499771
	test_majority_acc: 0.9814562437804147
	test_minority_acc: 0.9884216265956458
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.016638915985822678
	train_minority_loss: 0.006325253751128912
	train_majority_acc: 0.9941977867351001
	train_minority_acc: 0.9915215327500718
	train_majority_nonzero: 1546
	train_minority_nonzero: 1781
val:
	val_majority_loss: 0.002003716304898262
	val_minority_loss: 0.007117646746337414
	val_majority_acc: 1.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.013174351304769516
	test_minority_loss: 0.056941136717796326
	test_majority_acc: 0.9949695548712205
	test_minority_acc: 0.9800757178069013
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.02029840275645256
	train_minority_loss: 0.006496152840554714
	train_majority_acc: 0.9936625839610914
	train_minority_acc: 0.9884501608553061
	train_majority_nonzero: 1549
	train_minority_nonzero: 1024
val:
	val_majority_loss: 0.0027510072104632854
	val_minority_loss: 0.010007950477302074
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.0574602410197258
	test_minority_loss: 0.06585151702165604
	test_majority_acc: 0.9788845958435823
	test_minority_acc: 0.979251586160246
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.0033945052418857813
	train_minority_loss: 0.014351327903568745
	train_majority_acc: 0.9995024875621891
	train_minority_acc: 0.9648185676613512
	train_majority_nonzero: 1547
	train_minority_nonzero: 2158
val:
	val_majority_loss: 0.0039024408906698227
	val_minority_loss: 0.04224640503525734
	val_majority_acc: 1.0
	val_minority_acc: 0.9836065573770492
test:
	test_majority_loss: 0.03804466128349304
	test_minority_loss: 0.17596304416656494
	test_majority_acc: 0.9914326807425912
	test_minority_acc: 0.9440616293716614
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.004444007761776447
	train_minority_loss: 0.02251649647951126
	train_majority_acc: 0.9992892679459844
	train_minority_acc: 0.9253780466768224
	train_majority_nonzero: 1547
	train_minority_nonzero: 2601
val:
	val_majority_loss: 0.0008783919038251042
	val_minority_loss: 0.16200830042362213
	val_majority_acc: 1.0
	val_minority_acc: 0.9579655317360235
test:
	test_majority_loss: 0.05763624608516693
	test_minority_loss: 0.4030589461326599
	test_majority_acc: 0.9888480942764257
	test_minority_acc: 0.8932318606355178
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.005021441262215376
	train_minority_loss: 0.03738590329885483
	train_majority_acc: 0.9978893411729232
	train_minority_acc: 0.8400977123007316
	train_majority_nonzero: 1548
	train_minority_nonzero: 4325
val:
	val_majority_loss: 0.005034958478063345
	val_minority_loss: 0.3790341019630432
	val_majority_acc: 1.0
	val_minority_acc: 0.8913408995376209
test:
	test_majority_loss: 0.06930021941661835
	test_minority_loss: 0.6419637203216553
	test_majority_acc: 0.9858937875537366
	test_minority_acc: 0.823166429685585
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.009623288176953793
	train_minority_loss: 0.045464225113391876
	train_majority_acc: 0.9982587064676617
	train_minority_acc: 0.8480665824068183
	train_majority_nonzero: 1517
	train_minority_nonzero: 3837
val:
	val_majority_loss: 0.0022260919213294983
	val_minority_loss: 0.361158549785614
	val_majority_acc: 1.0
	val_minority_acc: 0.9005884825556956
test:
	test_majority_loss: 0.05152773857116699
	test_minority_loss: 0.598934531211853
	test_majority_acc: 0.9914278815104682
	test_minority_acc: 0.8524100200535772
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.005569693632423878
	train_minority_loss: 0.056816790252923965
	train_majority_acc: 1.0
	train_minority_acc: 0.7896523493568512
	train_majority_nonzero: 1531
	train_minority_nonzero: 4586
val:
	val_majority_loss: 0.014325274154543877
	val_minority_loss: 0.35917842388153076
	val_majority_acc: 1.0
	val_minority_acc: 0.837536780159731
test:
	test_majority_loss: 0.05857750400900841
	test_minority_loss: 0.5412413477897644
	test_majority_acc: 0.9926298045873914
	test_minority_acc: 0.7753458171192888
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.54381084442139 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.95
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.2349295616149902
	train_minority_loss: 2.2804789543151855
	train_majority_acc: 0.6494906558339394
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 0.8684746649116277
	train_minority_loss: 0.407155305147171
	train_majority_acc: 0.3659146825396825
	train_minority_acc: 0.9913053157216337
	train_majority_nonzero: 1028
	train_minority_nonzero: 1564
val:
	val_majority_loss: 0.16685423254966736
	val_minority_loss: 0.17569123208522797
	val_majority_acc: 0.9918032786885246
	val_minority_acc: 0.9754098360655737
test:
	test_majority_loss: 0.1742907017469406
	test_minority_loss: 0.1951943188905716
	test_majority_acc: 0.985291435777683
	test_minority_acc: 0.9656699048915942
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.09813646668568253
	train_minority_loss: 0.044693473726511
	train_majority_acc: 0.9719345238095238
	train_minority_acc: 0.9802817333192044
	train_majority_nonzero: 1030
	train_minority_nonzero: 1762
val:
	val_majority_loss: 0.00902789831161499
	val_minority_loss: 0.06669478863477707
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.023186730220913887
	test_minority_loss: 0.1174396350979805
	test_majority_acc: 0.9941111588812457
	test_minority_acc: 0.956043915242102
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.04200873523950577
	train_minority_loss: 0.01707473024725914
	train_majority_acc: 0.9875306009634368
	train_minority_acc: 0.9771415505736243
	train_majority_nonzero: 1048
	train_minority_nonzero: 2667
val:
	val_majority_loss: 0.009559244848787785
	val_minority_loss: 0.03909362852573395
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.05475073307752609
	test_minority_loss: 0.039500802755355835
	test_majority_acc: 0.983971113837103
	test_minority_acc: 0.9846797917036259
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.030912641435861588
	train_minority_loss: 0.008689879439771175
	train_majority_acc: 0.9878681986890943
	train_minority_acc: 0.9846864184415026
	train_majority_nonzero: 1043
	train_minority_nonzero: 1539
val:
	val_majority_loss: 0.0029984447173774242
	val_minority_loss: 0.03600630909204483
	val_majority_acc: 1.0
	val_minority_acc: 0.9836065573770492
test:
	test_majority_loss: 0.01186042558401823
	test_minority_loss: 0.10865817964076996
	test_majority_acc: 0.9966909461152882
	test_minority_acc: 0.9653892480389903
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.018514272618704128
	train_minority_loss: 0.012172485701739788
	train_majority_acc: 0.9946565656565656
	train_minority_acc: 0.9648255725637598
	train_majority_nonzero: 1049
	train_minority_nonzero: 1858
val:
	val_majority_loss: 0.00501289265230298
	val_minority_loss: 0.05764195695519447
	val_majority_acc: 1.0
	val_minority_acc: 0.9754098360655737
test:
	test_majority_loss: 0.026609007269144058
	test_minority_loss: 0.18007449805736542
	test_majority_acc: 0.9877320228478543
	test_minority_acc: 0.9452993762385922
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.003786126468926341
	train_minority_loss: 0.013484915718436241
	train_majority_acc: 0.9990000000000001
	train_minority_acc: 0.9562099298246974
	train_majority_nonzero: 1049
	train_minority_nonzero: 1757
val:
	val_majority_loss: 0.0037129647098481655
	val_minority_loss: 0.06905592232942581
	val_majority_acc: 1.0
	val_minority_acc: 0.9754098360655737
test:
	test_majority_loss: 0.03420965373516083
	test_minority_loss: 0.21372614800930023
	test_majority_acc: 0.9887615660981421
	test_minority_acc: 0.9339504884569179
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.0026773735880851746
	train_minority_loss: 0.015777060762047768
	train_majority_acc: 1.0
	train_minority_acc: 0.9342687295921487
	train_majority_nonzero: 1050
	train_minority_nonzero: 1997
val:
	val_majority_loss: 0.0005371314473450184
	val_minority_loss: 0.23998063802719116
	val_majority_acc: 1.0
	val_minority_acc: 0.9379991593106347
test:
	test_majority_loss: 0.014534294605255127
	test_minority_loss: 0.41063228249549866
	test_majority_acc: 0.9977874373433584
	test_minority_acc: 0.9011435771758541
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.0019944607414981875
	train_minority_loss: 0.035694241523742676
	train_majority_acc: 1.0
	train_minority_acc: 0.8551127565953892
	train_majority_nonzero: 1045
	train_minority_nonzero: 3982
val:
	val_majority_loss: 0.0030444744043052197
	val_minority_loss: 0.5334599018096924
	val_majority_acc: 1.0
	val_minority_acc: 0.8247162673392181
test:
	test_majority_loss: 0.022510837763547897
	test_minority_loss: 0.7076616287231445
	test_majority_acc: 0.9933565755589379
	test_minority_acc: 0.7984011745143875
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.005315828839882215
	train_minority_loss: 0.07858644425868988
	train_majority_acc: 1.0
	train_minority_acc: 0.7631476615700447
	train_majority_nonzero: 1033
	train_minority_nonzero: 5425
val:
	val_majority_loss: 0.010433302260935307
	val_minority_loss: 0.5925067663192749
	val_majority_acc: 1.0
	val_minority_acc: 0.7416981925178646
test:
	test_majority_loss: 0.02065448835492134
	test_minority_loss: 0.6655247211456299
	test_majority_acc: 0.9968319774718398
	test_minority_acc: 0.7223833451410582
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.0016415055142715573
	train_minority_loss: 0.03944011405110359
	train_majority_acc: 1.0
	train_minority_acc: 0.7362991699463889
	train_majority_nonzero: 1050
	train_minority_nonzero: 5860
val:
	val_majority_loss: 0.0012954608537256718
	val_minority_loss: 1.0588496923446655
	val_majority_acc: 1.0
	val_minority_acc: 0.7370744010088273
test:
	test_majority_loss: 0.03210565075278282
	test_minority_loss: 1.1915693283081055
	test_majority_acc: 0.9933565755589379
	test_minority_acc: 0.7077769808304426
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.44944715499878 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 0.975
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.234567921240251
	train_minority_loss: 2.280471086502075
	train_majority_acc: 0.6430468341182627
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 1.2279603158434231
	train_minority_loss: 0.3617665767669678
	train_majority_acc: 0.09476273148148145
	train_minority_acc: 0.99354463318477
	train_majority_nonzero: 544
	train_minority_nonzero: 1112
val:
	val_majority_loss: 0.6083422899246216
	val_minority_loss: 0.30212023854255676
	val_majority_acc: 0.790878520386717
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.6070598363876343
	test_minority_loss: 0.3078276515007019
	test_majority_acc: 0.8180325228387428
	test_minority_acc: 0.9961880210618692
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 0.3403874946988478
	train_minority_loss: 0.07827489823102951
	train_majority_acc: 0.8452508960573477
	train_minority_acc: 0.9877541612258232
	train_majority_nonzero: 539
	train_minority_nonzero: 1301
val:
	val_majority_loss: 0.07622206211090088
	val_minority_loss: 0.03717190772294998
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.09282824397087097
	test_minority_loss: 0.05067893862724304
	test_majority_acc: 0.9889920936724198
	test_minority_acc: 0.9901043112995312
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 0.29511655025517847
	train_minority_loss: 0.020764058455824852
	train_majority_acc: 0.9098639455782314
	train_minority_acc: 0.9904056705953584
	train_majority_nonzero: 542
	train_minority_nonzero: 2617
val:
	val_majority_loss: 0.08503824472427368
	val_minority_loss: 0.006654593627899885
	val_majority_acc: 0.9579655317360235
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.12592020630836487
	test_minority_loss: 0.02017519623041153
	test_majority_acc: 0.951355974719091
	test_minority_acc: 0.9934097715625387
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 0.08001647747168288
	train_minority_loss: 0.007851993665099144
	train_majority_acc: 0.9760416666666666
	train_minority_acc: 0.9941723747405816
	train_majority_nonzero: 544
	train_minority_nonzero: 700
val:
	val_majority_loss: 0.0640157163143158
	val_minority_loss: 0.004955886397510767
	val_majority_acc: 0.9625893232450609
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.14120955765247345
	test_minority_loss: 0.02052091248333454
	test_majority_acc: 0.9481063958601202
	test_minority_acc: 0.9921807803168825
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 0.04988289108917982
	train_minority_loss: 0.008046478033065796
	train_majority_acc: 0.9782403870639164
	train_minority_acc: 0.9860845002115299
	train_majority_nonzero: 550
	train_minority_nonzero: 1697
val:
	val_majority_loss: 0.002247275784611702
	val_minority_loss: 0.06753695011138916
	val_majority_acc: 1.0
	val_minority_acc: 0.9918032786885246
test:
	test_majority_loss: 0.03442099690437317
	test_minority_loss: 0.1667877733707428
	test_majority_acc: 0.9899911930757745
	test_minority_acc: 0.9454276280029204
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 0.0043553980397556405
	train_minority_loss: 0.03135409578680992
	train_majority_acc: 1.0
	train_minority_acc: 0.9234403301559735
	train_majority_nonzero: 547
	train_minority_nonzero: 3892
val:
	val_majority_loss: 0.007003297563642263
	val_minority_loss: 0.11722736805677414
	val_majority_acc: 1.0
	val_minority_acc: 0.9707860445565364
test:
	test_majority_loss: 0.048610106110572815
	test_minority_loss: 0.19283200800418854
	test_majority_acc: 0.9896274209416254
	test_minority_acc: 0.9336242270892687
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 0.009722981832847585
	train_minority_loss: 0.022448793053627014
	train_majority_acc: 0.9960526315789474
	train_minority_acc: 0.9193867379166131
	train_majority_nonzero: 545
	train_minority_nonzero: 3293
val:
	val_majority_loss: 0.0010751375230029225
	val_minority_loss: 0.5287254452705383
	val_majority_acc: 1.0
	val_minority_acc: 0.8759983186212694
test:
	test_majority_loss: 0.016704194247722626
	test_minority_loss: 0.7744171619415283
	test_majority_acc: 0.9948837032228689
	test_minority_acc: 0.7894533873591121
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.0025047009155412295
	train_minority_loss: 0.029996929690241814
	train_majority_acc: 1.0
	train_minority_acc: 0.8591879215955072
	train_majority_nonzero: 550
	train_minority_nonzero: 4185
val:
	val_majority_loss: 0.0014262187760323286
	val_minority_loss: 0.45966657996177673
	val_majority_acc: 1.0
	val_minority_acc: 0.8713745271122321
test:
	test_majority_loss: 0.06306387484073639
	test_minority_loss: 0.6645973920822144
	test_majority_acc: 0.9893880605213439
	test_minority_acc: 0.8321065513744904
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.0007346784164074061
	train_minority_loss: 0.03584640100598335
	train_majority_acc: 1.0
	train_minority_acc: 0.8210270148112819
	train_majority_nonzero: 550
	train_minority_nonzero: 4336
val:
	val_majority_loss: 0.001088643097318709
	val_minority_loss: 0.45582854747772217
	val_majority_acc: 1.0
	val_minority_acc: 0.8585540142917192
test:
	test_majority_loss: 0.024731023237109184
	test_minority_loss: 0.5811314582824707
	test_majority_acc: 0.9930258877282501
	test_minority_acc: 0.8240174460592478
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.001490042498801056
	train_minority_loss: 0.030130978673696518
	train_majority_acc: 1.0
	train_minority_acc: 0.8163031656385756
	train_majority_nonzero: 549
	train_minority_nonzero: 4257
val:
	val_majority_loss: 5.811713344883174e-05
	val_minority_loss: 0.6670505404472351
	val_majority_acc: 1.0
	val_minority_acc: 0.8293400588482556
test:
	test_majority_loss: 0.05128956586122513
	test_minority_loss: 0.8648775815963745
	test_majority_acc: 0.9929973910056744
	test_minority_acc: 0.8165799158417018
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.50522446632385 seconds.
Running imbalanced trial
	Config file: ./config/imbalanced_dataset_experiment.json
	Results directory: ./results/imbalanced_dataset_experiment
Beginning false positive dataset experiment.
	Method: sss
	Dataset: MNIST
	Total samples: 4000
	Majority class: 4
	Minority class: 9
	Proportion of minority to majority samples: 1.0
	Random seed: 0
	Training dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Eval dataloader kwargs: {'batch_size': 100, 'shuffle': False}
	Clean dataloader kwargs: {'batch_size': 100, 'shuffle': True}
	Clean samples per class: 10
	Validation samples per class: 100
	Model constructor: LeNet5
	Model constructor kwargs: {'overparameterize': False}
	Loss function constructor: CrossEntropyLoss
	Loss function constructor kwargs: {}
	Optimizer constructor: Adam
	Optimizer constructor kwargs: {}
	Number of epochs: 10
	Pretraining epochs: 0
	Fine-tuning epochs: 0
	Device: cuda
	Conduct initial measurements: True

Setting random seed.
Initializing and partitioning datasets.
Initializing dataloaders.
Initializing model.
LeNet5(
  (model): Sequential(
    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): Flatten(start_dim=1, end_dim=-1)
    (9): Linear(in_features=400, out_features=120, bias=True)
    (10): ReLU()
    (11): Linear(in_features=120, out_features=84, bias=True)
    (12): ReLU()
    (13): Linear(in_features=84, out_features=10, bias=True)
  )
)

Initializing loss function.
CrossEntropyLoss()

Initializing optimizer.
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)

Measuring initial performance.
Epoch 0 complete.
train:
	train_majority_loss: 2.236476497216658
	train_minority_loss: 2.2804484367370605
	train_majority_acc: 0.4772727272727273
	train_minority_acc: 0.0
val:
	val_majority_loss: 2.2353148460388184
	val_minority_loss: 2.2782516479492188
	val_majority_acc: 0.6345102984447246
	val_minority_acc: 0.0
test:
	test_majority_loss: 2.2353570461273193
	test_minority_loss: 2.2791152000427246
	test_majority_acc: 0.6071115522223866
	test_minority_acc: 0.0
Training model.
Beginning epoch 1.
Epoch 1 complete.
train:
	train_majority_loss: 3.9145543828923652
	train_minority_loss: 0.10650552809238434
	train_majority_acc: 0.0
	train_minority_acc: 0.9950248756218906
	train_majority_nonzero: 50
	train_minority_nonzero: 599
val:
	val_majority_loss: 2.2076101303100586
	val_minority_loss: 0.08251804113388062
	val_majority_acc: 0.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 2.191861629486084
	test_minority_loss: 0.08211200684309006
	test_majority_acc: 0.0
	test_minority_acc: 1.0
Beginning epoch 2.
Epoch 2 complete.
train:
	train_majority_loss: 2.1578166604042055
	train_minority_loss: 0.11884581297636032
	train_majority_acc: 0.0
	train_minority_acc: 1.0
	train_majority_nonzero: 50
	train_minority_nonzero: 100
val:
	val_majority_loss: 1.5498590469360352
	val_minority_loss: 0.2026117742061615
	val_majority_acc: 0.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 1.5415771007537842
	test_minority_loss: 0.20348919928073883
	test_majority_acc: 0.0
	test_minority_acc: 1.0
Beginning epoch 3.
Epoch 3 complete.
train:
	train_majority_loss: 1.1047322625337646
	train_minority_loss: 0.3220932185649872
	train_majority_acc: 0.046511627906976744
	train_minority_acc: 1.0
	train_majority_nonzero: 50
	train_minority_nonzero: 38
val:
	val_majority_loss: 1.0929524898529053
	val_minority_loss: 0.2548137903213501
	val_majority_acc: 0.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 1.085437297821045
	test_minority_loss: 0.25763601064682007
	test_majority_acc: 0.0
	test_minority_acc: 1.0
Beginning epoch 4.
Epoch 4 complete.
train:
	train_majority_loss: 1.8565579734065316
	train_minority_loss: 0.14777229726314545
	train_majority_acc: 0.045454545454545456
	train_minority_acc: 1.0
	train_majority_nonzero: 50
	train_minority_nonzero: 97
val:
	val_majority_loss: 1.199390172958374
	val_minority_loss: 0.19012628495693207
	val_majority_acc: 0.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 1.1979573965072632
	test_minority_loss: 0.18949148058891296
	test_majority_acc: 0.0
	test_minority_acc: 1.0
Beginning epoch 5.
Epoch 5 complete.
train:
	train_majority_loss: 1.5212267384580944
	train_minority_loss: 0.06889266520738602
	train_majority_acc: 0.17753623188405795
	train_minority_acc: 0.9997014925373134
	train_majority_nonzero: 50
	train_minority_nonzero: 138
val:
	val_majority_loss: 0.6707559823989868
	val_minority_loss: 0.1298259198665619
	val_majority_acc: 0.8329129886506936
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.6775597333908081
	test_minority_loss: 0.1339567005634308
	test_majority_acc: 0.8248464378350655
	test_minority_acc: 0.997618831640058
Beginning epoch 6.
Epoch 6 complete.
train:
	train_majority_loss: 2.3053001511292424
	train_minority_loss: 0.014445537701249123
	train_majority_acc: 0.5116279069767442
	train_minority_acc: 0.9965093723302678
	train_majority_nonzero: 50
	train_minority_nonzero: 502
val:
	val_majority_loss: 13.458763122558594
	val_minority_loss: 8.461477705168363e-07
	val_majority_acc: 0.0
	val_minority_acc: 1.0
test:
	test_majority_loss: 12.867164611816406
	test_minority_loss: 1.1832395330202417e-06
	test_majority_acc: 0.0
	test_minority_acc: 1.0
Beginning epoch 7.
Epoch 7 complete.
train:
	train_majority_loss: 2.878233507640702
	train_minority_loss: 0.003002146491780877
	train_majority_acc: 0.47348484848484845
	train_minority_acc: 0.9996019900497514
	train_majority_nonzero: 50
	train_minority_nonzero: 206
val:
	val_majority_loss: 1.8260291814804077
	val_minority_loss: 0.00012515901471488178
	val_majority_acc: 0.43568726355611603
	val_minority_acc: 1.0
test:
	test_majority_loss: 1.6960036754608154
	test_minority_loss: 0.00024387246230617166
	test_majority_acc: 0.516789131163805
	test_minority_acc: 1.0
Beginning epoch 8.
Epoch 8 complete.
train:
	train_majority_loss: 0.4742592575525748
	train_minority_loss: 0.0006397307734005153
	train_majority_acc: 0.8229166666666666
	train_minority_acc: 0.9997994874114278
	train_majority_nonzero: 50
	train_minority_nonzero: 103
val:
	val_majority_loss: 0.8479616641998291
	val_minority_loss: 3.5722707252716646e-05
	val_majority_acc: 0.7652374947456915
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.8218619227409363
	test_minority_loss: 0.0019847264047712088
	test_majority_acc: 0.7847041454069827
	test_minority_acc: 0.9988207547169812
Beginning epoch 9.
Epoch 9 complete.
train:
	train_majority_loss: 0.04277655367133219
	train_minority_loss: 0.0007339222356677055
	train_majority_acc: 0.9777777777777777
	train_minority_acc: 0.9998999949746219
	train_majority_nonzero: 50
	train_minority_nonzero: 114
val:
	val_majority_loss: 1.0159921646118164
	val_minority_loss: 3.636908877524547e-05
	val_majority_acc: 0.7406473308112653
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.9616444110870361
	test_minority_loss: 0.0006820004200562835
	test_majority_acc: 0.7920722806695434
	test_minority_acc: 1.0
Beginning epoch 10.
Epoch 10 complete.
train:
	train_majority_loss: 0.001178561596964932
	train_minority_loss: 0.00021713152818847448
	train_majority_acc: 1.0
	train_minority_acc: 1.0
	train_majority_nonzero: 50
	train_minority_nonzero: 11
val:
	val_majority_loss: 1.0309759378433228
	val_minority_loss: 2.77325543720508e-05
	val_majority_acc: 0.7406473308112653
	val_minority_acc: 1.0
test:
	test_majority_loss: 0.9831793904304504
	test_minority_loss: 0.0005629421211779118
	test_majority_acc: 0.7972366543697513
	test_minority_acc: 1.0
	Done training. Final accuracy: -inf
Trial complete.
	Time taken: 45.19088625907898 seconds.
